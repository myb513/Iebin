/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/bent/src/browser.js":
/*!******************************************!*\
  !*** ./node_modules/bent/src/browser.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* global fetch, btoa, Headers */\nconst core = __webpack_require__(/*! ./core */ \"./node_modules/bent/src/core.js\");\nclass StatusError extends Error {\n  constructor(res) {\n    for (var _len = arguments.length, params = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      params[_key - 1] = arguments[_key];\n    }\n    super(...params);\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, StatusError);\n    }\n    this.name = 'StatusError';\n    this.message = res.statusMessage;\n    this.statusCode = res.status;\n    this.res = res;\n    this.json = res.json.bind(res);\n    this.text = res.text.bind(res);\n    this.arrayBuffer = res.arrayBuffer.bind(res);\n    let buffer;\n    const get = () => {\n      if (!buffer) buffer = this.arrayBuffer();\n      return buffer;\n    };\n    Object.defineProperty(this, 'responseBody', {\n      get\n    });\n    // match Node.js headers object\n    this.headers = {};\n    for (const [key, value] of res.headers.entries()) {\n      this.headers[key.toLowerCase()] = value;\n    }\n  }\n}\nconst mkrequest = (statusCodes, method, encoding, headers, baseurl) => async function (_url, body) {\n  let _headers = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  _url = baseurl + (_url || '');\n  let parsed = new URL(_url);\n  if (!headers) headers = {};\n  if (parsed.username) {\n    headers.Authorization = 'Basic ' + btoa(parsed.username + ':' + parsed.password);\n    parsed = new URL(parsed.protocol + '//' + parsed.host + parsed.pathname + parsed.search);\n  }\n  if (parsed.protocol !== 'https:' && parsed.protocol !== 'http:') {\n    throw new Error(`Unknown protocol, ${parsed.protocol}`);\n  }\n  if (body) {\n    if (body instanceof ArrayBuffer || ArrayBuffer.isView(body) || typeof body === 'string') {\n      // noop\n    } else if (typeof body === 'object') {\n      body = JSON.stringify(body);\n      headers['Content-Type'] = 'application/json';\n    } else {\n      throw new Error('Unknown body type.');\n    }\n  }\n  _headers = new Headers({\n    ...(headers || {}),\n    ..._headers\n  });\n  const resp = await fetch(parsed, {\n    method,\n    headers: _headers,\n    body\n  });\n  resp.statusCode = resp.status;\n  if (!statusCodes.has(resp.status)) {\n    throw new StatusError(resp);\n  }\n  if (encoding === 'json') return resp.json();else if (encoding === 'buffer') return resp.arrayBuffer();else if (encoding === 'string') return resp.text();else return resp;\n};\nmodule.exports = core(mkrequest);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/bent/src/browser.js?");

/***/ }),

/***/ "./node_modules/bent/src/core.js":
/*!***************************************!*\
  !*** ./node_modules/bent/src/core.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst encodings = new Set(['json', 'buffer', 'string']);\nmodule.exports = mkrequest => function () {\n  const statusCodes = new Set();\n  let method;\n  let encoding;\n  let headers;\n  let baseurl = '';\n  for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n    args[_key] = arguments[_key];\n  }\n  args.forEach(arg => {\n    if (typeof arg === 'string') {\n      if (arg.toUpperCase() === arg) {\n        if (method) {\n          const msg = `Can't set method to ${arg}, already set to ${method}.`;\n          throw new Error(msg);\n        } else {\n          method = arg;\n        }\n      } else if (arg.startsWith('http:') || arg.startsWith('https:')) {\n        baseurl = arg;\n      } else {\n        if (encodings.has(arg)) {\n          encoding = arg;\n        } else {\n          throw new Error(`Unknown encoding, ${arg}`);\n        }\n      }\n    } else if (typeof arg === 'number') {\n      statusCodes.add(arg);\n    } else if (typeof arg === 'object') {\n      if (Array.isArray(arg) || arg instanceof Set) {\n        arg.forEach(code => statusCodes.add(code));\n      } else {\n        if (headers) {\n          throw new Error('Cannot set headers twice.');\n        }\n        headers = arg;\n      }\n    } else {\n      throw new Error(`Unknown type: ${typeof arg}`);\n    }\n  });\n  if (!method) method = 'GET';\n  if (statusCodes.size === 0) {\n    statusCodes.add(200);\n  }\n  return mkrequest(statusCodes, method, encoding, headers, baseurl);\n};\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/bent/src/core.js?");

/***/ }),

/***/ "./node_modules/cross-fetch/dist/browser-ponyfill.js":
/*!***********************************************************!*\
  !*** ./node_modules/cross-fetch/dist/browser-ponyfill.js ***!
  \***********************************************************/
/***/ (function(module, exports) {

eval("var global = typeof self !== 'undefined' ? self : this;\nvar __self__ = function () {\n  function F() {\n    this.fetch = false;\n    this.DOMException = global.DOMException;\n  }\n  F.prototype = global;\n  return new F();\n}();\n(function (self) {\n  var irrelevant = function (exports) {\n    var support = {\n      searchParams: 'URLSearchParams' in self,\n      iterable: 'Symbol' in self && 'iterator' in Symbol,\n      blob: 'FileReader' in self && 'Blob' in self && function () {\n        try {\n          new Blob();\n          return true;\n        } catch (e) {\n          return false;\n        }\n      }(),\n      formData: 'FormData' in self,\n      arrayBuffer: 'ArrayBuffer' in self\n    };\n    function isDataView(obj) {\n      return obj && DataView.prototype.isPrototypeOf(obj);\n    }\n    if (support.arrayBuffer) {\n      var viewClasses = ['[object Int8Array]', '[object Uint8Array]', '[object Uint8ClampedArray]', '[object Int16Array]', '[object Uint16Array]', '[object Int32Array]', '[object Uint32Array]', '[object Float32Array]', '[object Float64Array]'];\n      var isArrayBufferView = ArrayBuffer.isView || function (obj) {\n        return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1;\n      };\n    }\n    function normalizeName(name) {\n      if (typeof name !== 'string') {\n        name = String(name);\n      }\n      if (/[^a-z0-9\\-#$%&'*+.^_`|~]/i.test(name)) {\n        throw new TypeError('Invalid character in header field name');\n      }\n      return name.toLowerCase();\n    }\n    function normalizeValue(value) {\n      if (typeof value !== 'string') {\n        value = String(value);\n      }\n      return value;\n    }\n\n    // Build a destructive iterator for the value list\n    function iteratorFor(items) {\n      var iterator = {\n        next: function () {\n          var value = items.shift();\n          return {\n            done: value === undefined,\n            value: value\n          };\n        }\n      };\n      if (support.iterable) {\n        iterator[Symbol.iterator] = function () {\n          return iterator;\n        };\n      }\n      return iterator;\n    }\n    function Headers(headers) {\n      this.map = {};\n      if (headers instanceof Headers) {\n        headers.forEach(function (value, name) {\n          this.append(name, value);\n        }, this);\n      } else if (Array.isArray(headers)) {\n        headers.forEach(function (header) {\n          this.append(header[0], header[1]);\n        }, this);\n      } else if (headers) {\n        Object.getOwnPropertyNames(headers).forEach(function (name) {\n          this.append(name, headers[name]);\n        }, this);\n      }\n    }\n    Headers.prototype.append = function (name, value) {\n      name = normalizeName(name);\n      value = normalizeValue(value);\n      var oldValue = this.map[name];\n      this.map[name] = oldValue ? oldValue + ', ' + value : value;\n    };\n    Headers.prototype['delete'] = function (name) {\n      delete this.map[normalizeName(name)];\n    };\n    Headers.prototype.get = function (name) {\n      name = normalizeName(name);\n      return this.has(name) ? this.map[name] : null;\n    };\n    Headers.prototype.has = function (name) {\n      return this.map.hasOwnProperty(normalizeName(name));\n    };\n    Headers.prototype.set = function (name, value) {\n      this.map[normalizeName(name)] = normalizeValue(value);\n    };\n    Headers.prototype.forEach = function (callback, thisArg) {\n      for (var name in this.map) {\n        if (this.map.hasOwnProperty(name)) {\n          callback.call(thisArg, this.map[name], name, this);\n        }\n      }\n    };\n    Headers.prototype.keys = function () {\n      var items = [];\n      this.forEach(function (value, name) {\n        items.push(name);\n      });\n      return iteratorFor(items);\n    };\n    Headers.prototype.values = function () {\n      var items = [];\n      this.forEach(function (value) {\n        items.push(value);\n      });\n      return iteratorFor(items);\n    };\n    Headers.prototype.entries = function () {\n      var items = [];\n      this.forEach(function (value, name) {\n        items.push([name, value]);\n      });\n      return iteratorFor(items);\n    };\n    if (support.iterable) {\n      Headers.prototype[Symbol.iterator] = Headers.prototype.entries;\n    }\n    function consumed(body) {\n      if (body.bodyUsed) {\n        return Promise.reject(new TypeError('Already read'));\n      }\n      body.bodyUsed = true;\n    }\n    function fileReaderReady(reader) {\n      return new Promise(function (resolve, reject) {\n        reader.onload = function () {\n          resolve(reader.result);\n        };\n        reader.onerror = function () {\n          reject(reader.error);\n        };\n      });\n    }\n    function readBlobAsArrayBuffer(blob) {\n      var reader = new FileReader();\n      var promise = fileReaderReady(reader);\n      reader.readAsArrayBuffer(blob);\n      return promise;\n    }\n    function readBlobAsText(blob) {\n      var reader = new FileReader();\n      var promise = fileReaderReady(reader);\n      reader.readAsText(blob);\n      return promise;\n    }\n    function readArrayBufferAsText(buf) {\n      var view = new Uint8Array(buf);\n      var chars = new Array(view.length);\n      for (var i = 0; i < view.length; i++) {\n        chars[i] = String.fromCharCode(view[i]);\n      }\n      return chars.join('');\n    }\n    function bufferClone(buf) {\n      if (buf.slice) {\n        return buf.slice(0);\n      } else {\n        var view = new Uint8Array(buf.byteLength);\n        view.set(new Uint8Array(buf));\n        return view.buffer;\n      }\n    }\n    function Body() {\n      this.bodyUsed = false;\n      this._initBody = function (body) {\n        this._bodyInit = body;\n        if (!body) {\n          this._bodyText = '';\n        } else if (typeof body === 'string') {\n          this._bodyText = body;\n        } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n          this._bodyBlob = body;\n        } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n          this._bodyFormData = body;\n        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n          this._bodyText = body.toString();\n        } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n          this._bodyArrayBuffer = bufferClone(body.buffer);\n          // IE 10-11 can't handle a DataView body.\n          this._bodyInit = new Blob([this._bodyArrayBuffer]);\n        } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n          this._bodyArrayBuffer = bufferClone(body);\n        } else {\n          this._bodyText = body = Object.prototype.toString.call(body);\n        }\n        if (!this.headers.get('content-type')) {\n          if (typeof body === 'string') {\n            this.headers.set('content-type', 'text/plain;charset=UTF-8');\n          } else if (this._bodyBlob && this._bodyBlob.type) {\n            this.headers.set('content-type', this._bodyBlob.type);\n          } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n            this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8');\n          }\n        }\n      };\n      if (support.blob) {\n        this.blob = function () {\n          var rejected = consumed(this);\n          if (rejected) {\n            return rejected;\n          }\n          if (this._bodyBlob) {\n            return Promise.resolve(this._bodyBlob);\n          } else if (this._bodyArrayBuffer) {\n            return Promise.resolve(new Blob([this._bodyArrayBuffer]));\n          } else if (this._bodyFormData) {\n            throw new Error('could not read FormData body as blob');\n          } else {\n            return Promise.resolve(new Blob([this._bodyText]));\n          }\n        };\n        this.arrayBuffer = function () {\n          if (this._bodyArrayBuffer) {\n            return consumed(this) || Promise.resolve(this._bodyArrayBuffer);\n          } else {\n            return this.blob().then(readBlobAsArrayBuffer);\n          }\n        };\n      }\n      this.text = function () {\n        var rejected = consumed(this);\n        if (rejected) {\n          return rejected;\n        }\n        if (this._bodyBlob) {\n          return readBlobAsText(this._bodyBlob);\n        } else if (this._bodyArrayBuffer) {\n          return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer));\n        } else if (this._bodyFormData) {\n          throw new Error('could not read FormData body as text');\n        } else {\n          return Promise.resolve(this._bodyText);\n        }\n      };\n      if (support.formData) {\n        this.formData = function () {\n          return this.text().then(decode);\n        };\n      }\n      this.json = function () {\n        return this.text().then(JSON.parse);\n      };\n      return this;\n    }\n\n    // HTTP methods whose capitalization should be normalized\n    var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT'];\n    function normalizeMethod(method) {\n      var upcased = method.toUpperCase();\n      return methods.indexOf(upcased) > -1 ? upcased : method;\n    }\n    function Request(input, options) {\n      options = options || {};\n      var body = options.body;\n      if (input instanceof Request) {\n        if (input.bodyUsed) {\n          throw new TypeError('Already read');\n        }\n        this.url = input.url;\n        this.credentials = input.credentials;\n        if (!options.headers) {\n          this.headers = new Headers(input.headers);\n        }\n        this.method = input.method;\n        this.mode = input.mode;\n        this.signal = input.signal;\n        if (!body && input._bodyInit != null) {\n          body = input._bodyInit;\n          input.bodyUsed = true;\n        }\n      } else {\n        this.url = String(input);\n      }\n      this.credentials = options.credentials || this.credentials || 'same-origin';\n      if (options.headers || !this.headers) {\n        this.headers = new Headers(options.headers);\n      }\n      this.method = normalizeMethod(options.method || this.method || 'GET');\n      this.mode = options.mode || this.mode || null;\n      this.signal = options.signal || this.signal;\n      this.referrer = null;\n      if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n        throw new TypeError('Body not allowed for GET or HEAD requests');\n      }\n      this._initBody(body);\n    }\n    Request.prototype.clone = function () {\n      return new Request(this, {\n        body: this._bodyInit\n      });\n    };\n    function decode(body) {\n      var form = new FormData();\n      body.trim().split('&').forEach(function (bytes) {\n        if (bytes) {\n          var split = bytes.split('=');\n          var name = split.shift().replace(/\\+/g, ' ');\n          var value = split.join('=').replace(/\\+/g, ' ');\n          form.append(decodeURIComponent(name), decodeURIComponent(value));\n        }\n      });\n      return form;\n    }\n    function parseHeaders(rawHeaders) {\n      var headers = new Headers();\n      // Replace instances of \\r\\n and \\n followed by at least one space or horizontal tab with a space\n      // https://tools.ietf.org/html/rfc7230#section-3.2\n      var preProcessedHeaders = rawHeaders.replace(/\\r?\\n[\\t ]+/g, ' ');\n      preProcessedHeaders.split(/\\r?\\n/).forEach(function (line) {\n        var parts = line.split(':');\n        var key = parts.shift().trim();\n        if (key) {\n          var value = parts.join(':').trim();\n          headers.append(key, value);\n        }\n      });\n      return headers;\n    }\n    Body.call(Request.prototype);\n    function Response(bodyInit, options) {\n      if (!options) {\n        options = {};\n      }\n      this.type = 'default';\n      this.status = options.status === undefined ? 200 : options.status;\n      this.ok = this.status >= 200 && this.status < 300;\n      this.statusText = 'statusText' in options ? options.statusText : 'OK';\n      this.headers = new Headers(options.headers);\n      this.url = options.url || '';\n      this._initBody(bodyInit);\n    }\n    Body.call(Response.prototype);\n    Response.prototype.clone = function () {\n      return new Response(this._bodyInit, {\n        status: this.status,\n        statusText: this.statusText,\n        headers: new Headers(this.headers),\n        url: this.url\n      });\n    };\n    Response.error = function () {\n      var response = new Response(null, {\n        status: 0,\n        statusText: ''\n      });\n      response.type = 'error';\n      return response;\n    };\n    var redirectStatuses = [301, 302, 303, 307, 308];\n    Response.redirect = function (url, status) {\n      if (redirectStatuses.indexOf(status) === -1) {\n        throw new RangeError('Invalid status code');\n      }\n      return new Response(null, {\n        status: status,\n        headers: {\n          location: url\n        }\n      });\n    };\n    exports.DOMException = self.DOMException;\n    try {\n      new exports.DOMException();\n    } catch (err) {\n      exports.DOMException = function (message, name) {\n        this.message = message;\n        this.name = name;\n        var error = Error(message);\n        this.stack = error.stack;\n      };\n      exports.DOMException.prototype = Object.create(Error.prototype);\n      exports.DOMException.prototype.constructor = exports.DOMException;\n    }\n    function fetch(input, init) {\n      return new Promise(function (resolve, reject) {\n        var request = new Request(input, init);\n        if (request.signal && request.signal.aborted) {\n          return reject(new exports.DOMException('Aborted', 'AbortError'));\n        }\n        var xhr = new XMLHttpRequest();\n        function abortXhr() {\n          xhr.abort();\n        }\n        xhr.onload = function () {\n          var options = {\n            status: xhr.status,\n            statusText: xhr.statusText,\n            headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n          };\n          options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL');\n          var body = 'response' in xhr ? xhr.response : xhr.responseText;\n          resolve(new Response(body, options));\n        };\n        xhr.onerror = function () {\n          reject(new TypeError('Network request failed'));\n        };\n        xhr.ontimeout = function () {\n          reject(new TypeError('Network request failed'));\n        };\n        xhr.onabort = function () {\n          reject(new exports.DOMException('Aborted', 'AbortError'));\n        };\n        xhr.open(request.method, request.url, true);\n        if (request.credentials === 'include') {\n          xhr.withCredentials = true;\n        } else if (request.credentials === 'omit') {\n          xhr.withCredentials = false;\n        }\n        if ('responseType' in xhr && support.blob) {\n          xhr.responseType = 'blob';\n        }\n        request.headers.forEach(function (value, name) {\n          xhr.setRequestHeader(name, value);\n        });\n        if (request.signal) {\n          request.signal.addEventListener('abort', abortXhr);\n          xhr.onreadystatechange = function () {\n            // DONE (success or failure)\n            if (xhr.readyState === 4) {\n              request.signal.removeEventListener('abort', abortXhr);\n            }\n          };\n        }\n        xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit);\n      });\n    }\n    fetch.polyfill = true;\n    if (!self.fetch) {\n      self.fetch = fetch;\n      self.Headers = Headers;\n      self.Request = Request;\n      self.Response = Response;\n    }\n    exports.Headers = Headers;\n    exports.Request = Request;\n    exports.Response = Response;\n    exports.fetch = fetch;\n    Object.defineProperty(exports, '__esModule', {\n      value: true\n    });\n    return exports;\n  }({});\n})(__self__);\n__self__.fetch.ponyfill = true;\n// Remove \"polyfill\" property added by whatwg-fetch\ndelete __self__.fetch.polyfill;\n// Choose between native implementation (global) or custom implementation (__self__)\n// var ctx = global.fetch ? global : __self__;\nvar ctx = __self__; // this line disable service worker support temporarily\nexports = ctx.fetch; // To enable: import fetch from 'cross-fetch'\nexports[\"default\"] = ctx.fetch; // For TypeScript consumers without esModuleInterop.\nexports.fetch = ctx.fetch; // To enable: import {fetch} from 'cross-fetch'\nexports.Headers = ctx.Headers;\nexports.Request = ctx.Request;\nexports.Response = ctx.Response;\nmodule.exports = exports;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/cross-fetch/dist/browser-ponyfill.js?");

/***/ }),

/***/ "./node_modules/form-data/lib/browser.js":
/*!***********************************************!*\
  !*** ./node_modules/form-data/lib/browser.js ***!
  \***********************************************/
/***/ ((module) => {

eval("/* eslint-env browser */\nmodule.exports = typeof self == 'object' ? self.FormData : window.FormData;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/form-data/lib/browser.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ActivityReceivedEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ActivityReceivedEventArgs),\n/* harmony export */   \"AudioConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioConfig),\n/* harmony export */   \"AudioFormatTag\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioFormatTag),\n/* harmony export */   \"AudioInputStream\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioInputStream),\n/* harmony export */   \"AudioOutputStream\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioOutputStream),\n/* harmony export */   \"AudioStreamFormat\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamFormat),\n/* harmony export */   \"AutoDetectSourceLanguageConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AutoDetectSourceLanguageConfig),\n/* harmony export */   \"AutoDetectSourceLanguageResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.AutoDetectSourceLanguageResult),\n/* harmony export */   \"BaseAudioPlayer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.BaseAudioPlayer),\n/* harmony export */   \"BotFrameworkConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.BotFrameworkConfig),\n/* harmony export */   \"CancellationDetails\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationDetails),\n/* harmony export */   \"CancellationDetailsBase\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationDetailsBase),\n/* harmony export */   \"CancellationErrorCode\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode),\n/* harmony export */   \"CancellationReason\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason),\n/* harmony export */   \"Connection\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Connection),\n/* harmony export */   \"ConnectionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEventArgs),\n/* harmony export */   \"ConnectionMessage\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessage),\n/* harmony export */   \"ConnectionMessageEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessageEventArgs),\n/* harmony export */   \"Conversation\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Conversation),\n/* harmony export */   \"ConversationExpirationEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationExpirationEventArgs),\n/* harmony export */   \"ConversationParticipantsChangedEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationParticipantsChangedEventArgs),\n/* harmony export */   \"ConversationTranscriber\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranscriber),\n/* harmony export */   \"ConversationTranscriptionCanceledEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranscriptionCanceledEventArgs),\n/* harmony export */   \"ConversationTranscriptionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranscriptionEventArgs),\n/* harmony export */   \"ConversationTranslationCanceledEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationCanceledEventArgs),\n/* harmony export */   \"ConversationTranslationEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationEventArgs),\n/* harmony export */   \"ConversationTranslationResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslationResult),\n/* harmony export */   \"ConversationTranslator\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ConversationTranslator),\n/* harmony export */   \"CustomCommandsConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CustomCommandsConfig),\n/* harmony export */   \"Diagnostics\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Diagnostics),\n/* harmony export */   \"DialogServiceConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.DialogServiceConfig),\n/* harmony export */   \"DialogServiceConnector\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.DialogServiceConnector),\n/* harmony export */   \"IntentRecognitionCanceledEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognitionCanceledEventArgs),\n/* harmony export */   \"IntentRecognitionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognitionEventArgs),\n/* harmony export */   \"IntentRecognitionResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognitionResult),\n/* harmony export */   \"IntentRecognizer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentRecognizer),\n/* harmony export */   \"KeywordRecognitionModel\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.KeywordRecognitionModel),\n/* harmony export */   \"LanguageIdMode\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode),\n/* harmony export */   \"LanguageIdPriority\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LanguageIdPriority),\n/* harmony export */   \"LanguageUnderstandingModel\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LanguageUnderstandingModel),\n/* harmony export */   \"LogLevel\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.LogLevel),\n/* harmony export */   \"NoMatchDetails\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.NoMatchDetails),\n/* harmony export */   \"NoMatchReason\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.NoMatchReason),\n/* harmony export */   \"OutputFormat\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.OutputFormat),\n/* harmony export */   \"Participant\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Participant),\n/* harmony export */   \"ParticipantChangedReason\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ParticipantChangedReason),\n/* harmony export */   \"PhraseListGrammar\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PhraseListGrammar),\n/* harmony export */   \"ProfanityOption\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ProfanityOption),\n/* harmony export */   \"PronunciationAssessmentConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentConfig),\n/* harmony export */   \"PronunciationAssessmentGradingSystem\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentGradingSystem),\n/* harmony export */   \"PronunciationAssessmentGranularity\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentGranularity),\n/* harmony export */   \"PronunciationAssessmentResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PronunciationAssessmentResult),\n/* harmony export */   \"PropertyCollection\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection),\n/* harmony export */   \"PropertyId\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId),\n/* harmony export */   \"PullAudioInputStream\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PullAudioInputStream),\n/* harmony export */   \"PullAudioInputStreamCallback\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PullAudioInputStreamCallback),\n/* harmony export */   \"PullAudioOutputStream\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PullAudioOutputStream),\n/* harmony export */   \"PushAudioInputStream\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PushAudioInputStream),\n/* harmony export */   \"PushAudioOutputStream\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PushAudioOutputStream),\n/* harmony export */   \"PushAudioOutputStreamCallback\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PushAudioOutputStreamCallback),\n/* harmony export */   \"RecognitionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionEventArgs),\n/* harmony export */   \"RecognitionResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionResult),\n/* harmony export */   \"Recognizer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Recognizer),\n/* harmony export */   \"ResultReason\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ResultReason),\n/* harmony export */   \"ServiceEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ServiceEventArgs),\n/* harmony export */   \"ServicePropertyChannel\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.ServicePropertyChannel),\n/* harmony export */   \"SessionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SessionEventArgs),\n/* harmony export */   \"SourceLanguageConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SourceLanguageConfig),\n/* harmony export */   \"SpeakerAudioDestination\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerAudioDestination),\n/* harmony export */   \"SpeakerIdentificationModel\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerIdentificationModel),\n/* harmony export */   \"SpeakerRecognitionCancellationDetails\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionCancellationDetails),\n/* harmony export */   \"SpeakerRecognitionResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionResult),\n/* harmony export */   \"SpeakerRecognitionResultType\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognitionResultType),\n/* harmony export */   \"SpeakerRecognizer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerRecognizer),\n/* harmony export */   \"SpeakerVerificationModel\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerVerificationModel),\n/* harmony export */   \"SpeechConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechConfig),\n/* harmony export */   \"SpeechConfigImpl\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechConfigImpl),\n/* harmony export */   \"SpeechRecognitionCanceledEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionCanceledEventArgs),\n/* harmony export */   \"SpeechRecognitionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionEventArgs),\n/* harmony export */   \"SpeechRecognitionResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognitionResult),\n/* harmony export */   \"SpeechRecognizer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechRecognizer),\n/* harmony export */   \"SpeechSynthesisBookmarkEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisBookmarkEventArgs),\n/* harmony export */   \"SpeechSynthesisBoundaryType\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisBoundaryType),\n/* harmony export */   \"SpeechSynthesisEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisEventArgs),\n/* harmony export */   \"SpeechSynthesisOutputFormat\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisOutputFormat),\n/* harmony export */   \"SpeechSynthesisResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisResult),\n/* harmony export */   \"SpeechSynthesisVisemeEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisVisemeEventArgs),\n/* harmony export */   \"SpeechSynthesisWordBoundaryEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisWordBoundaryEventArgs),\n/* harmony export */   \"SpeechSynthesizer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesizer),\n/* harmony export */   \"SpeechTranslationConfig\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechTranslationConfig),\n/* harmony export */   \"SpeechTranslationConfigImpl\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechTranslationConfigImpl),\n/* harmony export */   \"SynthesisResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisResult),\n/* harmony export */   \"SynthesisVoicesResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisVoicesResult),\n/* harmony export */   \"TranslationRecognitionCanceledEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognitionCanceledEventArgs),\n/* harmony export */   \"TranslationRecognitionEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognitionEventArgs),\n/* harmony export */   \"TranslationRecognitionResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognitionResult),\n/* harmony export */   \"TranslationRecognizer\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationRecognizer),\n/* harmony export */   \"TranslationSynthesisEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationSynthesisEventArgs),\n/* harmony export */   \"TranslationSynthesisResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationSynthesisResult),\n/* harmony export */   \"Translations\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.Translations),\n/* harmony export */   \"TurnStatusReceivedEventArgs\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.TurnStatusReceivedEventArgs),\n/* harmony export */   \"User\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.User),\n/* harmony export */   \"VoiceInfo\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceInfo),\n/* harmony export */   \"VoiceProfile\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfile),\n/* harmony export */   \"VoiceProfileCancellationDetails\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileCancellationDetails),\n/* harmony export */   \"VoiceProfileClient\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileClient),\n/* harmony export */   \"VoiceProfileEnrollmentCancellationDetails\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileEnrollmentCancellationDetails),\n/* harmony export */   \"VoiceProfileEnrollmentResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileEnrollmentResult),\n/* harmony export */   \"VoiceProfilePhraseResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfilePhraseResult),\n/* harmony export */   \"VoiceProfileResult\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileResult),\n/* harmony export */   \"VoiceProfileType\": () => (/* reexport safe */ _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfileType)\n/* harmony export */ });\n/* harmony import */ var _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./src/common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js\");\n/* harmony import */ var _src_common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./src/common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _src_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./src/sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n// Common.Storage.SetLocalStorage(new Common.Browser.LocalStorage());\n// Common.Storage.SetSessionStorage(new Common.Browser.SessionStorage());\n_src_common_Exports__WEBPACK_IMPORTED_MODULE_0__.Events.instance.attachConsoleListener(new _src_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.ConsoleLoggingListener());\n// Speech SDK API\n\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CertCheckAgent\": () => (/* binding */ CertCheckAgent)\n/* harmony export */ });\n/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tls */ \"?14d6\");\n/* harmony import */ var tls__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(tls__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../external/ocsp/ocsp */ \"?2454\");\n/* harmony import */ var _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/OCSPEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! agent-base */ \"?6483\");\n/* harmony import */ var agent_base__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(agent_base__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! async-disk-cache */ \"?bed2\");\n/* harmony import */ var async_disk_cache__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(async_disk_cache__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! https-proxy-agent */ \"?72ad\");\n/* harmony import */ var https_proxy_agent__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(https_proxy_agent__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! net */ \"?a1bf\");\n/* harmony import */ var net__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(net__WEBPACK_IMPORTED_MODULE_5__);\n/* eslint-disable import/order */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-ignore\n\n\n\n\nclass CertCheckAgent {\n  constructor(proxyInfo) {\n    if (!!proxyInfo) {\n      this.privProxyInfo = proxyInfo;\n    }\n    // Initialize this here to allow tests to set the env variable before the cache is constructed.\n    if (!CertCheckAgent.privDiskCache) {\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment, @typescript-eslint/no-unsafe-call\n      CertCheckAgent.privDiskCache = new (async_disk_cache__WEBPACK_IMPORTED_MODULE_3___default())(\"microsoft-cognitiveservices-speech-sdk-cache\", {\n        supportBuffer: true,\n        location: typeof process !== \"undefined\" && !!process.env.SPEECH_OCSP_CACHE_ROOT ? process.env.SPEECH_OCSP_CACHE_ROOT : undefined\n      });\n    }\n  }\n  // Test hook to force the disk cache to be recreated.\n  static forceReinitDiskCache() {\n    CertCheckAgent.privDiskCache = undefined;\n    CertCheckAgent.privMemCache = {};\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  GetAgent(disableStapling) {\n    // eslint-disable-next-line @typescript-eslint/unbound-method\n    const agent = new (agent_base__WEBPACK_IMPORTED_MODULE_2___default().Agent)(this.CreateConnection);\n    if (this.privProxyInfo !== undefined && this.privProxyInfo.HostName !== undefined && this.privProxyInfo.Port > 0) {\n      const proxyName = \"privProxyInfo\";\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n      agent[proxyName] = this.privProxyInfo;\n    }\n    return agent;\n  }\n  static GetProxyAgent(proxyInfo) {\n    const httpProxyOptions = {\n      host: proxyInfo.HostName,\n      port: proxyInfo.Port\n    };\n    if (!!proxyInfo.UserName) {\n      httpProxyOptions.headers = {\n        \"Proxy-Authentication\": \"Basic \" + new Buffer(`${proxyInfo.UserName}:${proxyInfo.Password === undefined ? \"\" : proxyInfo.Password}`).toString(\"base64\")\n      };\n    } else {\n      httpProxyOptions.headers = {};\n    }\n    httpProxyOptions.headers.requestOCSP = \"true\";\n    const httpProxyAgent = new (https_proxy_agent__WEBPACK_IMPORTED_MODULE_4___default())(httpProxyOptions);\n    return httpProxyAgent;\n  }\n  static OCSPCheck(socketPromise, proxyInfo) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let ocspRequest;\n      let stapling;\n      let resolved = false;\n      const socket = yield socketPromise;\n      socket.cork();\n      const tlsSocket = socket;\n      return new Promise((resolve, reject) => {\n        socket.on(\"OCSPResponse\", data => {\n          if (!!data) {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPStapleReceivedEvent());\n            stapling = data;\n          }\n        });\n        socket.on(\"error\", error => {\n          if (!resolved) {\n            resolved = true;\n            socket.destroy();\n            reject(error);\n          }\n        });\n        // eslint-disable-next-line @typescript-eslint/no-misused-promises, @typescript-eslint/explicit-function-return-type\n        tlsSocket.on(\"secure\", () => __awaiter(this, void 0, void 0, function* () {\n          const peer = tlsSocket.getPeerCertificate(true);\n          try {\n            const issuer = yield this.GetIssuer(peer);\n            // We always need a request to verify the response.\n            ocspRequest = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.request.generate(peer.raw, issuer.raw);\n            // Do we have a result for this certificate in our memory cache?\n            const sig = ocspRequest.id.toString(\"hex\");\n            // Stapled response trumps cached response.\n            if (!stapling) {\n              const cacheEntry = yield CertCheckAgent.GetResponseFromCache(sig, ocspRequest, proxyInfo);\n              stapling = cacheEntry;\n            }\n            yield this.VerifyOCSPResponse(stapling, ocspRequest, proxyInfo);\n            socket.uncork();\n            resolved = true;\n            resolve(socket);\n          } catch (e) {\n            socket.destroy();\n            resolved = true;\n            reject(e);\n          }\n        }));\n      });\n    });\n  }\n  static GetIssuer(peer) {\n    if (peer.issuerCertificate) {\n      return Promise.resolve(peer.issuerCertificate);\n    }\n    return new Promise((resolve, reject) => {\n      const ocspAgent = new _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.Agent({});\n      ocspAgent.fetchIssuer(peer, null, (error, value) => {\n        if (!!error) {\n          reject(error);\n          return;\n        }\n        resolve(value);\n      });\n    });\n  }\n  static GetResponseFromCache(signature, ocspRequest, proxyInfo) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let cachedResponse = CertCheckAgent.privMemCache[signature];\n      if (!!cachedResponse) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPMemoryCacheHitEvent(signature));\n      }\n      // Do we have a result for this certificate on disk in %TMP%?\n      if (!cachedResponse) {\n        try {\n          // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n          const diskCacheResponse = yield CertCheckAgent.privDiskCache.get(signature);\n          if (!!diskCacheResponse.isCached) {\n            CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPDiskCacheHitEvent(signature));\n            CertCheckAgent.StoreMemoryCacheEntry(signature, diskCacheResponse.value);\n            cachedResponse = diskCacheResponse.value;\n          }\n        } catch (error) {\n          cachedResponse = null;\n        }\n      }\n      if (!cachedResponse) {\n        return cachedResponse;\n      }\n      try {\n        const cachedOcspResponse = _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.utils.parseResponse(cachedResponse);\n        const responseValue = cachedOcspResponse.value;\n        const tbsData = responseValue.tbsResponseData;\n        if (tbsData.responses.length < 1) {\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheFetchErrorEvent(signature, \"Not enough data in cached response\"));\n          return;\n        }\n        const cachedStartTime = tbsData.responses[0].thisUpdate;\n        const cachedNextTime = tbsData.responses[0].nextUpdate;\n        if (cachedNextTime < Date.now() + this.testTimeOffset - 60000) {\n          // Cached entry has expired.\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheEntryExpiredEvent(signature, cachedNextTime));\n          cachedResponse = null;\n        } else {\n          // If we're within one day of the next update, or 50% of the way through the validity period,\n          // background an update to the cache.\n          const minUpdate = Math.min(24 * 60 * 60 * 1000, (cachedNextTime - cachedStartTime) / 2);\n          if (cachedNextTime - (Date.now() + this.testTimeOffset) < minUpdate) {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheEntryNeedsRefreshEvent(signature, cachedStartTime, cachedNextTime));\n            this.UpdateCache(ocspRequest, proxyInfo).catch(error => {\n              // Well, not much we can do here.\n              this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheUpdateErrorEvent(signature, error.toString()));\n            });\n          } else {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheHitEvent(signature, cachedStartTime, cachedNextTime));\n          }\n        }\n      } catch (error) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheFetchErrorEvent(signature, error));\n        cachedResponse = null;\n      }\n      if (!cachedResponse) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheMissEvent(signature));\n      }\n      return cachedResponse;\n    });\n  }\n  static VerifyOCSPResponse(cacheValue, ocspRequest, proxyInfo) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let ocspResponse = cacheValue;\n      // Do we have a valid response?\n      if (!ocspResponse) {\n        ocspResponse = yield CertCheckAgent.GetOCSPResponse(ocspRequest, proxyInfo);\n      }\n      return new Promise((resolve, reject) => {\n        _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.verify({\n          request: ocspRequest,\n          response: ocspResponse\n        }, error => {\n          if (!!error) {\n            CertCheckAgent.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPVerificationFailedEvent(ocspRequest.id.toString(\"hex\"), error));\n            // Bad Cached Value? One more try without the cache.\n            if (!!cacheValue) {\n              this.VerifyOCSPResponse(null, ocspRequest, proxyInfo).then(() => {\n                resolve();\n              }, error => {\n                reject(error);\n              });\n            } else {\n              reject(error);\n            }\n          } else {\n            if (!cacheValue) {\n              CertCheckAgent.StoreCacheEntry(ocspRequest.id.toString(\"hex\"), ocspResponse);\n            }\n            resolve();\n          }\n        });\n      });\n    });\n  }\n  static UpdateCache(req, proxyInfo) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const signature = req.id.toString(\"hex\");\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheUpdateNeededEvent(signature));\n      const rawResponse = yield this.GetOCSPResponse(req, proxyInfo);\n      this.StoreCacheEntry(signature, rawResponse);\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPCacheUpdateCompleteEvent(req.id.toString(\"hex\")));\n    });\n  }\n  static StoreCacheEntry(sig, rawResponse) {\n    this.StoreMemoryCacheEntry(sig, rawResponse);\n    this.StoreDiskCacheEntry(sig, rawResponse);\n  }\n  static StoreMemoryCacheEntry(sig, rawResponse) {\n    this.privMemCache[sig] = rawResponse;\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPMemoryCacheStoreEvent(sig));\n  }\n  static StoreDiskCacheEntry(sig, rawResponse) {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access, @typescript-eslint/no-unsafe-call\n    this.privDiskCache.set(sig, rawResponse).then(() => {\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPDiskCacheStoreEvent(sig));\n    });\n  }\n  static GetOCSPResponse(req, proxyInfo) {\n    const ocspMethod = \"1.3.6.1.5.5.7.48.1\";\n    let options = {};\n    if (!!proxyInfo) {\n      const agent = CertCheckAgent.GetProxyAgent(proxyInfo);\n      options.agent = agent;\n    }\n    return new Promise((resolve, reject) => {\n      _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.utils.getAuthorityInfo(req.cert, ocspMethod, (error, uri) => {\n        if (error) {\n          reject(error);\n          return;\n        }\n        const url = new URL(uri);\n        options = Object.assign(Object.assign({}, options), {\n          host: url.host,\n          protocol: url.protocol,\n          port: url.port,\n          path: url.pathname,\n          hostname: url.host\n        });\n        _external_ocsp_ocsp__WEBPACK_IMPORTED_MODULE_1__.utils.getResponse(options, req.data, (error, raw) => {\n          if (error) {\n            reject(error);\n            return;\n          }\n          const certID = req.certID;\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.OCSPResponseRetrievedEvent(certID.toString(\"hex\")));\n          resolve(raw);\n        });\n      });\n    });\n  }\n  static onEvent(event) {\n    _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Events.instance.onEvent(event);\n  }\n  CreateConnection(request, options) {\n    const enableOCSP = typeof process !== \"undefined\" && process.env.NODE_TLS_REJECT_UNAUTHORIZED !== \"0\" && process.env.SPEECH_CONDUCT_OCSP_CHECK !== \"0\" && options.secureEndpoint;\n    let socketPromise;\n    options = Object.assign(Object.assign({}, options), {\n      requestOCSP: !CertCheckAgent.forceDisableOCSPStapling,\n      servername: options.host\n    });\n    if (!!this.privProxyInfo) {\n      const httpProxyAgent = CertCheckAgent.GetProxyAgent(this.privProxyInfo);\n      const baseAgent = httpProxyAgent;\n      socketPromise = new Promise((resolve, reject) => {\n        baseAgent.callback(request, options, (error, socket) => {\n          if (!!error) {\n            reject(error);\n          } else {\n            resolve(socket);\n          }\n        });\n      });\n    } else {\n      if (!!options.secureEndpoint) {\n        socketPromise = Promise.resolve(tls__WEBPACK_IMPORTED_MODULE_0__.connect(options));\n      } else {\n        socketPromise = Promise.resolve(net__WEBPACK_IMPORTED_MODULE_5__.connect(options));\n      }\n    }\n    if (!!enableOCSP) {\n      return CertCheckAgent.OCSPCheck(socketPromise, this.privProxyInfo);\n    } else {\n      return socketPromise;\n    }\n  }\n}\n// Test hook to enable forcing expiration / refresh to happen.\nCertCheckAgent.testTimeOffset = 0;\n// Test hook to disable stapling for cache testing.\nCertCheckAgent.forceDisableOCSPStapling = false;\n// An in memory cache for recived responses.\nCertCheckAgent.privMemCache = {};\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConsoleLoggingListener\": () => (/* binding */ ConsoleLoggingListener)\n/* harmony export */ });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"?0825\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/LogLevel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass ConsoleLoggingListener {\n  constructor() {\n    let logLevelFilter = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.None;\n    this.privLogPath = undefined;\n    this.privLogLevelFilter = logLevelFilter;\n  }\n  set logPath(path) {\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__.openSync, \"\\nFile System access not available\");\n    this.privLogPath = path;\n  }\n  onEvent(event) {\n    if (event.eventType >= this.privLogLevelFilter) {\n      const log = this.toString(event);\n      if (!!this.privLogPath) {\n        fs__WEBPACK_IMPORTED_MODULE_0__.writeFileSync(this.privLogPath, log + \"\\n\", {\n          flag: \"a+\"\n        });\n      }\n      switch (event.eventType) {\n        case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Debug:\n          // eslint-disable-next-line no-console\n          console.debug(log);\n          break;\n        case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Info:\n          // eslint-disable-next-line no-console\n          console.info(log);\n          break;\n        case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Warning:\n          // eslint-disable-next-line no-console\n          console.warn(log);\n          break;\n        case _sdk_LogLevel__WEBPACK_IMPORTED_MODULE_1__.EventType.Error:\n          // eslint-disable-next-line no-console\n          console.error(log);\n          break;\n        default:\n          // eslint-disable-next-line no-console\n          console.log(log);\n          break;\n      }\n    }\n  }\n  toString(event) {\n    const logFragments = [`${event.eventTime}`, `${event.name}`];\n    const e = event;\n    for (const prop in e) {\n      if (prop && event.hasOwnProperty(prop) && prop !== \"eventTime\" && prop !== \"eventType\" && prop !== \"eventId\" && prop !== \"name\" && prop !== \"constructor\") {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        const value = e[prop];\n        let valueToLog = \"<NULL>\";\n        if (value !== undefined && value !== null) {\n          if (typeof value === \"number\" || typeof value === \"string\") {\n            valueToLog = value.toString();\n          } else {\n            valueToLog = JSON.stringify(value);\n          }\n        }\n        logFragments.push(`${prop}: ${valueToLog}`);\n      }\n    }\n    return logFragments.join(\" | \");\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FileAudioSource\": () => (/* binding */ FileAudioSource)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\nclass FileAudioSource {\n  constructor(file, filename, audioSourceId) {\n    this.privStreams = {};\n    this.privHeaderEnd = 44;\n    this.privId = audioSourceId ? audioSourceId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n    this.privSource = file;\n    if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && this.privSource instanceof Blob) {\n      this.privFilename = file.name;\n    } else {\n      this.privFilename = filename || \"unknown.wav\";\n    }\n    // Read the header.\n    this.privAudioFormatPromise = this.readHeader();\n  }\n  get format() {\n    return this.privAudioFormatPromise;\n  }\n  get blob() {\n    return Promise.resolve(this.privSource);\n  }\n  turnOn() {\n    if (this.privFilename.lastIndexOf(\".wav\") !== this.privFilename.length - 4) {\n      const errorMsg = this.privFilename + \" is not supported. Only WAVE files are allowed at the moment.\";\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceErrorEvent(errorMsg, \"\"));\n      return Promise.reject(errorMsg);\n    }\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceInitializingEvent(this.privId)); // no stream id\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceReadyEvent(this.privId));\n    return;\n  }\n  id() {\n    return this.privId;\n  }\n  attach(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n      const stream = yield this.upload(audioNodeId);\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n      return Promise.resolve({\n        detach: () => __awaiter(this, void 0, void 0, function* () {\n          stream.readEnded();\n          delete this.privStreams[audioNodeId];\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n          yield this.turnOff();\n        }),\n        id: () => audioNodeId,\n        read: () => stream.read()\n      });\n    });\n  }\n  detach(audioNodeId) {\n    if (audioNodeId && this.privStreams[audioNodeId]) {\n      this.privStreams[audioNodeId].close();\n      delete this.privStreams[audioNodeId];\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n  }\n  turnOff() {\n    for (const streamId in this.privStreams) {\n      if (streamId) {\n        const stream = this.privStreams[streamId];\n        if (stream && !stream.isClosed) {\n          stream.close();\n        }\n      }\n    }\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioSourceOffEvent(this.privId)); // no stream now\n    return Promise.resolve();\n  }\n  get events() {\n    return this.privEvents;\n  }\n  get deviceInfo() {\n    return this.privAudioFormatPromise.then(result => Promise.resolve({\n      bitspersample: result.bitsPerSample,\n      channelcount: result.channels,\n      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.connectivity.Unknown,\n      manufacturer: \"Speech SDK\",\n      model: \"File\",\n      samplerate: result.samplesPerSec,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.type.File\n    }));\n  }\n  readHeader() {\n    // Read the wave header.\n    const maxHeaderSize = 512;\n    const header = this.privSource.slice(0, maxHeaderSize);\n    const headerResult = new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Deferred();\n    const processHeader = header => {\n      const view = new DataView(header);\n      const getWord = index => String.fromCharCode(view.getUint8(index), view.getUint8(index + 1), view.getUint8(index + 2), view.getUint8(index + 3));\n      // RIFF 4 bytes.\n      if (\"RIFF\" !== getWord(0)) {\n        headerResult.reject(\"Invalid WAV header in file, RIFF was not found\");\n        return;\n      }\n      // length, 4 bytes\n      // RIFF Type & fmt 8 bytes\n      if (\"WAVE\" !== getWord(8) || \"fmt \" !== getWord(12)) {\n        headerResult.reject(\"Invalid WAV header in file, WAVEfmt was not found\");\n        return;\n      }\n      const formatSize = view.getInt32(16, true);\n      const channelCount = view.getUint16(22, true);\n      const sampleRate = view.getUint32(24, true);\n      const bitsPerSample = view.getUint16(34, true);\n      // Confirm if header is 44 bytes long.\n      let pos = 36 + Math.max(formatSize - 16, 0);\n      for (; getWord(pos) !== \"data\"; pos += 2) {\n        if (pos > maxHeaderSize - 8) {\n          headerResult.reject(\"Invalid WAV header in file, data block was not found\");\n          return;\n        }\n      }\n      this.privHeaderEnd = pos + 8;\n      headerResult.resolve(_sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_5__.AudioStreamFormat.getWaveFormatPCM(sampleRate, bitsPerSample, channelCount));\n    };\n    if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && header instanceof Blob) {\n      const reader = new FileReader();\n      reader.onload = event => {\n        const header = event.target.result;\n        processHeader(header);\n      };\n      reader.readAsArrayBuffer(header);\n    } else {\n      const h = header;\n      processHeader(h.buffer.slice(h.byteOffset, h.byteOffset + h.byteLength));\n    }\n    return headerResult.promise;\n  }\n  upload(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const onerror = error => {\n        const errorMsg = `Error occurred while processing '${this.privFilename}'. ${error}`;\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.AudioStreamNodeErrorEvent(this.privId, audioNodeId, errorMsg));\n        throw new Error(errorMsg);\n      };\n      try {\n        yield this.turnOn();\n        const format = yield this.privAudioFormatPromise;\n        const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.ChunkedArrayBufferStream(format.avgBytesPerSec / 10, audioNodeId);\n        this.privStreams[audioNodeId] = stream;\n        const chunk = this.privSource.slice(this.privHeaderEnd);\n        const processFile = buff => {\n          if (stream.isClosed) {\n            return; // output stream was closed (somebody called TurnOff). We're done here.\n          }\n\n          stream.writeStreamChunk({\n            buffer: buff,\n            isEnd: false,\n            timeReceived: Date.now()\n          });\n          stream.close();\n        };\n        if (typeof window !== \"undefined\" && typeof Blob !== \"undefined\" && chunk instanceof Blob) {\n          const reader = new FileReader();\n          reader.onerror = ev => onerror(ev.toString());\n          reader.onload = event => {\n            const fileBuffer = event.target.result;\n            processFile(fileBuffer);\n          };\n          reader.readAsArrayBuffer(chunk);\n        } else {\n          const c = chunk;\n          processFile(c.buffer.slice(c.byteOffset, c.byteOffset + c.byteLength));\n        }\n        return stream;\n      } catch (e) {\n        onerror(e);\n      }\n    });\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Events.instance.onEvent(event);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioWorkletSourceURLPropertyName\": () => (/* binding */ AudioWorkletSourceURLPropertyName),\n/* harmony export */   \"MicAudioSource\": () => (/* binding */ MicAudioSource)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\nconst AudioWorkletSourceURLPropertyName = \"MICROPHONE-WorkletSourceUrl\";\nclass MicAudioSource {\n  constructor(privRecorder, deviceId, audioSourceId, mediaStream) {\n    this.privRecorder = privRecorder;\n    this.deviceId = deviceId;\n    this.privStreams = {};\n    this.privOutputChunkSize = MicAudioSource.AUDIOFORMAT.avgBytesPerSec / 10;\n    this.privId = audioSourceId ? audioSourceId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n    this.privMediaStream = mediaStream || null;\n    this.privIsClosing = false;\n  }\n  get format() {\n    return Promise.resolve(MicAudioSource.AUDIOFORMAT);\n  }\n  get blob() {\n    return Promise.reject(\"Not implemented for Mic input\");\n  }\n  turnOn() {\n    if (this.privInitializeDeferral) {\n      return this.privInitializeDeferral.promise;\n    }\n    this.privInitializeDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n    try {\n      this.createAudioContext();\n    } catch (error) {\n      if (error instanceof Error) {\n        const typedError = error;\n        this.privInitializeDeferral.reject(typedError.name + \": \" + typedError.message);\n      } else {\n        this.privInitializeDeferral.reject(error);\n      }\n      return this.privInitializeDeferral.promise;\n    }\n    const nav = window.navigator;\n    let getUserMedia =\n    // eslint-disable-next-line\n    nav.getUserMedia || nav.webkitGetUserMedia || nav.mozGetUserMedia || nav.msGetUserMedia;\n    if (!!nav.mediaDevices) {\n      getUserMedia = (constraints, successCallback, errorCallback) => {\n        nav.mediaDevices.getUserMedia(constraints).then(successCallback).catch(errorCallback);\n      };\n    }\n    if (!getUserMedia) {\n      const errorMsg = \"Browser does not support getUserMedia.\";\n      this.privInitializeDeferral.reject(errorMsg);\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceErrorEvent(errorMsg, \"\")); // mic initialized error - no streamid at this point\n    } else {\n      const next = () => {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceInitializingEvent(this.privId)); // no stream id\n        if (this.privMediaStream && this.privMediaStream.active) {\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceReadyEvent(this.privId));\n          this.privInitializeDeferral.resolve();\n        } else {\n          getUserMedia({\n            audio: this.deviceId ? {\n              deviceId: this.deviceId\n            } : true,\n            video: false\n          }, mediaStream => {\n            this.privMediaStream = mediaStream;\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceReadyEvent(this.privId));\n            this.privInitializeDeferral.resolve();\n          }, error => {\n            const errorMsg = `Error occurred during microphone initialization: ${error}`;\n            this.privInitializeDeferral.reject(errorMsg);\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceErrorEvent(this.privId, errorMsg));\n          });\n        }\n      };\n      if (this.privContext.state === \"suspended\") {\n        // NOTE: On iOS, the Web Audio API requires sounds to be triggered from an explicit user action.\n        // https://github.com/WebAudio/web-audio-api/issues/790\n        this.privContext.resume().then(next).catch(reason => {\n          this.privInitializeDeferral.reject(`Failed to initialize audio context: ${reason}`);\n        });\n      } else {\n        next();\n      }\n    }\n    return this.privInitializeDeferral.promise;\n  }\n  id() {\n    return this.privId;\n  }\n  attach(audioNodeId) {\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n    return this.listen(audioNodeId).then(stream => {\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n      return {\n        detach: () => __awaiter(this, void 0, void 0, function* () {\n          stream.readEnded();\n          delete this.privStreams[audioNodeId];\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n          return this.turnOff();\n        }),\n        id: () => audioNodeId,\n        read: () => stream.read()\n      };\n    });\n  }\n  detach(audioNodeId) {\n    if (audioNodeId && this.privStreams[audioNodeId]) {\n      this.privStreams[audioNodeId].close();\n      delete this.privStreams[audioNodeId];\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n    }\n  }\n  turnOff() {\n    return __awaiter(this, void 0, void 0, function* () {\n      for (const streamId in this.privStreams) {\n        if (streamId) {\n          const stream = this.privStreams[streamId];\n          if (stream) {\n            stream.close();\n          }\n        }\n      }\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioSourceOffEvent(this.privId)); // no stream now\n      if (this.privInitializeDeferral) {\n        // Correctly handle when browser forces mic off before turnOn() completes\n        // eslint-disable-next-line @typescript-eslint/await-thenable\n        yield this.privInitializeDeferral;\n        this.privInitializeDeferral = null;\n      }\n      yield this.destroyAudioContext();\n      return;\n    });\n  }\n  get events() {\n    return this.privEvents;\n  }\n  get deviceInfo() {\n    return this.getMicrophoneLabel().then(label => ({\n      bitspersample: MicAudioSource.AUDIOFORMAT.bitsPerSample,\n      channelcount: MicAudioSource.AUDIOFORMAT.channels,\n      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.connectivity.Unknown,\n      manufacturer: \"Speech SDK\",\n      model: label,\n      samplerate: MicAudioSource.AUDIOFORMAT.samplesPerSec,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.type.Microphones\n    }));\n  }\n  setProperty(name, value) {\n    if (name === AudioWorkletSourceURLPropertyName) {\n      this.privRecorder.setWorkletUrl(value);\n    } else {\n      throw new Error(\"Property '\" + name + \"' is not supported on Microphone.\");\n    }\n  }\n  getMicrophoneLabel() {\n    const defaultMicrophoneName = \"microphone\";\n    // If we did this already, return the value.\n    if (this.privMicrophoneLabel !== undefined) {\n      return Promise.resolve(this.privMicrophoneLabel);\n    }\n    // If the stream isn't currently running, we can't query devices because security.\n    if (this.privMediaStream === undefined || !this.privMediaStream.active) {\n      return Promise.resolve(defaultMicrophoneName);\n    }\n    // Setup a default\n    this.privMicrophoneLabel = defaultMicrophoneName;\n    // Get the id of the device running the audio track.\n    const microphoneDeviceId = this.privMediaStream.getTracks()[0].getSettings().deviceId;\n    // If the browser doesn't support getting the device ID, set a default and return.\n    if (undefined === microphoneDeviceId) {\n      return Promise.resolve(this.privMicrophoneLabel);\n    }\n    const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n    // Enumerate the media devices.\n    navigator.mediaDevices.enumerateDevices().then(devices => {\n      for (const device of devices) {\n        if (device.deviceId === microphoneDeviceId) {\n          // Found the device\n          this.privMicrophoneLabel = device.label;\n          break;\n        }\n      }\n      deferred.resolve(this.privMicrophoneLabel);\n    }, () => deferred.resolve(this.privMicrophoneLabel));\n    return deferred.promise;\n  }\n  listen(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.turnOn();\n      const stream = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.ChunkedArrayBufferStream(this.privOutputChunkSize, audioNodeId);\n      this.privStreams[audioNodeId] = stream;\n      try {\n        this.privRecorder.record(this.privContext, this.privMediaStream, stream);\n      } catch (error) {\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.AudioStreamNodeErrorEvent(this.privId, audioNodeId, error));\n        throw error;\n      }\n      const result = stream;\n      return result;\n    });\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);\n  }\n  createAudioContext() {\n    if (!!this.privContext) {\n      return;\n    }\n    this.privContext = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__.AudioStreamFormatImpl.getAudioContext(MicAudioSource.AUDIOFORMAT.samplesPerSec);\n  }\n  destroyAudioContext() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privContext) {\n        return;\n      }\n      this.privRecorder.releaseMediaResources(this.privContext);\n      // This pattern brought to you by a bug in the TypeScript compiler where it\n      // confuses the (\"close\" in this.privContext) with this.privContext always being null as the alternate.\n      // https://github.com/Microsoft/TypeScript/issues/11498\n      let hasClose = false;\n      if (\"close\" in this.privContext) {\n        hasClose = true;\n      }\n      if (hasClose) {\n        if (!this.privIsClosing) {\n          // The audio context close may take enough time that the close is called twice\n          this.privIsClosing = true;\n          yield this.privContext.close();\n          this.privContext = null;\n          this.privIsClosing = false;\n        }\n      } else if (null !== this.privContext && this.privContext.state === \"running\") {\n        // Suspend actually takes a callback, but analogous to the\n        // resume method, it'll be only fired if suspend is called\n        // in a direct response to a user action. The later is not always\n        // the case, as TurnOff is also called, when we receive an\n        // end-of-speech message from the service. So, doing a best effort\n        // fire-and-forget here.\n        yield this.privContext.suspend();\n      }\n    });\n  }\n}\nMicAudioSource.AUDIOFORMAT = _sdk_Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_7__.AudioStreamFormat.getDefaultInputFormat();\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PcmRecorder\": () => (/* binding */ PcmRecorder)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass PcmRecorder {\n  constructor(stopInputOnRelease) {\n    this.privStopInputOnRelease = stopInputOnRelease;\n  }\n  record(context, mediaStream, outputStream) {\n    const desiredSampleRate = 16000;\n    const waveStreamEncoder = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.RiffPcmEncoder(context.sampleRate, desiredSampleRate);\n    const micInput = context.createMediaStreamSource(mediaStream);\n    const attachScriptProcessor = () => {\n      // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n      const scriptNode = (() => {\n        let bufferSize = 0;\n        try {\n          return context.createScriptProcessor(bufferSize, 1, 1);\n        } catch (error) {\n          // Webkit (<= version 31) requires a valid bufferSize.\n          bufferSize = 2048;\n          let audioSampleRate = context.sampleRate;\n          while (bufferSize < 16384 && audioSampleRate >= 2 * desiredSampleRate) {\n            bufferSize <<= 1;\n            audioSampleRate >>= 1;\n          }\n          return context.createScriptProcessor(bufferSize, 1, 1);\n        }\n      })();\n      scriptNode.onaudioprocess = event => {\n        const inputFrame = event.inputBuffer.getChannelData(0);\n        if (outputStream && !outputStream.isClosed) {\n          const waveFrame = waveStreamEncoder.encode(inputFrame);\n          if (!!waveFrame) {\n            outputStream.writeStreamChunk({\n              buffer: waveFrame,\n              isEnd: false,\n              timeReceived: Date.now()\n            });\n          }\n        }\n      };\n      micInput.connect(scriptNode);\n      scriptNode.connect(context.destination);\n      this.privMediaResources = {\n        scriptProcessorNode: scriptNode,\n        source: micInput,\n        stream: mediaStream\n      };\n    };\n    // https://webaudio.github.io/web-audio-api/#audioworklet\n    // Using AudioWorklet to improve audio quality and avoid audio glitches due to blocking the UI thread\n    if (!!context.audioWorklet) {\n      if (!this.privSpeechProcessorScript) {\n        const workletScript = `class SP extends AudioWorkletProcessor {\n                    constructor(options) {\n                      super(options);\n                    }\n                    process(inputs, outputs) {\n                      const input = inputs[0];\n                      const output = [];\n                      for (let channel = 0; channel < input.length; channel += 1) {\n                        output[channel] = input[channel];\n                      }\n                      this.port.postMessage(output[0]);\n                      return true;\n                    }\n                  }\n                  registerProcessor('speech-processor', SP);`;\n        const blob = new Blob([workletScript], {\n          type: \"application/javascript; charset=utf-8\"\n        });\n        this.privSpeechProcessorScript = URL.createObjectURL(blob);\n      }\n      context.audioWorklet.addModule(this.privSpeechProcessorScript).then(() => {\n        const workletNode = new AudioWorkletNode(context, \"speech-processor\");\n        workletNode.port.onmessage = ev => {\n          const inputFrame = ev.data;\n          if (outputStream && !outputStream.isClosed) {\n            const waveFrame = waveStreamEncoder.encode(inputFrame);\n            if (!!waveFrame) {\n              outputStream.writeStreamChunk({\n                buffer: waveFrame,\n                isEnd: false,\n                timeReceived: Date.now()\n              });\n            }\n          }\n        };\n        micInput.connect(workletNode);\n        workletNode.connect(context.destination);\n        this.privMediaResources = {\n          scriptProcessorNode: workletNode,\n          source: micInput,\n          stream: mediaStream\n        };\n      }).catch(() => {\n        attachScriptProcessor();\n      });\n    } else {\n      try {\n        attachScriptProcessor();\n      } catch (err) {\n        throw new Error(`Unable to start audio worklet node for PCMRecorder: ${err}`);\n      }\n    }\n  }\n  releaseMediaResources(context) {\n    if (this.privMediaResources) {\n      if (this.privMediaResources.scriptProcessorNode) {\n        this.privMediaResources.scriptProcessorNode.disconnect(context.destination);\n        this.privMediaResources.scriptProcessorNode = null;\n      }\n      if (this.privMediaResources.source) {\n        this.privMediaResources.source.disconnect();\n        if (this.privStopInputOnRelease) {\n          this.privMediaResources.stream.getTracks().forEach(track => track.stop());\n        }\n        this.privMediaResources.source = null;\n      }\n    }\n  }\n  setWorkletUrl(url) {\n    this.privSpeechProcessorScript = url;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ProxyInfo\": () => (/* binding */ ProxyInfo)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ProxyInfo {\n  constructor(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n    this.privProxyHostName = proxyHostName;\n    this.privProxyPort = proxyPort;\n    this.privProxyUserName = proxyUserName;\n    this.privProxyPassword = proxyPassword;\n  }\n  static fromParameters(parameters) {\n    return new ProxyInfo(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyHostName), parseInt(parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyPort), 10), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyUserName), parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ProxyPassword));\n  }\n  static fromRecognizerConfig(config) {\n    return this.fromParameters(config.parameters);\n  }\n  get HostName() {\n    return this.privProxyHostName;\n  }\n  get Port() {\n    return this.privProxyPort;\n  }\n  get UserName() {\n    return this.privProxyUserName;\n  }\n  get Password() {\n    return this.privProxyPassword;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ReplayableAudioNode\": () => (/* binding */ ReplayableAudioNode)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ReplayableAudioNode {\n  constructor(audioSource, bytesPerSecond) {\n    this.privBuffers = [];\n    this.privReplayOffset = 0;\n    this.privLastShrinkOffset = 0;\n    this.privBufferStartOffset = 0;\n    this.privBufferSerial = 0;\n    this.privBufferedBytes = 0;\n    this.privReplay = false;\n    this.privLastChunkAcquiredTime = 0;\n    this.privAudioNode = audioSource;\n    this.privBytesPerSecond = bytesPerSecond;\n  }\n  id() {\n    return this.privAudioNode.id();\n  }\n  // Reads and returns the next chunk of audio buffer.\n  // If replay of existing buffers are needed, read() will first seek and replay\n  // existing content, and upoin completion it will read new content from the underlying\n  // audio node, saving that content into the replayable buffers.\n  read() {\n    // if there is a replay request to honor.\n    if (!!this.privReplay && this.privBuffers.length !== 0) {\n      // Find the start point in the buffers.\n      // Offsets are in 100ns increments.\n      // So how many bytes do we need to seek to get the right offset?\n      const offsetToSeek = this.privReplayOffset - this.privBufferStartOffset;\n      let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n      if (0 !== bytesToSeek % 2) {\n        bytesToSeek++;\n      }\n      let i = 0;\n      while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n        bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n      }\n      if (i < this.privBuffers.length) {\n        const retVal = this.privBuffers[i].chunk.buffer.slice(bytesToSeek);\n        this.privReplayOffset += retVal.byteLength / this.privBytesPerSecond * 1e+7;\n        // If we've reached the end of the buffers, stop replaying.\n        if (i === this.privBuffers.length - 1) {\n          this.privReplay = false;\n        }\n        return Promise.resolve({\n          buffer: retVal,\n          isEnd: false,\n          timeReceived: this.privBuffers[i].chunk.timeReceived\n        });\n      }\n    }\n    return this.privAudioNode.read().then(result => {\n      if (result && result.buffer) {\n        this.privBuffers.push(new BufferEntry(result, this.privBufferSerial++, this.privBufferedBytes));\n        this.privBufferedBytes += result.buffer.byteLength;\n      }\n      return result;\n    });\n  }\n  detach() {\n    this.privBuffers = undefined;\n    return this.privAudioNode.detach();\n  }\n  replay() {\n    if (this.privBuffers && 0 !== this.privBuffers.length) {\n      this.privReplay = true;\n      this.privReplayOffset = this.privLastShrinkOffset;\n    }\n  }\n  // Shrinks the existing audio buffers to start at the new offset, or at the\n  // beginning of the buffer closest to the requested offset.\n  // A replay request will start from the last shrink point.\n  shrinkBuffers(offset) {\n    if (this.privBuffers === undefined || this.privBuffers.length === 0) {\n      return;\n    }\n    this.privLastShrinkOffset = offset;\n    // Find the start point in the buffers.\n    // Offsets are in 100ns increments.\n    // So how many bytes do we need to seek to get the right offset?\n    const offsetToSeek = offset - this.privBufferStartOffset;\n    let bytesToSeek = Math.round(offsetToSeek * this.privBytesPerSecond * 1e-7);\n    let i = 0;\n    while (i < this.privBuffers.length && bytesToSeek >= this.privBuffers[i].chunk.buffer.byteLength) {\n      bytesToSeek -= this.privBuffers[i++].chunk.buffer.byteLength;\n    }\n    this.privBufferStartOffset = Math.round(offset - bytesToSeek / this.privBytesPerSecond * 1e+7);\n    this.privBuffers = this.privBuffers.slice(i);\n  }\n  // Finds the time a buffer of audio was first seen by offset.\n  findTimeAtOffset(offset) {\n    if (offset < this.privBufferStartOffset || this.privBuffers === undefined) {\n      return 0;\n    }\n    for (const value of this.privBuffers) {\n      const startOffset = value.byteOffset / this.privBytesPerSecond * 1e7;\n      const endOffset = startOffset + value.chunk.buffer.byteLength / this.privBytesPerSecond * 1e7;\n      if (offset >= startOffset && offset <= endOffset) {\n        return value.chunk.timeReceived;\n      }\n    }\n    return 0;\n  }\n}\n// Primary use of this class is to help debugging problems with the replay\n// code. If the memory cost of alloc / dealloc gets too much, drop it and just use\n// the ArrayBuffer directly.\nclass BufferEntry {\n  constructor(chunk, serial, byteOffset) {\n    this.chunk = chunk;\n    this.serial = serial;\n    this.byteOffset = byteOffset;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RestConfigBase\": () => (/* binding */ RestConfigBase)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass RestConfigBase {\n  static get requestOptions() {\n    return RestConfigBase.privDefaultRequestOptions;\n  }\n  static get configParams() {\n    return RestConfigBase.privDefaultParams;\n  }\n  static get restErrors() {\n    return RestConfigBase.privRestErrors;\n  }\n}\nRestConfigBase.privDefaultRequestOptions = {\n  headers: {\n    Accept: \"application/json\"\n  },\n  ignoreCache: false,\n  timeout: 10000\n};\nRestConfigBase.privRestErrors = {\n  authInvalidSubscriptionKey: \"You must specify either an authentication token to use, or a Cognitive Speech subscription key.\",\n  authInvalidSubscriptionRegion: \"You must specify the Cognitive Speech region to use.\",\n  invalidArgs: \"Required input not found: {arg}.\",\n  invalidCreateJoinConversationResponse: \"Creating/Joining conversation failed with HTTP {status}.\",\n  invalidParticipantRequest: \"The requested participant was not found.\",\n  permissionDeniedConnect: \"Required credentials not found.\",\n  permissionDeniedConversation: \"Invalid operation: only the host can {command} the conversation.\",\n  permissionDeniedParticipant: \"Invalid operation: only the host can {command} a participant.\",\n  permissionDeniedSend: \"Invalid operation: the conversation is not in a connected state.\",\n  permissionDeniedStart: \"Invalid operation: there is already an active conversation.\"\n};\nRestConfigBase.privDefaultParams = {\n  apiVersion: \"api-version\",\n  authorization: \"Authorization\",\n  clientAppId: \"X-ClientAppId\",\n  contentTypeKey: \"Content-Type\",\n  correlationId: \"X-CorrelationId\",\n  languageCode: \"language\",\n  nickname: \"nickname\",\n  profanity: \"profanity\",\n  requestId: \"X-RequestId\",\n  roomId: \"roomid\",\n  sessionToken: \"token\",\n  subscriptionKey: \"Ocp-Apim-Subscription-Key\",\n  subscriptionRegion: \"Ocp-Apim-Subscription-Region\",\n  token: \"X-CapitoToken\"\n};\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RestMessageAdapter\": () => (/* binding */ RestMessageAdapter),\n/* harmony export */   \"RestRequestType\": () => (/* binding */ RestRequestType)\n/* harmony export */ });\n/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bent */ \"./node_modules/bent/src/browser.js\");\n/* harmony import */ var bent__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(bent__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\nvar RestRequestType;\n(function (RestRequestType) {\n  RestRequestType[\"Get\"] = \"GET\";\n  RestRequestType[\"Post\"] = \"POST\";\n  RestRequestType[\"Delete\"] = \"DELETE\";\n  RestRequestType[\"File\"] = \"file\";\n})(RestRequestType || (RestRequestType = {}));\n// accept rest operations via request method and return abstracted objects from server response\nclass RestMessageAdapter {\n  constructor(configParams) {\n    if (!configParams) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"configParams\");\n    }\n    this.privHeaders = configParams.headers;\n    this.privIgnoreCache = configParams.ignoreCache;\n  }\n  static extractHeaderValue(headerKey, headers) {\n    let headerValue = \"\";\n    try {\n      const arr = headers.trim().split(/[\\r\\n]+/);\n      const headerMap = {};\n      arr.forEach(line => {\n        const parts = line.split(\": \");\n        const header = parts.shift().toLowerCase();\n        const value = parts.join(\": \");\n        headerMap[header] = value;\n      });\n      headerValue = headerMap[headerKey.toLowerCase()];\n    } catch (e) {\n      // ignore the error\n    }\n    return headerValue;\n  }\n  set options(configParams) {\n    this.privHeaders = configParams.headers;\n    this.privIgnoreCache = configParams.ignoreCache;\n  }\n  setHeaders(key, value) {\n    this.privHeaders[key] = value;\n  }\n  request(method, uri) {\n    let queryParams = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n    let body = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;\n    let binaryBody = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;\n    const responseReceivedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n    const requestCommand = method === RestRequestType.File ? \"POST\" : method;\n    const handleRestResponse = function (data) {\n      let j = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n      const d = data;\n      return {\n        data: JSON.stringify(j),\n        headers: JSON.stringify(data.headers),\n        json: j,\n        ok: data.statusCode >= 200 && data.statusCode < 300,\n        status: data.statusCode,\n        statusText: j.error ? j.error.message : d.statusText ? d.statusText : d.statusMessage\n      };\n    };\n    const blobToArrayBuffer = blob => {\n      const reader = new FileReader();\n      reader.readAsArrayBuffer(blob);\n      return new Promise(resolve => {\n        reader.onloadend = () => {\n          resolve(reader.result);\n        };\n      });\n    };\n    const send = postData => {\n      const sendRequest = bent__WEBPACK_IMPORTED_MODULE_0___default()(uri, requestCommand, this.privHeaders, 200, 201, 202, 204, 400, 401, 402, 403, 404);\n      const params = this.queryParams(queryParams) === \"\" ? \"\" : `?${this.queryParams(queryParams)}`;\n      sendRequest(params, postData).then(data => __awaiter(this, void 0, void 0, function* () {\n        if (method === RestRequestType.Delete || data.statusCode === 204) {\n          // No JSON from Delete and reset (204) operations\n          responseReceivedDeferral.resolve(handleRestResponse(data));\n        } else {\n          try {\n            const j = yield data.json();\n            responseReceivedDeferral.resolve(handleRestResponse(data, j));\n          } catch (_a) {\n            responseReceivedDeferral.resolve(handleRestResponse(data));\n          }\n        }\n      })).catch(error => {\n        responseReceivedDeferral.reject(error);\n      });\n    };\n    if (this.privIgnoreCache) {\n      this.privHeaders[\"Cache-Control\"] = \"no-cache\";\n    }\n    if (method === RestRequestType.File && binaryBody) {\n      const contentType = \"multipart/form-data\";\n      this.privHeaders[\"content-type\"] = contentType;\n      this.privHeaders[\"Content-Type\"] = contentType;\n      if (typeof Blob !== \"undefined\" && binaryBody instanceof Blob) {\n        blobToArrayBuffer(binaryBody).then(res => {\n          send(res);\n        }).catch(error => {\n          responseReceivedDeferral.reject(error);\n        });\n      } else {\n        send(binaryBody);\n      }\n    } else {\n      if (method === RestRequestType.Post && body) {\n        this.privHeaders[\"content-type\"] = \"application/json\";\n        this.privHeaders[\"Content-Type\"] = \"application/json\";\n      }\n      send(body);\n    }\n    return responseReceivedDeferral.promise;\n  }\n  withQuery(url) {\n    let params = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    const queryString = this.queryParams(params);\n    return queryString ? url + (url.indexOf(\"?\") === -1 ? \"?\" : \"&\") + queryString : url;\n  }\n  queryParams() {\n    let params = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    return Object.keys(params).map(k => encodeURIComponent(k) + \"=\" + encodeURIComponent(params[k])).join(\"&\");\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WebsocketConnection\": () => (/* binding */ WebsocketConnection)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WebsocketMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\nclass WebsocketConnection {\n  constructor(uri, queryParameters, headers, messageFormatter, proxyInfo) {\n    let enableCompression = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : false;\n    let connectionId = arguments.length > 6 ? arguments[6] : undefined;\n    this.privIsDisposed = false;\n    if (!uri) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"uri\");\n    }\n    if (!messageFormatter) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"messageFormatter\");\n    }\n    this.privMessageFormatter = messageFormatter;\n    let queryParams = \"\";\n    let i = 0;\n    if (queryParameters) {\n      for (const paramName in queryParameters) {\n        if (paramName) {\n          queryParams += i === 0 && uri.indexOf(\"?\") === -1 ? \"?\" : \"&\";\n          const val = encodeURIComponent(queryParameters[paramName]);\n          queryParams += `${paramName}=${val}`;\n          i++;\n        }\n      }\n    }\n    if (headers) {\n      for (const headerName in headers) {\n        if (headerName) {\n          queryParams += i === 0 && uri.indexOf(\"?\") === -1 ? \"?\" : \"&\";\n          const val = encodeURIComponent(headers[headerName]);\n          queryParams += `${headerName}=${val}`;\n          i++;\n        }\n      }\n    }\n    this.privUri = uri + queryParams;\n    this.privId = connectionId ? connectionId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n    this.privConnectionMessageAdapter = new _WebsocketMessageAdapter__WEBPACK_IMPORTED_MODULE_2__.WebsocketMessageAdapter(this.privUri, this.id, this.privMessageFormatter, proxyInfo, headers, enableCompression);\n  }\n  dispose() {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privIsDisposed = true;\n      if (this.privConnectionMessageAdapter) {\n        yield this.privConnectionMessageAdapter.close();\n      }\n    });\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  get id() {\n    return this.privId;\n  }\n  state() {\n    return this.privConnectionMessageAdapter.state;\n  }\n  open() {\n    return this.privConnectionMessageAdapter.open();\n  }\n  send(message) {\n    return this.privConnectionMessageAdapter.send(message);\n  }\n  read() {\n    return this.privConnectionMessageAdapter.read();\n  }\n  get events() {\n    return this.privConnectionMessageAdapter.events;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WebsocketMessageAdapter\": () => (/* binding */ WebsocketMessageAdapter)\n/* harmony export */ });\n/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ws */ \"?e42a\");\n/* harmony import */ var ws__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(ws__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _CertChecks__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./CertChecks */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/CertChecks.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n// Node.JS specific web socket / browser support.\n\n\n\n\nclass WebsocketMessageAdapter {\n  constructor(uri, connectionId, messageFormatter, proxyInfo, headers, enableCompression) {\n    if (!uri) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"uri\");\n    }\n    if (!messageFormatter) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"messageFormatter\");\n    }\n    this.proxyInfo = proxyInfo;\n    this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n    this.privConnectionId = connectionId;\n    this.privMessageFormatter = messageFormatter;\n    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.None;\n    this.privUri = uri;\n    this.privHeaders = headers;\n    this.privEnableCompression = enableCompression;\n    // Add the connection ID to the headers\n    this.privHeaders[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_4__.HeaderNames.ConnectionId] = this.privConnectionId;\n    this.privLastErrorReceived = \"\";\n  }\n  get state() {\n    return this.privConnectionState;\n  }\n  open() {\n    if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected) {\n      return Promise.reject(`Cannot open a connection that is in ${this.privConnectionState} state`);\n    }\n    if (this.privConnectionEstablishDeferral) {\n      return this.privConnectionEstablishDeferral.promise;\n    }\n    this.privConnectionEstablishDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n    this.privCertificateValidatedDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n    this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connecting;\n    try {\n      if (typeof WebSocket !== \"undefined\" && !WebsocketMessageAdapter.forceNpmWebSocket) {\n        // Browser handles cert checks.\n        this.privCertificateValidatedDeferral.resolve();\n        this.privWebsocketClient = new WebSocket(this.privUri);\n      } else {\n        const options = {\n          headers: this.privHeaders,\n          perMessageDeflate: this.privEnableCompression\n        };\n        // The ocsp library will handle validation for us and fail the connection if needed.\n        this.privCertificateValidatedDeferral.resolve();\n        const checkAgent = new _CertChecks__WEBPACK_IMPORTED_MODULE_6__.CertCheckAgent(this.proxyInfo);\n        options.agent = checkAgent.GetAgent();\n        // Workaround for https://github.com/microsoft/cognitive-services-speech-sdk-js/issues/465\n        // Which is root caused by https://github.com/TooTallNate/node-agent-base/issues/61\n        const uri = new URL(this.privUri);\n        let protocol = uri.protocol;\n        if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === \"wss:\") {\n          protocol = \"https:\";\n        } else if ((protocol === null || protocol === void 0 ? void 0 : protocol.toLocaleLowerCase()) === \"ws:\") {\n          protocol = \"http:\";\n        }\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n        options.agent.protocol = protocol;\n        this.privWebsocketClient = new (ws__WEBPACK_IMPORTED_MODULE_0___default())(this.privUri, options);\n      }\n      this.privWebsocketClient.binaryType = \"arraybuffer\";\n      this.privReceivingMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Queue();\n      this.privDisconnectDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n      this.privSendMessageQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_7__.Queue();\n      this.processSendQueue().catch(reason => {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.BackgroundEvent(reason));\n      });\n    } catch (error) {\n      this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.ConnectionOpenResponse(500, error));\n      return this.privConnectionEstablishDeferral.promise;\n    }\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionStartEvent(this.privConnectionId, this.privUri));\n    this.privWebsocketClient.onopen = () => {\n      this.privCertificateValidatedDeferral.promise.then(() => {\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected;\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionEstablishedEvent(this.privConnectionId));\n        this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.ConnectionOpenResponse(200, \"\"));\n      }, error => {\n        this.privConnectionEstablishDeferral.reject(error);\n      });\n    };\n    this.privWebsocketClient.onerror = e => {\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionErrorEvent(this.privConnectionId, e.message, e.type));\n      this.privLastErrorReceived = e.message;\n    };\n    this.privWebsocketClient.onclose = e => {\n      if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connecting) {\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected;\n        // this.onEvent(new ConnectionEstablishErrorEvent(this.connectionId, e.code, e.reason));\n        this.privConnectionEstablishDeferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_10__.ConnectionOpenResponse(e.code, e.reason + \" \" + this.privLastErrorReceived));\n      } else {\n        this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected;\n        this.privWebsocketClient = null;\n        this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionClosedEvent(this.privConnectionId, e.code, e.reason));\n      }\n      this.onClose(e.code, e.reason).catch(reason => {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_9__.BackgroundEvent(reason));\n      });\n    };\n    this.privWebsocketClient.onmessage = e => {\n      const networkReceivedTime = new Date().toISOString();\n      if (this.privConnectionState === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected) {\n        const deferred = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n        // let id = ++this.idCounter;\n        this.privReceivingMessageQueue.enqueueFromPromise(deferred.promise);\n        if (e.data instanceof ArrayBuffer) {\n          const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_12__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, e.data);\n          this.privMessageFormatter.toConnectionMessage(rawMessage).then(connectionMessage => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));\n            deferred.resolve(connectionMessage);\n          }, error => {\n            // TODO: Events for these ?\n            deferred.reject(`Invalid binary message format. Error: ${error}`);\n          });\n        } else {\n          const rawMessage = new _common_Exports__WEBPACK_IMPORTED_MODULE_12__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, e.data);\n          this.privMessageFormatter.toConnectionMessage(rawMessage).then(connectionMessage => {\n            this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionMessageReceivedEvent(this.privConnectionId, networkReceivedTime, connectionMessage));\n            deferred.resolve(connectionMessage);\n          }, error => {\n            // TODO: Events for these ?\n            deferred.reject(`Invalid text message format. Error: ${error}`);\n          });\n        }\n      }\n    };\n    return this.privConnectionEstablishDeferral.promise;\n  }\n  send(message) {\n    if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected) {\n      return Promise.reject(`Cannot send on connection that is in ${_common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState[this.privConnectionState]} state`);\n    }\n    const messageSendStatusDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n    const messageSendDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Deferred();\n    this.privSendMessageQueue.enqueueFromPromise(messageSendDeferral.promise);\n    this.privMessageFormatter.fromConnectionMessage(message).then(rawMessage => {\n      messageSendDeferral.resolve({\n        Message: message,\n        RawWebsocketMessage: rawMessage,\n        sendStatusDeferral: messageSendStatusDeferral\n      });\n    }, error => {\n      messageSendDeferral.reject(`Error formatting the message. ${error}`);\n    });\n    return messageSendStatusDeferral.promise;\n  }\n  read() {\n    if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Connected) {\n      return Promise.reject(`Cannot read on connection that is in ${this.privConnectionState} state`);\n    }\n    return this.privReceivingMessageQueue.dequeue();\n  }\n  close(reason) {\n    if (this.privWebsocketClient) {\n      if (this.privConnectionState !== _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected) {\n        this.privWebsocketClient.close(1000, reason ? reason : \"Normal closure by client\");\n      }\n    } else {\n      return Promise.resolve();\n    }\n    return this.privDisconnectDeferral.promise;\n  }\n  get events() {\n    return this.privConnectionEvents;\n  }\n  sendRawMessage(sendItem) {\n    try {\n      // indicates we are draining the queue and it came with no message;\n      if (!sendItem) {\n        return Promise.resolve();\n      }\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.ConnectionMessageSentEvent(this.privConnectionId, new Date().toISOString(), sendItem.Message));\n      // add a check for the ws readystate in order to stop the red console error 'WebSocket is already in CLOSING or CLOSED state' appearing\n      if (this.isWebsocketOpen) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n        this.privWebsocketClient.send(sendItem.RawWebsocketMessage.payload);\n      } else {\n        return Promise.reject(\"websocket send error: Websocket not ready \" + this.privConnectionId + \" \" + sendItem.Message.id + \" \" + new Error().stack);\n      }\n      return Promise.resolve();\n    } catch (e) {\n      return Promise.reject(`websocket send error: ${e}`);\n    }\n  }\n  onClose(code, reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const closeReason = `Connection closed. ${code}: ${reason}`;\n      this.privConnectionState = _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ConnectionState.Disconnected;\n      this.privDisconnectDeferral.resolve();\n      yield this.privReceivingMessageQueue.drainAndDispose(() => {\n        // TODO: Events for these ?\n        // Logger.instance.onEvent(new LoggingEvent(LogType.Warning, null, `Failed to process received message. Reason: ${closeReason}, Message: ${JSON.stringify(pendingReceiveItem)}`));\n      }, closeReason);\n      yield this.privSendMessageQueue.drainAndDispose(pendingSendItem => {\n        pendingSendItem.sendStatusDeferral.reject(closeReason);\n      }, closeReason);\n    });\n  }\n  processSendQueue() {\n    return __awaiter(this, void 0, void 0, function* () {\n      while (true) {\n        const itemToSend = this.privSendMessageQueue.dequeue();\n        const sendItem = yield itemToSend;\n        // indicates we are draining the queue and it came with no message;\n        if (!sendItem) {\n          return;\n        }\n        try {\n          yield this.sendRawMessage(sendItem);\n          sendItem.sendStatusDeferral.resolve();\n        } catch (sendError) {\n          sendItem.sendStatusDeferral.reject(sendError);\n        }\n      }\n    });\n  }\n  onEvent(event) {\n    this.privConnectionEvents.onEvent(event);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Events.instance.onEvent(event);\n  }\n  get isWebsocketOpen() {\n    return this.privWebsocketClient && this.privWebsocketClient.readyState === this.privWebsocketClient.OPEN;\n  }\n}\nWebsocketMessageAdapter.forceNpmWebSocket = false;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AddedLmIntent\": () => (/* binding */ AddedLmIntent)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class AddedLmIntent\n */\n// eslint-disable-next-line max-classes-per-file\nclass AddedLmIntent {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param modelImpl - The model.\n   * @param intentName - The intent name.\n   */\n  constructor(modelImpl, intentName) {\n    this.modelImpl = modelImpl;\n    this.intentName = intentName;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AgentConfig\": () => (/* binding */ AgentConfig)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Represents the JSON used in the agent.config message sent to the speech service.\n */\nclass AgentConfig {\n  toJsonString() {\n    return JSON.stringify(this.iPrivConfig);\n  }\n  get() {\n    return this.iPrivConfig;\n  }\n  /**\n   * Setter for the agent.config object.\n   * @param value a JSON serializable object.\n   */\n  set(value) {\n    this.iPrivConfig = value;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CognitiveSubscriptionKeyAuthentication\": () => (/* binding */ CognitiveSubscriptionKeyAuthentication)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * @class\n */\nclass CognitiveSubscriptionKeyAuthentication {\n  /**\n   * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.\n   * @constructor\n   * @param {string} subscriptionKey - The subscription key\n   */\n  constructor(subscriptionKey) {\n    if (!subscriptionKey) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"subscriptionKey\");\n    }\n    this.privAuthInfo = new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.AuthKey, subscriptionKey);\n  }\n  /**\n   * Fetches the subscription key.\n   * @member\n   * @function\n   * @public\n   * @param {string} authFetchEventId - The id to fetch.\n   */\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  fetch(authFetchEventId) {\n    return Promise.resolve(this.privAuthInfo);\n  }\n  /**\n   * Fetches the subscription key.\n   * @member\n   * @function\n   * @public\n   * @param {string} authFetchEventId - The id to fetch.\n   */\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  fetchOnExpiry(authFetchEventId) {\n    return Promise.resolve(this.privAuthInfo);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CognitiveTokenAuthentication\": () => (/* binding */ CognitiveTokenAuthentication)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass CognitiveTokenAuthentication {\n  constructor(fetchCallback, fetchOnExpiryCallback) {\n    if (!fetchCallback) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"fetchCallback\");\n    }\n    if (!fetchOnExpiryCallback) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"fetchOnExpiryCallback\");\n    }\n    this.privFetchCallback = fetchCallback;\n    this.privFetchOnExpiryCallback = fetchOnExpiryCallback;\n  }\n  fetch(authFetchEventId) {\n    return this.privFetchCallback(authFetchEventId).then(token => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n  }\n  fetchOnExpiry(authFetchEventId) {\n    return this.privFetchOnExpiryCallback(authFetchEventId).then(token => new _IAuthentication__WEBPACK_IMPORTED_MODULE_1__.AuthInfo(_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Authorization, token === undefined ? undefined : CognitiveTokenAuthentication.privTokenPrefix + token));\n  }\n}\nCognitiveTokenAuthentication.privTokenPrefix = \"bearer \";\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionFactoryBase\": () => (/* binding */ ConnectionFactoryBase)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass ConnectionFactoryBase {\n  static getHostSuffix(region) {\n    if (!!region) {\n      if (region.toLowerCase().startsWith(\"china\")) {\n        return \".azure.cn\";\n      }\n      if (region.toLowerCase().startsWith(\"usgov\")) {\n        return \".azure.us\";\n      }\n    }\n    return \".microsoft.com\";\n  }\n  setCommonUrlParams(config, queryParams, endpoint) {\n    const propertyIdToParameterMap = new Map([[_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.Speech_SegmentationSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.SegmentationSilenceTimeoutMs], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EnableAudioLogging, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableAudioLogging], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EndSilenceTimeoutMs], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.InitialSilenceTimeoutMs], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_PostProcessingOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.Postprocessing], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_ProfanityOption, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.Profanity], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.EnableWordLevelTimestamps], [_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_StablePartialResultThreshold, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_1__.QueryParameterNames.StableIntermediateThreshold]]);\n    propertyIdToParameterMap.forEach((parameterName, propertyId) => {\n      this.setUrlParameter(propertyId, parameterName, config, queryParams, endpoint);\n    });\n    const serviceProperties = JSON.parse(config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.ServicePropertiesPropertyName, \"{}\"));\n    Object.keys(serviceProperties).forEach(value => {\n      queryParams[value] = serviceProperties[value];\n    });\n  }\n  setUrlParameter(propId, parameterName, config, queryParams, endpoint) {\n    const value = config.parameters.getProperty(propId, undefined);\n    if (value && (!endpoint || endpoint.search(parameterName) === -1)) {\n      queryParams[parameterName] = value.toLocaleLowerCase();\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogConnectionFactory\": () => (/* binding */ DialogConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n\n\nclass DialogConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n  create(config, authInfo, connectionId) {\n    const applicationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Conversation_ApplicationId, \"\");\n    const dialogType = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Conversation_DialogType);\n    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region);\n    const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, \"en-US\");\n    const requestTurnStatus = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Conversation_Request_Bot_Status_Messages, \"true\");\n    const queryParams = {};\n    queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;\n    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]).toLowerCase();\n    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.Language] = language;\n    queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.RequestBotStatusMessages] = requestTurnStatus;\n    if (applicationId) {\n      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.BotId] = applicationId;\n      if (dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.CustomCommands) {\n        queryParams[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.CustomCommandsAppId] = applicationId;\n      }\n    }\n    const resourceInfix = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.CustomCommands ? \"commands/\" : \"\";\n    const version = dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.CustomCommands ? \"v1\" : dialogType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceConfig.DialogTypes.BotFramework ? \"v3\" : \"v0\";\n    const headers = {};\n    if (authInfo.token != null && authInfo.token !== \"\") {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    // The URL used for connection is chosen in a priority order of specification:\n    //  1. If a custom endpoint is provided, that URL is used verbatim.\n    //  2. If a custom host is provided (e.g. \"wss://my.custom.endpoint.com:1123\"), a URL is constructed from it.\n    //  3. If no custom connection details are provided, a URL is constructed from default values.\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, \"\");\n    if (!endpoint) {\n      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n      const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, `wss://${region}.${DialogConnectionFactory.BaseUrl}${hostSuffix}`);\n      const standardizedHost = host.endsWith(\"/\") ? host : host + \"/\";\n      endpoint = `${standardizedHost}${resourceInfix}${DialogConnectionFactory.ApiKey}/${version}`;\n    }\n    this.setCommonUrlParams(config, queryParams, endpoint);\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_8__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n}\nDialogConnectionFactory.ApiKey = \"api\";\nDialogConnectionFactory.BaseUrl = \"convai.speech\";\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceAdapter\": () => (/* binding */ DialogServiceAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js\");\n/* harmony import */ var _common_DialogEvents__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ../common/DialogEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js\");\n/* harmony import */ var _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./DialogServiceTurnStateManager */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\n\n\n\n\nclass DialogServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, dialogServiceConnector);\n    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n    this.privDialogServiceConnector = dialogServiceConnector;\n    this.receiveMessageOverride = () => this.receiveDialogMessageOverride();\n    this.privTurnStateManager = new _DialogServiceTurnStateManager__WEBPACK_IMPORTED_MODULE_2__.DialogServiceTurnStateManager();\n    this.recognizeOverride = (recoMode, successCallback, errorCallback) => this.listenOnce(recoMode, successCallback, errorCallback);\n    this.postConnectImplOverride = connection => this.dialogConnectImpl(connection);\n    this.configConnectionOverride = connection => this.configConnection(connection);\n    this.disconnectOverride = () => this.privDisconnect();\n    this.privDialogAudioSource = audioSource;\n    this.agentConfigSent = false;\n    this.privLastResult = null;\n    this.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        this.terminateMessageLoop = true;\n      }\n    });\n  }\n  sendMessage(message) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const interactionGuid = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)();\n      const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createNoDashGuid)();\n      const agentMessage = {\n        context: {\n          interactionId: interactionGuid\n        },\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n        messagePayload: JSON.parse(message),\n        version: 0.5\n      };\n      const agentMessageJson = JSON.stringify(agentMessage);\n      const connection = yield this.fetchConnection();\n      yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, \"agent\", requestId, \"application/json\", agentMessageJson));\n    });\n  }\n  privDisconnect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.NoError, \"Disconnecting\");\n      this.terminateMessageLoop = true;\n      this.agentConfigSent = false;\n      return;\n    });\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();\n    if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text) {\n      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n    }\n    let result;\n    let processed;\n    switch (connectionMessage.path.toLowerCase()) {\n      case \"speech.phrase\":\n        const speechPhrase = _Exports__WEBPACK_IMPORTED_MODULE_10__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + speechPhrase.Offset + speechPhrase.Duration);\n        if (speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_11__.RecognitionStatus.TooManyRequests && speechPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_11__.RecognitionStatus.Error) {\n          const args = this.fireEventForResult(speechPhrase, resultProps);\n          this.privLastResult = args.result;\n          if (!!this.privDialogServiceConnector.recognized) {\n            try {\n              this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, args);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n        }\n        processed = true;\n        break;\n      case \"speech.hypothesis\":\n        const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_12__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n        const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined, undefined, connectionMessage.textBody, resultProps);\n        this.privRequestSession.onHypothesis(offset);\n        const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n        if (!!this.privDialogServiceConnector.recognizing) {\n          try {\n            this.privDialogServiceConnector.recognizing(this.privDialogServiceConnector, ev);\n            /* eslint-disable no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"speech.keyword\":\n        const keyword = _Exports__WEBPACK_IMPORTED_MODULE_16__.SpeechKeyword.fromJSON(connectionMessage.textBody);\n        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, keyword.Status === \"Accepted\" ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.RecognizedKeyword : _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.NoMatch, keyword.Text, keyword.Duration, keyword.Offset, undefined, undefined, undefined, undefined, connectionMessage.textBody, resultProps);\n        if (keyword.Status !== \"Accepted\") {\n          this.privLastResult = result;\n        }\n        const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, result.duration, result.resultId);\n        if (!!this.privDialogServiceConnector.recognized) {\n          try {\n            this.privDialogServiceConnector.recognized(this.privDialogServiceConnector, event);\n            /* eslint-disable no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"audio\":\n        {\n          const audioRequestId = connectionMessage.requestId.toUpperCase();\n          const turn = this.privTurnStateManager.GetTurn(audioRequestId);\n          try {\n            // Empty binary message signals end of stream.\n            if (!connectionMessage.binaryBody) {\n              turn.endAudioStream();\n            } else {\n              turn.audioStream.write(connectionMessage.binaryBody);\n            }\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"response\":\n        {\n          this.handleResponseMessage(connectionMessage);\n        }\n        processed = true;\n        break;\n      default:\n        break;\n    }\n    const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.Deferred();\n    defferal.resolve(processed);\n    return defferal.promise;\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.terminateMessageLoop = true;\n      if (!!this.privRequestSession.isRecognizing) {\n        yield this.privRequestSession.onStopRecognizing();\n      }\n      if (!!this.privDialogServiceConnector.canceled) {\n        const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();\n        properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_18__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode[errorCode]);\n        const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_19__.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n        try {\n          this.privDialogServiceConnector.canceled(this.privDialogServiceConnector, cancelEvent);\n          /* eslint-disable no-empty */\n        } catch (_a) {}\n        if (!!this.privSuccessCallback) {\n          const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(undefined,\n          // ResultId\n          _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ResultReason.Canceled, undefined,\n          // Text\n          undefined,\n          // Duration\n          undefined,\n          // Offset\n          undefined,\n          // Language\n          undefined,\n          // Language Detection Confidence\n          undefined,\n          // Speaker Id\n          error, undefined,\n          // Json\n          properties);\n          try {\n            this.privSuccessCallback(result);\n            this.privSuccessCallback = undefined;\n            /* eslint-disable no-empty */\n          } catch (_b) {}\n        }\n      }\n    });\n  }\n  listenOnce(recoMode, successCallback, errorCallback) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privRecognizerConfig.recognitionMode = recoMode;\n      this.privSuccessCallback = successCallback;\n      this.privErrorCallback = errorCallback;\n      this.privRequestSession.startNewRecognition();\n      this.privRequestSession.listenForServiceTelemetry(this.privDialogAudioSource.events);\n      this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Speech_SessionId, this.privRequestSession.sessionId);\n      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n      const conPromise = this.connectImpl();\n      const preAudioPromise = this.sendPreAudioMessages();\n      const node = yield this.privDialogAudioSource.attach(this.privRequestSession.audioNodeId);\n      const format = yield this.privDialogAudioSource.format;\n      const deviceInfo = yield this.privDialogAudioSource.deviceInfo;\n      const audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_20__.ReplayableAudioNode(node, format.avgBytesPerSec);\n      yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n      this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {\n        source: deviceInfo\n      };\n      try {\n        yield conPromise;\n        yield preAudioPromise;\n      } catch (error) {\n        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.ConnectionFailure, error);\n        return Promise.resolve();\n      }\n      const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.SessionEventArgs(this.privRequestSession.sessionId);\n      if (!!this.privRecognizer.sessionStarted) {\n        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n      }\n      const audioSendPromise = this.sendAudio(audioNode);\n      // /* eslint-disable no-empty */\n      audioSendPromise.then(() => {}, error => __awaiter(this, void 0, void 0, function* () {\n        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.RuntimeError, error);\n      }));\n    });\n  }\n  // Establishes a websocket connection to the end point.\n  dialogConnectImpl(connection) {\n    this.privConnectionLoop = this.startMessageLoop();\n    return connection;\n  }\n  receiveDialogMessageOverride() {\n    // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n    const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.Deferred();\n    const loop = () => __awaiter(this, void 0, void 0, function* () {\n      try {\n        const isDisposed = this.isDisposed();\n        const terminateMessageLoop = !this.isDisposed() && this.terminateMessageLoop;\n        if (isDisposed || terminateMessageLoop) {\n          // We're done.\n          communicationCustodian.resolve(undefined);\n          return;\n        }\n        const connection = yield this.fetchConnection();\n        const message = yield connection.read();\n        if (!message) {\n          return loop();\n        }\n        const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage.fromConnectionMessage(message);\n        switch (connectionMessage.path.toLowerCase()) {\n          case \"turn.start\":\n            {\n              const turnRequestId = connectionMessage.requestId.toUpperCase();\n              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n              // turn started by the service\n              if (turnRequestId !== audioSessionReqId) {\n                this.privTurnStateManager.StartTurn(turnRequestId);\n              } else {\n                this.privRequestSession.onServiceTurnStartResponse();\n              }\n            }\n            break;\n          case \"speech.startdetected\":\n            const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected.fromJSON(connectionMessage.textBody);\n            const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.speechStartDetected) {\n              this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n            }\n            break;\n          case \"speech.enddetected\":\n            let json;\n            if (connectionMessage.textBody.length > 0) {\n              json = connectionMessage.textBody;\n            } else {\n              // If the request was empty, the JSON returned is empty.\n              json = \"{ Offset: 0 }\";\n            }\n            const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_22__.SpeechDetected.fromJSON(json);\n            this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n            const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_23__.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n            if (!!this.privRecognizer.speechEndDetected) {\n              this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n            }\n            break;\n          case \"turn.end\":\n            {\n              const turnEndRequestId = connectionMessage.requestId.toUpperCase();\n              const audioSessionReqId = this.privRequestSession.requestId.toUpperCase();\n              // turn started by the service\n              if (turnEndRequestId !== audioSessionReqId) {\n                this.privTurnStateManager.CompleteTurn(turnEndRequestId);\n              } else {\n                // Audio session turn\n                const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.SessionEventArgs(this.privRequestSession.sessionId);\n                yield this.privRequestSession.onServiceTurnEndResponse(false);\n                if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                  if (!!this.privRecognizer.sessionStopped) {\n                    this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                  }\n                }\n                // report result to promise.\n                if (!!this.privSuccessCallback && this.privLastResult) {\n                  try {\n                    this.privSuccessCallback(this.privLastResult);\n                    this.privLastResult = null;\n                  } catch (e) {\n                    if (!!this.privErrorCallback) {\n                      this.privErrorCallback(e);\n                    }\n                  }\n                  // Only invoke the call back once.\n                  // and if it's successful don't invoke the\n                  // error after that.\n                  this.privSuccessCallback = undefined;\n                  this.privErrorCallback = undefined;\n                }\n              }\n            }\n            break;\n          default:\n            try {\n              const processed = yield this.processTypeSpecificMessages(connectionMessage);\n              if (!processed) {\n                if (!!this.serviceEvents) {\n                  this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_24__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                }\n              }\n            } catch (e) {\n              //\n            }\n        }\n        const ret = loop();\n        return ret;\n      } catch (error) {\n        this.terminateMessageLoop = true;\n        communicationCustodian.resolve();\n      }\n    });\n    loop().catch(reason => {\n      _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_26__.BackgroundEvent(reason));\n    });\n    return communicationCustodian.promise;\n  }\n  startMessageLoop() {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.terminateMessageLoop = false;\n      try {\n        yield this.receiveDialogMessageOverride();\n      } catch (error) {\n        yield this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationErrorCode.RuntimeError, error);\n      }\n      return Promise.resolve();\n    });\n  }\n  // Takes an established websocket connection to the endpoint and sends speech configuration information.\n  configConnection(connection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.terminateMessageLoop) {\n        this.terminateMessageLoop = false;\n        return Promise.reject(\"Connection to service terminated.\");\n      }\n      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n      yield this.sendAgentConfig(connection);\n      return connection;\n    });\n  }\n  sendPreAudioMessages() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.fetchConnection();\n      this.addKeywordContextData();\n      yield this.sendSpeechContext(connection, true);\n      yield this.sendAgentContext(connection);\n      yield this.sendWaveHeader(connection);\n    });\n  }\n  sendAgentConfig(connection) {\n    if (this.agentConfig && !this.agentConfigSent) {\n      if (this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Conversation_DialogType) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_27__.DialogServiceConfig.DialogTypes.CustomCommands) {\n        const config = this.agentConfig.get();\n        config.botInfo.commandsCulture = this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_RecoLanguage, \"en-us\");\n        this.agentConfig.set(config);\n      }\n      this.onEvent(new _common_DialogEvents__WEBPACK_IMPORTED_MODULE_28__.SendingAgentContextMessageEvent(this.agentConfig));\n      const agentConfigJson = this.agentConfig.toJsonString();\n      // guard against sending this multiple times on one connection\n      this.agentConfigSent = true;\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, \"agent.config\", this.privRequestSession.requestId, \"application/json\", agentConfigJson));\n    }\n    return;\n  }\n  sendAgentContext(connection) {\n    const guid = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)();\n    const speechActivityTemplate = this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.Conversation_Speech_Activity_Template);\n    const agentContext = {\n      channelData: \"\",\n      context: {\n        interactionId: guid\n      },\n      messagePayload: typeof speechActivityTemplate === undefined ? undefined : speechActivityTemplate,\n      version: 0.5\n    };\n    const agentContextJson = JSON.stringify(agentContext);\n    return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_4__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_5__.MessageType.Text, \"speech.agent.context\", this.privRequestSession.requestId, \"application/json\", agentContextJson));\n  }\n  fireEventForResult(serviceResult, properties) {\n    const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_29__.EnumTranslation.implTranslateRecognitionResult(serviceResult.RecognitionStatus);\n    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, serviceResult.DisplayText, serviceResult.Duration, offset, serviceResult.Language, serviceResult.LanguageDetectionConfidence, undefined, undefined, JSON.stringify(serviceResult), properties);\n    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);\n    return ev;\n  }\n  handleResponseMessage(responseMessage) {\n    // \"response\" messages can contain either \"message\" (activity) or \"MessageStatus\" data. Fire the appropriate\n    // event according to the message type that's specified.\n    const responsePayload = JSON.parse(responseMessage.textBody);\n    switch (responsePayload.messageType.toLowerCase()) {\n      case \"message\":\n        const responseRequestId = responseMessage.requestId.toUpperCase();\n        const activityPayload = _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_30__.ActivityPayloadResponse.fromJSON(responseMessage.textBody);\n        const turn = this.privTurnStateManager.GetTurn(responseRequestId);\n        // update the conversation Id\n        if (activityPayload.conversationId) {\n          const updateAgentConfig = this.agentConfig.get();\n          updateAgentConfig.botInfo.conversationId = activityPayload.conversationId;\n          this.agentConfig.set(updateAgentConfig);\n        }\n        const pullAudioOutputStream = turn.processActivityPayload(activityPayload, _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_31__.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(this.privDialogServiceConnector.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)));\n        const activity = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_32__.ActivityReceivedEventArgs(activityPayload.messagePayload, pullAudioOutputStream);\n        if (!!this.privDialogServiceConnector.activityReceived) {\n          try {\n            this.privDialogServiceConnector.activityReceived(this.privDialogServiceConnector, activity);\n            /* eslint-disable-next-line no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        break;\n      case \"messagestatus\":\n        if (!!this.privDialogServiceConnector.turnStatusReceived) {\n          try {\n            this.privDialogServiceConnector.turnStatusReceived(this.privDialogServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_33__.TurnStatusReceivedEventArgs(responseMessage.textBody));\n            /* eslint-disable-next-line no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        break;\n      default:\n        _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_26__.BackgroundEvent(`Unexpected response of type ${responsePayload.messageType}. Ignoring.`));\n        break;\n    }\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_25__.Events.instance.onEvent(event);\n  }\n  addKeywordContextData() {\n    const keywordPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect\");\n    if (keywordPropertyValue === undefined) {\n      return;\n    }\n    const keywordOffsetPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect-Offsets\");\n    const keywordDurationPropertyValue = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-KeywordsToDetect-Durations\");\n    const keywords = keywordPropertyValue.split(\";\");\n    const keywordOffsets = keywordOffsetPropertyValue === undefined ? [] : keywordOffsetPropertyValue.split(\";\");\n    const keywordDurations = keywordDurationPropertyValue === undefined ? [] : keywordDurationPropertyValue.split(\";\");\n    const keywordDefinitionArray = [];\n    for (let i = 0; i < keywords.length; i++) {\n      const definition = {};\n      definition.text = keywords[i];\n      if (i < keywordOffsets.length) {\n        definition.offset = Number(keywordOffsets[i]);\n      }\n      if (i < keywordDurations.length) {\n        definition.duration = Number(keywordDurations[i]);\n      }\n      keywordDefinitionArray.push(definition);\n    }\n    this.speechContext.setSection(\"invocationSource\", \"VoiceActivationWithKeyword\");\n    this.speechContext.setSection(\"keywordDetection\", [{\n      clientDetectedKeywords: keywordDefinitionArray,\n      onReject: {\n        action: \"EndOfTurn\"\n      },\n      type: \"startTrigger\"\n    }]);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceTurnState\": () => (/* binding */ DialogServiceTurnState)\n/* harmony export */ });\n/* harmony import */ var _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ServiceMessages/ActivityResponsePayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass DialogServiceTurnState {\n  constructor(manager, requestId) {\n    this.privRequestId = requestId;\n    this.privIsCompleted = false;\n    this.privAudioStream = null;\n    this.privTurnManager = manager;\n    this.resetTurnEndTimeout();\n  }\n  get audioStream() {\n    // Called when is needed to stream.\n    this.resetTurnEndTimeout();\n    return this.privAudioStream;\n  }\n  processActivityPayload(payload, audioFormat) {\n    if (payload.messageDataStreamType === _ServiceMessages_ActivityResponsePayload__WEBPACK_IMPORTED_MODULE_0__.MessageDataStreamType.TextToSpeechAudio) {\n      this.privAudioStream = _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_1__.AudioOutputStream.createPullStream();\n      this.privAudioStream.format = audioFormat !== undefined ? audioFormat : _sdk_Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__.AudioOutputFormatImpl.getDefaultOutputFormat();\n    }\n    return this.privAudioStream;\n  }\n  endAudioStream() {\n    if (this.privAudioStream !== null && !this.privAudioStream.isClosed) {\n      this.privAudioStream.close();\n    }\n  }\n  complete() {\n    if (this.privTimeoutToken !== undefined) {\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n      clearTimeout(this.privTimeoutToken);\n    }\n    this.endAudioStream();\n  }\n  resetTurnEndTimeout() {\n    if (this.privTimeoutToken !== undefined) {\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n      clearTimeout(this.privTimeoutToken);\n    }\n    this.privTimeoutToken = setTimeout(() => {\n      this.privTurnManager.CompleteTurn(this.privRequestId);\n      return;\n    }, 2000);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceTurnStateManager\": () => (/* binding */ DialogServiceTurnStateManager)\n/* harmony export */ });\n/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DialogServiceTurnState */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnState.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass DialogServiceTurnStateManager {\n  constructor() {\n    this.privTurnMap = new Map();\n    return;\n  }\n  StartTurn(id) {\n    if (this.privTurnMap.has(id)) {\n      throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Service error: There is already a turn with id:\" + id);\n    }\n    const turnState = new _DialogServiceTurnState__WEBPACK_IMPORTED_MODULE_1__.DialogServiceTurnState(this, id);\n    this.privTurnMap.set(id, turnState);\n    return this.privTurnMap.get(id);\n  }\n  GetTurn(id) {\n    return this.privTurnMap.get(id);\n  }\n  CompleteTurn(id) {\n    if (!this.privTurnMap.has(id)) {\n      throw new _common_Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Service error: Received turn end for an unknown turn id:\" + id);\n    }\n    const turnState = this.privTurnMap.get(id);\n    turnState.complete();\n    this.privTurnMap.delete(id);\n    return turnState;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceTurnStateManager.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DynamicGrammarBuilder\": () => (/* binding */ DynamicGrammarBuilder)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Responsible for building the object to be sent to the speech service to support dynamic grammars.\n * @class DynamicGrammarBuilder\n */\nclass DynamicGrammarBuilder {\n  // Adds one more reference phrases to the dynamic grammar to send.\n  // All added phrases are generic phrases.\n  addPhrase(phrase) {\n    if (!this.privPhrases) {\n      this.privPhrases = [];\n    }\n    if (phrase instanceof Array) {\n      this.privPhrases = this.privPhrases.concat(phrase);\n    } else {\n      this.privPhrases.push(phrase);\n    }\n  }\n  // Clears all phrases stored in the current object.\n  clearPhrases() {\n    this.privPhrases = undefined;\n  }\n  // Adds one or more reference grammars to the current grammar.\n  addReferenceGrammar(grammar) {\n    if (!this.privGrammars) {\n      this.privGrammars = [];\n    }\n    if (grammar instanceof Array) {\n      this.privGrammars = this.privGrammars.concat(grammar);\n    } else {\n      this.privGrammars.push(grammar);\n    }\n  }\n  // clears all grammars stored on the recognizer.\n  clearGrammars() {\n    this.privGrammars = undefined;\n  }\n  // Generates an object that represents the dynamic grammar used by the Speech Service.\n  // This is done by building an object with the correct layout based on the phrases and reference grammars added to this instance\n  // of a DynamicGrammarBuilder\n  generateGrammarObject() {\n    if (this.privGrammars === undefined && this.privPhrases === undefined) {\n      return undefined;\n    }\n    const retObj = {};\n    retObj.ReferenceGrammars = this.privGrammars;\n    if (undefined !== this.privPhrases && 0 !== this.privPhrases.length) {\n      const retPhrases = [];\n      this.privPhrases.forEach(value => {\n        retPhrases.push({\n          Text: value\n        });\n      });\n      retObj.Groups = [{\n        Type: \"Generic\",\n        Items: retPhrases\n      }];\n    }\n    return retObj;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js ***!
  \**************************************************************************************************************************/
/***/ (() => {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EnumTranslation\": () => (/* binding */ EnumTranslation)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass EnumTranslation {\n  static implTranslateRecognitionResult(recognitionStatus) {\n    let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled;\n    switch (recognitionStatus) {\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Success:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeech;\n        break;\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.NoMatch:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.InitialSilenceTimeout:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BabbleTimeout:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.EndOfDictation:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.NoMatch;\n        break;\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:\n      default:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled;\n        break;\n    }\n    return reason;\n  }\n  static implTranslateCancelResult(recognitionStatus) {\n    let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.EndOfStream;\n    switch (recognitionStatus) {\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Success:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.EndOfDictation:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.NoMatch:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.EndOfStream;\n        break;\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.InitialSilenceTimeout:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BabbleTimeout:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:\n      default:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.Error;\n        break;\n    }\n    return reason;\n  }\n  static implTranslateCancelErrorCode(recognitionStatus) {\n    let reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;\n    switch (recognitionStatus) {\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Error:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.ServiceError;\n        break;\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.TooManyRequests:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.TooManyRequests;\n        break;\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.BadRequest:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.BadRequestParameters;\n        break;\n      case _Exports__WEBPACK_IMPORTED_MODULE_1__.RecognitionStatus.Forbidden:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.Forbidden;\n        break;\n      default:\n        reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;\n        break;\n    }\n    return reason;\n  }\n  static implTranslateErrorDetails(cancellationErrorCode) {\n    let errorDetails = \"The speech service encountered an internal error and could not continue.\";\n    switch (cancellationErrorCode) {\n      case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.Forbidden:\n        errorDetails = \"The recognizer is using a free subscription that ran out of quota.\";\n        break;\n      case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.BadRequestParameters:\n        errorDetails = \"Invalid parameter or unsupported audio format in the request.\";\n        break;\n      case _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.TooManyRequests:\n        errorDetails = \"The number of parallel requests exceeded the number of allowed concurrent transcriptions.\";\n        break;\n      default:\n        break;\n    }\n    return errorDetails;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AddedLmIntent\": () => (/* reexport safe */ _AddedLmIntent__WEBPACK_IMPORTED_MODULE_28__.AddedLmIntent),\n/* harmony export */   \"AgentConfig\": () => (/* reexport safe */ _AgentConfig__WEBPACK_IMPORTED_MODULE_36__.AgentConfig),\n/* harmony export */   \"AuthInfo\": () => (/* reexport safe */ _IAuthentication__WEBPACK_IMPORTED_MODULE_2__.AuthInfo),\n/* harmony export */   \"AutoDetectSourceLanguagesOpenRangeOptionName\": () => (/* binding */ AutoDetectSourceLanguagesOpenRangeOptionName),\n/* harmony export */   \"CancellationErrorCodePropertyName\": () => (/* binding */ CancellationErrorCodePropertyName),\n/* harmony export */   \"CognitiveSubscriptionKeyAuthentication\": () => (/* reexport safe */ _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__.CognitiveSubscriptionKeyAuthentication),\n/* harmony export */   \"CognitiveTokenAuthentication\": () => (/* reexport safe */ _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__.CognitiveTokenAuthentication),\n/* harmony export */   \"ConnectingToServiceEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.ConnectingToServiceEvent),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.Context),\n/* harmony export */   \"ConversationConnectionConfig\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ConversationConnectionConfig),\n/* harmony export */   \"ConversationManager\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ConversationManager),\n/* harmony export */   \"ConversationReceivedTranslationEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ConversationReceivedTranslationEventArgs),\n/* harmony export */   \"ConversationRecognizerFactory\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ConversationRecognizerFactory),\n/* harmony export */   \"ConversationTranslatorCommandTypes\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ConversationTranslatorCommandTypes),\n/* harmony export */   \"ConversationTranslatorMessageTypes\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ConversationTranslatorMessageTypes),\n/* harmony export */   \"DetailedSpeechPhrase\": () => (/* reexport safe */ _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_26__.DetailedSpeechPhrase),\n/* harmony export */   \"Device\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.Device),\n/* harmony export */   \"DialogServiceAdapter\": () => (/* reexport safe */ _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_35__.DialogServiceAdapter),\n/* harmony export */   \"DynamicGrammarBuilder\": () => (/* reexport safe */ _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_33__.DynamicGrammarBuilder),\n/* harmony export */   \"EnumTranslation\": () => (/* reexport safe */ _EnumTranslation__WEBPACK_IMPORTED_MODULE_15__.EnumTranslation),\n/* harmony export */   \"ForceDictationPropertyName\": () => (/* binding */ ForceDictationPropertyName),\n/* harmony export */   \"IntentConnectionFactory\": () => (/* reexport safe */ _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__.IntentConnectionFactory),\n/* harmony export */   \"IntentResponse\": () => (/* reexport safe */ _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_30__.IntentResponse),\n/* harmony export */   \"IntentServiceRecognizer\": () => (/* reexport safe */ _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_29__.IntentServiceRecognizer),\n/* harmony export */   \"InternalParticipants\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.InternalParticipants),\n/* harmony export */   \"ListeningStartedEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.ListeningStartedEvent),\n/* harmony export */   \"LockRoomEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.LockRoomEventArgs),\n/* harmony export */   \"MetadataType\": () => (/* reexport safe */ _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__.MetadataType),\n/* harmony export */   \"MuteAllEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.MuteAllEventArgs),\n/* harmony export */   \"OS\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.OS),\n/* harmony export */   \"OutputFormatPropertyName\": () => (/* binding */ OutputFormatPropertyName),\n/* harmony export */   \"ParticipantAttributeEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ParticipantAttributeEventArgs),\n/* harmony export */   \"ParticipantEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ParticipantEventArgs),\n/* harmony export */   \"ParticipantsListEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.ParticipantsListEventArgs),\n/* harmony export */   \"RecognitionCompletionStatus\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionCompletionStatus),\n/* harmony export */   \"RecognitionEndedEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionEndedEvent),\n/* harmony export */   \"RecognitionMode\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.RecognitionMode),\n/* harmony export */   \"RecognitionStartedEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionStartedEvent),\n/* harmony export */   \"RecognitionStatus\": () => (/* reexport safe */ _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__.RecognitionStatus),\n/* harmony export */   \"RecognitionTriggeredEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.RecognitionTriggeredEvent),\n/* harmony export */   \"RecognizerConfig\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.RecognizerConfig),\n/* harmony export */   \"RequestSession\": () => (/* reexport safe */ _RequestSession__WEBPACK_IMPORTED_MODULE_31__.RequestSession),\n/* harmony export */   \"ServicePropertiesPropertyName\": () => (/* binding */ ServicePropertiesPropertyName),\n/* harmony export */   \"ServiceRecognizerBase\": () => (/* reexport safe */ _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__.ServiceRecognizerBase),\n/* harmony export */   \"SimpleSpeechPhrase\": () => (/* reexport safe */ _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__.SimpleSpeechPhrase),\n/* harmony export */   \"SpeakerIdMessageAdapter\": () => (/* reexport safe */ _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_45__.SpeakerIdMessageAdapter),\n/* harmony export */   \"SpeakerRecognitionConfig\": () => (/* reexport safe */ _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_44__.SpeakerRecognitionConfig),\n/* harmony export */   \"SpeechConnectionFactory\": () => (/* reexport safe */ _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_11__.SpeechConnectionFactory),\n/* harmony export */   \"SpeechContext\": () => (/* reexport safe */ _SpeechContext__WEBPACK_IMPORTED_MODULE_32__.SpeechContext),\n/* harmony export */   \"SpeechDetected\": () => (/* reexport safe */ _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_21__.SpeechDetected),\n/* harmony export */   \"SpeechHypothesis\": () => (/* reexport safe */ _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_22__.SpeechHypothesis),\n/* harmony export */   \"SpeechKeyword\": () => (/* reexport safe */ _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_23__.SpeechKeyword),\n/* harmony export */   \"SpeechRecognitionEvent\": () => (/* reexport safe */ _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEvent),\n/* harmony export */   \"SpeechResultFormat\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.SpeechResultFormat),\n/* harmony export */   \"SpeechServiceConfig\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.SpeechServiceConfig),\n/* harmony export */   \"SpeechServiceRecognizer\": () => (/* reexport safe */ _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_24__.SpeechServiceRecognizer),\n/* harmony export */   \"SpeechSynthesisConnectionFactory\": () => (/* reexport safe */ _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_14__.SpeechSynthesisConnectionFactory),\n/* harmony export */   \"SynthesisAdapterBase\": () => (/* reexport safe */ _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_40__.SynthesisAdapterBase),\n/* harmony export */   \"SynthesisAudioMetadata\": () => (/* reexport safe */ _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__.SynthesisAudioMetadata),\n/* harmony export */   \"SynthesisContext\": () => (/* reexport safe */ _SynthesisContext__WEBPACK_IMPORTED_MODULE_43__.SynthesisContext),\n/* harmony export */   \"SynthesisRestAdapter\": () => (/* reexport safe */ _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_41__.SynthesisRestAdapter),\n/* harmony export */   \"SynthesisServiceType\": () => (/* reexport safe */ _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_42__.SynthesisServiceType),\n/* harmony export */   \"SynthesisStatus\": () => (/* reexport safe */ _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__.SynthesisStatus),\n/* harmony export */   \"SynthesisTurn\": () => (/* reexport safe */ _SynthesisTurn__WEBPACK_IMPORTED_MODULE_39__.SynthesisTurn),\n/* harmony export */   \"SynthesizerConfig\": () => (/* reexport safe */ _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_42__.SynthesizerConfig),\n/* harmony export */   \"System\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.System),\n/* harmony export */   \"TranscriberConnectionFactory\": () => (/* reexport safe */ _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_12__.TranscriberConnectionFactory),\n/* harmony export */   \"TranscriberRecognizer\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__.TranscriberRecognizer),\n/* harmony export */   \"TranscriptionServiceRecognizer\": () => (/* reexport safe */ _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__.TranscriptionServiceRecognizer),\n/* harmony export */   \"TranslationConnectionFactory\": () => (/* reexport safe */ _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_13__.TranslationConnectionFactory),\n/* harmony export */   \"TranslationHypothesis\": () => (/* reexport safe */ _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_18__.TranslationHypothesis),\n/* harmony export */   \"TranslationPhrase\": () => (/* reexport safe */ _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_19__.TranslationPhrase),\n/* harmony export */   \"TranslationServiceRecognizer\": () => (/* reexport safe */ _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_20__.TranslationServiceRecognizer),\n/* harmony export */   \"TranslationSynthesisEnd\": () => (/* reexport safe */ _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_17__.TranslationSynthesisEnd),\n/* harmony export */   \"WebsocketMessageFormatter\": () => (/* reexport safe */ _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_10__.WebsocketMessageFormatter),\n/* harmony export */   \"connectivity\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.connectivity),\n/* harmony export */   \"type\": () => (/* reexport safe */ _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__.type)\n/* harmony export */ });\n/* harmony import */ var _CognitiveSubscriptionKeyAuthentication__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CognitiveSubscriptionKeyAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\");\n/* harmony import */ var _CognitiveTokenAuthentication__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./CognitiveTokenAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _IAuthentication__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IAuthentication */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js\");\n/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./IConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js\");\n/* harmony import */ var _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _IConnectionFactory__WEBPACK_IMPORTED_MODULE_3__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ISynthesisConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js\");\n/* harmony import */ var _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _ISynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_4__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _IntentConnectionFactory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./IntentConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n/* harmony import */ var _ServiceRecognizerBase__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./ServiceRecognizerBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _RecognizerConfig__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./RecognizerConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./SpeechServiceInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js\");\n/* harmony import */ var _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9___default = /*#__PURE__*/__webpack_require__.n(_SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"IntentConnectionFactory\",\"ConnectingToServiceEvent\",\"ListeningStartedEvent\",\"RecognitionCompletionStatus\",\"RecognitionEndedEvent\",\"RecognitionStartedEvent\",\"RecognitionTriggeredEvent\",\"SpeechRecognitionEvent\",\"ServiceRecognizerBase\",\"Context\",\"Device\",\"OS\",\"RecognitionMode\",\"RecognizerConfig\",\"SpeechResultFormat\",\"SpeechServiceConfig\",\"System\",\"connectivity\",\"type\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _SpeechServiceInterfaces__WEBPACK_IMPORTED_MODULE_9__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _WebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./WebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _SpeechConnectionFactory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./SpeechConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js\");\n/* harmony import */ var _TranscriberConnectionFactory__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./TranscriberConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js\");\n/* harmony import */ var _TranslationConnectionFactory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./TranslationConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js\");\n/* harmony import */ var _SpeechSynthesisConnectionFactory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./SpeechSynthesisConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js\");\n/* harmony import */ var _EnumTranslation__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./EnumTranslation */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _ServiceMessages_Enums__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./ServiceMessages/Enums */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _ServiceMessages_TranslationSynthesisEnd__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./ServiceMessages/TranslationSynthesisEnd */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js\");\n/* harmony import */ var _ServiceMessages_TranslationHypothesis__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./ServiceMessages/TranslationHypothesis */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js\");\n/* harmony import */ var _ServiceMessages_TranslationPhrase__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./ServiceMessages/TranslationPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js\");\n/* harmony import */ var _TranslationServiceRecognizer__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js\");\n/* harmony import */ var _ServiceMessages_SpeechDetected__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./ServiceMessages/SpeechDetected */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony import */ var _ServiceMessages_SpeechHypothesis__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ServiceMessages/SpeechHypothesis */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _ServiceMessages_SpeechKeyword__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./ServiceMessages/SpeechKeyword */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js\");\n/* harmony import */ var _SpeechServiceRecognizer__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js\");\n/* harmony import */ var _TranscriptionServiceRecognizer__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./TranscriptionServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js\");\n/* harmony import */ var _ServiceMessages_DetailedSpeechPhrase__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./ServiceMessages/DetailedSpeechPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n/* harmony import */ var _ServiceMessages_SimpleSpeechPhrase__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./ServiceMessages/SimpleSpeechPhrase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _AddedLmIntent__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./AddedLmIntent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js\");\n/* harmony import */ var _IntentServiceRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentServiceRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js\");\n/* harmony import */ var _ServiceMessages_IntentResponse__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./ServiceMessages/IntentResponse */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js\");\n/* harmony import */ var _RequestSession__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./RequestSession */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js\");\n/* harmony import */ var _SpeechContext__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./SpeechContext */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js\");\n/* harmony import */ var _DynamicGrammarBuilder__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./DynamicGrammarBuilder */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js\");\n/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./DynamicGrammarInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarInterfaces.js\");\n/* harmony import */ var _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34___default = /*#__PURE__*/__webpack_require__.n(_DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__);\n/* harmony reexport (unknown) */ var __WEBPACK_REEXPORT_OBJECT__ = {};\n/* harmony reexport (unknown) */ for(const __WEBPACK_IMPORT_KEY__ in _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__) if([\"default\",\"OutputFormatPropertyName\",\"CancellationErrorCodePropertyName\",\"ServicePropertiesPropertyName\",\"ForceDictationPropertyName\",\"AutoDetectSourceLanguagesOpenRangeOptionName\",\"CognitiveSubscriptionKeyAuthentication\",\"CognitiveTokenAuthentication\",\"AuthInfo\",\"IntentConnectionFactory\",\"ConnectingToServiceEvent\",\"ListeningStartedEvent\",\"RecognitionCompletionStatus\",\"RecognitionEndedEvent\",\"RecognitionStartedEvent\",\"RecognitionTriggeredEvent\",\"SpeechRecognitionEvent\",\"ServiceRecognizerBase\",\"Context\",\"Device\",\"OS\",\"RecognitionMode\",\"RecognizerConfig\",\"SpeechResultFormat\",\"SpeechServiceConfig\",\"System\",\"connectivity\",\"type\",\"WebsocketMessageFormatter\",\"SpeechConnectionFactory\",\"TranscriberConnectionFactory\",\"TranslationConnectionFactory\",\"SpeechSynthesisConnectionFactory\",\"EnumTranslation\",\"RecognitionStatus\",\"SynthesisStatus\",\"TranslationSynthesisEnd\",\"TranslationHypothesis\",\"TranslationPhrase\",\"TranslationServiceRecognizer\",\"SpeechDetected\",\"SpeechHypothesis\",\"SpeechKeyword\",\"SpeechServiceRecognizer\",\"TranscriptionServiceRecognizer\",\"DetailedSpeechPhrase\",\"SimpleSpeechPhrase\",\"AddedLmIntent\",\"IntentServiceRecognizer\",\"IntentResponse\",\"RequestSession\",\"SpeechContext\",\"DynamicGrammarBuilder\"].indexOf(__WEBPACK_IMPORT_KEY__) < 0) __WEBPACK_REEXPORT_OBJECT__[__WEBPACK_IMPORT_KEY__] = () => _DynamicGrammarInterfaces__WEBPACK_IMPORTED_MODULE_34__[__WEBPACK_IMPORT_KEY__]\n/* harmony reexport (unknown) */ __webpack_require__.d(__webpack_exports__, __WEBPACK_REEXPORT_OBJECT__);\n/* harmony import */ var _DialogServiceAdapter__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./DialogServiceAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js\");\n/* harmony import */ var _AgentConfig__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./AgentConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js\");\n/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SynthesisTurn__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./SynthesisTurn */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js\");\n/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./SynthesisAdapterBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _SynthesisRestAdapter__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./SynthesisRestAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js\");\n/* harmony import */ var _SynthesizerConfig__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./SynthesizerConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js\");\n/* harmony import */ var _SynthesisContext__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./SynthesisContext */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js\");\n/* harmony import */ var _SpeakerRecognitionConfig__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./SpeakerRecognitionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js\");\n/* harmony import */ var _SpeakerIdMessageAdapter__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./SpeakerIdMessageAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Make sure not to export internal modules.\n//\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst OutputFormatPropertyName = \"OutputFormat\";\nconst CancellationErrorCodePropertyName = \"CancellationErrorCode\";\nconst ServicePropertiesPropertyName = \"ServiceProperties\";\nconst ForceDictationPropertyName = \"ForceDictation\";\nconst AutoDetectSourceLanguagesOpenRangeOptionName = \"OpenRange\";\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"HeaderNames\": () => (/* binding */ HeaderNames)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass HeaderNames {}\nHeaderNames.AuthKey = \"Ocp-Apim-Subscription-Key\";\nHeaderNames.Authorization = \"Authorization\";\nHeaderNames.ConnectionId = \"X-ConnectionId\";\nHeaderNames.ContentType = \"Content-Type\";\nHeaderNames.CustomCommandsAppId = \"X-CommandsAppId\";\nHeaderNames.Path = \"Path\";\nHeaderNames.RequestId = \"X-RequestId\";\nHeaderNames.RequestStreamId = \"X-StreamId\";\nHeaderNames.RequestTimestamp = \"X-Timestamp\";\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AuthInfo\": () => (/* binding */ AuthInfo)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass AuthInfo {\n  constructor(headerName, token) {\n    this.privHeaderName = headerName;\n    this.privToken = token;\n  }\n  get headerName() {\n    return this.privHeaderName;\n  }\n  get token() {\n    return this.privToken;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IAuthentication.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js ***!
  \********************************************************************************************************************/
/***/ (() => {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js ***!
  \*****************************************************************************************************************************/
/***/ (() => {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ISynthesisConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentConnectionFactory\": () => (/* binding */ IntentConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\nclass IntentConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n  create(config, authInfo, connectionId) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint);\n    if (!endpoint) {\n      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion);\n      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n      const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".sr.speech\" + hostSuffix);\n      endpoint = host + \"/speech/recognition/interactive/cognitiveservices/v1\";\n    }\n    const queryParams = {\n      format: \"simple\",\n      language: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage)\n    };\n    this.setCommonUrlParams(config, queryParams, endpoint);\n    const headers = {};\n    if (authInfo.token !== undefined && authInfo.token !== \"\") {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;\n    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n  getSpeechRegionFromIntentRegion(intentRegion) {\n    switch (intentRegion) {\n      case \"West US\":\n      case \"US West\":\n      case \"westus\":\n        return \"uswest\";\n      case \"West US 2\":\n      case \"US West 2\":\n      case \"westus2\":\n        return \"uswest2\";\n      case \"South Central US\":\n      case \"US South Central\":\n      case \"southcentralus\":\n        return \"ussouthcentral\";\n      case \"West Central US\":\n      case \"US West Central\":\n      case \"westcentralus\":\n        return \"uswestcentral\";\n      case \"East US\":\n      case \"US East\":\n      case \"eastus\":\n        return \"useast\";\n      case \"East US 2\":\n      case \"US East 2\":\n      case \"eastus2\":\n        return \"useast2\";\n      case \"West Europe\":\n      case \"Europe West\":\n      case \"westeurope\":\n        return \"europewest\";\n      case \"North Europe\":\n      case \"Europe North\":\n      case \"northeurope\":\n        return \"europenorth\";\n      case \"Brazil South\":\n      case \"South Brazil\":\n      case \"southbrazil\":\n        return \"brazilsouth\";\n      case \"Australia East\":\n      case \"East Australia\":\n      case \"eastaustralia\":\n        return \"australiaeast\";\n      case \"Southeast Asia\":\n      case \"Asia Southeast\":\n      case \"southeastasia\":\n        return \"asiasoutheast\";\n      case \"East Asia\":\n      case \"Asia East\":\n      case \"eastasia\":\n        return \"asiaeast\";\n      default:\n        return intentRegion;\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentServiceRecognizer\": () => (/* binding */ IntentServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass IntentServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, recognizer);\n    this.privIntentRecognizer = recognizer;\n    this.privIntentDataSent = false;\n  }\n  setIntents(addedIntents, umbrellaIntent) {\n    this.privAddedLmIntents = addedIntents;\n    this.privUmbrellaIntent = umbrellaIntent;\n    this.privIntentDataSent = true;\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    let result;\n    let ev;\n    let processed = false;\n    const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n    if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_2__.MessageType.Text) {\n      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n    }\n    switch (connectionMessage.path.toLowerCase()) {\n      case \"speech.hypothesis\":\n        const speechHypothesis = _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.RecognizingIntent, speechHypothesis.Text, speechHypothesis.Duration, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, speechHypothesis.Language, speechHypothesis.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);\n        this.privRequestSession.onHypothesis(result.offset);\n        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(result, speechHypothesis.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n        if (!!this.privIntentRecognizer.recognizing) {\n          try {\n            this.privIntentRecognizer.recognizing(this.privIntentRecognizer, ev);\n            /* eslint-disable no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        processed = true;\n        break;\n      case \"speech.phrase\":\n        const simple = _Exports__WEBPACK_IMPORTED_MODULE_8__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n        result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined, this.privRequestSession.requestId, _Exports__WEBPACK_IMPORTED_MODULE_9__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus), simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined, connectionMessage.textBody, resultProps);\n        ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n        const sendEvent = () => {\n          if (!!this.privIntentRecognizer.recognized) {\n            try {\n              this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n          // report result to promise.\n          if (!!this.privSuccessCallback) {\n            try {\n              this.privSuccessCallback(result);\n            } catch (e) {\n              if (!!this.privErrorCallback) {\n                this.privErrorCallback(e);\n              }\n            }\n            // Only invoke the call back once.\n            // and if it's successful don't invoke the\n            // error after that.\n            this.privSuccessCallback = undefined;\n            this.privErrorCallback = undefined;\n          }\n        };\n        // If intent data was sent, the terminal result for this recognizer is an intent being found.\n        // If no intent data was sent, the terminal event is speech recognition being successful.\n        if (false === this.privIntentDataSent || _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.NoMatch === ev.result.reason) {\n          // Advance the buffers.\n          this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n          sendEvent();\n        } else {\n          // Squirrel away the args, when the response event arrives it will build upon them\n          // and then return\n          this.privPendingIntentArgs = ev;\n        }\n        processed = true;\n        break;\n      case \"response\":\n        // Response from LUIS\n        ev = this.privPendingIntentArgs;\n        this.privPendingIntentArgs = undefined;\n        if (undefined === ev) {\n          if (\"\" === connectionMessage.textBody) {\n            // This condition happens if there is nothing but silence in the\n            // audio sent to the service.\n            return;\n          }\n          // Odd... Not sure this can happen\n          ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(), 0, this.privRequestSession.sessionId);\n        }\n        const intentResponse = _Exports__WEBPACK_IMPORTED_MODULE_10__.IntentResponse.fromJSON(connectionMessage.textBody);\n        // If LUIS didn't return anything, send the existing event, else\n        // modify it to show the match.\n        // See if the intent found is in the list of intents asked for.\n        if (null !== intentResponse && !!intentResponse.topScoringIntent && !!intentResponse.topScoringIntent.intent) {\n          let addedIntent = this.privAddedLmIntents[intentResponse.topScoringIntent.intent];\n          if (this.privUmbrellaIntent !== undefined) {\n            addedIntent = this.privUmbrellaIntent;\n          }\n          if (!!addedIntent) {\n            const intentId = addedIntent === undefined || addedIntent.intentName === undefined ? intentResponse.topScoringIntent.intent : addedIntent.intentName;\n            let reason = ev.result.reason;\n            if (undefined !== intentId) {\n              reason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.RecognizedIntent;\n            }\n            // make sure, properties is set.\n            const properties = undefined !== ev.result.properties ? ev.result.properties : new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n            properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.LanguageUnderstandingServiceResponse_JsonResult, connectionMessage.textBody);\n            ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentRecognitionEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(intentId, ev.result.resultId, reason, ev.result.text, ev.result.duration, ev.result.offset, undefined, undefined, ev.result.errorDetails, ev.result.json, properties), ev.offset, ev.sessionId);\n          }\n        }\n        this.privRequestSession.onPhraseRecognized(ev.offset + ev.result.duration);\n        if (!!this.privIntentRecognizer.recognized) {\n          try {\n            this.privIntentRecognizer.recognized(this.privIntentRecognizer, ev);\n            /* eslint-disable no-empty */\n          } catch (error) {\n            // Not going to let errors in the event handler\n            // trip things up.\n          }\n        }\n        // report result to promise.\n        if (!!this.privSuccessCallback) {\n          try {\n            this.privSuccessCallback(ev.result);\n          } catch (e) {\n            if (!!this.privErrorCallback) {\n              this.privErrorCallback(e);\n            }\n          }\n          // Only invoke the call back once.\n          // and if it's successful don't invoke the\n          // error after that.\n          this.privSuccessCallback = undefined;\n          this.privErrorCallback = undefined;\n        }\n        processed = true;\n        break;\n      default:\n        break;\n    }\n    const defferal = new _common_Exports__WEBPACK_IMPORTED_MODULE_11__.Deferred();\n    defferal.resolve(processed);\n    return defferal.promise;\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_12__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);\n    if (!!this.privIntentRecognizer.canceled) {\n      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.IntentRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, undefined, sessionId);\n      try {\n        this.privIntentRecognizer.canceled(this.privIntentRecognizer, cancelEvent);\n        /* eslint-disable no-empty */\n      } catch (_a) {}\n    }\n    if (!!this.privSuccessCallback) {\n      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.IntentRecognitionResult(undefined,\n      // Intent Id\n      requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.ResultReason.Canceled, undefined,\n      // Text\n      undefined,\n      // Duration\n      undefined,\n      // Offset\n      undefined,\n      // Language\n      undefined,\n      // LanguageDetectionConfidence\n      error, undefined,\n      // Json\n      properties);\n      try {\n        this.privSuccessCallback(result);\n        this.privSuccessCallback = undefined;\n        /* eslint-disable no-empty */\n      } catch (_b) {}\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"QueryParameterNames\": () => (/* binding */ QueryParameterNames)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass QueryParameterNames {}\nQueryParameterNames.BotId = \"botid\";\nQueryParameterNames.CustomSpeechDeploymentId = \"cid\";\nQueryParameterNames.CustomVoiceDeploymentId = \"deploymentId\";\nQueryParameterNames.EnableAudioLogging = \"storeAudio\";\nQueryParameterNames.EnableLanguageId = \"lidEnabled\";\nQueryParameterNames.EnableWordLevelTimestamps = \"wordLevelTimestamps\";\nQueryParameterNames.EndSilenceTimeoutMs = \"endSilenceTimeoutMs\";\nQueryParameterNames.SegmentationSilenceTimeoutMs = \"segmentationSilenceTimeoutMs\";\nQueryParameterNames.Format = \"format\";\nQueryParameterNames.InitialSilenceTimeoutMs = \"initialSilenceTimeoutMs\";\nQueryParameterNames.Language = \"language\";\nQueryParameterNames.Profanity = \"profanity\";\nQueryParameterNames.RequestBotStatusMessages = \"enableBotMessageStatus\";\nQueryParameterNames.StableIntermediateThreshold = \"stableIntermediateThreshold\";\nQueryParameterNames.StableTranslation = \"stableTranslation\";\nQueryParameterNames.TestHooks = \"testhooks\";\nQueryParameterNames.Postprocessing = \"postprocessing\";\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectingToServiceEvent\": () => (/* binding */ ConnectingToServiceEvent),\n/* harmony export */   \"ListeningStartedEvent\": () => (/* binding */ ListeningStartedEvent),\n/* harmony export */   \"RecognitionCompletionStatus\": () => (/* binding */ RecognitionCompletionStatus),\n/* harmony export */   \"RecognitionEndedEvent\": () => (/* binding */ RecognitionEndedEvent),\n/* harmony export */   \"RecognitionStartedEvent\": () => (/* binding */ RecognitionStartedEvent),\n/* harmony export */   \"RecognitionTriggeredEvent\": () => (/* binding */ RecognitionTriggeredEvent),\n/* harmony export */   \"SpeechRecognitionEvent\": () => (/* binding */ SpeechRecognitionEvent)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass SpeechRecognitionEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName, requestId, sessionId) {\n    let eventType = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info;\n    super(eventName, eventType);\n    this.privRequestId = requestId;\n    this.privSessionId = sessionId;\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n  get sessionId() {\n    return this.privSessionId;\n  }\n}\nclass RecognitionTriggeredEvent extends SpeechRecognitionEvent {\n  constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n    super(\"RecognitionTriggeredEvent\", requestId, sessionId);\n    this.privAudioSourceId = audioSourceId;\n    this.privAudioNodeId = audioNodeId;\n  }\n  get audioSourceId() {\n    return this.privAudioSourceId;\n  }\n  get audioNodeId() {\n    return this.privAudioNodeId;\n  }\n}\nclass ListeningStartedEvent extends SpeechRecognitionEvent {\n  constructor(requestId, sessionId, audioSourceId, audioNodeId) {\n    super(\"ListeningStartedEvent\", requestId, sessionId);\n    this.privAudioSourceId = audioSourceId;\n    this.privAudioNodeId = audioNodeId;\n  }\n  get audioSourceId() {\n    return this.privAudioSourceId;\n  }\n  get audioNodeId() {\n    return this.privAudioNodeId;\n  }\n}\nclass ConnectingToServiceEvent extends SpeechRecognitionEvent {\n  constructor(requestId, authFetchEventid, sessionId) {\n    super(\"ConnectingToServiceEvent\", requestId, sessionId);\n    this.privAuthFetchEventid = authFetchEventid;\n  }\n  get authFetchEventid() {\n    return this.privAuthFetchEventid;\n  }\n}\nclass RecognitionStartedEvent extends SpeechRecognitionEvent {\n  constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId) {\n    super(\"RecognitionStartedEvent\", requestId, sessionId);\n    this.privAudioSourceId = audioSourceId;\n    this.privAudioNodeId = audioNodeId;\n    this.privAuthFetchEventId = authFetchEventId;\n  }\n  get audioSourceId() {\n    return this.privAudioSourceId;\n  }\n  get audioNodeId() {\n    return this.privAudioNodeId;\n  }\n  get authFetchEventId() {\n    return this.privAuthFetchEventId;\n  }\n}\nvar RecognitionCompletionStatus;\n(function (RecognitionCompletionStatus) {\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"Success\"] = 0] = \"Success\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceError\"] = 1] = \"AudioSourceError\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"AudioSourceTimeout\"] = 2] = \"AudioSourceTimeout\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchError\"] = 3] = \"AuthTokenFetchError\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"AuthTokenFetchTimeout\"] = 4] = \"AuthTokenFetchTimeout\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnAuthorized\"] = 5] = \"UnAuthorized\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectTimeout\"] = 6] = \"ConnectTimeout\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"ConnectError\"] = 7] = \"ConnectError\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"ClientRecognitionActivityTimeout\"] = 8] = \"ClientRecognitionActivityTimeout\";\n  RecognitionCompletionStatus[RecognitionCompletionStatus[\"UnknownError\"] = 9] = \"UnknownError\";\n})(RecognitionCompletionStatus || (RecognitionCompletionStatus = {}));\nclass RecognitionEndedEvent extends SpeechRecognitionEvent {\n  constructor(requestId, audioSourceId, audioNodeId, authFetchEventId, sessionId, serviceTag, status, error) {\n    super(\"RecognitionEndedEvent\", requestId, sessionId, status === RecognitionCompletionStatus.Success ? _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info : _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n    this.privAudioSourceId = audioSourceId;\n    this.privAudioNodeId = audioNodeId;\n    this.privAuthFetchEventId = authFetchEventId;\n    this.privStatus = status;\n    this.privError = error;\n    this.privServiceTag = serviceTag;\n  }\n  get audioSourceId() {\n    return this.privAudioSourceId;\n  }\n  get audioNodeId() {\n    return this.privAudioNodeId;\n  }\n  get authFetchEventId() {\n    return this.privAuthFetchEventId;\n  }\n  get serviceTag() {\n    return this.privServiceTag;\n  }\n  get status() {\n    return this.privStatus;\n  }\n  get error() {\n    return this.privError;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Context\": () => (/* binding */ Context),\n/* harmony export */   \"Device\": () => (/* binding */ Device),\n/* harmony export */   \"OS\": () => (/* binding */ OS),\n/* harmony export */   \"RecognitionMode\": () => (/* binding */ RecognitionMode),\n/* harmony export */   \"RecognizerConfig\": () => (/* binding */ RecognizerConfig),\n/* harmony export */   \"SpeechResultFormat\": () => (/* binding */ SpeechResultFormat),\n/* harmony export */   \"SpeechServiceConfig\": () => (/* binding */ SpeechServiceConfig),\n/* harmony export */   \"System\": () => (/* binding */ System),\n/* harmony export */   \"connectivity\": () => (/* binding */ connectivity),\n/* harmony export */   \"type\": () => (/* binding */ type)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nvar RecognitionMode;\n(function (RecognitionMode) {\n  RecognitionMode[RecognitionMode[\"Interactive\"] = 0] = \"Interactive\";\n  RecognitionMode[RecognitionMode[\"Conversation\"] = 1] = \"Conversation\";\n  RecognitionMode[RecognitionMode[\"Dictation\"] = 2] = \"Dictation\";\n})(RecognitionMode || (RecognitionMode = {}));\nvar SpeechResultFormat;\n(function (SpeechResultFormat) {\n  SpeechResultFormat[SpeechResultFormat[\"Simple\"] = 0] = \"Simple\";\n  SpeechResultFormat[SpeechResultFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(SpeechResultFormat || (SpeechResultFormat = {}));\nclass RecognizerConfig {\n  constructor(speechServiceConfig, parameters) {\n    this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new SpeechServiceConfig(new Context(null));\n    this.privParameters = parameters;\n    this.privMaxRetryCount = parseInt(parameters.getProperty(\"SPEECH-Error-MaxRetryCount\", \"4\"), 10);\n    this.privLanguageIdPriority = parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority, undefined);\n    this.privLanguageIdMode = this.privLanguageIdPriority === \"Latency\" ? \"DetectContinuous\" : \"DetectAtAudioStart\";\n    if (this.privLanguageIdMode === \"DetectAtAudioStart\") {\n      this.privLanguageIdPriority = parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_AtStartLanguageIdPriority, undefined);\n    }\n  }\n  get parameters() {\n    return this.privParameters;\n  }\n  get recognitionMode() {\n    return this.privRecognitionMode;\n  }\n  set recognitionMode(value) {\n    this.privRecognitionMode = value;\n    this.privRecognitionActivityTimeout = value === RecognitionMode.Interactive ? 8000 : 25000;\n    this.privSpeechServiceConfig.Recognition = RecognitionMode[value];\n  }\n  get SpeechServiceConfig() {\n    return this.privSpeechServiceConfig;\n  }\n  get recognitionActivityTimeout() {\n    return this.privRecognitionActivityTimeout;\n  }\n  get isContinuousRecognition() {\n    return this.privRecognitionMode !== RecognitionMode.Interactive;\n  }\n  get languageIdPriority() {\n    return !!this.privLanguageIdPriority ? `Prioritize${this.privLanguageIdPriority}` : \"\";\n  }\n  get languageIdMode() {\n    return this.privLanguageIdMode;\n  }\n  get autoDetectSourceLanguages() {\n    return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, undefined);\n  }\n  get recognitionEndpointVersion() {\n    return this.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, undefined);\n  }\n  get sourceLanguageModels() {\n    const models = [];\n    let modelsExist = false;\n    if (this.autoDetectSourceLanguages !== undefined) {\n      for (const language of this.autoDetectSourceLanguages.split(\",\")) {\n        const customProperty = language + _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndpointId.toString();\n        const modelId = this.parameters.getProperty(customProperty, undefined);\n        if (modelId !== undefined) {\n          models.push({\n            language,\n            endpoint: modelId\n          });\n          modelsExist = true;\n        } else {\n          models.push({\n            language,\n            endpoint: \"\"\n          });\n        }\n      }\n    }\n    return modelsExist ? models : undefined;\n  }\n  get maxRetryCount() {\n    return this.privMaxRetryCount;\n  }\n}\n// The config is serialized and sent as the Speech.Config\nclass SpeechServiceConfig {\n  constructor(context) {\n    this.context = context;\n  }\n  serialize() {\n    return JSON.stringify(this, (key, value) => {\n      if (value && typeof value === \"object\") {\n        const replacement = {};\n        for (const k in value) {\n          if (Object.hasOwnProperty.call(value, k)) {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n            replacement[k && k.charAt(0).toLowerCase() + k.substring(1)] = value[k];\n          }\n        }\n        return replacement;\n      }\n      return value;\n    });\n  }\n  get Context() {\n    return this.context;\n  }\n  get Recognition() {\n    return this.recognition;\n  }\n  set Recognition(value) {\n    this.recognition = value.toLowerCase();\n  }\n}\nclass Context {\n  constructor(os) {\n    this.system = new System();\n    this.os = os;\n  }\n}\nclass System {\n  constructor() {\n    // Note: below will be patched for official builds.\n    const SPEECHSDK_CLIENTSDK_VERSION = \"1.24.1\";\n    this.name = \"SpeechSDK\";\n    this.version = SPEECHSDK_CLIENTSDK_VERSION;\n    this.build = \"JavaScript\";\n    this.lang = \"JavaScript\";\n  }\n}\nclass OS {\n  constructor(platform, name, version) {\n    this.platform = platform;\n    this.name = name;\n    this.version = version;\n  }\n}\nclass Device {\n  constructor(manufacturer, model, version) {\n    this.manufacturer = manufacturer;\n    this.model = model;\n    this.version = version;\n  }\n}\nvar connectivity;\n(function (connectivity) {\n  connectivity[\"Bluetooth\"] = \"Bluetooth\";\n  connectivity[\"Wired\"] = \"Wired\";\n  connectivity[\"WiFi\"] = \"WiFi\";\n  connectivity[\"Cellular\"] = \"Cellular\";\n  connectivity[\"InBuilt\"] = \"InBuilt\";\n  connectivity[\"Unknown\"] = \"Unknown\";\n})(connectivity || (connectivity = {}));\nvar type;\n(function (type) {\n  type[\"Phone\"] = \"Phone\";\n  type[\"Speaker\"] = \"Speaker\";\n  type[\"Car\"] = \"Car\";\n  type[\"Headset\"] = \"Headset\";\n  type[\"Thermostat\"] = \"Thermostat\";\n  type[\"Microphones\"] = \"Microphones\";\n  type[\"Deskphone\"] = \"Deskphone\";\n  type[\"RemoteControl\"] = \"RemoteControl\";\n  type[\"Unknown\"] = \"Unknown\";\n  type[\"File\"] = \"File\";\n  type[\"Stream\"] = \"Stream\";\n})(type || (type = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RequestSession\": () => (/* binding */ RequestSession)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n/* harmony import */ var _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ServiceTelemetryListener.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\nclass RequestSession {\n  constructor(audioSourceId) {\n    this.privIsDisposed = false;\n    this.privDetachables = new Array();\n    this.privIsAudioNodeDetached = false;\n    this.privIsRecognizing = false;\n    this.privIsSpeechEnded = false;\n    this.privTurnStartAudioOffset = 0;\n    this.privLastRecoOffset = 0;\n    this.privHypothesisReceived = false;\n    this.privBytesSent = 0;\n    this.privRecogNumber = 0;\n    this.privInTurn = false;\n    this.privConnectionAttempts = 0;\n    this.privAudioSourceId = audioSourceId;\n    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privAudioNodeId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    // We're not in a turn, so resolve.\n    this.privTurnDeferral.resolve();\n  }\n  get sessionId() {\n    return this.privSessionId;\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n  get audioNodeId() {\n    return this.privAudioNodeId;\n  }\n  get turnCompletionPromise() {\n    return this.privTurnDeferral.promise;\n  }\n  get isSpeechEnded() {\n    return this.privIsSpeechEnded;\n  }\n  get isRecognizing() {\n    return this.privIsRecognizing;\n  }\n  get currentTurnAudioOffset() {\n    return this.privTurnStartAudioOffset;\n  }\n  get recogNumber() {\n    return this.privRecogNumber;\n  }\n  get numConnectionAttempts() {\n    return this.privConnectionAttempts;\n  }\n  // The number of bytes sent for the current connection.\n  // Counter is reset to 0 each time a connection is established.\n  get bytesSent() {\n    return this.privBytesSent;\n  }\n  listenForServiceTelemetry(eventSource) {\n    if (!!this.privServiceTelemetryListener) {\n      this.privDetachables.push(eventSource.attachListener(this.privServiceTelemetryListener));\n    }\n  }\n  startNewRecognition() {\n    this.privIsSpeechEnded = false;\n    this.privIsRecognizing = true;\n    this.privTurnStartAudioOffset = 0;\n    this.privLastRecoOffset = 0;\n    this.privRecogNumber++;\n    this.privServiceTelemetryListener = new _ServiceTelemetryListener_Internal__WEBPACK_IMPORTED_MODULE_2__.ServiceTelemetryListener(this.privRequestId, this.privAudioSourceId, this.privAudioNodeId);\n    this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.RecognitionTriggeredEvent(this.requestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n  }\n  onAudioSourceAttachCompleted(audioNode, isError) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privAudioNode = audioNode;\n      this.privIsAudioNodeDetached = false;\n      if (isError) {\n        yield this.onComplete();\n      } else {\n        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.ListeningStartedEvent(this.privRequestId, this.privSessionId, this.privAudioSourceId, this.privAudioNodeId));\n      }\n    });\n  }\n  onPreConnectionStart(authFetchEventId, connectionId) {\n    this.privAuthFetchEventId = authFetchEventId;\n    this.privSessionId = connectionId;\n    this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.ConnectingToServiceEvent(this.privRequestId, this.privAuthFetchEventId, this.privSessionId));\n  }\n  onAuthCompleted(isError) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (isError) {\n        yield this.onComplete();\n      }\n    });\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  onConnectionEstablishCompleted(statusCode, reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (statusCode === 200) {\n        this.onEvent(new _RecognitionEvents__WEBPACK_IMPORTED_MODULE_3__.RecognitionStartedEvent(this.requestId, this.privAudioSourceId, this.privAudioNodeId, this.privAuthFetchEventId, this.privSessionId));\n        if (!!this.privAudioNode) {\n          this.privAudioNode.replay();\n        }\n        this.privTurnStartAudioOffset = this.privLastRecoOffset;\n        this.privBytesSent = 0;\n        return;\n      } else if (statusCode === 403) {\n        yield this.onComplete();\n      }\n    });\n  }\n  onServiceTurnEndResponse(continuousRecognition) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privTurnDeferral.resolve();\n      if (!continuousRecognition || this.isSpeechEnded) {\n        yield this.onComplete();\n        this.privInTurn = false;\n      } else {\n        // Start a new request set.\n        this.privTurnStartAudioOffset = this.privLastRecoOffset;\n        this.privAudioNode.replay();\n      }\n    });\n  }\n  onSpeechContext() {\n    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n  }\n  onServiceTurnStartResponse() {\n    if (!!this.privTurnDeferral && !!this.privInTurn) {\n      // What? How are we starting a turn with another not done?\n      this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n      // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n      this.privTurnDeferral.promise.then().catch(() => {});\n    }\n    this.privInTurn = true;\n    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n  }\n  onHypothesis(offset) {\n    if (!this.privHypothesisReceived) {\n      this.privHypothesisReceived = true;\n      this.privServiceTelemetryListener.hypothesisReceived(this.privAudioNode.findTimeAtOffset(offset));\n    }\n  }\n  onPhraseRecognized(offset) {\n    this.privServiceTelemetryListener.phraseReceived(this.privAudioNode.findTimeAtOffset(offset));\n    this.onServiceRecognized(offset);\n  }\n  onServiceRecognized(offset) {\n    this.privLastRecoOffset = offset;\n    this.privHypothesisReceived = false;\n    this.privAudioNode.shrinkBuffers(offset);\n    this.privConnectionAttempts = 0;\n  }\n  onAudioSent(bytesSent) {\n    this.privBytesSent += bytesSent;\n  }\n  onRetryConnection() {\n    this.privConnectionAttempts++;\n  }\n  dispose() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privIsDisposed) {\n        // we should have completed by now. If we did not its an unknown error.\n        this.privIsDisposed = true;\n        for (const detachable of this.privDetachables) {\n          yield detachable.detach();\n        }\n        if (!!this.privServiceTelemetryListener) {\n          this.privServiceTelemetryListener.dispose();\n        }\n        this.privIsRecognizing = false;\n      }\n    });\n  }\n  getTelemetry() {\n    if (this.privServiceTelemetryListener.hasTelemetry) {\n      return this.privServiceTelemetryListener.getTelemetry();\n    } else {\n      return null;\n    }\n  }\n  onStopRecognizing() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.onComplete();\n    });\n  }\n  // Should be called with the audioNode for this session has indicated that it is out of speech.\n  onSpeechEnded() {\n    this.privIsSpeechEnded = true;\n  }\n  onEvent(event) {\n    if (!!this.privServiceTelemetryListener) {\n      this.privServiceTelemetryListener.onEvent(event);\n    }\n    _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Events.instance.onEvent(event);\n  }\n  onComplete() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privIsRecognizing) {\n        this.privIsRecognizing = false;\n        yield this.detachAudioNode();\n      }\n    });\n  }\n  detachAudioNode() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privIsAudioNodeDetached) {\n        this.privIsAudioNodeDetached = true;\n        if (this.privAudioNode) {\n          yield this.privAudioNode.detach();\n        }\n      }\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js ***!
  \*****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ActivityPayloadResponse\": () => (/* binding */ ActivityPayloadResponse),\n/* harmony export */   \"MessageDataStreamType\": () => (/* binding */ MessageDataStreamType)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nclass ActivityPayloadResponse {\n  constructor(json) {\n    this.privActivityResponse = JSON.parse(json);\n  }\n  static fromJSON(json) {\n    return new ActivityPayloadResponse(json);\n  }\n  get conversationId() {\n    return this.privActivityResponse.conversationId;\n  }\n  get messageDataStreamType() {\n    return this.privActivityResponse.messageDataStreamType;\n  }\n  get messagePayload() {\n    return this.privActivityResponse.messagePayload;\n  }\n  get version() {\n    return this.privActivityResponse.version;\n  }\n}\nvar MessageDataStreamType;\n(function (MessageDataStreamType) {\n  MessageDataStreamType[MessageDataStreamType[\"None\"] = 0] = \"None\";\n  MessageDataStreamType[MessageDataStreamType[\"TextToSpeechAudio\"] = 1] = \"TextToSpeechAudio\";\n})(MessageDataStreamType || (MessageDataStreamType = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/ActivityResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DetailedSpeechPhrase\": () => (/* binding */ DetailedSpeechPhrase)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass DetailedSpeechPhrase {\n  constructor(json) {\n    this.privDetailedSpeechPhrase = JSON.parse(json);\n    this.privDetailedSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privDetailedSpeechPhrase.RecognitionStatus];\n  }\n  static fromJSON(json) {\n    return new DetailedSpeechPhrase(json);\n  }\n  getJsonWithCorrectedOffsets(baseOffset) {\n    if (!!this.privDetailedSpeechPhrase.NBest) {\n      let firstWordOffset;\n      for (const phrase of this.privDetailedSpeechPhrase.NBest) {\n        if (!!phrase.Words && !!phrase.Words[0]) {\n          firstWordOffset = phrase.Words[0].Offset;\n          break;\n        }\n      }\n      if (!!firstWordOffset && firstWordOffset < baseOffset) {\n        const offset = baseOffset - firstWordOffset;\n        for (const details of this.privDetailedSpeechPhrase.NBest) {\n          if (!!details.Words) {\n            for (const word of details.Words) {\n              word.Offset += offset;\n            }\n          }\n        }\n      }\n    }\n    return JSON.stringify(this.privDetailedSpeechPhrase);\n  }\n  get RecognitionStatus() {\n    return this.privDetailedSpeechPhrase.RecognitionStatus;\n  }\n  get NBest() {\n    return this.privDetailedSpeechPhrase.NBest;\n  }\n  get Duration() {\n    return this.privDetailedSpeechPhrase.Duration;\n  }\n  get Offset() {\n    return this.privDetailedSpeechPhrase.Offset;\n  }\n  get Language() {\n    return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Language;\n  }\n  get LanguageDetectionConfidence() {\n    return this.privDetailedSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privDetailedSpeechPhrase.PrimaryLanguage.Confidence;\n  }\n  get Text() {\n    if (!!this.privDetailedSpeechPhrase.NBest && this.privDetailedSpeechPhrase.NBest[0]) {\n      return this.privDetailedSpeechPhrase.NBest[0].Display || this.privDetailedSpeechPhrase.NBest[0].DisplayText;\n    }\n    return this.privDetailedSpeechPhrase.DisplayText;\n  }\n  get SpeakerId() {\n    return this.privDetailedSpeechPhrase.SpeakerId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RecognitionStatus\": () => (/* binding */ RecognitionStatus),\n/* harmony export */   \"SynthesisStatus\": () => (/* binding */ SynthesisStatus)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class SynthesisStatus\n * @private\n */\nvar SynthesisStatus;\n(function (SynthesisStatus) {\n  /**\n   * The response contains valid audio data.\n   * @member SynthesisStatus.Success\n   */\n  SynthesisStatus[SynthesisStatus[\"Success\"] = 0] = \"Success\";\n  /**\n   * Indicates the end of audio data. No valid audio data is included in the message.\n   * @member SynthesisStatus.SynthesisEnd\n   */\n  SynthesisStatus[SynthesisStatus[\"SynthesisEnd\"] = 1] = \"SynthesisEnd\";\n  /**\n   * Indicates an error occurred during synthesis data processing.\n   * @member SynthesisStatus.Error\n   */\n  SynthesisStatus[SynthesisStatus[\"Error\"] = 2] = \"Error\";\n})(SynthesisStatus || (SynthesisStatus = {}));\nvar RecognitionStatus;\n(function (RecognitionStatus) {\n  RecognitionStatus[RecognitionStatus[\"Success\"] = 0] = \"Success\";\n  RecognitionStatus[RecognitionStatus[\"NoMatch\"] = 1] = \"NoMatch\";\n  RecognitionStatus[RecognitionStatus[\"InitialSilenceTimeout\"] = 2] = \"InitialSilenceTimeout\";\n  RecognitionStatus[RecognitionStatus[\"BabbleTimeout\"] = 3] = \"BabbleTimeout\";\n  RecognitionStatus[RecognitionStatus[\"Error\"] = 4] = \"Error\";\n  RecognitionStatus[RecognitionStatus[\"EndOfDictation\"] = 5] = \"EndOfDictation\";\n  RecognitionStatus[RecognitionStatus[\"TooManyRequests\"] = 6] = \"TooManyRequests\";\n  RecognitionStatus[RecognitionStatus[\"BadRequest\"] = 7] = \"BadRequest\";\n  RecognitionStatus[RecognitionStatus[\"Forbidden\"] = 8] = \"Forbidden\";\n})(RecognitionStatus || (RecognitionStatus = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentResponse\": () => (/* binding */ IntentResponse)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// response\nclass IntentResponse {\n  constructor(json) {\n    if (json === \"\") {\n      this.privIntentResponse = {};\n    } else {\n      this.privIntentResponse = JSON.parse(json);\n    }\n  }\n  static fromJSON(json) {\n    return new IntentResponse(json);\n  }\n  get query() {\n    return this.privIntentResponse.query;\n  }\n  get topScoringIntent() {\n    return this.privIntentResponse.topScoringIntent;\n  }\n  get entities() {\n    return this.privIntentResponse.entities;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/IntentResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SimpleSpeechPhrase\": () => (/* binding */ SimpleSpeechPhrase)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SimpleSpeechPhrase {\n  constructor(json) {\n    this.privSimpleSpeechPhrase = JSON.parse(json);\n    this.privSimpleSpeechPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privSimpleSpeechPhrase.RecognitionStatus];\n  }\n  static fromJSON(json) {\n    return new SimpleSpeechPhrase(json);\n  }\n  get RecognitionStatus() {\n    return this.privSimpleSpeechPhrase.RecognitionStatus;\n  }\n  get DisplayText() {\n    return this.privSimpleSpeechPhrase.DisplayText;\n  }\n  get Offset() {\n    return this.privSimpleSpeechPhrase.Offset;\n  }\n  get Duration() {\n    return this.privSimpleSpeechPhrase.Duration;\n  }\n  get Language() {\n    return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Language;\n  }\n  get LanguageDetectionConfidence() {\n    return this.privSimpleSpeechPhrase.PrimaryLanguage === undefined ? undefined : this.privSimpleSpeechPhrase.PrimaryLanguage.Confidence;\n  }\n  get SpeakerId() {\n    return this.privSimpleSpeechPhrase.SpeakerId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechDetected\": () => (/* binding */ SpeechDetected)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechDetected {\n  constructor(json) {\n    this.privSpeechStartDetected = JSON.parse(json);\n  }\n  static fromJSON(json) {\n    return new SpeechDetected(json);\n  }\n  get Offset() {\n    return this.privSpeechStartDetected.Offset;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechHypothesis\": () => (/* binding */ SpeechHypothesis)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechHypothesis {\n  constructor(json) {\n    this.privSpeechHypothesis = JSON.parse(json);\n  }\n  static fromJSON(json) {\n    return new SpeechHypothesis(json);\n  }\n  get Text() {\n    return this.privSpeechHypothesis.Text;\n  }\n  get Offset() {\n    return this.privSpeechHypothesis.Offset;\n  }\n  get Duration() {\n    return this.privSpeechHypothesis.Duration;\n  }\n  get Language() {\n    return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Language;\n  }\n  get LanguageDetectionConfidence() {\n    return this.privSpeechHypothesis.PrimaryLanguage === undefined ? undefined : this.privSpeechHypothesis.PrimaryLanguage.Confidence;\n  }\n  get SpeakerId() {\n    return this.privSpeechHypothesis.SpeakerId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechKeyword\": () => (/* binding */ SpeechKeyword)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass SpeechKeyword {\n  constructor(json) {\n    this.privSpeechKeyword = JSON.parse(json);\n  }\n  static fromJSON(json) {\n    return new SpeechKeyword(json);\n  }\n  get Status() {\n    return this.privSpeechKeyword.Status;\n  }\n  get Text() {\n    return this.privSpeechKeyword.Text;\n  }\n  get Offset() {\n    return this.privSpeechKeyword.Offset;\n  }\n  get Duration() {\n    return this.privSpeechKeyword.Duration;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechKeyword.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MetadataType\": () => (/* binding */ MetadataType),\n/* harmony export */   \"SynthesisAudioMetadata\": () => (/* binding */ SynthesisAudioMetadata)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar MetadataType;\n(function (MetadataType) {\n  MetadataType[\"WordBoundary\"] = \"WordBoundary\";\n  MetadataType[\"Bookmark\"] = \"Bookmark\";\n  MetadataType[\"Viseme\"] = \"Viseme\";\n  MetadataType[\"SentenceBoundary\"] = \"SentenceBoundary\";\n  MetadataType[\"SessionEnd\"] = \"SessionEnd\";\n})(MetadataType || (MetadataType = {}));\nclass SynthesisAudioMetadata {\n  constructor(json) {\n    this.privSynthesisAudioMetadata = JSON.parse(json);\n  }\n  static fromJSON(json) {\n    return new SynthesisAudioMetadata(json);\n  }\n  get Metadata() {\n    return this.privSynthesisAudioMetadata.Metadata;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationHypothesis\": () => (/* binding */ TranslationHypothesis)\n/* harmony export */ });\n/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass TranslationHypothesis {\n  constructor(json) {\n    this.privTranslationHypothesis = JSON.parse(json);\n    this.privTranslationHypothesis.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_0__.TranslationStatus[this.privTranslationHypothesis.Translation.TranslationStatus];\n  }\n  static fromJSON(json) {\n    return new TranslationHypothesis(json);\n  }\n  get Duration() {\n    return this.privTranslationHypothesis.Duration;\n  }\n  get Offset() {\n    return this.privTranslationHypothesis.Offset;\n  }\n  get Text() {\n    return this.privTranslationHypothesis.Text;\n  }\n  get Translation() {\n    return this.privTranslationHypothesis.Translation;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationPhrase\": () => (/* binding */ TranslationPhrase)\n/* harmony export */ });\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../TranslationStatus */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass TranslationPhrase {\n  constructor(phrase) {\n    this.privTranslationPhrase = phrase;\n    this.privTranslationPhrase.RecognitionStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionStatus[this.privTranslationPhrase.RecognitionStatus];\n    if (this.privTranslationPhrase.Translation !== undefined) {\n      this.privTranslationPhrase.Translation.TranslationStatus = _TranslationStatus__WEBPACK_IMPORTED_MODULE_1__.TranslationStatus[this.privTranslationPhrase.Translation.TranslationStatus];\n    }\n  }\n  static fromJSON(json) {\n    return new TranslationPhrase(JSON.parse(json));\n  }\n  static fromTranslationResponse(translationResponse) {\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(translationResponse, \"translationResponse\");\n    const phrase = translationResponse.SpeechPhrase;\n    translationResponse.SpeechPhrase = undefined;\n    phrase.Translation = translationResponse;\n    phrase.Text = phrase.DisplayText;\n    return new TranslationPhrase(phrase);\n  }\n  get RecognitionStatus() {\n    return this.privTranslationPhrase.RecognitionStatus;\n  }\n  get Offset() {\n    return this.privTranslationPhrase.Offset;\n  }\n  get Duration() {\n    return this.privTranslationPhrase.Duration;\n  }\n  get Text() {\n    return this.privTranslationPhrase.Text;\n  }\n  get Translation() {\n    return this.privTranslationPhrase.Translation;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js":
/*!*****************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js ***!
  \*****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationSynthesisEnd\": () => (/* binding */ TranslationSynthesisEnd)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass TranslationSynthesisEnd {\n  constructor(json) {\n    this.privSynthesisEnd = JSON.parse(json);\n    this.privSynthesisEnd.SynthesisStatus = _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisStatus[this.privSynthesisEnd.SynthesisStatus];\n  }\n  static fromJSON(json) {\n    return new TranslationSynthesisEnd(json);\n  }\n  get SynthesisStatus() {\n    return this.privSynthesisEnd.SynthesisStatus;\n  }\n  get FailureReason() {\n    return this.privSynthesisEnd.FailureReason;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TurnStatusResponsePayload\": () => (/* binding */ TurnStatusResponsePayload)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass TurnStatusResponsePayload {\n  constructor(json) {\n    this.privMessageStatusResponse = JSON.parse(json);\n  }\n  static fromJSON(json) {\n    return new TurnStatusResponsePayload(json);\n  }\n  get interactionId() {\n    return this.privMessageStatusResponse.interactionId;\n  }\n  get conversationId() {\n    return this.privMessageStatusResponse.conversationId;\n  }\n  get statusCode() {\n    // Payloads may contain a limited set of textual representations or a numeric status\n    // code. The textual values are here converted into numeric ones.\n    switch (this.privMessageStatusResponse.statusCode) {\n      case \"Success\":\n        return 200;\n      case \"Failed\":\n        return 400;\n      case \"TimedOut\":\n        return 429;\n      default:\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n        return this.privMessageStatusResponse.statusCode;\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServiceRecognizerBase\": () => (/* binding */ ServiceRecognizerBase)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ReplayableAudioNode.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RequestSession.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DynamicGrammarBuilder.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechDetected.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\nclass ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, recognizer) {\n    // A promise for a configured connection.\n    // Do not consume directly, call fetchConnection instead.\n    this.privConnectionConfigurationPromise = undefined;\n    // A promise for a connection, but one that has not had the speech context sent yet.\n    // Do not consume directly, call fetchConnection instead.\n    this.privConnectionPromise = undefined;\n    this.privSetTimeout = setTimeout;\n    this.privIsLiveAudio = false;\n    this.recognizeOverride = undefined;\n    this.disconnectOverride = undefined;\n    this.receiveMessageOverride = undefined;\n    this.sendPrePayloadJSONOverride = undefined;\n    this.postConnectImplOverride = undefined;\n    this.configConnectionOverride = undefined;\n    if (!authentication) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"authentication\");\n    }\n    if (!connectionFactory) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"connectionFactory\");\n    }\n    if (!audioSource) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"audioSource\");\n    }\n    if (!recognizerConfig) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"recognizerConfig\");\n    }\n    this.privMustReportEndOfStream = false;\n    this.privAuthentication = authentication;\n    this.privConnectionFactory = connectionFactory;\n    this.privAudioSource = audioSource;\n    this.privRecognizerConfig = recognizerConfig;\n    this.privIsDisposed = false;\n    this.privRecognizer = recognizer;\n    this.privRequestSession = new _Exports__WEBPACK_IMPORTED_MODULE_1__.RequestSession(this.privAudioSource.id());\n    this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n    this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n    this.privDynamicGrammar = new _Exports__WEBPACK_IMPORTED_MODULE_3__.DynamicGrammarBuilder();\n    this.privSpeechContext = new _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechContext(this.privDynamicGrammar);\n    this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_5__.AgentConfig();\n    if (typeof Blob !== \"undefined\" && typeof Worker !== \"undefined\") {\n      this.privSetTimeout = _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Timeout.setTimeout;\n    }\n    this.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        const connectionClosedEvent = connectionEvent;\n        if (connectionClosedEvent.statusCode === 1003 || connectionClosedEvent.statusCode === 1007 || connectionClosedEvent.statusCode === 1002 || connectionClosedEvent.statusCode === 4000 || this.privRequestSession.numConnectionAttempts > this.privRecognizerConfig.maxRetryCount) {\n          void this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n        }\n      }\n    });\n  }\n  get audioSource() {\n    return this.privAudioSource;\n  }\n  get speechContext() {\n    return this.privSpeechContext;\n  }\n  get dynamicGrammar() {\n    return this.privDynamicGrammar;\n  }\n  get agentConfig() {\n    return this.privAgentConfig;\n  }\n  set conversationTranslatorToken(token) {\n    this.privRecognizerConfig.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.ConversationTranslator_Token, token);\n  }\n  set authentication(auth) {\n    this.privAuthentication = this.authentication;\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  dispose(reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privIsDisposed = true;\n      if (this.privConnectionConfigurationPromise !== undefined) {\n        try {\n          const connection = yield this.privConnectionConfigurationPromise;\n          yield connection.dispose(reason);\n        } catch (error) {\n          // The connection is in a bad state. But we're trying to kill it, so...\n          return;\n        }\n      }\n    });\n  }\n  get connectionEvents() {\n    return this.privConnectionEvents;\n  }\n  get serviceEvents() {\n    return this.privServiceEvents;\n  }\n  get recognitionMode() {\n    return this.privRecognizerConfig.recognitionMode;\n  }\n  recognize(recoMode, successCallback, errorCallBack) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.recognizeOverride !== undefined) {\n        yield this.recognizeOverride(recoMode, successCallback, errorCallBack);\n        return;\n      }\n      // Clear the existing configuration promise to force a re-transmission of config and context.\n      this.privConnectionConfigurationPromise = undefined;\n      this.privRecognizerConfig.recognitionMode = recoMode;\n      this.privSuccessCallback = successCallback;\n      this.privErrorCallback = errorCallBack;\n      this.privRequestSession.startNewRecognition();\n      this.privRequestSession.listenForServiceTelemetry(this.privAudioSource.events);\n      // Start the connection to the service. The promise this will create is stored and will be used by configureConnection().\n      const conPromise = this.connectImpl();\n      let audioNode;\n      try {\n        const audioStreamNode = yield this.audioSource.attach(this.privRequestSession.audioNodeId);\n        const format = yield this.audioSource.format;\n        const deviceInfo = yield this.audioSource.deviceInfo;\n        this.privIsLiveAudio = deviceInfo.type && deviceInfo.type === _Exports__WEBPACK_IMPORTED_MODULE_10__.type.Microphones;\n        audioNode = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_11__.ReplayableAudioNode(audioStreamNode, format.avgBytesPerSec);\n        yield this.privRequestSession.onAudioSourceAttachCompleted(audioNode, false);\n        this.privRecognizerConfig.SpeechServiceConfig.Context.audio = {\n          source: deviceInfo\n        };\n      } catch (error) {\n        yield this.privRequestSession.onStopRecognizing();\n        throw error;\n      }\n      try {\n        yield conPromise;\n      } catch (error) {\n        yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.ConnectionFailure, error);\n        return;\n      }\n      const sessionStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);\n      if (!!this.privRecognizer.sessionStarted) {\n        this.privRecognizer.sessionStarted(this.privRecognizer, sessionStartEventArgs);\n      }\n      void this.receiveMessage();\n      const audioSendPromise = this.sendAudio(audioNode);\n      audioSendPromise.catch(error => __awaiter(this, void 0, void 0, function* () {\n        yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.RuntimeError, error);\n      }));\n      return;\n    });\n  }\n  stopRecognizing() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privRequestSession.isRecognizing) {\n        try {\n          yield this.audioSource.turnOff();\n          yield this.sendFinalAudio();\n          yield this.privRequestSession.onStopRecognizing();\n          yield this.privRequestSession.turnCompletionPromise;\n        } finally {\n          yield this.privRequestSession.dispose();\n        }\n      }\n      return;\n    });\n  }\n  connect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.connectImpl();\n      return Promise.resolve();\n    });\n  }\n  connectAsync(cb, err) {\n    this.connectImpl().then(() => {\n      try {\n        if (!!cb) {\n          cb();\n        }\n      } catch (e) {\n        if (!!err) {\n          err(e);\n        }\n      }\n    }, reason => {\n      try {\n        if (!!err) {\n          err(reason);\n        }\n        /* eslint-disable no-empty */\n      } catch (error) {}\n    });\n  }\n  disconnect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.NoError, \"Disconnecting\");\n      if (this.disconnectOverride !== undefined) {\n        yield this.disconnectOverride();\n      }\n      if (this.privConnectionPromise !== undefined) {\n        try {\n          yield (yield this.privConnectionPromise).dispose();\n        } catch (error) {}\n      }\n      this.privConnectionPromise = undefined;\n    });\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  sendMessage(message) {\n    return;\n  }\n  sendNetworkMessage(path, payload) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const type = typeof payload === \"string\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text : _common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary;\n      const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n      const connection = yield this.fetchConnection();\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(type, path, this.privRequestSession.requestId, contentType, payload));\n    });\n  }\n  set activityTemplate(messagePayload) {\n    this.privActivityTemplate = messagePayload;\n  }\n  get activityTemplate() {\n    return this.privActivityTemplate;\n  }\n  sendTelemetryData() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const telemetryData = this.privRequestSession.getTelemetry();\n      if (ServiceRecognizerBase.telemetryDataEnabled !== true || this.privIsDisposed || null === telemetryData) {\n        return;\n      }\n      if (!!ServiceRecognizerBase.telemetryData) {\n        try {\n          ServiceRecognizerBase.telemetryData(telemetryData);\n          /* eslint-disable no-empty */\n        } catch (_a) {}\n      }\n      const connection = yield this.fetchConnection();\n      yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, \"telemetry\", this.privRequestSession.requestId, \"application/json\", telemetryData));\n    });\n  }\n  // Cancels recognition.\n  cancelRecognitionLocal(cancellationReason, errorCode, error) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privRequestSession.isRecognizing) {\n        yield this.privRequestSession.onStopRecognizing();\n        this.cancelRecognition(this.privRequestSession.sessionId, this.privRequestSession.requestId, cancellationReason, errorCode, error);\n      }\n    });\n  }\n  receiveMessage() {\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        if (this.privIsDisposed) {\n          // We're done.\n          return;\n        }\n        let connection = yield this.fetchConnection();\n        const message = yield connection.read();\n        if (this.receiveMessageOverride !== undefined) {\n          return this.receiveMessageOverride();\n        }\n        // indicates we are draining the queue and it came with no message;\n        if (!message) {\n          if (!this.privRequestSession.isRecognizing) {\n            return;\n          } else {\n            return this.receiveMessage();\n          }\n        }\n        this.privServiceHasSentMessage = true;\n        const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage.fromConnectionMessage(message);\n        if (connectionMessage.requestId.toLowerCase() === this.privRequestSession.requestId.toLowerCase()) {\n          switch (connectionMessage.path.toLowerCase()) {\n            case \"turn.start\":\n              this.privMustReportEndOfStream = true;\n              this.privRequestSession.onServiceTurnStartResponse();\n              break;\n            case \"speech.startdetected\":\n              const speechStartDetected = _Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechDetected.fromJSON(connectionMessage.textBody);\n              const speechStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.RecognitionEventArgs(speechStartDetected.Offset, this.privRequestSession.sessionId);\n              if (!!this.privRecognizer.speechStartDetected) {\n                this.privRecognizer.speechStartDetected(this.privRecognizer, speechStartEventArgs);\n              }\n              break;\n            case \"speech.enddetected\":\n              let json;\n              if (connectionMessage.textBody.length > 0) {\n                json = connectionMessage.textBody;\n              } else {\n                // If the request was empty, the JSON returned is empty.\n                json = \"{ Offset: 0 }\";\n              }\n              const speechStopDetected = _Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechDetected.fromJSON(json);\n              // Only shrink the buffers for continuous recognition.\n              // For single shot, the speech.phrase message will come after the speech.end and it should own buffer shrink.\n              if (this.privRecognizerConfig.isContinuousRecognition) {\n                this.privRequestSession.onServiceRecognized(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset);\n              }\n              const speechStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.RecognitionEventArgs(speechStopDetected.Offset + this.privRequestSession.currentTurnAudioOffset, this.privRequestSession.sessionId);\n              if (!!this.privRecognizer.speechEndDetected) {\n                this.privRecognizer.speechEndDetected(this.privRecognizer, speechStopEventArgs);\n              }\n              break;\n            case \"turn.end\":\n              yield this.sendTelemetryData();\n              if (this.privRequestSession.isSpeechEnded && this.privMustReportEndOfStream) {\n                this.privMustReportEndOfStream = false;\n                yield this.cancelRecognitionLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.EndOfStream, _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.CancellationErrorCode.NoError, undefined);\n              }\n              const sessionStopEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.SessionEventArgs(this.privRequestSession.sessionId);\n              yield this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition);\n              if (!this.privRecognizerConfig.isContinuousRecognition || this.privRequestSession.isSpeechEnded || !this.privRequestSession.isRecognizing) {\n                if (!!this.privRecognizer.sessionStopped) {\n                  this.privRecognizer.sessionStopped(this.privRecognizer, sessionStopEventArgs);\n                }\n                return;\n              } else {\n                connection = yield this.fetchConnection();\n                yield this.sendPrePayloadJSON(connection);\n              }\n              break;\n            default:\n              if (!(yield this.processTypeSpecificMessages(connectionMessage))) {\n                // here are some messages that the derived class has not processed, dispatch them to connect class\n                if (!!this.privServiceEvents) {\n                  this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_17__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                }\n              }\n          }\n        }\n        return this.receiveMessage();\n      } catch (error) {\n        return null;\n      }\n    });\n  }\n  sendSpeechContext(connection, generateNewRequestId) {\n    const speechContextJson = this.speechContext.toJSON();\n    if (generateNewRequestId) {\n      this.privRequestSession.onSpeechContext();\n    }\n    if (speechContextJson) {\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, \"speech.context\", this.privRequestSession.requestId, \"application/json\", speechContextJson));\n    }\n    return;\n  }\n  // Encapsulated for derived service recognizers that need to send additional JSON\n  sendPrePayloadJSON(connection) {\n    let generateNewRequestId = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.sendPrePayloadJSONOverride !== undefined) {\n        return this.sendPrePayloadJSONOverride(connection);\n      }\n      yield this.sendSpeechContext(connection, generateNewRequestId);\n      yield this.sendWaveHeader(connection);\n      return;\n    });\n  }\n  sendWaveHeader(connection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const format = yield this.audioSource.format;\n      // this.writeBufferToConsole(format.header);\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, \"audio\", this.privRequestSession.requestId, \"audio/x-wav\", format.header));\n    });\n  }\n  // Establishes a websocket connection to the end point.\n  connectImpl() {\n    if (this.privConnectionPromise !== undefined) {\n      return this.privConnectionPromise.then(connection => {\n        if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ConnectionState.Disconnected) {\n          this.privConnectionId = null;\n          this.privConnectionPromise = undefined;\n          this.privServiceHasSentMessage = false;\n          return this.connectImpl();\n        }\n        return this.privConnectionPromise;\n      }, () => {\n        this.privConnectionId = null;\n        this.privConnectionPromise = undefined;\n        this.privServiceHasSentMessage = false;\n        return this.connectImpl();\n      });\n    }\n    this.privConnectionPromise = this.retryableConnect();\n    // Attach an empty handler to allow the promise to run in the background while\n    // other startup events happen. It'll eventually be awaited on.\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    this.privConnectionPromise.catch(() => {});\n    if (this.postConnectImplOverride !== undefined) {\n      return this.postConnectImplOverride(this.privConnectionPromise);\n    }\n    return this.privConnectionPromise;\n  }\n  sendSpeechServiceConfig(connection, requestSession, SpeechServiceConfigJson) {\n    requestSession.onSpeechContext();\n    // filter out anything that is not required for the service to work.\n    if (ServiceRecognizerBase.telemetryDataEnabled !== true) {\n      const withTelemetry = JSON.parse(SpeechServiceConfigJson);\n      const replacement = {\n        context: {\n          system: withTelemetry.context.system\n        }\n      };\n      SpeechServiceConfigJson = JSON.stringify(replacement);\n    }\n    if (this.privRecognizerConfig.parameters.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() === \"true\") {\n      const json = JSON.parse(SpeechServiceConfigJson);\n      json.context.DisableReferenceChannel = \"True\";\n      json.context.MicSpec = \"1_0_0\";\n      SpeechServiceConfigJson = JSON.stringify(json);\n    }\n    if (SpeechServiceConfigJson) {\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Text, \"speech.config\", requestSession.requestId, \"application/json\", SpeechServiceConfigJson));\n    }\n    return;\n  }\n  fetchConnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privConnectionConfigurationPromise !== undefined) {\n        return this.privConnectionConfigurationPromise.then(connection => {\n          if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ConnectionState.Disconnected) {\n            this.privConnectionId = null;\n            this.privConnectionConfigurationPromise = undefined;\n            this.privServiceHasSentMessage = false;\n            return this.fetchConnection();\n          }\n          return this.privConnectionConfigurationPromise;\n        }, () => {\n          this.privConnectionId = null;\n          this.privConnectionConfigurationPromise = undefined;\n          this.privServiceHasSentMessage = false;\n          return this.fetchConnection();\n        });\n      }\n      this.privConnectionConfigurationPromise = this.configureConnection();\n      return yield this.privConnectionConfigurationPromise;\n    });\n  }\n  sendAudio(audioStreamNode) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const audioFormat = yield this.audioSource.format;\n      // The time we last sent data to the service.\n      let nextSendTime = Date.now();\n      // Max amount to send before we start to throttle\n      const fastLaneSizeMs = this.privRecognizerConfig.parameters.getProperty(\"SPEECH-TransmitLengthBeforThrottleMs\", \"5000\");\n      const maxSendUnthrottledBytes = audioFormat.avgBytesPerSec / 1000 * parseInt(fastLaneSizeMs, 10);\n      const startRecogNumber = this.privRequestSession.recogNumber;\n      const readAndUploadCycle = () => __awaiter(this, void 0, void 0, function* () {\n        // If speech is done, stop sending audio.\n        if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {\n          const connection = yield this.fetchConnection();\n          const audioStreamChunk = yield audioStreamNode.read();\n          // we have a new audio chunk to upload.\n          if (this.privRequestSession.isSpeechEnded) {\n            // If service already recognized audio end then don't send any more audio\n            return;\n          }\n          let payload;\n          let sendDelay;\n          if (!audioStreamChunk || audioStreamChunk.isEnd) {\n            payload = null;\n            sendDelay = 0;\n          } else {\n            payload = audioStreamChunk.buffer;\n            this.privRequestSession.onAudioSent(payload.byteLength);\n            if (maxSendUnthrottledBytes >= this.privRequestSession.bytesSent) {\n              sendDelay = 0;\n            } else {\n              sendDelay = Math.max(0, nextSendTime - Date.now());\n            }\n          }\n          if (0 !== sendDelay) {\n            yield this.delay(sendDelay);\n          }\n          if (payload !== null) {\n            nextSendTime = Date.now() + payload.byteLength * 1000 / (audioFormat.avgBytesPerSec * 2);\n          }\n          // Are we still alive?\n          if (!this.privIsDisposed && !this.privRequestSession.isSpeechEnded && this.privRequestSession.isRecognizing && this.privRequestSession.recogNumber === startRecogNumber) {\n            connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, payload)).catch(() => {\n              // eslint-disable-next-line @typescript-eslint/no-empty-function\n              this.privRequestSession.onServiceTurnEndResponse(this.privRecognizerConfig.isContinuousRecognition).catch(() => {});\n            });\n            if (!(audioStreamChunk === null || audioStreamChunk === void 0 ? void 0 : audioStreamChunk.isEnd)) {\n              // this.writeBufferToConsole(payload);\n              // Regardless of success or failure, schedule the next upload.\n              // If the underlying connection was broken, the next cycle will\n              // get a new connection and re-transmit missing audio automatically.\n              return readAndUploadCycle();\n            } else {\n              // the audio stream has been closed, no need to schedule next\n              // read-upload cycle.\n              if (!this.privIsLiveAudio) {\n                this.privRequestSession.onSpeechEnded();\n              }\n            }\n          }\n        }\n      });\n      return readAndUploadCycle();\n    });\n  }\n  retryableConnect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      let isUnAuthorized = false;\n      this.privAuthFetchEventId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_19__.createNoDashGuid)();\n      const sessionId = this.privRequestSession.sessionId;\n      this.privConnectionId = sessionId !== undefined ? sessionId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_19__.createNoDashGuid)();\n      this.privRequestSession.onPreConnectionStart(this.privAuthFetchEventId, this.privConnectionId);\n      let lastStatusCode = 0;\n      let lastReason = \"\";\n      while (this.privRequestSession.numConnectionAttempts <= this.privRecognizerConfig.maxRetryCount) {\n        // Get the auth information for the connection. This is a bit of overkill for the current API surface, but leaving the plumbing in place to be able to raise a developer-customer\n        // facing event when a connection fails to let them try and provide new auth information.\n        const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n        const auth = yield authPromise;\n        yield this.privRequestSession.onAuthCompleted(false);\n        // Create the connection\n        const connection = this.privConnectionFactory.create(this.privRecognizerConfig, auth, this.privConnectionId);\n        // Attach the telemetry handlers.\n        this.privRequestSession.listenForServiceTelemetry(connection.events);\n        // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n        // it'll stop sending events.\n        connection.events.attach(event => {\n          this.connectionEvents.onEvent(event);\n        });\n        const response = yield connection.open();\n        // 200 == everything is fine.\n        if (response.statusCode === 200) {\n          yield this.privRequestSession.onConnectionEstablishCompleted(response.statusCode);\n          return Promise.resolve(connection);\n        } else if (response.statusCode === 1006) {\n          isUnAuthorized = true;\n        }\n        lastStatusCode = response.statusCode;\n        lastReason = response.reason;\n        this.privRequestSession.onRetryConnection();\n      }\n      yield this.privRequestSession.onConnectionEstablishCompleted(lastStatusCode, lastReason);\n      return Promise.reject(`Unable to contact server. StatusCode: ${lastStatusCode}, ${this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${lastReason}`);\n    });\n  }\n  delay(delayMs) {\n    return new Promise(resolve => this.privSetTimeout(resolve, delayMs));\n  }\n  writeBufferToConsole(buffer) {\n    let out = \"Buffer Size: \";\n    if (null === buffer) {\n      out += \"null\";\n    } else {\n      const readView = new Uint8Array(buffer);\n      out += `${buffer.byteLength}\\r\\n`;\n      for (let i = 0; i < buffer.byteLength; i++) {\n        out += readView[i].toString(16).padStart(2, \"0\") + \" \";\n        if ((i + 1) % 16 === 0) {\n          // eslint-disable-next-line no-console\n          console.info(out);\n          out = \"\";\n        }\n      }\n    }\n    // eslint-disable-next-line no-console\n    console.info(out);\n  }\n  sendFinalAudio() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.fetchConnection();\n      yield connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_14__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_13__.MessageType.Binary, \"audio\", this.privRequestSession.requestId, null, null));\n      return;\n    });\n  }\n  // Takes an established websocket connection to the endpoint and sends speech configuration information.\n  configureConnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.connectImpl();\n      if (this.configConnectionOverride !== undefined) {\n        return this.configConnectionOverride(connection);\n      }\n      yield this.sendSpeechServiceConfig(connection, this.privRequestSession, this.privRecognizerConfig.SpeechServiceConfig.serialize());\n      yield this.sendPrePayloadJSON(connection, false);\n      return connection;\n    });\n  }\n}\nServiceRecognizerBase.telemetryDataEnabled = true;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServiceTelemetryListener\": () => (/* binding */ ServiceTelemetryListener)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./RecognitionEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognitionEvents.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\nclass ServiceTelemetryListener {\n  constructor(requestId, audioSourceId, audioNodeId) {\n    this.privIsDisposed = false;\n    this.privListeningTriggerMetric = null;\n    this.privMicMetric = null;\n    this.privConnectionEstablishMetric = null;\n    this.privRequestId = requestId;\n    this.privAudioSourceId = audioSourceId;\n    this.privAudioNodeId = audioNodeId;\n    this.privReceivedMessages = {};\n    this.privPhraseLatencies = [];\n    this.privHypothesisLatencies = [];\n  }\n  phraseReceived(audioReceivedTime) {\n    if (audioReceivedTime > 0) {\n      // 0 indicates the time is unknown. Drop it.\n      this.privPhraseLatencies.push(Date.now() - audioReceivedTime);\n    }\n  }\n  hypothesisReceived(audioReceivedTime) {\n    if (audioReceivedTime > 0) {\n      // 0 indicates the time is unknown. Drop it.\n      this.privHypothesisLatencies.push(Date.now() - audioReceivedTime);\n    }\n  }\n  onEvent(e) {\n    if (this.privIsDisposed) {\n      return;\n    }\n    if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__.RecognitionTriggeredEvent && e.requestId === this.privRequestId) {\n      this.privListeningTriggerMetric = {\n        End: e.eventTime,\n        Name: \"ListeningTrigger\",\n        Start: e.eventTime\n      };\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeAttachingEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n      this.privMicStartTime = e.eventTime;\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeAttachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n      this.privMicStartTime = e.eventTime;\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioSourceErrorEvent && e.audioSourceId === this.privAudioSourceId) {\n      if (!this.privMicMetric) {\n        this.privMicMetric = {\n          End: e.eventTime,\n          Error: e.error,\n          Name: \"Microphone\",\n          Start: this.privMicStartTime\n        };\n      }\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeErrorEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n      if (!this.privMicMetric) {\n        this.privMicMetric = {\n          End: e.eventTime,\n          Error: e.error,\n          Name: \"Microphone\",\n          Start: this.privMicStartTime\n        };\n      }\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_1__.AudioStreamNodeDetachedEvent && e.audioSourceId === this.privAudioSourceId && e.audioNodeId === this.privAudioNodeId) {\n      if (!this.privMicMetric) {\n        this.privMicMetric = {\n          End: e.eventTime,\n          Name: \"Microphone\",\n          Start: this.privMicStartTime\n        };\n      }\n    }\n    if (e instanceof _RecognitionEvents__WEBPACK_IMPORTED_MODULE_0__.ConnectingToServiceEvent && e.requestId === this.privRequestId) {\n      this.privConnectionId = e.sessionId;\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionStartEvent && e.connectionId === this.privConnectionId) {\n      this.privConnectionStartTime = e.eventTime;\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEstablishedEvent && e.connectionId === this.privConnectionId) {\n      if (!this.privConnectionEstablishMetric) {\n        this.privConnectionEstablishMetric = {\n          End: e.eventTime,\n          Id: this.privConnectionId,\n          Name: \"Connection\",\n          Start: this.privConnectionStartTime\n        };\n      }\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionEstablishErrorEvent && e.connectionId === this.privConnectionId) {\n      if (!this.privConnectionEstablishMetric) {\n        this.privConnectionEstablishMetric = {\n          End: e.eventTime,\n          Error: this.getConnectionError(e.statusCode),\n          Id: this.privConnectionId,\n          Name: \"Connection\",\n          Start: this.privConnectionStartTime\n        };\n      }\n    }\n    if (e instanceof _common_Exports__WEBPACK_IMPORTED_MODULE_2__.ConnectionMessageReceivedEvent && e.connectionId === this.privConnectionId) {\n      if (e.message && e.message.headers && e.message.headers.path) {\n        if (!this.privReceivedMessages[e.message.headers.path]) {\n          this.privReceivedMessages[e.message.headers.path] = new Array();\n        }\n        const maxMessagesToSend = 50;\n        if (this.privReceivedMessages[e.message.headers.path].length < maxMessagesToSend) {\n          this.privReceivedMessages[e.message.headers.path].push(e.networkReceivedTime);\n        }\n      }\n    }\n  }\n  getTelemetry() {\n    const metrics = new Array();\n    if (this.privListeningTriggerMetric) {\n      metrics.push(this.privListeningTriggerMetric);\n    }\n    if (this.privMicMetric) {\n      metrics.push(this.privMicMetric);\n    }\n    if (this.privConnectionEstablishMetric) {\n      metrics.push(this.privConnectionEstablishMetric);\n    }\n    if (this.privPhraseLatencies.length > 0) {\n      metrics.push({\n        PhraseLatencyMs: this.privPhraseLatencies\n      });\n    }\n    if (this.privHypothesisLatencies.length > 0) {\n      metrics.push({\n        FirstHypothesisLatencyMs: this.privHypothesisLatencies\n      });\n    }\n    const telemetry = {\n      Metrics: metrics,\n      ReceivedMessages: this.privReceivedMessages\n    };\n    const json = JSON.stringify(telemetry);\n    // We dont want to send the same telemetry again. So clean those out.\n    this.privReceivedMessages = {};\n    this.privListeningTriggerMetric = null;\n    this.privMicMetric = null;\n    this.privConnectionEstablishMetric = null;\n    this.privPhraseLatencies = [];\n    this.privHypothesisLatencies = [];\n    return json;\n  }\n  // Determines if there are any telemetry events to send to the service.\n  get hasTelemetry() {\n    return Object.keys(this.privReceivedMessages).length !== 0 || this.privListeningTriggerMetric !== null || this.privMicMetric !== null || this.privConnectionEstablishMetric !== null || this.privPhraseLatencies.length !== 0 || this.privHypothesisLatencies.length !== 0;\n  }\n  dispose() {\n    this.privIsDisposed = true;\n  }\n  getConnectionError(statusCode) {\n    /*\n    -- Websocket status codes --\n    NormalClosure = 1000,\n    EndpointUnavailable = 1001,\n    ProtocolError = 1002,\n    InvalidMessageType = 1003,\n    Empty = 1005,\n    InvalidPayloadData = 1007,\n    PolicyViolation = 1008,\n    MessageTooBig = 1009,\n    MandatoryExtension = 1010,\n    InternalServerError = 1011\n    */\n    switch (statusCode) {\n      case 400:\n      case 1002:\n      case 1003:\n      case 1005:\n      case 1007:\n      case 1008:\n      case 1009:\n        return \"BadRequest\";\n      case 401:\n        return \"Unauthorized\";\n      case 403:\n        return \"Forbidden\";\n      case 503:\n      case 1001:\n        return \"ServerUnavailable\";\n      case 500:\n      case 1011:\n        return \"ServerError\";\n      case 408:\n      case 504:\n        return \"Timeout\";\n      default:\n        return \"statuscode:\" + statusCode.toString();\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceTelemetryListener.Internal.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerIdMessageAdapter\": () => (/* binding */ SpeakerIdMessageAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SpeakerIdMessageAdapter\n */\nclass SpeakerIdMessageAdapter {\n  constructor(config) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n    if (!endpoint) {\n      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, \"westus\");\n      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);\n      endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, `https://${region}.api.cognitive${hostSuffix}`);\n    }\n    this.privUri = `${endpoint}/speaker-recognition/{mode}/{dependency}/profiles`;\n    const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.requestOptions;\n    options.headers[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.configParams.subscriptionKey] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Key, undefined);\n    this.privApiVersion = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeakerRecognition_Api_Version, \"2021-09-05\");\n    this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestMessageAdapter(options);\n  }\n  /**\n   * Sends create profile request to endpoint.\n   * @function\n   * @param {VoiceProfileType} profileType - type of voice profile to create.\n   * @param {string} lang - language/locale of voice profile\n   * @public\n   * @returns {Promise<IRestResponse>} promised rest response containing id of created profile.\n   */\n  createProfile(profileType, lang) {\n    const uri = this.getOperationUri(profileType);\n    return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Post, uri, this.getQueryParams({}), {\n      locale: lang\n    });\n  }\n  /**\n   * Sends create enrollment request to endpoint.\n   * @function\n   * @param {VoiceProfile} profileType - voice profile for which to create new enrollment.\n   * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n   * @public\n   * @returns {Promise<IRestResponse>} rest response to enrollment request.\n   */\n  createEnrollment(profile, audioSource) {\n    const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId + \"/enrollments\";\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n    return audioSource.blob.then(result => this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.File, uri, this.getQueryParams({\n      ignoreMinLength: \"true\"\n    }), null, result));\n  }\n  /**\n   * Sends verification request to endpoint.\n   * @function\n   * @param {SpeakerVerificationModel} model - voice model to verify against.\n   * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n   * @public\n   * @returns {Promise<IRestResponse>} rest response to enrollment request.\n   */\n  verifySpeaker(model, audioSource) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const uri = this.getOperationUri(model.voiceProfile.profileType) + \"/\" + model.voiceProfile.profileId + \":verify\";\n      try {\n        const result = yield audioSource.blob;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.File, uri, this.getQueryParams({\n          ignoreMinLength: \"true\"\n        }), null, result);\n      } catch (e) {\n        return Promise.resolve({\n          data: e\n        });\n      }\n    });\n  }\n  /**\n   * Sends identification request to endpoint.\n   * @function\n   * @param {SpeakerIdentificationModel} model - voice profiles against which to identify.\n   * @param {IAudioSource} audioSource - audioSource from which to pull data to send\n   * @public\n   * @returns {Promise<IRestResponse>} rest response to enrollment request.\n   */\n  identifySpeaker(model, audioSource) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const uri = this.getOperationUri(_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileType.TextIndependentIdentification) + \":identifySingleSpeaker\";\n      try {\n        const result = yield audioSource.blob;\n        return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.File, uri, this.getQueryParams({\n          profileIds: model.voiceProfileIds,\n          ignoreMinLength: \"true\"\n        }), null, result);\n      } catch (e) {\n        return Promise.resolve({\n          data: e\n        });\n      }\n    });\n  }\n  /**\n   * Sends profile status request to endpoint.\n   * @function\n   * @param {VoiceProfile} profile - voice profile to check.\n   * @public\n   * @returns {Promise<IRestResponse>} rest response to status request\n   */\n  getProfileStatus(profile) {\n    const uri = `${this.getOperationUri(profile.profileType)}/${profile.profileId}`;\n    return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, uri, this.getQueryParams());\n  }\n  /**\n   * Sends get all profiles request to endpoint.\n   * @function\n   * @param {VoiceProfileType} profileType - type of profiles to return list of\n   * @public\n   * @returns {Promise<IRestResponse>} promised rest response containing all profiles\n   */\n  getProfiles(profileType) {\n    const uri = this.getOperationUri(profileType);\n    return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, uri, this.getQueryParams());\n  }\n  /**\n   * Sends get activation/auth phrases request to endpoint.\n   * @function\n   * @param {VoiceProfileType} profileType - type of profiles to return phrases for\n   * @param {string} lang - language/locale of voice profile\n   * @public\n   * @returns {Promise<IRestResponse>} promised rest response containing list of valid phrases\n   */\n  getPhrases(profileType, lang) {\n    const uri = `${this.getOperationUri(profileType)}`.replace(\"profiles\", \"phrases\") + \"/\" + lang;\n    return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, uri, this.getQueryParams());\n  }\n  /**\n   * Sends delete profile request to endpoint.\n   * @function\n   * @param {VoiceProfile} profile - voice profile to delete.\n   * @public\n   * @returns {Promise<IRestResponse>} rest response to deletion request\n   */\n  deleteProfile(profile) {\n    const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId;\n    return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Delete, uri, this.getQueryParams());\n  }\n  /**\n   * Sends reset profile request to endpoint.\n   * @function\n   * @param {VoiceProfile} profile - voice profile to reset enrollments for.\n   * @public\n   * @returns {Promise<IRestResponse>} rest response to reset request\n   */\n  resetProfile(profile) {\n    const uri = this.getOperationUri(profile.profileType) + \"/\" + profile.profileId + \":reset\";\n    return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Post, uri, this.getQueryParams());\n  }\n  getOperationUri(profileType) {\n    const mode = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileType.TextIndependentIdentification ? \"identification\" : \"verification\";\n    const dependency = profileType === _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.VoiceProfileType.TextDependentVerification ? \"text-dependent\" : \"text-independent\";\n    return this.privUri.replace(\"{mode}\", mode).replace(\"{dependency}\", dependency);\n  }\n  getQueryParams() {\n    let params = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    params[_common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.configParams.apiVersion] = this.privApiVersion;\n    return params;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerRecognitionConfig\": () => (/* binding */ SpeakerRecognitionConfig)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SpeakerRecognitionConfig {\n  constructor(context, parameters) {\n    this.privContext = context ? context : new _Exports__WEBPACK_IMPORTED_MODULE_0__.Context(null);\n    this.privParameters = parameters;\n  }\n  get parameters() {\n    return this.privParameters;\n  }\n  get Context() {\n    return this.privContext;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechConnectionFactory\": () => (/* binding */ SpeechConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\nclass SpeechConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n  constructor() {\n    super(...arguments);\n    this.interactiveRelativeUri = \"/speech/recognition/interactive/cognitiveservices/v1\";\n    this.conversationRelativeUri = \"/speech/recognition/conversation/cognitiveservices/v1\";\n    this.dictationRelativeUri = \"/speech/recognition/dictation/cognitiveservices/v1\";\n    this.universalUri = \"/speech/universal/v\";\n  }\n  create(config, authInfo, connectionId) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, undefined);\n    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n    const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".stt.speech\" + hostSuffix);\n    const queryParams = {};\n    const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n    const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n    if (endpointId) {\n      if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId) === -1) {\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n      }\n    } else if (language) {\n      if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language) === -1) {\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language] = language;\n      }\n    }\n    if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format) === -1) {\n      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format] = config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple]).toLowerCase();\n    }\n    if (config.autoDetectSourceLanguages !== undefined) {\n      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.EnableLanguageId] = \"true\";\n    }\n    this.setCommonUrlParams(config, queryParams, endpoint);\n    if (!endpoint) {\n      switch (config.recognitionMode) {\n        case _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation:\n          if (config.parameters.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ForceDictationPropertyName, \"false\") === \"true\") {\n            endpoint = host + this.dictationRelativeUri;\n          } else {\n            if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n              endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n            } else {\n              endpoint = host + this.conversationRelativeUri;\n            }\n          }\n          break;\n        case _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Dictation:\n          endpoint = host + this.dictationRelativeUri;\n          break;\n        default:\n          if (config.recognitionEndpointVersion !== undefined && parseInt(config.recognitionEndpointVersion, 10) > 1) {\n            endpoint = `${host}${this.universalUri}${config.recognitionEndpointVersion}`;\n          } else {\n            endpoint = host + this.interactiveRelativeUri; // default is interactive\n          }\n\n          break;\n      }\n    }\n    const headers = {};\n    if (authInfo.token !== undefined && authInfo.token !== \"\") {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_6__.HeaderNames.ConnectionId] = connectionId;\n    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_8__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_9__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechConnectionMessage\": () => (/* binding */ SpeechConnectionMessage)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass SpeechConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ConnectionMessage {\n  constructor(messageType, path, requestId, contentType, body, streamId, additionalHeaders, id) {\n    if (!path) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"path\");\n    }\n    if (!requestId) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ArgumentNullError(\"requestId\");\n    }\n    const headers = {};\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Path] = path;\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestId] = requestId;\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestTimestamp] = new Date().toISOString();\n    if (contentType) {\n      headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ContentType] = contentType;\n    }\n    if (streamId) {\n      headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestStreamId] = streamId;\n    }\n    if (additionalHeaders) {\n      for (const headerName in additionalHeaders) {\n        if (headerName) {\n          headers[headerName] = additionalHeaders[headerName];\n        }\n      }\n    }\n    if (id) {\n      super(messageType, body, headers, id);\n    } else {\n      super(messageType, body, headers);\n    }\n    this.privPath = path;\n    this.privRequestId = requestId;\n    this.privContentType = contentType;\n    this.privStreamId = streamId;\n    this.privAdditionalHeaders = additionalHeaders;\n  }\n  get path() {\n    return this.privPath;\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n  get contentType() {\n    return this.privContentType;\n  }\n  get streamId() {\n    return this.privStreamId;\n  }\n  get additionalHeaders() {\n    return this.privAdditionalHeaders;\n  }\n  static fromConnectionMessage(message) {\n    let path = null;\n    let requestId = null;\n    let contentType = null;\n    // let requestTimestamp = null;\n    let streamId = null;\n    const additionalHeaders = {};\n    if (message.headers) {\n      for (const headerName in message.headers) {\n        if (headerName) {\n          if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.Path.toLowerCase()) {\n            path = message.headers[headerName];\n          } else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestId.toLowerCase()) {\n            requestId = message.headers[headerName];\n            // } else if (headerName.toLowerCase() === HeaderNames.RequestTimestamp.toLowerCase()) {\n            //  requestTimestamp = message.headers[headerName];\n          } else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ContentType.toLowerCase()) {\n            contentType = message.headers[headerName];\n          } else if (headerName.toLowerCase() === _HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.RequestStreamId.toLowerCase()) {\n            streamId = message.headers[headerName];\n          } else {\n            additionalHeaders[headerName] = message.headers[headerName];\n          }\n        }\n      }\n    }\n    return new SpeechConnectionMessage(message.messageType, path, requestId, contentType, message.body, streamId, additionalHeaders, message.id);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechContext\": () => (/* binding */ SpeechContext)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Represents the JSON used in the speech.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SpeechContext {\n  constructor(dynamicGrammar) {\n    this.privContext = {};\n    this.privDynamicGrammar = dynamicGrammar;\n  }\n  /**\n   * Adds a section to the speech.context object.\n   * @param sectionName Name of the section to add.\n   * @param value JSON serializable object that represents the value.\n   */\n  setSection(sectionName, value) {\n    this.privContext[sectionName] = value;\n  }\n  /**\n   * @Internal\n   * This is only used by pronunciation assessment config.\n   * Do not use externally, object returned will change without warning or notice.\n   */\n  setPronunciationAssessmentParams(params) {\n    if (this.privContext.phraseDetection === undefined) {\n      this.privContext.phraseDetection = {\n        enrichment: {\n          pronunciationAssessment: {}\n        }\n      };\n    }\n    this.privContext.phraseDetection.enrichment.pronunciationAssessment = JSON.parse(params);\n    this.setWordLevelTimings();\n    this.privContext.phraseOutput.detailed.options.push(\"PronunciationAssessment\");\n    if (this.privContext.phraseOutput.detailed.options.indexOf(\"SNR\") === -1) {\n      this.privContext.phraseOutput.detailed.options.push(\"SNR\");\n    }\n  }\n  setWordLevelTimings() {\n    if (this.privContext.phraseOutput === undefined) {\n      this.privContext.phraseOutput = {\n        detailed: {\n          options: []\n        },\n        format: {}\n      };\n    }\n    if (this.privContext.phraseOutput.detailed === undefined) {\n      this.privContext.phraseOutput.detailed = {\n        options: []\n      };\n    }\n    this.privContext.phraseOutput.format = \"Detailed\";\n    if (this.privContext.phraseOutput.detailed.options.indexOf(\"WordTimings\") === -1) {\n      this.privContext.phraseOutput.detailed.options.push(\"WordTimings\");\n    }\n  }\n  toJSON() {\n    const dgi = this.privDynamicGrammar.generateGrammarObject();\n    this.setSection(\"dgi\", dgi);\n    const ret = JSON.stringify(this.privContext);\n    return ret;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechContext.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js ***!
  \*************************************************************************************************************************/
/***/ (() => {

eval("// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechServiceRecognizer\": () => (/* binding */ SpeechServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n// eslint-disable-next-line max-classes-per-file\nclass SpeechServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, speechRecognizer);\n    this.privSpeechRecognizer = speechRecognizer;\n    const phraseDetection = {};\n    const speechSegmentationTimeout = recognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.Speech_SegmentationSilenceTimeoutMs, undefined);\n    if (speechSegmentationTimeout !== undefined) {\n      const segmentationSilenceTimeoutMs = parseInt(speechSegmentationTimeout, 10);\n      phraseDetection.mode = \"INTERACTIVE\";\n      phraseDetection.INTERACTIVE = {\n        segmentation: {\n          mode: \"Custom\",\n          segmentationSilenceTimeoutMs\n        }\n      };\n    }\n    if (recognizerConfig.autoDetectSourceLanguages !== undefined) {\n      const sourceLanguages = recognizerConfig.autoDetectSourceLanguages.split(\",\");\n      this.privSpeechContext.setSection(\"languageId\", {\n        Priority: recognizerConfig.languageIdPriority,\n        languages: sourceLanguages,\n        mode: recognizerConfig.languageIdMode,\n        onSuccess: {\n          action: \"Recognize\"\n        },\n        onUnknown: {\n          action: \"None\"\n        }\n      });\n      this.privSpeechContext.setSection(\"phraseOutput\", {\n        interimResults: {\n          resultType: \"Auto\"\n        },\n        phraseResults: {\n          resultType: \"Always\"\n        }\n      });\n      const customModels = recognizerConfig.sourceLanguageModels;\n      if (customModels !== undefined) {\n        phraseDetection.customModels = customModels;\n        phraseDetection.onInterim = {\n          action: \"None\"\n        };\n        phraseDetection.onSuccess = {\n          action: \"None\"\n        };\n      }\n    }\n    const isEmpty = obj => {\n      // eslint-disable-next-line guard-for-in, brace-style\n      for (const x in obj) {\n        return false;\n      }\n      return true;\n    };\n    if (!isEmpty(phraseDetection)) {\n      this.privSpeechContext.setSection(\"phraseDetection\", phraseDetection);\n    }\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let result;\n      const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n      let processed = false;\n      switch (connectionMessage.path.toLowerCase()) {\n        case \"speech.hypothesis\":\n        case \"speech.fragment\":\n          const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n          const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n          result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, undefined,\n          // Speaker Id\n          undefined, connectionMessage.textBody, resultProps);\n          this.privRequestSession.onHypothesis(offset);\n          const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n          if (!!this.privSpeechRecognizer.recognizing) {\n            try {\n              this.privSpeechRecognizer.recognizing(this.privSpeechRecognizer, ev);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n          processed = true;\n          break;\n        case \"speech.phrase\":\n          const simple = _Exports__WEBPACK_IMPORTED_MODULE_7__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n          const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n          this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n          if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled === resultReason) {\n            const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n            const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n          } else {\n            if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.InitialSilenceTimeout)) {\n              if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.OutputFormatPropertyName) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat.Simple]) {\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, undefined,\n                // Speaker Id\n                undefined, connectionMessage.textBody, resultProps);\n              } else {\n                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_12__.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody);\n                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.Success ? detailed.NBest[0].Display : undefined, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, undefined,\n                // Speaker Id\n                undefined, offsetCorrectedJson, resultProps);\n              }\n              const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n              if (!!this.privSpeechRecognizer.recognized) {\n                try {\n                  this.privSpeechRecognizer.recognized(this.privSpeechRecognizer, event);\n                  /* eslint-disable no-empty */\n                } catch (error) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n            }\n            if (!!this.privSuccessCallback) {\n              try {\n                this.privSuccessCallback(result);\n              } catch (e) {\n                if (!!this.privErrorCallback) {\n                  this.privErrorCallback(e);\n                }\n              }\n              // Only invoke the call back once.\n              // and if it's successful don't invoke the\n              // error after that.\n              this.privSuccessCallback = undefined;\n              this.privErrorCallback = undefined;\n            }\n          }\n          processed = true;\n          break;\n        default:\n          break;\n      }\n      return processed;\n    });\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);\n    if (!!this.privSpeechRecognizer.canceled) {\n      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.SpeechRecognitionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n      try {\n        this.privSpeechRecognizer.canceled(this.privSpeechRecognizer, cancelEvent);\n        /* eslint-disable no-empty */\n      } catch (_a) {}\n    }\n    if (!!this.privSuccessCallback) {\n      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined,\n      // Text\n      undefined,\n      // Duration\n      undefined,\n      // Offset\n      undefined,\n      // Language\n      undefined,\n      // Language Detection Confidence\n      undefined,\n      // Speaker Id\n      error, undefined,\n      // Json\n      properties);\n      try {\n        this.privSuccessCallback(result);\n        this.privSuccessCallback = undefined;\n        /* eslint-disable no-empty */\n      } catch (_b) {}\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisConnectionFactory\": () => (/* binding */ SpeechSynthesisConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass SpeechSynthesisConnectionFactory {\n  constructor() {\n    this.synthesisUri = \"/cognitiveservices/websocket/v1\";\n  }\n  create(config, authInfo, connectionId) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, undefined);\n    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);\n    const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n    const hostPrefix = endpointId === undefined ? \"tts\" : \"voice\";\n    const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".\" + hostPrefix + \".speech\" + hostSuffix);\n    const queryParams = {};\n    if (!endpoint) {\n      endpoint = host + this.synthesisUri;\n    }\n    const headers = {};\n    if (authInfo.token !== undefined && authInfo.token !== \"\") {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_2__.HeaderNames.ConnectionId] = connectionId;\n    if (endpointId !== undefined) {\n      headers[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_3__.QueryParameterNames.CustomVoiceDeploymentId] = endpointId;\n    }\n    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Url, endpoint);\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__.ProxyInfo.fromParameters(config.parameters), enableCompression, connectionId);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisAdapterBase\": () => (/* binding */ SynthesisAdapterBase)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AgentConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\nclass SynthesisAdapterBase {\n  constructor(authentication, connectionFactory, synthesizerConfig, speechSynthesizer, audioDestination) {\n    this.speakOverride = undefined;\n    this.receiveMessageOverride = undefined;\n    this.connectImplOverride = undefined;\n    this.configConnectionOverride = undefined;\n    // A promise for a configured connection.\n    // Do not consume directly, call fetchConnection instead.\n    this.privConnectionConfigurationPromise = undefined;\n    if (!authentication) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"authentication\");\n    }\n    if (!connectionFactory) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"connectionFactory\");\n    }\n    if (!synthesizerConfig) {\n      throw new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"synthesizerConfig\");\n    }\n    this.privAuthentication = authentication;\n    this.privConnectionFactory = connectionFactory;\n    this.privSynthesizerConfig = synthesizerConfig;\n    this.privIsDisposed = false;\n    this.privSpeechSynthesizer = speechSynthesizer;\n    this.privSessionAudioDestination = audioDestination;\n    this.privSynthesisTurn = new _Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisTurn();\n    this.privConnectionEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n    this.privServiceEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.EventSource();\n    this.privSynthesisContext = new _Exports__WEBPACK_IMPORTED_MODULE_3__.SynthesisContext(this.privSpeechSynthesizer);\n    this.privAgentConfig = new _Exports__WEBPACK_IMPORTED_MODULE_4__.AgentConfig();\n    this.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        const connectionClosedEvent = connectionEvent;\n        if (connectionClosedEvent.statusCode !== 1000) {\n          this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, connectionClosedEvent.statusCode === 1007 ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.BadRequestParameters : _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, `${connectionClosedEvent.reason} websocket error code: ${connectionClosedEvent.statusCode}`);\n        }\n      }\n    });\n  }\n  get synthesisContext() {\n    return this.privSynthesisContext;\n  }\n  get agentConfig() {\n    return this.privAgentConfig;\n  }\n  get connectionEvents() {\n    return this.privConnectionEvents;\n  }\n  get serviceEvents() {\n    return this.privServiceEvents;\n  }\n  set activityTemplate(messagePayload) {\n    this.privActivityTemplate = messagePayload;\n  }\n  get activityTemplate() {\n    return this.privActivityTemplate;\n  }\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n    this.privSynthesisTurn.audioOutputFormat = format;\n    if (this.privSessionAudioDestination !== undefined) {\n      this.privSessionAudioDestination.format = format;\n    }\n    if (this.synthesisContext !== undefined) {\n      this.synthesisContext.audioOutputFormat = format;\n    }\n  }\n  static addHeader(audio, format) {\n    if (!format.hasHeader) {\n      return audio;\n    }\n    format.updateHeader(audio.byteLength);\n    const tmp = new Uint8Array(audio.byteLength + format.header.byteLength);\n    tmp.set(new Uint8Array(format.header), 0);\n    tmp.set(new Uint8Array(audio), format.header.byteLength);\n    return tmp.buffer;\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  dispose(reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privIsDisposed = true;\n      if (this.privSessionAudioDestination !== undefined) {\n        this.privSessionAudioDestination.close();\n      }\n      if (this.privConnectionConfigurationPromise !== undefined) {\n        const connection = yield this.privConnectionConfigurationPromise;\n        yield connection.dispose(reason);\n      }\n    });\n  }\n  connect() {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.connectImpl();\n    });\n  }\n  sendNetworkMessage(path, payload) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const type = typeof payload === \"string\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text : _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Binary;\n      const contentType = typeof payload === \"string\" ? \"application/json\" : \"\";\n      const connection = yield this.fetchConnection();\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(type, path, this.privSynthesisTurn.requestId, contentType, payload));\n    });\n  }\n  Speak(text, isSSML, requestId, successCallback, errorCallBack, audioDestination) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let ssml;\n      if (isSSML) {\n        ssml = text;\n      } else {\n        ssml = this.privSpeechSynthesizer.buildSsml(text);\n      }\n      if (this.speakOverride !== undefined) {\n        return this.speakOverride(ssml, requestId, successCallback, errorCallBack);\n      }\n      this.privSuccessCallback = successCallback;\n      this.privErrorCallback = errorCallBack;\n      this.privSynthesisTurn.startNewSynthesis(requestId, text, isSSML, audioDestination);\n      try {\n        yield this.connectImpl();\n        const connection = yield this.fetchConnection();\n        yield this.sendSynthesisContext(connection);\n        yield this.sendSsmlMessage(connection, ssml, requestId);\n        const synthesisStartEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudioStarted));\n        if (!!this.privSpeechSynthesizer.synthesisStarted) {\n          this.privSpeechSynthesizer.synthesisStarted(this.privSpeechSynthesizer, synthesisStartEventArgs);\n        }\n        void this.receiveMessage();\n      } catch (e) {\n        this.cancelSynthesisLocal(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.ConnectionFailure, e);\n        return Promise.reject(e);\n      }\n    });\n  }\n  // Cancels synthesis.\n  cancelSynthesis(requestId, cancellationReason, errorCode, error) {\n    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.PropertyCollection();\n    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode[errorCode]);\n    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.Canceled, undefined, error, properties);\n    if (!!this.privSpeechSynthesizer.SynthesisCanceled) {\n      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(result);\n      try {\n        this.privSpeechSynthesizer.SynthesisCanceled(this.privSpeechSynthesizer, cancelEvent);\n        /* eslint-disable no-empty */\n      } catch (_a) {}\n    }\n    if (!!this.privSuccessCallback) {\n      try {\n        this.privSuccessCallback(result);\n        /* eslint-disable no-empty */\n      } catch (_b) {}\n    }\n  }\n  // Cancels synthesis.\n  cancelSynthesisLocal(cancellationReason, errorCode, error) {\n    if (!!this.privSynthesisTurn.isSynthesizing) {\n      this.privSynthesisTurn.onStopSynthesizing();\n      this.cancelSynthesis(this.privSynthesisTurn.requestId, cancellationReason, errorCode, error);\n    }\n  }\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  processTypeSpecificMessages(connectionMessage) {\n    return true;\n  }\n  receiveMessage() {\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        const connection = yield this.fetchConnection();\n        const message = yield connection.read();\n        if (this.receiveMessageOverride !== undefined) {\n          return this.receiveMessageOverride();\n        }\n        if (this.privIsDisposed) {\n          // We're done.\n          return;\n        }\n        // indicates we are draining the queue and it came with no message;\n        if (!message) {\n          if (!this.privSynthesisTurn.isSynthesizing) {\n            return;\n          } else {\n            return this.receiveMessage();\n          }\n        }\n        const connectionMessage = _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage.fromConnectionMessage(message);\n        if (connectionMessage.requestId.toLowerCase() === this.privSynthesisTurn.requestId.toLowerCase()) {\n          switch (connectionMessage.path.toLowerCase()) {\n            case \"turn.start\":\n              this.privSynthesisTurn.onServiceTurnStartResponse();\n              break;\n            case \"response\":\n              this.privSynthesisTurn.onServiceResponseMessage(connectionMessage.textBody);\n              break;\n            case \"audio\":\n              if (this.privSynthesisTurn.streamId.toLowerCase() === connectionMessage.streamId.toLowerCase() && !!connectionMessage.binaryBody) {\n                this.privSynthesisTurn.onAudioChunkReceived(connectionMessage.binaryBody);\n                if (!!this.privSpeechSynthesizer.synthesizing) {\n                  try {\n                    const audioWithHeader = SynthesisAdapterBase.addHeader(connectionMessage.binaryBody, this.privSynthesisTurn.audioOutputFormat);\n                    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudio, audioWithHeader));\n                    this.privSpeechSynthesizer.synthesizing(this.privSpeechSynthesizer, ev);\n                  } catch (error) {\n                    // Not going to let errors in the event handler\n                    // trip things up.\n                  }\n                }\n                if (this.privSessionAudioDestination !== undefined) {\n                  this.privSessionAudioDestination.write(connectionMessage.binaryBody);\n                }\n              }\n              break;\n            case \"audio.metadata\":\n              const metadataList = _Exports__WEBPACK_IMPORTED_MODULE_14__.SynthesisAudioMetadata.fromJSON(connectionMessage.textBody).Metadata;\n              for (const metadata of metadataList) {\n                switch (metadata.Type) {\n                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.WordBoundary:\n                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.SentenceBoundary:\n                    this.privSynthesisTurn.onTextBoundaryEvent(metadata);\n                    const wordBoundaryEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechSynthesisWordBoundaryEventArgs(metadata.Data.Offset, metadata.Data.Duration, metadata.Data.text.Text, metadata.Data.text.Length, metadata.Type === _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.WordBoundary ? this.privSynthesisTurn.currentTextOffset : this.privSynthesisTurn.currentSentenceOffset, metadata.Data.text.BoundaryType);\n                    if (!!this.privSpeechSynthesizer.wordBoundary) {\n                      try {\n                        this.privSpeechSynthesizer.wordBoundary(this.privSpeechSynthesizer, wordBoundaryEventArgs);\n                      } catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                      }\n                    }\n                    break;\n                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.Bookmark:\n                    const bookmarkEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.SpeechSynthesisBookmarkEventArgs(metadata.Data.Offset, metadata.Data.Bookmark);\n                    if (!!this.privSpeechSynthesizer.bookmarkReached) {\n                      try {\n                        this.privSpeechSynthesizer.bookmarkReached(this.privSpeechSynthesizer, bookmarkEventArgs);\n                      } catch (error) {\n                        // Not going to let errors in the event handler\n                        // trip things up.\n                      }\n                    }\n                    break;\n                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.Viseme:\n                    this.privSynthesisTurn.onVisemeMetadataReceived(metadata);\n                    if (metadata.Data.IsLastAnimation) {\n                      const visemeEventArgs = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_17__.SpeechSynthesisVisemeEventArgs(metadata.Data.Offset, metadata.Data.VisemeId, this.privSynthesisTurn.getAndClearVisemeAnimation());\n                      if (!!this.privSpeechSynthesizer.visemeReceived) {\n                        try {\n                          this.privSpeechSynthesizer.visemeReceived(this.privSpeechSynthesizer, visemeEventArgs);\n                        } catch (error) {\n                          // Not going to let errors in the event handler\n                          // trip things up.\n                        }\n                      }\n                    }\n                    break;\n                  case _Exports__WEBPACK_IMPORTED_MODULE_14__.MetadataType.SessionEnd:\n                    this.privSynthesisTurn.onSessionEnd(metadata);\n                    break;\n                }\n              }\n              break;\n            case \"turn.end\":\n              this.privSynthesisTurn.onServiceTurnEndResponse();\n              let result;\n              try {\n                const audioBuffer = yield this.privSynthesisTurn.getAllReceivedAudioWithHeader();\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_10__.SpeechSynthesisResult(this.privSynthesisTurn.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.ResultReason.SynthesizingAudioCompleted, audioBuffer, undefined, undefined, this.privSynthesisTurn.audioDuration);\n                if (!!this.privSuccessCallback) {\n                  this.privSuccessCallback(result);\n                }\n              } catch (error) {\n                if (!!this.privErrorCallback) {\n                  this.privErrorCallback(error);\n                }\n              }\n              if (this.privSpeechSynthesizer.synthesisCompleted) {\n                try {\n                  this.privSpeechSynthesizer.synthesisCompleted(this.privSpeechSynthesizer, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechSynthesisEventArgs(result));\n                } catch (e) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n              break;\n            default:\n              if (!this.processTypeSpecificMessages(connectionMessage)) {\n                // here are some messages that the derived class has not processed, dispatch them to connect class\n                if (!!this.privServiceEvents) {\n                  this.serviceEvents.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_18__.ServiceEvent(connectionMessage.path.toLowerCase(), connectionMessage.textBody));\n                }\n              }\n          }\n        }\n        return this.receiveMessage();\n      } catch (e) {\n        // TODO: What goes here?\n      }\n    });\n  }\n  sendSynthesisContext(connection) {\n    const synthesisContextJson = this.synthesisContext.toJSON();\n    if (synthesisContextJson) {\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, \"synthesis.context\", this.privSynthesisTurn.requestId, \"application/json\", synthesisContextJson));\n    }\n    return;\n  }\n  connectImpl() {\n    let isUnAuthorized = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n    if (this.privConnectionPromise != null) {\n      return this.privConnectionPromise.then(connection => {\n        if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.ConnectionState.Disconnected) {\n          this.privConnectionId = null;\n          this.privConnectionPromise = null;\n          return this.connectImpl();\n        }\n        return this.privConnectionPromise;\n      }, () => {\n        this.privConnectionId = null;\n        this.privConnectionPromise = null;\n        return this.connectImpl();\n      });\n    }\n    this.privAuthFetchEventId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_20__.createNoDashGuid)();\n    this.privConnectionId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_20__.createNoDashGuid)();\n    this.privSynthesisTurn.onPreConnectionStart(this.privAuthFetchEventId);\n    const authPromise = isUnAuthorized ? this.privAuthentication.fetchOnExpiry(this.privAuthFetchEventId) : this.privAuthentication.fetch(this.privAuthFetchEventId);\n    this.privConnectionPromise = authPromise.then(result => __awaiter(this, void 0, void 0, function* () {\n      this.privSynthesisTurn.onAuthCompleted(false);\n      const connection = this.privConnectionFactory.create(this.privSynthesizerConfig, result, this.privConnectionId);\n      // Attach to the underlying event. No need to hold onto the detach pointers as in the event the connection goes away,\n      // it'll stop sending events.\n      connection.events.attach(event => {\n        this.connectionEvents.onEvent(event);\n      });\n      const response = yield connection.open();\n      if (response.statusCode === 200) {\n        this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n        return Promise.resolve(connection);\n      } else if (response.statusCode === 403 && !isUnAuthorized) {\n        return this.connectImpl(true);\n      } else {\n        this.privSynthesisTurn.onConnectionEstablishCompleted(response.statusCode);\n        return Promise.reject(`Unable to contact server. StatusCode: ${response.statusCode}, ${this.privSynthesizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_21__.PropertyId.SpeechServiceConnection_Endpoint)} Reason: ${response.reason}`);\n      }\n    }), error => {\n      this.privSynthesisTurn.onAuthCompleted(true);\n      throw new Error(error);\n    });\n    // Attach an empty handler to allow the promise to run in the background while\n    // other startup events happen. It'll eventually be awaited on.\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    this.privConnectionPromise.catch(() => {});\n    return this.privConnectionPromise;\n  }\n  sendSpeechServiceConfig(connection, SpeechServiceConfigJson) {\n    if (SpeechServiceConfigJson) {\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, \"speech.config\", this.privSynthesisTurn.requestId, \"application/json\", SpeechServiceConfigJson));\n    }\n  }\n  sendSsmlMessage(connection, ssml, requestId) {\n    return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_8__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text, \"ssml\", requestId, \"application/ssml+xml\", ssml));\n  }\n  fetchConnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privConnectionConfigurationPromise !== undefined) {\n        return this.privConnectionConfigurationPromise.then(connection => {\n          if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.ConnectionState.Disconnected) {\n            this.privConnectionId = null;\n            this.privConnectionConfigurationPromise = undefined;\n            return this.fetchConnection();\n          }\n          return this.privConnectionConfigurationPromise;\n        }, () => {\n          this.privConnectionId = null;\n          this.privConnectionConfigurationPromise = undefined;\n          return this.fetchConnection();\n        });\n      }\n      this.privConnectionConfigurationPromise = this.configureConnection();\n      return yield this.privConnectionConfigurationPromise;\n    });\n  }\n  // Takes an established websocket connection to the endpoint and sends speech configuration information.\n  configureConnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.connectImpl();\n      if (this.configConnectionOverride !== undefined) {\n        return this.configConnectionOverride(connection);\n      }\n      yield this.sendSpeechServiceConfig(connection, this.privSynthesizerConfig.SpeechServiceConfig.serialize());\n      return connection;\n    });\n  }\n}\nSynthesisAdapterBase.telemetryDataEnabled = true;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisContext\": () => (/* binding */ SynthesisContext)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents the JSON used in the synthesis.context message sent to the speech service.\n * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.\n */\nclass SynthesisContext {\n  constructor(speechSynthesizer) {\n    this.privContext = {};\n    this.privSpeechSynthesizer = speechSynthesizer;\n  }\n  /**\n   * Adds a section to the synthesis.context object.\n   * @param sectionName Name of the section to add.\n   * @param value JSON serializable object that represents the value.\n   */\n  setSection(sectionName, value) {\n    this.privContext[sectionName] = value;\n  }\n  /**\n   * Sets the audio output format for synthesis context generation.\n   * @param format {AudioOutputFormatImpl} the output format\n   */\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n  }\n  toJSON() {\n    const synthesisSection = this.buildSynthesisContext();\n    this.setSection(\"synthesis\", synthesisSection);\n    return JSON.stringify(this.privContext);\n  }\n  buildSynthesisContext() {\n    return {\n      audio: {\n        metadataOptions: {\n          bookmarkEnabled: !!this.privSpeechSynthesizer.bookmarkReached,\n          punctuationBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestPunctuationBoundary, !!this.privSpeechSynthesizer.wordBoundary),\n          sentenceBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestSentenceBoundary, false),\n          sessionEndEnabled: true,\n          visemeEnabled: !!this.privSpeechSynthesizer.visemeReceived,\n          wordBoundaryEnabled: this.privSpeechSynthesizer.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceResponse_RequestWordBoundary, !!this.privSpeechSynthesizer.wordBoundary)\n        },\n        outputFormat: this.privAudioOutputFormat.requestAudioFormatString\n      },\n      language: {\n        autoDetection: this.privSpeechSynthesizer.autoDetectSourceLanguage\n      }\n    };\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisContext.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectingToSynthesisServiceEvent\": () => (/* binding */ ConnectingToSynthesisServiceEvent),\n/* harmony export */   \"SpeechSynthesisEvent\": () => (/* binding */ SpeechSynthesisEvent),\n/* harmony export */   \"SynthesisStartedEvent\": () => (/* binding */ SynthesisStartedEvent),\n/* harmony export */   \"SynthesisTriggeredEvent\": () => (/* binding */ SynthesisTriggeredEvent)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass SpeechSynthesisEvent extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName, requestId) {\n    let eventType = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : _common_Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Info;\n    super(eventName, eventType);\n    this.privRequestId = requestId;\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n}\nclass SynthesisTriggeredEvent extends SpeechSynthesisEvent {\n  constructor(requestId, sessionAudioDestinationId, turnAudioDestinationId) {\n    super(\"SynthesisTriggeredEvent\", requestId);\n    this.privSessionAudioDestinationId = sessionAudioDestinationId;\n    this.privTurnAudioDestinationId = turnAudioDestinationId;\n  }\n  get audioSessionDestinationId() {\n    return this.privSessionAudioDestinationId;\n  }\n  get audioTurnDestinationId() {\n    return this.privTurnAudioDestinationId;\n  }\n}\nclass ConnectingToSynthesisServiceEvent extends SpeechSynthesisEvent {\n  constructor(requestId, authFetchEventId) {\n    super(\"ConnectingToSynthesisServiceEvent\", requestId);\n    this.privAuthFetchEventId = authFetchEventId;\n  }\n  get authFetchEventId() {\n    return this.privAuthFetchEventId;\n  }\n}\nclass SynthesisStartedEvent extends SpeechSynthesisEvent {\n  constructor(requestId, authFetchEventId) {\n    super(\"SynthesisStartedEvent\", requestId);\n    this.privAuthFetchEventId = authFetchEventId;\n  }\n  get authFetchEventId() {\n    return this.privAuthFetchEventId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisRestAdapter\": () => (/* binding */ SynthesisRestAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n\n\n\n\n/**\n * Implements methods for speaker recognition classes, sending requests to endpoint\n * and parsing response into expected format\n * @class SynthesisRestAdapter\n */\nclass SynthesisRestAdapter {\n  constructor(config, authentication) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n    if (!endpoint) {\n      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Region, \"westus\");\n      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_1__.ConnectionFactoryBase.getHostSuffix(region);\n      endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId.SpeechServiceConnection_Host, `https://${region}.tts.speech${hostSuffix}`);\n    }\n    this.privUri = `${endpoint}/cognitiveservices/voices/list`;\n    const options = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.RestConfigBase.requestOptions;\n    this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestMessageAdapter(options);\n    this.privAuthentication = authentication;\n  }\n  /**\n   * Sends list voices request to endpoint.\n   * @function\n   * @public\n   * @param connectionId - guid for connectionId\n   * @returns {Promise<IRestResponse>} rest response to status request\n   */\n  getVoicesList(connectionId) {\n    this.privRestAdapter.setHeaders(_HeaderNames__WEBPACK_IMPORTED_MODULE_4__.HeaderNames.ConnectionId, connectionId);\n    return this.privAuthentication.fetch(connectionId).then(authInfo => {\n      this.privRestAdapter.setHeaders(authInfo.headerName, authInfo.token);\n      return this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_3__.RestRequestType.Get, this.privUri);\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisTurn\": () => (/* binding */ SynthesisTurn)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../sdk/Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ServiceMessages/SynthesisAudioMetadata */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SynthesisAudioMetadata.js\");\n/* harmony import */ var _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SynthesisAdapterBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SynthesisEvents */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisEvents.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\nclass SynthesisTurn {\n  constructor() {\n    this.privIsDisposed = false;\n    this.privIsSynthesizing = false;\n    this.privIsSynthesisEnded = false;\n    this.privBytesReceived = 0;\n    this.privInTurn = false;\n    this.privTextOffset = 0;\n    this.privNextSearchTextIndex = 0;\n    this.privSentenceOffset = 0;\n    this.privNextSearchSentenceIndex = 0;\n    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    // We're not in a turn, so resolve.\n    this.privTurnDeferral.resolve();\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n  get streamId() {\n    return this.privStreamId;\n  }\n  set streamId(value) {\n    this.privStreamId = value;\n  }\n  get audioOutputFormat() {\n    return this.privAudioOutputFormat;\n  }\n  set audioOutputFormat(format) {\n    this.privAudioOutputFormat = format;\n  }\n  get turnCompletionPromise() {\n    return this.privTurnDeferral.promise;\n  }\n  get isSynthesisEnded() {\n    return this.privIsSynthesisEnded;\n  }\n  get isSynthesizing() {\n    return this.privIsSynthesizing;\n  }\n  get currentTextOffset() {\n    return this.privTextOffset;\n  }\n  get currentSentenceOffset() {\n    return this.privSentenceOffset;\n  }\n  // The number of bytes received for current turn\n  get bytesReceived() {\n    return this.privBytesReceived;\n  }\n  get audioDuration() {\n    return this.privAudioDuration;\n  }\n  getAllReceivedAudio() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privReceivedAudio) {\n        return Promise.resolve(this.privReceivedAudio);\n      }\n      if (!this.privIsSynthesisEnded) {\n        return null;\n      }\n      yield this.readAllAudioFromStream();\n      return Promise.resolve(this.privReceivedAudio);\n    });\n  }\n  getAllReceivedAudioWithHeader() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privReceivedAudioWithHeader) {\n        return this.privReceivedAudioWithHeader;\n      }\n      if (!this.privIsSynthesisEnded) {\n        return null;\n      }\n      if (this.audioOutputFormat.hasHeader) {\n        const audio = yield this.getAllReceivedAudio();\n        this.privReceivedAudioWithHeader = _SynthesisAdapterBase__WEBPACK_IMPORTED_MODULE_2__.SynthesisAdapterBase.addHeader(audio, this.audioOutputFormat);\n        return this.privReceivedAudioWithHeader;\n      } else {\n        return this.getAllReceivedAudio();\n      }\n    });\n  }\n  startNewSynthesis(requestId, rawText, isSSML, audioDestination) {\n    this.privIsSynthesisEnded = false;\n    this.privIsSynthesizing = true;\n    this.privRequestId = requestId;\n    this.privRawText = rawText;\n    this.privIsSSML = isSSML;\n    this.privAudioOutputStream = new _sdk_Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PullAudioOutputStreamImpl();\n    this.privAudioOutputStream.format = this.privAudioOutputFormat;\n    this.privReceivedAudio = null;\n    this.privReceivedAudioWithHeader = null;\n    this.privBytesReceived = 0;\n    this.privTextOffset = 0;\n    this.privNextSearchTextIndex = 0;\n    this.privSentenceOffset = 0;\n    this.privNextSearchSentenceIndex = 0;\n    this.privPartialVisemeAnimation = \"\";\n    if (audioDestination !== undefined) {\n      this.privTurnAudioDestination = audioDestination;\n      this.privTurnAudioDestination.format = this.privAudioOutputFormat;\n    }\n    this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.SynthesisTriggeredEvent(this.requestId, undefined, audioDestination === undefined ? undefined : audioDestination.id()));\n  }\n  onPreConnectionStart(authFetchEventId) {\n    this.privAuthFetchEventId = authFetchEventId;\n    this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.ConnectingToSynthesisServiceEvent(this.privRequestId, this.privAuthFetchEventId));\n  }\n  onAuthCompleted(isError) {\n    if (isError) {\n      this.onComplete();\n    }\n  }\n  onConnectionEstablishCompleted(statusCode) {\n    if (statusCode === 200) {\n      this.onEvent(new _SynthesisEvents__WEBPACK_IMPORTED_MODULE_4__.SynthesisStartedEvent(this.requestId, this.privAuthFetchEventId));\n      this.privBytesReceived = 0;\n      return;\n    } else if (statusCode === 403) {\n      this.onComplete();\n    }\n  }\n  onServiceResponseMessage(responseJson) {\n    const response = JSON.parse(responseJson);\n    this.streamId = response.audio.streamId;\n  }\n  onServiceTurnEndResponse() {\n    this.privInTurn = false;\n    this.privTurnDeferral.resolve();\n    this.onComplete();\n  }\n  onServiceTurnStartResponse() {\n    if (!!this.privTurnDeferral && !!this.privInTurn) {\n      // What? How are we starting a turn with another not done?\n      this.privTurnDeferral.reject(\"Another turn started before current completed.\");\n      // Avoid UnhandledPromiseRejection if privTurnDeferral is not being awaited\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n      this.privTurnDeferral.promise.then().catch(() => {});\n    }\n    this.privInTurn = true;\n    this.privTurnDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n  }\n  onAudioChunkReceived(data) {\n    if (this.isSynthesizing) {\n      this.privAudioOutputStream.write(data);\n      this.privBytesReceived += data.byteLength;\n      if (this.privTurnAudioDestination !== undefined) {\n        this.privTurnAudioDestination.write(data);\n      }\n    }\n  }\n  onTextBoundaryEvent(metadata) {\n    this.updateTextOffset(metadata.Data.text.Text, metadata.Type);\n  }\n  onVisemeMetadataReceived(metadata) {\n    if (metadata.Data.AnimationChunk !== undefined) {\n      this.privPartialVisemeAnimation += metadata.Data.AnimationChunk;\n    }\n  }\n  onSessionEnd(metadata) {\n    this.privAudioDuration = metadata.Data.Offset;\n  }\n  dispose() {\n    if (!this.privIsDisposed) {\n      // we should have completed by now. If we did not its an unknown error.\n      this.privIsDisposed = true;\n    }\n  }\n  onStopSynthesizing() {\n    this.onComplete();\n  }\n  /**\n   * Gets the viseme animation string (merged from animation chunk), and clears the internal\n   * partial animation.\n   */\n  getAndClearVisemeAnimation() {\n    const animation = this.privPartialVisemeAnimation;\n    this.privPartialVisemeAnimation = \"\";\n    return animation;\n  }\n  onEvent(event) {\n    _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(event);\n  }\n  /**\n   * Check if the text is an XML(SSML) tag\n   * @param text\n   * @private\n   */\n  static isXmlTag(text) {\n    return text.length >= 2 && text[0] === \"<\" && text[text.length - 1] === \">\";\n  }\n  updateTextOffset(text, type) {\n    if (type === _ServiceMessages_SynthesisAudioMetadata__WEBPACK_IMPORTED_MODULE_6__.MetadataType.WordBoundary) {\n      this.privTextOffset = this.privRawText.indexOf(text, this.privNextSearchTextIndex);\n      if (this.privTextOffset >= 0) {\n        this.privNextSearchTextIndex = this.privTextOffset + text.length;\n        if (this.privIsSSML) {\n          if (this.withinXmlTag(this.privTextOffset) && !SynthesisTurn.isXmlTag(text)) {\n            this.updateTextOffset(text, type);\n          }\n        }\n      }\n    } else {\n      this.privSentenceOffset = this.privRawText.indexOf(text, this.privNextSearchSentenceIndex);\n      if (this.privSentenceOffset >= 0) {\n        this.privNextSearchSentenceIndex = this.privSentenceOffset + text.length;\n        if (this.privIsSSML) {\n          if (this.withinXmlTag(this.privSentenceOffset) && !SynthesisTurn.isXmlTag(text)) {\n            this.updateTextOffset(text, type);\n          }\n        }\n      }\n    }\n  }\n  onComplete() {\n    if (this.privIsSynthesizing) {\n      this.privIsSynthesizing = false;\n      this.privIsSynthesisEnded = true;\n      this.privAudioOutputStream.close();\n      this.privInTurn = false;\n      if (this.privTurnAudioDestination !== undefined) {\n        this.privTurnAudioDestination.close();\n        this.privTurnAudioDestination = undefined;\n      }\n    }\n  }\n  readAllAudioFromStream() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privIsSynthesisEnded) {\n        this.privReceivedAudio = new ArrayBuffer(this.bytesReceived);\n        try {\n          yield this.privAudioOutputStream.read(this.privReceivedAudio);\n        } catch (e) {\n          this.privReceivedAudio = new ArrayBuffer(0);\n        }\n      }\n    });\n  }\n  /**\n   * Check if current idx is in XML(SSML) tag\n   * @param idx\n   * @private\n   */\n  withinXmlTag(idx) {\n    return this.privRawText.indexOf(\"<\", idx + 1) > this.privRawText.indexOf(\">\", idx + 1);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisTurn.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisServiceType\": () => (/* binding */ SynthesisServiceType),\n/* harmony export */   \"SynthesizerConfig\": () => (/* binding */ SynthesizerConfig)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nvar SynthesisServiceType;\n(function (SynthesisServiceType) {\n  SynthesisServiceType[SynthesisServiceType[\"Standard\"] = 0] = \"Standard\";\n  SynthesisServiceType[SynthesisServiceType[\"Custom\"] = 1] = \"Custom\";\n})(SynthesisServiceType || (SynthesisServiceType = {}));\nclass SynthesizerConfig {\n  constructor(speechServiceConfig, parameters) {\n    this.privSynthesisServiceType = SynthesisServiceType.Standard;\n    this.privSpeechServiceConfig = speechServiceConfig ? speechServiceConfig : new _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechServiceConfig(new _Exports__WEBPACK_IMPORTED_MODULE_0__.Context(null));\n    this.privParameters = parameters;\n  }\n  get parameters() {\n    return this.privParameters;\n  }\n  get synthesisServiceType() {\n    return this.privSynthesisServiceType;\n  }\n  set synthesisServiceType(value) {\n    this.privSynthesisServiceType = value;\n  }\n  get SpeechServiceConfig() {\n    return this.privSpeechServiceConfig;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranscriberConnectionFactory\": () => (/* binding */ TranscriberConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass TranscriberConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n  constructor() {\n    super(...arguments);\n    this.multiaudioRelativeUri = \"/speech/recognition/multiaudio\";\n  }\n  create(config, authInfo, connectionId) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n    const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, \"centralus\");\n    const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n    const hostDefault = \"wss://transcribe.\" + region + \".cts.speech\" + hostSuffix + this.multiaudioRelativeUri;\n    const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, hostDefault);\n    const queryParams = {};\n    const endpointId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, undefined);\n    const language = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, undefined);\n    if (endpointId) {\n      if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId) === -1) {\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.CustomSpeechDeploymentId] = endpointId;\n      }\n    } else if (language) {\n      if (!endpoint || endpoint.search(_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language) === -1) {\n        queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Language] = language;\n      }\n    }\n    const wordLevelTimings = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"false\").toLowerCase() === \"true\";\n    const detailed = config.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormatPropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple]) !== _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple];\n    if (wordLevelTimings || detailed) {\n      queryParams[_QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.Format] = _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Detailed].toLowerCase();\n    }\n    this.setCommonUrlParams(config, queryParams, endpoint);\n    if (!endpoint) {\n      endpoint = host;\n    }\n    const headers = {};\n    if (authInfo.token !== undefined && authInfo.token !== \"\") {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_5__.HeaderNames.ConnectionId] = connectionId;\n    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_7__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_8__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranscriptionServiceRecognizer\": () => (/* binding */ TranscriptionServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SpeechHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/DetailedSpeechPhrase.js\");\n/* harmony import */ var _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./SpeechConnectionMessage.Internal */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionMessage.Internal.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass TranscriptionServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, transcriber) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, transcriber);\n    this.privTranscriberRecognizer = transcriber;\n    this.sendPrePayloadJSONOverride = connection => this.sendTranscriptionStartJSON(connection);\n    if (this.privRecognizerConfig.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps) === \"true\") {\n      this.privSpeechContext.setWordLevelTimings();\n    }\n  }\n  sendSpeechEventAsync(info, command) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privRequestSession.isRecognizing) {\n        const connection = yield this.fetchConnection();\n        yield this.sendSpeechEvent(connection, this.createSpeechEventPayload(info, command));\n      }\n    });\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    return __awaiter(this, void 0, void 0, function* () {\n      let result;\n      const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n      resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n      let processed = false;\n      switch (connectionMessage.path.toLowerCase()) {\n        case \"speech.hypothesis\":\n        case \"speech.fragment\":\n          const hypothesis = _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechHypothesis.fromJSON(connectionMessage.textBody);\n          const offset = hypothesis.Offset + this.privRequestSession.currentTurnAudioOffset;\n          result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizingSpeech, hypothesis.Text, hypothesis.Duration, offset, hypothesis.Language, hypothesis.LanguageDetectionConfidence, hypothesis.SpeakerId, undefined, connectionMessage.textBody, resultProps);\n          this.privRequestSession.onHypothesis(offset);\n          const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, hypothesis.Duration, this.privRequestSession.sessionId);\n          if (!!this.privTranscriberRecognizer.recognizing) {\n            try {\n              this.privTranscriberRecognizer.recognizing(this.privTranscriberRecognizer, ev);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n          processed = true;\n          break;\n        case \"speech.phrase\":\n          const simple = _Exports__WEBPACK_IMPORTED_MODULE_7__.SimpleSpeechPhrase.fromJSON(connectionMessage.textBody);\n          const resultReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateRecognitionResult(simple.RecognitionStatus);\n          this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + simple.Offset + simple.Duration);\n          if (_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled === resultReason) {\n            const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelResult(simple.RecognitionStatus);\n            const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateCancelErrorCode(simple.RecognitionStatus);\n            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_8__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n          } else {\n            if (!(this.privRequestSession.isSpeechEnded && resultReason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && simple.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_9__.RecognitionStatus.InitialSilenceTimeout)) {\n              if (this.privRecognizerConfig.parameters.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.OutputFormatPropertyName) === _sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat[_sdk_Exports__WEBPACK_IMPORTED_MODULE_11__.OutputFormat.Simple]) {\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, simple.DisplayText, simple.Duration, simple.Offset + this.privRequestSession.currentTurnAudioOffset, simple.Language, simple.LanguageDetectionConfidence, simple.SpeakerId, undefined, connectionMessage.textBody, resultProps);\n              } else {\n                const detailed = _Exports__WEBPACK_IMPORTED_MODULE_12__.DetailedSpeechPhrase.fromJSON(connectionMessage.textBody);\n                const totalOffset = detailed.Offset + this.privRequestSession.currentTurnAudioOffset;\n                const offsetCorrectedJson = detailed.getJsonWithCorrectedOffsets(totalOffset);\n                result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(this.privRequestSession.requestId, resultReason, detailed.Text, detailed.Duration, totalOffset, detailed.Language, detailed.LanguageDetectionConfidence, detailed.SpeakerId, undefined, offsetCorrectedJson, resultProps);\n              }\n              const event = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n              if (!!this.privTranscriberRecognizer.recognized) {\n                try {\n                  this.privTranscriberRecognizer.recognized(this.privTranscriberRecognizer, event);\n                  /* eslint-disable no-empty */\n                } catch (error) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n            }\n            if (!!this.privSuccessCallback) {\n              try {\n                this.privSuccessCallback(result);\n              } catch (e) {\n                if (!!this.privErrorCallback) {\n                  this.privErrorCallback(e);\n                }\n              }\n              // Only invoke the call back once.\n              // and if it's successful don't invoke the\n              // error after that.\n              this.privSuccessCallback = undefined;\n              this.privErrorCallback = undefined;\n            }\n          }\n          processed = true;\n          break;\n        default:\n          break;\n      }\n      return processed;\n    });\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.CancellationErrorCode[errorCode]);\n    if (!!this.privTranscriberRecognizer.canceled) {\n      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.ConversationTranscriptionCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n      try {\n        this.privTranscriberRecognizer.canceled(this.privTranscriberRecognizer, cancelEvent);\n        /* eslint-disable no-empty */\n      } catch (_a) {}\n    }\n    if (!!this.privSuccessCallback) {\n      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechRecognitionResult(requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined,\n      // Text\n      undefined,\n      // Duration\n      undefined,\n      // Offset\n      undefined,\n      // Language\n      undefined,\n      // Language Detection Confidence\n      undefined,\n      // Speaker Id\n      error, undefined,\n      // Json\n      properties);\n      try {\n        this.privSuccessCallback(result);\n        this.privSuccessCallback = undefined;\n        /* eslint-disable no-empty */\n      } catch (_b) {}\n    }\n  }\n  // Encapsulated for derived service recognizers that need to send additional JSON\n  sendTranscriptionStartJSON(connection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.sendSpeechContext(connection, true);\n      const info = this.privTranscriberRecognizer.getConversationInfo();\n      const payload = this.createSpeechEventPayload(info, \"start\");\n      yield this.sendSpeechEvent(connection, payload);\n      yield this.sendWaveHeader(connection);\n      return;\n    });\n  }\n  sendSpeechEvent(connection, payload) {\n    const speechEventJson = JSON.stringify(payload);\n    if (speechEventJson) {\n      return connection.send(new _SpeechConnectionMessage_Internal__WEBPACK_IMPORTED_MODULE_15__.SpeechConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_16__.MessageType.Text, \"speech.event\", this.privRequestSession.requestId, \"application/json\", speechEventJson));\n    }\n    return;\n  }\n  createSpeechEventPayload(info, command) {\n    const eventDict = {\n      id: \"meeting\",\n      name: command,\n      meeting: info.conversationProperties\n    };\n    eventDict.meeting.id = info.id;\n    eventDict.meeting.attendees = info.participants;\n    eventDict.meeting.record = info.conversationProperties.audiorecording === \"on\" ? \"true\" : \"false\";\n    return eventDict;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionConfig\": () => (/* binding */ ConversationConnectionConfig)\n/* harmony export */ });\n/* harmony import */ var _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/RestConfigBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestConfigBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ConversationConnectionConfig extends _common_browser_RestConfigBase__WEBPACK_IMPORTED_MODULE_0__.RestConfigBase {\n  static get host() {\n    return ConversationConnectionConfig.privHost;\n  }\n  static get apiVersion() {\n    return ConversationConnectionConfig.privApiVersion;\n  }\n  static get clientAppId() {\n    return ConversationConnectionConfig.privClientAppId;\n  }\n  static get defaultLanguageCode() {\n    return ConversationConnectionConfig.privDefaultLanguageCode;\n  }\n  static get restPath() {\n    return ConversationConnectionConfig.privRestPath;\n  }\n  static get webSocketPath() {\n    return ConversationConnectionConfig.privWebSocketPath;\n  }\n  static get speechHost() {\n    return ConversationConnectionConfig.privSpeechHost;\n  }\n  static get speechPath() {\n    return ConversationConnectionConfig.privSpeechPath;\n  }\n  static get transcriptionEventKeys() {\n    return ConversationConnectionConfig.privTranscriptionEventKeys;\n  }\n}\nConversationConnectionConfig.privHost = \"dev.microsofttranslator.com\";\nConversationConnectionConfig.privRestPath = \"/capito/room\";\nConversationConnectionConfig.privApiVersion = \"2.0\";\nConversationConnectionConfig.privDefaultLanguageCode = \"en-US\";\nConversationConnectionConfig.privClientAppId = \"FC539C22-1767-4F1F-84BC-B4D811114F15\";\nConversationConnectionConfig.privWebSocketPath = \"/capito/translate\";\nConversationConnectionConfig.privSpeechHost = \"{region}.s2s.speech.microsoft.com\";\nConversationConnectionConfig.privSpeechPath = \"/speech/translation/cognitiveservices/v1\";\nConversationConnectionConfig.privTranscriptionEventKeys = [\"iCalUid\", \"callId\", \"organizer\", \"FLAC\", \"MTUri\", \"DifferentiateGuestSpeakers\", \"audiorecording\", \"Threadid\", \"OrganizerMri\", \"OrganizerTenantId\", \"UserToken\"];\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js ***!
  \*********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionFactory\": () => (/* binding */ ConversationConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConversationWebsocketMessageFormatter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n/**\n * Create a connection to the Conversation Translator websocket for sending instant messages and commands, and for receiving translated messages.\n * The conversation must already have been started or joined.\n */\nclass ConversationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n  create(config, authInfo, connectionId) {\n    const endpointHost = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_Host, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.host);\n    const correlationId = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_CorrelationId, (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.createGuid)());\n    const endpoint = `wss://${endpointHost}${_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.webSocketPath}`;\n    const token = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.ConversationTranslator_Token, undefined);\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_4__.Contracts.throwIfNullOrUndefined(token, \"token\");\n    const queryParams = {};\n    queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.apiVersion] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.apiVersion;\n    queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.token] = token;\n    queryParams[_ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionConfig.configParams.correlationId] = correlationId;\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketConnection(endpoint, queryParams, {}, new _ConversationWebsocketMessageFormatter__WEBPACK_IMPORTED_MODULE_6__.ConversationWebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_7__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js":
/*!*********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js ***!
  \*********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionMessage\": () => (/* binding */ ConversationConnectionMessage)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ConversationConnectionMessage extends _common_Exports__WEBPACK_IMPORTED_MODULE_0__.ConnectionMessage {\n  constructor(messageType, body, headers, id) {\n    super(messageType, body, headers, id);\n    const json = JSON.parse(this.textBody);\n    if (json.type !== undefined) {\n      this.privConversationMessageType = json.type;\n    }\n  }\n  get conversationMessageType() {\n    return this.privConversationMessageType;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationManager\": () => (/* binding */ ConversationManager)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/RestMessageAdapter.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\nclass ConversationManager {\n  constructor() {\n    //\n    this.privRequestParams = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.configParams;\n    this.privErrors = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.restErrors;\n    this.privHost = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.host;\n    this.privApiVersion = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.apiVersion;\n    this.privRestPath = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.restPath;\n    this.privRestAdapter = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestMessageAdapter({});\n  }\n  /**\n   * Make a POST request to the Conversation Manager service endpoint to create or join a conversation.\n   * @param args\n   * @param conversationCode\n   * @param callback\n   * @param errorCallback\n   */\n  createOrJoin(args, conversationCode, cb, err) {\n    try {\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(args, \"args\");\n      const languageCode = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage, _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.defaultLanguageCode);\n      const nickname = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Name, \"conversation_host\");\n      const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Host, this.privHost);\n      const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_CorrelationId);\n      const subscriptionKey = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Key);\n      const subscriptionRegion = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Region);\n      const authToken = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(languageCode, \"languageCode\");\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(nickname, \"nickname\");\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(endpointHost, \"endpointHost\");\n      const queryParams = {};\n      queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n      queryParams[this.privRequestParams.languageCode] = languageCode;\n      queryParams[this.privRequestParams.nickname] = nickname;\n      const headers = {};\n      if (correlationId) {\n        headers[this.privRequestParams.correlationId] = correlationId;\n      }\n      headers[this.privRequestParams.clientAppId] = _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_0__.ConversationConnectionConfig.clientAppId;\n      if (conversationCode !== undefined) {\n        queryParams[this.privRequestParams.roomId] = conversationCode;\n      } else {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(subscriptionRegion, this.privErrors.authInvalidSubscriptionRegion);\n        headers[this.privRequestParams.subscriptionRegion] = subscriptionRegion;\n        if (subscriptionKey) {\n          headers[this.privRequestParams.subscriptionKey] = subscriptionKey;\n        } else if (authToken) {\n          headers[this.privRequestParams.authorization] = `Bearer ${authToken}`;\n        } else {\n          _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(subscriptionKey, this.privErrors.authInvalidSubscriptionKey);\n        }\n      }\n      const config = {};\n      config.headers = headers;\n      this.privRestAdapter.options = config;\n      const endpoint = `https://${endpointHost}${this.privRestPath}`;\n      // TODO: support a proxy and certificate validation\n      this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestRequestType.Post, endpoint, queryParams, null).then(response => {\n        const requestId = _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestMessageAdapter.extractHeaderValue(this.privRequestParams.requestId, response.headers);\n        if (!response.ok) {\n          if (!!err) {\n            // get the error\n            let errorMessage = this.privErrors.invalidCreateJoinConversationResponse.replace(\"{status}\", response.status.toString());\n            let errMessageRaw;\n            try {\n              errMessageRaw = JSON.parse(response.data);\n              errorMessage += ` [${errMessageRaw.error.code}: ${errMessageRaw.error.message}]`;\n            } catch (e) {\n              errorMessage += ` [${response.data}]`;\n            }\n            if (requestId) {\n              errorMessage += ` ${requestId}`;\n            }\n            err(errorMessage);\n          }\n          return;\n        }\n        const conversation = JSON.parse(response.data);\n        if (conversation) {\n          conversation.requestId = requestId;\n        }\n        if (!!cb) {\n          try {\n            cb(conversation);\n          } catch (e) {\n            if (!!err) {\n              err(e);\n            }\n          }\n          cb = undefined;\n        }\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n      }).catch(() => {});\n    } catch (error) {\n      if (!!err) {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n      }\n    }\n  }\n  /**\n   * Make a DELETE request to the Conversation Manager service endpoint to leave the conversation.\n   * @param args\n   * @param sessionToken\n   * @param callback\n   */\n  leave(args, sessionToken) {\n    return new Promise((resolve, reject) => {\n      try {\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(args, this.privErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n        _sdk_Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(sessionToken, this.privErrors.invalidArgs.replace(\"{arg}\", \"token\"));\n        const endpointHost = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_Host, this.privHost);\n        const correlationId = args.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.ConversationTranslator_CorrelationId);\n        const queryParams = {};\n        queryParams[this.privRequestParams.apiVersion] = this.privApiVersion;\n        queryParams[this.privRequestParams.sessionToken] = sessionToken;\n        const headers = {};\n        if (correlationId) {\n          headers[this.privRequestParams.correlationId] = correlationId;\n        }\n        const config = {};\n        config.headers = headers;\n        this.privRestAdapter.options = config;\n        const endpoint = `https://${endpointHost}${this.privRestPath}`;\n        // TODO: support a proxy and certificate validation\n        this.privRestAdapter.request(_common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.RestRequestType.Delete, endpoint, queryParams, null).then(response => {\n          if (!response.ok) {\n            // ignore errors on delete\n          }\n          resolve();\n          // eslint-disable-next-line @typescript-eslint/no-empty-function\n        }).catch(() => {});\n      } catch (error) {\n        if (error instanceof Error) {\n          const typedError = error;\n          reject(typedError.name + \": \" + typedError.message);\n        } else {\n          reject(error);\n        }\n      }\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationRequestSession\": () => (/* binding */ ConversationRequestSession)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n/**\n * Placeholder class for the Conversation Request Session. Based off RequestSession.\n * TODO: define what telemetry is required.\n */\nclass ConversationRequestSession {\n  constructor(sessionId) {\n    this.privIsDisposed = false;\n    this.privDetachables = new Array();\n    this.privSessionId = sessionId;\n    this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privRequestCompletionDeferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n  }\n  get sessionId() {\n    return this.privSessionId;\n  }\n  get requestId() {\n    return this.privRequestId;\n  }\n  get completionPromise() {\n    return this.privRequestCompletionDeferral.promise;\n  }\n  onPreConnectionStart(authFetchEventId, connectionId) {\n    this.privSessionId = connectionId;\n  }\n  onAuthCompleted(isError) {\n    if (isError) {\n      this.onComplete();\n    }\n  }\n  onConnectionEstablishCompleted(statusCode) {\n    if (statusCode === 200) {\n      return;\n    } else if (statusCode === 403) {\n      this.onComplete();\n    }\n  }\n  onServiceTurnEndResponse(continuousRecognition) {\n    if (!continuousRecognition) {\n      this.onComplete();\n    } else {\n      this.privRequestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    }\n  }\n  dispose() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privIsDisposed) {\n        // we should have completed by now. If we did not its an unknown error.\n        this.privIsDisposed = true;\n        for (const detachable of this.privDetachables) {\n          yield detachable.detach();\n        }\n      }\n    });\n  }\n  onComplete() {\n    //\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationServiceAdapter\": () => (/* binding */ ConversationServiceAdapter)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ConversationConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n/* harmony import */ var _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationRequestSession */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationRequestSession.js\");\n/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\n/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js\");\n/* harmony import */ var _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./ServiceMessages/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\n\n\n\n/**\n * The service adapter handles sending and receiving messages to the Conversation Translator websocket.\n */\nclass ConversationServiceAdapter extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, conversationServiceConnector);\n    this.privConnectionConfigPromise = undefined;\n    this.privLastPartialUtteranceId = \"\";\n    this.privConversationServiceConnector = conversationServiceConnector;\n    this.privConversationAuthentication = authentication;\n    this.receiveMessageOverride = () => this.receiveConversationMessageOverride();\n    this.recognizeOverride = () => this.noOp();\n    this.postConnectImplOverride = connection => this.conversationConnectImpl(connection);\n    this.configConnectionOverride = () => this.configConnection();\n    this.disconnectOverride = () => this.privDisconnect();\n    this.privConversationRequestSession = new _ConversationRequestSession__WEBPACK_IMPORTED_MODULE_1__.ConversationRequestSession((0,_common_Exports__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)());\n    this.privConversationConnectionFactory = connectionFactory;\n    this.privConversationIsDisposed = false;\n  }\n  isDisposed() {\n    return super.isDisposed() || this.privConversationIsDisposed;\n  }\n  dispose(reason) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privConversationIsDisposed = true;\n      if (this.privConnectionConfigPromise !== undefined) {\n        const connection = yield this.privConnectionConfigPromise;\n        yield connection.dispose(reason);\n      }\n      yield _super.dispose.call(this, reason);\n    });\n  }\n  sendMessage(message) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.fetchConnection();\n      return connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__.ConversationConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_4__.MessageType.Text, message));\n    });\n  }\n  sendMessageAsync(message) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const connection = yield this.fetchConnection();\n      yield connection.send(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_3__.ConversationConnectionMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_4__.MessageType.Text, message));\n    });\n  }\n  privDisconnect() {\n    if (this.terminateMessageLoop) {\n      return;\n    }\n    this.cancelRecognition(this.privConversationRequestSession.sessionId, this.privConversationRequestSession.requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.NoError, \"Disconnecting\");\n    this.terminateMessageLoop = true;\n    return Promise.resolve();\n  }\n  // eslint-disable-next-line @typescript-eslint/require-await\n  processTypeSpecificMessages() {\n    return __awaiter(this, void 0, void 0, function* () {\n      return true;\n    });\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    this.terminateMessageLoop = true;\n    const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationCanceledEventArgs(cancellationReason, error, errorCode, undefined, sessionId);\n    try {\n      if (!!this.privConversationServiceConnector.canceled) {\n        this.privConversationServiceConnector.canceled(this.privConversationServiceConnector, cancelEvent);\n      }\n    } catch (_a) {\n      // continue on error\n    }\n  }\n  noOp() {\n    // operation not supported\n    return;\n  }\n  /**\n   * Establishes a websocket connection to the end point.\n   */\n  conversationConnectImpl(connection) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privConnectionLoop = this.startMessageLoop();\n      return connection;\n    });\n  }\n  /**\n   * Process incoming websocket messages\n   */\n  receiveConversationMessageOverride() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.isDisposed() || this.terminateMessageLoop) {\n        return Promise.resolve();\n      }\n      // we won't rely on the cascading promises of the connection since we want to continually be available to receive messages\n      const communicationCustodian = new _common_Exports__WEBPACK_IMPORTED_MODULE_8__.Deferred();\n      try {\n        const connection = yield this.fetchConnection();\n        const message = yield connection.read();\n        if (this.isDisposed() || this.terminateMessageLoop) {\n          // We're done.\n          communicationCustodian.resolve();\n          return Promise.resolve();\n        }\n        if (!message) {\n          return this.receiveConversationMessageOverride();\n        }\n        const sessionId = this.privConversationRequestSession.sessionId;\n        let sendFinal = false;\n        try {\n          switch (message.conversationMessageType.toLowerCase()) {\n            case \"info\":\n            case \"participant_command\":\n            case \"command\":\n              const commandPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_9__.CommandResponsePayload.fromJSON(message.textBody);\n              switch (commandPayload.command.toLowerCase()) {\n                /**\n                 * 'ParticpantList' is the first message sent to the user after the websocket connection has opened.\n                 * The consuming client must wait for this message to arrive\n                 * before starting to send their own data.\n                 */\n                case \"participantlist\":\n                  const participantsPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__.ParticipantsListPayloadResponse.fromJSON(message.textBody);\n                  const participantsResult = participantsPayload.participants.map(p => {\n                    const participant = {\n                      avatar: p.avatar,\n                      displayName: p.nickname,\n                      id: p.participantId,\n                      isHost: p.ishost,\n                      isMuted: p.ismuted,\n                      isUsingTts: p.usetts,\n                      preferredLanguage: p.locale\n                    };\n                    return participant;\n                  });\n                  if (!!this.privConversationServiceConnector.participantsListReceived) {\n                    this.privConversationServiceConnector.participantsListReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantsListEventArgs(participantsPayload.roomid, participantsPayload.token, participantsPayload.translateTo, participantsPayload.profanityFilter, participantsPayload.roomProfanityFilter, participantsPayload.roomLocked, participantsPayload.muteAll, participantsResult, sessionId));\n                  }\n                  break;\n                /**\n                 * 'SetTranslateToLanguages' represents the list of languages being used in the Conversation by all users(?).\n                 * This is sent at the start of the Conversation\n                 */\n                case \"settranslatetolanguages\":\n                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setTranslateToLanguages, commandPayload.value, sessionId));\n                  }\n                  break;\n                /**\n                 * 'SetProfanityFiltering' lets the client set the level of profanity filtering.\n                 * If sent by the participant the setting will effect only their own profanity level.\n                 * If sent by the host, the setting will effect all participants including the host.\n                 * Note: the profanity filters differ from Speech Service (?): 'marked', 'raw', 'removed', 'tagged'\n                 */\n                case \"setprofanityfiltering\":\n                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setProfanityFiltering, commandPayload.value, sessionId));\n                  }\n                  break;\n                /**\n                 * 'SetMute' is sent if the participant has been muted by the host.\n                 * Check the 'participantId' to determine if the current user has been muted.\n                 */\n                case \"setmute\":\n                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setMute, commandPayload.value, sessionId));\n                  }\n                  break;\n                /**\n                 * 'SetMuteAll' is sent if the Conversation has been muted by the host.\n                 */\n                case \"setmuteall\":\n                  if (!!this.privConversationServiceConnector.muteAllCommandReceived) {\n                    this.privConversationServiceConnector.muteAllCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.MuteAllEventArgs(commandPayload.value, sessionId));\n                  }\n                  break;\n                /**\n                 * 'RoomExpirationWarning' is sent towards the end of the Conversation session to give a timeout warning.\n                 */\n                case \"roomexpirationwarning\":\n                  if (!!this.privConversationServiceConnector.conversationExpiration) {\n                    this.privConversationServiceConnector.conversationExpiration(this.privConversationServiceConnector, new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.ConversationExpirationEventArgs(commandPayload.value, this.privConversationRequestSession.sessionId));\n                  }\n                  break;\n                /**\n                 * 'SetUseTts' is sent as a confirmation if the user requests TTS to be turned on or off.\n                 */\n                case \"setusetts\":\n                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.setUseTTS, commandPayload.value, sessionId));\n                  }\n                  break;\n                /**\n                 * 'SetLockState' is set if the host has locked or unlocked the Conversation.\n                 */\n                case \"setlockstate\":\n                  if (!!this.privConversationServiceConnector.lockRoomCommandReceived) {\n                    this.privConversationServiceConnector.lockRoomCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.LockRoomEventArgs(commandPayload.value, sessionId));\n                  }\n                  break;\n                /**\n                 * 'ChangeNickname' is received if a user changes their display name.\n                 * Any cached particpiants list should be updated to reflect the display name.\n                 */\n                case \"changenickname\":\n                  if (!!this.privConversationServiceConnector.participantUpdateCommandReceived) {\n                    this.privConversationServiceConnector.participantUpdateCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantAttributeEventArgs(commandPayload.participantId, _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorCommandTypes.changeNickname, commandPayload.nickname, sessionId));\n                  }\n                  break;\n                /**\n                 * 'JoinSession' is sent when a user joins the Conversation.\n                 */\n                case \"joinsession\":\n                  const joinParticipantPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_10__.ParticipantPayloadResponse.fromJSON(message.textBody);\n                  const joiningParticipant = {\n                    avatar: joinParticipantPayload.avatar,\n                    displayName: joinParticipantPayload.nickname,\n                    id: joinParticipantPayload.participantId,\n                    isHost: joinParticipantPayload.ishost,\n                    isMuted: joinParticipantPayload.ismuted,\n                    isUsingTts: joinParticipantPayload.usetts,\n                    preferredLanguage: joinParticipantPayload.locale\n                  };\n                  if (!!this.privConversationServiceConnector.participantJoinCommandReceived) {\n                    this.privConversationServiceConnector.participantJoinCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantEventArgs(joiningParticipant, sessionId));\n                  }\n                  break;\n                /**\n                 * 'LeaveSession' is sent when a user leaves the Conversation'.\n                 */\n                case \"leavesession\":\n                  const leavingParticipant = {\n                    id: commandPayload.participantId\n                  };\n                  if (!!this.privConversationServiceConnector.participantLeaveCommandReceived) {\n                    this.privConversationServiceConnector.participantLeaveCommandReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ParticipantEventArgs(leavingParticipant, sessionId));\n                  }\n                  break;\n                /**\n                 * 'DisconnectSession' is sent when a user is disconnected from the session (e.g. network problem).\n                 * Check the 'ParticipantId' to check whether the message is for the current user.\n                 */\n                case \"disconnectsession\":\n                  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n                  const disconnectParticipant = {\n                    id: commandPayload.participantId\n                  };\n                  break;\n                case \"token\":\n                  const token = new _Exports__WEBPACK_IMPORTED_MODULE_14__.CognitiveTokenAuthentication(() => {\n                    const authorizationToken = commandPayload.token;\n                    return Promise.resolve(authorizationToken);\n                  }, () => {\n                    const authorizationToken = commandPayload.token;\n                    return Promise.resolve(authorizationToken);\n                  });\n                  this.authentication = token;\n                  break;\n                /**\n                 * Message not recognized.\n                 */\n                default:\n                  break;\n              }\n              break;\n            /**\n             * 'partial' (or 'hypothesis') represents a unfinalized speech message.\n             */\n            case \"partial\":\n            /**\n             * 'final' (or 'phrase') represents a finalized speech message.\n             */\n            case \"final\":\n              const speechPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__.SpeechResponsePayload.fromJSON(message.textBody);\n              const speechResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.ConversationTranslationResult(speechPayload.participantId, this.getTranslations(speechPayload.translations), speechPayload.language, undefined, undefined, speechPayload.recognition, undefined, undefined, message.textBody, undefined);\n              if (speechPayload.isFinal) {\n                // check the length, sometimes empty finals are returned\n                if (speechResult.text !== undefined && speechResult.text.length > 0) {\n                  sendFinal = true;\n                } else if (speechPayload.id === this.privLastPartialUtteranceId) {\n                  // send final as normal. We had a non-empty partial for this same utterance\n                  // so sending the empty final is important\n                  sendFinal = true;\n                } else {\n                  // suppress unneeded final\n                }\n                if (sendFinal) {\n                  if (!!this.privConversationServiceConnector.translationReceived) {\n                    this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.final, speechResult, sessionId));\n                  }\n                }\n              } else if (speechResult.text !== undefined) {\n                this.privLastPartialUtteranceId = speechPayload.id;\n                if (!!this.privConversationServiceConnector.translationReceived) {\n                  this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.partial, speechResult, sessionId));\n                }\n              }\n              break;\n            /**\n             * \"translated_message\" is a text message or instant message (IM).\n             */\n            case \"translated_message\":\n              const textPayload = _ServiceMessages_Exports__WEBPACK_IMPORTED_MODULE_15__.TextResponsePayload.fromJSON(message.textBody);\n              const textResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.ConversationTranslationResult(textPayload.participantId, this.getTranslations(textPayload.translations), textPayload.language, undefined, undefined, textPayload.originalText, undefined, undefined, undefined, message.textBody, undefined);\n              if (!!this.privConversationServiceConnector.translationReceived) {\n                this.privConversationServiceConnector.translationReceived(this.privConversationServiceConnector, new _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_11__.ConversationReceivedTranslationEventArgs(_ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_12__.ConversationTranslatorMessageTypes.instantMessage, textResult, sessionId));\n              }\n              break;\n            default:\n              // ignore any unsupported message types\n              break;\n          }\n        } catch (e) {\n          // continue\n        }\n        return this.receiveConversationMessageOverride();\n      } catch (e) {\n        this.terminateMessageLoop = true;\n      }\n      return communicationCustodian.promise;\n    });\n  }\n  startMessageLoop() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.isDisposed()) {\n        return Promise.resolve();\n      }\n      this.terminateMessageLoop = false;\n      const messageRetrievalPromise = this.receiveConversationMessageOverride();\n      try {\n        const r = yield messageRetrievalPromise;\n        return r;\n      } catch (error) {\n        this.cancelRecognition(this.privRequestSession ? this.privRequestSession.sessionId : \"\", this.privRequestSession ? this.privRequestSession.requestId : \"\", _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error, _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCode.RuntimeError, error);\n        return null;\n      }\n    });\n  }\n  // Takes an established websocket connection to the endpoint\n  configConnection() {\n    if (this.isDisposed()) {\n      return Promise.resolve(undefined);\n    }\n    if (this.privConnectionConfigPromise !== undefined) {\n      return this.privConnectionConfigPromise.then(connection => {\n        if (connection.state() === _common_Exports__WEBPACK_IMPORTED_MODULE_17__.ConnectionState.Disconnected) {\n          this.privConnectionId = null;\n          this.privConnectionConfigPromise = undefined;\n          return this.configConnection();\n        }\n        return this.privConnectionConfigPromise;\n      }, () => {\n        this.privConnectionId = null;\n        this.privConnectionConfigPromise = undefined;\n        return this.configConnection();\n      });\n    }\n    if (this.terminateMessageLoop) {\n      return Promise.resolve(undefined);\n    }\n    this.privConnectionConfigPromise = this.connectImpl().then(connection => connection);\n    return this.privConnectionConfigPromise;\n  }\n  getTranslations(serviceResultTranslations) {\n    let translations;\n    if (undefined !== serviceResultTranslations) {\n      translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__.Translations();\n      for (const translation of serviceResultTranslations) {\n        translations.set(translation.lang, translation.translation);\n      }\n    }\n    return translations;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js":
/*!***********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js ***!
  \***********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationReceivedTranslationEventArgs\": () => (/* binding */ ConversationReceivedTranslationEventArgs),\n/* harmony export */   \"LockRoomEventArgs\": () => (/* binding */ LockRoomEventArgs),\n/* harmony export */   \"MuteAllEventArgs\": () => (/* binding */ MuteAllEventArgs),\n/* harmony export */   \"ParticipantAttributeEventArgs\": () => (/* binding */ ParticipantAttributeEventArgs),\n/* harmony export */   \"ParticipantEventArgs\": () => (/* binding */ ParticipantEventArgs),\n/* harmony export */   \"ParticipantsListEventArgs\": () => (/* binding */ ParticipantsListEventArgs)\n/* harmony export */ });\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass MuteAllEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(isMuted, sessionId) {\n    super(sessionId);\n    this.privIsMuted = isMuted;\n  }\n  get isMuted() {\n    return this.privIsMuted;\n  }\n}\nclass LockRoomEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(isLocked, sessionId) {\n    super(sessionId);\n    this.privIsLocked = isLocked;\n  }\n  get isMuted() {\n    return this.privIsLocked;\n  }\n}\nclass ParticipantEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(participant, sessionId) {\n    super(sessionId);\n    this.privParticipant = participant;\n  }\n  get participant() {\n    return this.privParticipant;\n  }\n}\nclass ParticipantAttributeEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(participantId, key, value, sessionId) {\n    super(sessionId);\n    this.privKey = key;\n    this.privValue = value;\n    this.privParticipantId = participantId;\n  }\n  get value() {\n    return this.privValue;\n  }\n  get key() {\n    return this.privKey;\n  }\n  get id() {\n    return this.privParticipantId;\n  }\n}\nclass ParticipantsListEventArgs extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(conversationId, token, translateTo, profanityFilter, roomProfanityFilter, isRoomLocked, isMuteAll, participants, sessionId) {\n    super(sessionId);\n    this.privRoomId = conversationId;\n    this.privSessionToken = token;\n    this.privTranslateTo = translateTo;\n    this.privProfanityFilter = profanityFilter;\n    this.privRoomProfanityFilter = roomProfanityFilter;\n    this.privIsRoomLocked = isRoomLocked;\n    this.privIsRoomLocked = isMuteAll;\n    this.privParticipants = participants;\n  }\n  get sessionToken() {\n    return this.privSessionToken;\n  }\n  get conversationId() {\n    return this.privRoomId;\n  }\n  get translateTo() {\n    return this.privTranslateTo;\n  }\n  get profanityFilter() {\n    return this.privProfanityFilter;\n  }\n  get roomProfanityFilter() {\n    return this.privRoomProfanityFilter;\n  }\n  get isRoomLocked() {\n    return this.privIsRoomLocked;\n  }\n  get isMuteAll() {\n    return this.privIsMuteAll;\n  }\n  get participants() {\n    return this.privParticipants;\n  }\n}\nclass ConversationReceivedTranslationEventArgs {\n  constructor(command, payload, sessionId) {\n    this.privPayload = payload;\n    this.privCommand = command;\n    this.privSessionId = sessionId;\n  }\n  get payload() {\n    return this.privPayload;\n  }\n  get command() {\n    return this.privCommand;\n  }\n  get sessionId() {\n    return this.privSessionId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js ***!
  \************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslatorCommandTypes\": () => (/* binding */ ConversationTranslatorCommandTypes),\n/* harmony export */   \"ConversationTranslatorMessageTypes\": () => (/* binding */ ConversationTranslatorMessageTypes),\n/* harmony export */   \"InternalParticipants\": () => (/* binding */ InternalParticipants)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/** Users participating in the conversation */\nclass InternalParticipants {\n  constructor() {\n    let participants = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : [];\n    let meId = arguments.length > 1 ? arguments[1] : undefined;\n    this.participants = participants;\n    this.meId = meId;\n  }\n  /**\n   * Add or update a participant\n   * @param value\n   */\n  addOrUpdateParticipant(value) {\n    if (value === undefined) {\n      return;\n    }\n    const exists = this.getParticipantIndex(value.id);\n    if (exists > -1) {\n      this.participants.splice(exists, 1, value);\n    } else {\n      this.participants.push(value);\n    }\n    // ensure it was added ok\n    return this.getParticipant(value.id);\n  }\n  /**\n   * Find the participant's position in the participants list.\n   * @param id\n   */\n  getParticipantIndex(id) {\n    return this.participants.findIndex(p => p.id === id);\n  }\n  /**\n   * Find the participant by id.\n   * @param id\n   */\n  getParticipant(id) {\n    return this.participants.find(p => p.id === id);\n  }\n  /**\n   * Remove a participant from the participants list.\n   */\n  deleteParticipant(id) {\n    this.participants = this.participants.filter(p => p.id !== id);\n  }\n  /**\n   * Helper to return the conversation host.\n   */\n  get host() {\n    return this.participants.find(p => p.isHost === true);\n  }\n  /**\n   * Helper to return the current user.\n   */\n  get me() {\n    return this.getParticipant(this.meId);\n  }\n}\n/**\n * List of command message types\n */\nconst ConversationTranslatorMessageTypes = {\n  command: \"command\",\n  final: \"final\",\n  info: \"info\",\n  instantMessage: \"instant_message\",\n  keepAlive: \"keep_alive\",\n  partial: \"partial\",\n  participantCommand: \"participant_command\",\n  translatedMessage: \"translated_message\"\n};\n/**\n * List of command types\n */\nconst ConversationTranslatorCommandTypes = {\n  changeNickname: \"ChangeNickname\",\n  disconnectSession: \"DisconnectSession\",\n  ejectParticipant: \"EjectParticipant\",\n  instant_message: \"instant_message\",\n  joinSession: \"JoinSession\",\n  leaveSession: \"LeaveSession\",\n  participantList: \"ParticipantList\",\n  roomExpirationWarning: \"RoomExpirationWarning\",\n  setLockState: \"SetLockState\",\n  setMute: \"SetMute\",\n  setMuteAll: \"SetMuteAll\",\n  setProfanityFiltering: \"SetProfanityFiltering\",\n  setTranslateToLanguages: \"SetTranslateToLanguages\",\n  setUseTTS: \"SetUseTTS\"\n};\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js ***!
  \************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationRecognizerFactory\": () => (/* binding */ ConversationRecognizerFactory),\n/* harmony export */   \"ConversationTranslatorRecognizer\": () => (/* binding */ ConversationTranslatorRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n/* harmony import */ var _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionFactory.js\");\n/* harmony import */ var _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./ConversationServiceAdapter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationServiceAdapter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n// eslint-disable-next-line max-classes-per-file\n\n\n\n\n\n\nclass ConversationRecognizerFactory {\n  static fromConfig(conversation, speechConfig, audioConfig) {\n    return new ConversationTranslatorRecognizer(conversation, speechConfig, audioConfig);\n  }\n}\n/**\n * Sends messages to the Conversation Translator websocket and listens for incoming events containing websocket messages.\n * Based off the recognizers in the SDK folder.\n */\nclass ConversationTranslatorRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n  constructor(conversation, speechConfig, audioConfig) {\n    const serviceConfigImpl = speechConfig;\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(serviceConfigImpl, \"speechConfig\");\n    const conversationImpl = conversation;\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(conversationImpl, \"conversationImpl\");\n    super(audioConfig, serviceConfigImpl.properties, new _ConversationConnectionFactory__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionFactory());\n    this.privConversation = conversationImpl;\n    this.privIsDisposed = false;\n    this.privProperties = serviceConfigImpl.properties.clone();\n    this.privConnection = _sdk_Exports__WEBPACK_IMPORTED_MODULE_3__.Connection.fromRecognizer(this);\n    this.privSetTimeout = typeof Blob !== \"undefined\" && typeof Worker !== \"undefined\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Timeout.setTimeout : setTimeout;\n    this.privClearTimeout = typeof Blob !== \"undefined\" && typeof Worker !== \"undefined\" ? _common_Exports__WEBPACK_IMPORTED_MODULE_4__.Timeout.clearTimeout : clearTimeout;\n  }\n  set connected(cb) {\n    this.privConnection.connected = cb;\n  }\n  set disconnected(cb) {\n    this.privConnection.disconnected = cb;\n  }\n  /**\n   * Return the speech language used by the recognizer\n   */\n  get speechRecognitionLanguage() {\n    return this.privSpeechRecognitionLanguage;\n  }\n  /**\n   * Return the properties for the recognizer\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  /**\n   * Connect to the recognizer\n   * @param token\n   */\n  connect(token, cb, err) {\n    try {\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n      this.privReco.conversationTranslatorToken = token;\n      this.resetConversationTimeout();\n      this.privReco.connectAsync(cb, err);\n    } catch (error) {\n      if (!!err) {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n      }\n    }\n  }\n  /**\n   * Disconnect from the recognizer\n   */\n  disconnect(cb, err) {\n    try {\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n      if (this.privTimeoutToken !== undefined) {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n        this.privClearTimeout(this.privTimeoutToken);\n      }\n      this.privReco.disconnect().then(() => {\n        if (!!cb) {\n          cb();\n        }\n      }, error => {\n        if (!!err) {\n          err(error);\n        }\n      });\n    } catch (error) {\n      if (!!err) {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n      }\n      // Destroy the recognizer.\n      this.dispose(true).catch(reason => {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.BackgroundEvent(reason));\n      });\n    }\n  }\n  /**\n   * Send the mute all participants command to the websocket\n   * @param conversationId\n   * @param participantId\n   * @param isMuted\n   */\n  sendRequest(command, cb, err) {\n    try {\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n      this.sendMessage(command, cb, err);\n    } catch (error) {\n      if (!!err) {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n      }\n      // Destroy the recognizer.\n      this.dispose(true).catch(reason => {\n        _common_Exports__WEBPACK_IMPORTED_MODULE_5__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_6__.BackgroundEvent(reason));\n      });\n    }\n  }\n  /**\n   * Close and dispose the recognizer\n   */\n  close() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privIsDisposed) {\n        if (!!this.privConnection) {\n          this.privConnection.closeConnection();\n          this.privConnection.close();\n        }\n        this.privConnection = undefined;\n        yield this.dispose(true);\n      }\n    });\n  }\n  /**\n   * Dispose the recognizer\n   * @param disposing\n   */\n  dispose(disposing) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privIsDisposed) {\n        return;\n      }\n      if (disposing) {\n        if (this.privTimeoutToken !== undefined) {\n          // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n          this.privClearTimeout(this.privTimeoutToken);\n        }\n        this.privIsDisposed = true;\n        if (!!this.privConnection) {\n          this.privConnection.closeConnection();\n          this.privConnection.close();\n          this.privConnection = undefined;\n        }\n        yield _super.dispose.call(this, disposing);\n      }\n    });\n  }\n  /**\n   * Create the config for the recognizer\n   * @param speechConfig\n   */\n  createRecognizerConfig(speechConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognizerConfig(speechConfig, this.privProperties);\n  }\n  /**\n   * Create the service recognizer.\n   * The audio source is redundnant here but is required by the implementation.\n   * @param authentication\n   * @param connectionFactory\n   * @param audioConfig\n   * @param recognizerConfig\n   */\n  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n    const audioSource = audioConfig;\n    return new _ConversationServiceAdapter__WEBPACK_IMPORTED_MODULE_8__.ConversationServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);\n  }\n  sendMessage(msg, cb, err) {\n    const withAsync = this.privReco;\n    const PromiseToEmptyCallback = (promise, cb, err) => {\n      if (promise !== undefined) {\n        promise.then(() => {\n          try {\n            if (!!cb) {\n              cb();\n            }\n          } catch (e) {\n            if (!!err) {\n              err(`'Unhandled error on promise callback: ${e}'`);\n            }\n          }\n        }, reason => {\n          try {\n            if (!!err) {\n              err(reason);\n            }\n            // eslint-disable-next-line no-empty\n          } catch (error) {}\n        });\n      } else {\n        if (!!err) {\n          err(\"Null promise\");\n        }\n      }\n    };\n    PromiseToEmptyCallback(withAsync.sendMessageAsync(msg), cb, err);\n    this.resetConversationTimeout();\n  }\n  resetConversationTimeout() {\n    if (this.privTimeoutToken !== undefined) {\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n      this.privClearTimeout(this.privTimeoutToken);\n    }\n    this.privTimeoutToken = this.privSetTimeout(() => {\n      this.sendRequest(this.privConversation.getKeepAlive());\n    }, 60000);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js":
/*!*****************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js ***!
  \*****************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationWebsocketMessageFormatter\": () => (/* binding */ ConversationWebsocketMessageFormatter)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n/* harmony import */ var _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Based off WebsocketMessageFormatter. The messages for Conversation Translator have some variations from the Speech messages.\n */\nclass ConversationWebsocketMessageFormatter {\n  /**\n   * Format incoming messages: text (speech partial/final, IM) or binary (tts)\n   */\n  toConnectionMessage(message) {\n    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n    try {\n      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n        const incomingMessage = new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionMessage(message.messageType, message.textContent, {}, message.id);\n        deferral.resolve(incomingMessage);\n      } else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n        deferral.resolve(new _ConversationConnectionMessage__WEBPACK_IMPORTED_MODULE_2__.ConversationConnectionMessage(message.messageType, message.binaryContent, undefined, message.id));\n      }\n    } catch (e) {\n      deferral.reject(`Error formatting the message. Error: ${e}`);\n    }\n    return deferral.promise;\n  }\n  /**\n   * Format outgoing messages: text (commands or IM)\n   */\n  fromConnectionMessage(message) {\n    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n    try {\n      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n        const payload = `${message.textBody ? message.textBody : \"\"}`;\n        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text, payload, message.id));\n      }\n    } catch (e) {\n      deferral.reject(`Error formatting the message. ${e}`);\n    }\n    return deferral.promise;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationWebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationConnectionConfig\": () => (/* reexport safe */ _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig),\n/* harmony export */   \"ConversationManager\": () => (/* reexport safe */ _ConversationManager__WEBPACK_IMPORTED_MODULE_0__.ConversationManager),\n/* harmony export */   \"ConversationReceivedTranslationEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ConversationReceivedTranslationEventArgs),\n/* harmony export */   \"ConversationRecognizerFactory\": () => (/* reexport safe */ _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__.ConversationRecognizerFactory),\n/* harmony export */   \"ConversationTranslatorCommandTypes\": () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.ConversationTranslatorCommandTypes),\n/* harmony export */   \"ConversationTranslatorMessageTypes\": () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.ConversationTranslatorMessageTypes),\n/* harmony export */   \"InternalParticipants\": () => (/* reexport safe */ _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__.InternalParticipants),\n/* harmony export */   \"LockRoomEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.LockRoomEventArgs),\n/* harmony export */   \"MuteAllEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.MuteAllEventArgs),\n/* harmony export */   \"ParticipantAttributeEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantAttributeEventArgs),\n/* harmony export */   \"ParticipantEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantEventArgs),\n/* harmony export */   \"ParticipantsListEventArgs\": () => (/* reexport safe */ _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__.ParticipantsListEventArgs),\n/* harmony export */   \"TranscriberRecognizer\": () => (/* reexport safe */ _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__.TranscriberRecognizer)\n/* harmony export */ });\n/* harmony import */ var _ConversationManager__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConversationManager */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js\");\n/* harmony import */ var _ConversationConnectionConfig__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConversationConnectionConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _ConversationTranslatorRecognizer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ConversationTranslatorRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js\");\n/* harmony import */ var _TranscriberRecognizer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./TranscriberRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js\");\n/* harmony import */ var _ConversationTranslatorEventArgs__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ConversationTranslatorEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorEventArgs.js\");\n/* harmony import */ var _ConversationTranslatorInterfaces__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ConversationTranslatorInterfaces */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js":
/*!******************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js ***!
  \******************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CommandResponsePayload\": () => (/* binding */ CommandResponsePayload)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseCommandResponse = json => JSON.parse(json);\nclass CommandResponsePayload {\n  constructor(json) {\n    this.privCommandResponse = parseCommandResponse(json);\n  }\n  get type() {\n    return this.privCommandResponse.type;\n  }\n  get command() {\n    return this.privCommandResponse.command;\n  }\n  get id() {\n    return this.privCommandResponse.id;\n  }\n  get nickname() {\n    return this.privCommandResponse.nickname;\n  }\n  get participantId() {\n    return this.privCommandResponse.participantId;\n  }\n  get roomid() {\n    return this.privCommandResponse.roomid;\n  }\n  get value() {\n    return this.privCommandResponse.value;\n  }\n  get token() {\n    return this.privCommandResponse.token;\n  }\n  static fromJSON(json) {\n    return new CommandResponsePayload(json);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/CommandResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ParticipantPayloadResponse\": () => (/* binding */ ParticipantPayloadResponse),\n/* harmony export */   \"ParticipantsListPayloadResponse\": () => (/* binding */ ParticipantsListPayloadResponse)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseListResponse = json => JSON.parse(json);\nconst parseParticipantResponse = json => JSON.parse(json);\nclass ParticipantsListPayloadResponse {\n  constructor(json) {\n    this.privParticipantsPayloadResponse = parseListResponse(json);\n  }\n  get roomid() {\n    return this.privParticipantsPayloadResponse.roomid;\n  }\n  get id() {\n    return this.privParticipantsPayloadResponse.id;\n  }\n  get command() {\n    return this.privParticipantsPayloadResponse.command;\n  }\n  get participants() {\n    return this.privParticipantsPayloadResponse.participants;\n  }\n  get token() {\n    return this.privParticipantsPayloadResponse.token;\n  }\n  get translateTo() {\n    return this.privParticipantsPayloadResponse.translateTo;\n  }\n  get profanityFilter() {\n    return this.privParticipantsPayloadResponse.profanityFilter;\n  }\n  get roomProfanityFilter() {\n    return this.privParticipantsPayloadResponse.roomProfanityFilter;\n  }\n  get roomLocked() {\n    return this.privParticipantsPayloadResponse.roomLocked;\n  }\n  get muteAll() {\n    return this.privParticipantsPayloadResponse.muteAll;\n  }\n  get type() {\n    return this.privParticipantsPayloadResponse.type;\n  }\n  static fromJSON(json) {\n    return new ParticipantsListPayloadResponse(json);\n  }\n}\nclass ParticipantPayloadResponse {\n  constructor(json) {\n    this.privParticipantPayloadResponse = parseParticipantResponse(json);\n  }\n  get nickname() {\n    return this.privParticipantPayloadResponse.nickname;\n  }\n  get locale() {\n    return this.privParticipantPayloadResponse.locale;\n  }\n  get usetts() {\n    return this.privParticipantPayloadResponse.usetts;\n  }\n  get ismuted() {\n    return this.privParticipantPayloadResponse.ismuted;\n  }\n  get ishost() {\n    return this.privParticipantPayloadResponse.ishost;\n  }\n  get participantId() {\n    return this.privParticipantPayloadResponse.participantId;\n  }\n  get avatar() {\n    return this.privParticipantPayloadResponse.avatar;\n  }\n  static fromJSON(json) {\n    return new ParticipantPayloadResponse(json);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/ParticipantResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js":
/*!**********************************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js ***!
  \**********************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechResponsePayload\": () => (/* binding */ SpeechResponsePayload),\n/* harmony export */   \"TextResponsePayload\": () => (/* binding */ TextResponsePayload)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nconst parseSpeechResponse = json => JSON.parse(json);\nconst parseTextResponse = json => JSON.parse(json);\nclass SpeechResponsePayload {\n  constructor(json) {\n    this.privSpeechResponse = parseSpeechResponse(json);\n  }\n  get recognition() {\n    return this.privSpeechResponse.recognition;\n  }\n  get translations() {\n    return this.privSpeechResponse.translations;\n  }\n  get id() {\n    return this.privSpeechResponse.id;\n  }\n  get language() {\n    return this.privSpeechResponse.language;\n  }\n  get nickname() {\n    return this.privSpeechResponse.nickname;\n  }\n  get participantId() {\n    return this.privSpeechResponse.participantId;\n  }\n  get roomid() {\n    return this.privSpeechResponse.roomid;\n  }\n  get timestamp() {\n    return this.privSpeechResponse.timestamp;\n  }\n  get type() {\n    return this.privSpeechResponse.type;\n  }\n  get isFinal() {\n    return this.privSpeechResponse.type === \"final\";\n  }\n  static fromJSON(json) {\n    return new SpeechResponsePayload(json);\n  }\n}\nclass TextResponsePayload {\n  constructor(json) {\n    this.privTextResponse = parseTextResponse(json);\n  }\n  get originalText() {\n    return this.privTextResponse.originalText;\n  }\n  get translations() {\n    return this.privTextResponse.translations;\n  }\n  get id() {\n    return this.privTextResponse.id;\n  }\n  get language() {\n    return this.privTextResponse.language;\n  }\n  get nickname() {\n    return this.privTextResponse.nickname;\n  }\n  get participantId() {\n    return this.privTextResponse.participantId;\n  }\n  get roomid() {\n    return this.privTextResponse.roomid;\n  }\n  get timestamp() {\n    return this.privTextResponse.timestamp;\n  }\n  get type() {\n    return this.privTextResponse.type;\n  }\n  static fromJSON(json) {\n    return new TextResponsePayload(json);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ServiceMessages/TranslationResponsePayload.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranscriberRecognizer\": () => (/* binding */ TranscriberRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../sdk/Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriberConnectionFactory.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranscriptionServiceRecognizer.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\nclass TranscriberRecognizer extends _sdk_Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n  /**\n   * TranscriberRecognizer constructor.\n   * @constructor\n   * @param {SpeechTranslationConfig} speechTranslationConfig - Non-audio configuration associated with the recognizer\n   * @param {AudioConfig} audioConfig - An audio configuration associated with the recognizer\n   */\n  constructor(speechTranslationConfig, audioConfig) {\n    const speechTranslationConfigImpl = speechTranslationConfig;\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechTranslationConfigImpl, \"speechTranslationConfig\");\n    const audioConfigImpl = audioConfig;\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(audioConfigImpl, \"audioConfigImpl\");\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(speechTranslationConfigImpl.speechRecognitionLanguage, _sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    super(audioConfig, speechTranslationConfigImpl.properties, new _Exports__WEBPACK_IMPORTED_MODULE_3__.TranscriberConnectionFactory());\n    this.privDisposedRecognizer = false;\n  }\n  get speechRecognitionLanguage() {\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  get authorizationToken() {\n    return this.properties.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  set authorizationToken(token) {\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  set conversation(c) {\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(c, \"Conversation\");\n    this.privConversation = c;\n  }\n  getConversationInfo() {\n    _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privConversation, \"Conversation\");\n    return this.privConversation.conversationInfo;\n  }\n  startContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);\n  }\n  stopContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n  }\n  close() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privDisposedRecognizer) {\n        yield this.dispose(true);\n      }\n    });\n  }\n  // Push async join/leave conversation message via serviceRecognizer\n  pushConversationEvent(conversationInfo, command) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const reco = this.privReco;\n      _sdk_Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(reco, \"serviceRecognizer\");\n      yield reco.sendSpeechEventAsync(conversationInfo, command);\n    });\n  }\n  enforceAudioGating() {\n    return __awaiter(this, void 0, void 0, function* () {\n      const audioConfigImpl = this.audioConfig;\n      const format = yield audioConfigImpl.format;\n      const channels = format.channels;\n      if (channels === 1) {\n        if (this.properties.getProperty(\"f0f5debc-f8c9-4892-ac4b-90a7ab359fd2\", \"false\").toLowerCase() !== \"true\") {\n          throw new Error(\"Single channel audio configuration for ConversationTranscriber is currently under private preview, please contact diarizationrequest@microsoft.com for more details\");\n        }\n      } else if (channels !== 8) {\n        throw new Error(`Unsupported audio configuration: Detected ${channels}-channel audio`);\n      }\n      return;\n    });\n  }\n  connectCallbacks(transcriber) {\n    this.canceled = (s, e) => {\n      if (!!transcriber.canceled) {\n        transcriber.canceled(transcriber, e);\n      }\n    };\n    this.recognizing = (s, e) => {\n      if (!!transcriber.transcribing) {\n        transcriber.transcribing(transcriber, e);\n      }\n    };\n    this.recognized = (s, e) => {\n      if (!!transcriber.transcribed) {\n        transcriber.transcribed(transcriber, e);\n      }\n    };\n    this.sessionStarted = (s, e) => {\n      if (!!transcriber.sessionStarted) {\n        transcriber.sessionStarted(transcriber, e);\n      }\n    };\n    this.sessionStopped = (s, e) => {\n      if (!!transcriber.sessionStopped) {\n        transcriber.sessionStopped(transcriber, e);\n      }\n    };\n  }\n  disconnectCallbacks() {\n    this.canceled = undefined;\n    this.recognizing = undefined;\n    this.recognized = undefined;\n    this.sessionStarted = undefined;\n    this.sessionStopped = undefined;\n  }\n  /**\n   * Disposes any resources held by the object.\n   * @member ConversationTranscriber.prototype.dispose\n   * @function\n   * @public\n   * @param {boolean} disposing - true if disposing the object.\n   */\n  dispose(disposing) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposedRecognizer) {\n        return;\n      }\n      if (disposing) {\n        this.privDisposedRecognizer = true;\n        yield this.implRecognizerStop();\n      }\n      yield _super.dispose.call(this, disposing);\n    });\n  }\n  createRecognizerConfig(speechConfig) {\n    return new _Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.properties);\n  }\n  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n    const configImpl = audioConfig;\n    return new _Exports__WEBPACK_IMPORTED_MODULE_6__.TranscriptionServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationConnectionFactory\": () => (/* binding */ TranslationConnectionFactory)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/WebsocketConnection.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ProxyInfo.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ConnectionFactoryBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ConnectionFactoryBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js\");\n/* harmony import */ var _HeaderNames__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./QueryParameterNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/QueryParameterNames.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\nclass TranslationConnectionFactory extends _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase {\n  create(config, authInfo, connectionId) {\n    let endpoint = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, undefined);\n    if (!endpoint) {\n      const region = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, undefined);\n      const hostSuffix = _ConnectionFactoryBase__WEBPACK_IMPORTED_MODULE_0__.ConnectionFactoryBase.getHostSuffix(region);\n      const host = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, \"wss://\" + region + \".s2s.speech\" + hostSuffix);\n      endpoint = host + \"/speech/translation/cognitiveservices/v1\";\n    }\n    const queryParams = {\n      from: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage),\n      to: config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_TranslationToLanguages)\n    };\n    this.setCommonUrlParams(config, queryParams, endpoint);\n    this.setUrlParameter(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult, _QueryParameterNames__WEBPACK_IMPORTED_MODULE_2__.QueryParameterNames.StableTranslation, config, queryParams, endpoint);\n    const voiceName = \"voice\";\n    const featureName = \"features\";\n    if (config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {\n      queryParams[voiceName] = config.parameters.getProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_TranslationVoice);\n      queryParams[featureName] = \"texttospeech\";\n    }\n    const headers = {};\n    if (authInfo.token !== undefined && authInfo.token !== \"\") {\n      headers[authInfo.headerName] = authInfo.token;\n    }\n    headers[_HeaderNames__WEBPACK_IMPORTED_MODULE_3__.HeaderNames.ConnectionId] = connectionId;\n    config.parameters.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Url, endpoint);\n    const enableCompression = config.parameters.getProperty(\"SPEECH-EnableWebsocketCompression\", \"false\") === \"true\";\n    return new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_4__.WebsocketConnection(endpoint, queryParams, headers, new _Exports__WEBPACK_IMPORTED_MODULE_5__.WebsocketMessageFormatter(), _common_browser_Exports__WEBPACK_IMPORTED_MODULE_6__.ProxyInfo.fromRecognizerConfig(config), enableCompression, connectionId);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationServiceRecognizer\": () => (/* binding */ TranslationServiceRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../sdk/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationHypothesis.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationPhrase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TranslationSynthesisEnd.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n// eslint-disable-next-line max-classes-per-file\nclass TranslationServiceRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.ServiceRecognizerBase {\n  constructor(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer) {\n    super(authentication, connectionFactory, audioSource, recognizerConfig, translationRecognizer);\n    this.privTranslationRecognizer = translationRecognizer;\n    this.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n        this.privTranslationRecognizer.onConnection();\n      } else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        void this.privTranslationRecognizer.onDisconnection();\n      }\n    });\n  }\n  processTypeSpecificMessages(connectionMessage) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const resultProps = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n      let processed = false;\n      const handleTranslationPhrase = translatedPhrase => __awaiter(this, void 0, void 0, function* () {\n        this.privRequestSession.onPhraseRecognized(this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset + translatedPhrase.Duration);\n        if (translatedPhrase.RecognitionStatus === _Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.Success) {\n          // OK, the recognition was successful. How'd the translation do?\n          const result = this.fireEventForResult(translatedPhrase, resultProps);\n          if (!!this.privTranslationRecognizer.recognized) {\n            try {\n              this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, result);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n          // report result to promise.\n          if (!!this.privSuccessCallback) {\n            try {\n              this.privSuccessCallback(result.result);\n            } catch (e) {\n              if (!!this.privErrorCallback) {\n                this.privErrorCallback(e);\n              }\n            }\n            // Only invoke the call back once.\n            // and if it's successful don't invoke the\n            // error after that.\n            this.privSuccessCallback = undefined;\n            this.privErrorCallback = undefined;\n          }\n        } else {\n          const reason = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateRecognitionResult(translatedPhrase.RecognitionStatus);\n          const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(undefined, this.privRequestSession.requestId, reason, translatedPhrase.Text, translatedPhrase.Duration, this.privRequestSession.currentTurnAudioOffset + translatedPhrase.Offset, undefined, connectionMessage.textBody, resultProps);\n          if (reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled) {\n            const cancelReason = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateCancelResult(translatedPhrase.RecognitionStatus);\n            const cancellationErrorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateCancelErrorCode(translatedPhrase.RecognitionStatus);\n            yield this.cancelRecognitionLocal(cancelReason, cancellationErrorCode, _Exports__WEBPACK_IMPORTED_MODULE_3__.EnumTranslation.implTranslateErrorDetails(cancellationErrorCode));\n          } else {\n            if (!(this.privRequestSession.isSpeechEnded && reason === _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.NoMatch && translatedPhrase.RecognitionStatus !== _Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.InitialSilenceTimeout)) {\n              const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(result, result.offset, this.privRequestSession.sessionId);\n              if (!!this.privTranslationRecognizer.recognized) {\n                try {\n                  this.privTranslationRecognizer.recognized(this.privTranslationRecognizer, ev);\n                  /* eslint-disable no-empty */\n                } catch (error) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n            }\n            // report result to promise.\n            if (!!this.privSuccessCallback) {\n              try {\n                this.privSuccessCallback(result);\n              } catch (e) {\n                if (!!this.privErrorCallback) {\n                  this.privErrorCallback(e);\n                }\n              }\n              // Only invoke the call back once.\n              // and if it's successful don't invoke the\n              // error after that.\n              this.privSuccessCallback = undefined;\n              this.privErrorCallback = undefined;\n            }\n          }\n          processed = true;\n        }\n      });\n      if (connectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_7__.MessageType.Text) {\n        resultProps.setProperty(_sdk_Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyId.SpeechServiceResponse_JsonResult, connectionMessage.textBody);\n      }\n      switch (connectionMessage.path.toLowerCase()) {\n        case \"translation.hypothesis\":\n          const result = this.fireEventForResult(_Exports__WEBPACK_IMPORTED_MODULE_9__.TranslationHypothesis.fromJSON(connectionMessage.textBody), resultProps);\n          this.privRequestSession.onHypothesis(this.privRequestSession.currentTurnAudioOffset + result.offset);\n          if (!!this.privTranslationRecognizer.recognizing) {\n            try {\n              this.privTranslationRecognizer.recognizing(this.privTranslationRecognizer, result);\n              /* eslint-disable no-empty */\n            } catch (error) {\n              // Not going to let errors in the event handler\n              // trip things up.\n            }\n          }\n          processed = true;\n          break;\n        case \"translation.response\":\n          const phrase = JSON.parse(connectionMessage.textBody);\n          if (!!phrase.SpeechPhrase) {\n            yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase.fromTranslationResponse(phrase));\n          }\n          break;\n        case \"translation.phrase\":\n          yield handleTranslationPhrase(_Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase.fromJSON(connectionMessage.textBody));\n          break;\n        case \"translation.synthesis\":\n          this.sendSynthesisAudio(connectionMessage.binaryBody, this.privRequestSession.sessionId);\n          processed = true;\n          break;\n        case \"translation.synthesis.end\":\n          const synthEnd = _Exports__WEBPACK_IMPORTED_MODULE_11__.TranslationSynthesisEnd.fromJSON(connectionMessage.textBody);\n          switch (synthEnd.SynthesisStatus) {\n            case _Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisStatus.Error:\n              if (!!this.privTranslationRecognizer.synthesizing) {\n                const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.TranslationSynthesisResult(_sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined);\n                const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.TranslationSynthesisEventArgs(result, this.privRequestSession.sessionId);\n                try {\n                  this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n                  /* eslint-disable no-empty */\n                } catch (error) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n              if (!!this.privTranslationRecognizer.canceled) {\n                // And raise a canceled event to send the rich(er) error message back.\n                const canceledResult = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.TranslationRecognitionCanceledEventArgs(this.privRequestSession.sessionId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_15__.CancellationReason.Error, synthEnd.FailureReason, _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.CancellationErrorCode.ServiceError, null);\n                try {\n                  this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, canceledResult);\n                  /* eslint-disable no-empty */\n                } catch (error) {\n                  // Not going to let errors in the event handler\n                  // trip things up.\n                }\n              }\n              break;\n            case _Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisStatus.Success:\n              this.sendSynthesisAudio(undefined, this.privRequestSession.sessionId);\n              break;\n            default:\n              break;\n          }\n          processed = true;\n          break;\n        default:\n          break;\n      }\n      return processed;\n    });\n  }\n  // Cancels recognition.\n  cancelRecognition(sessionId, requestId, cancellationReason, errorCode, error) {\n    const properties = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n    properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_17__.CancellationErrorCodePropertyName, _sdk_Exports__WEBPACK_IMPORTED_MODULE_16__.CancellationErrorCode[errorCode]);\n    if (!!this.privTranslationRecognizer.canceled) {\n      const cancelEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_14__.TranslationRecognitionCanceledEventArgs(sessionId, cancellationReason, error, errorCode, undefined);\n      try {\n        this.privTranslationRecognizer.canceled(this.privTranslationRecognizer, cancelEvent);\n        /* eslint-disable no-empty */\n      } catch (_a) {}\n    }\n    if (!!this.privSuccessCallback) {\n      const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(undefined,\n      // Translations\n      requestId, _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.Canceled, undefined,\n      // Text\n      undefined,\n      // Druation\n      undefined,\n      // Offset\n      error, undefined,\n      // Json\n      properties);\n      try {\n        this.privSuccessCallback(result);\n        /* eslint-disable no-empty */\n        this.privSuccessCallback = undefined;\n      } catch (_b) {}\n    }\n  }\n  fireEventForResult(serviceResult, properties) {\n    let translations;\n    if (undefined !== serviceResult.Translation.Translations) {\n      translations = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_18__.Translations();\n      for (const translation of serviceResult.Translation.Translations) {\n        translations.set(translation.Language, translation.Text || translation.DisplayText);\n      }\n    }\n    let resultReason;\n    if (serviceResult instanceof _Exports__WEBPACK_IMPORTED_MODULE_10__.TranslationPhrase) {\n      if (serviceResult.Translation.TranslationStatus === _common_Exports__WEBPACK_IMPORTED_MODULE_19__.TranslationStatus.Success) {\n        resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.TranslatedSpeech;\n      } else {\n        resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.RecognizedSpeech;\n      }\n    } else {\n      resultReason = _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.TranslatingSpeech;\n    }\n    const offset = serviceResult.Offset + this.privRequestSession.currentTurnAudioOffset;\n    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_4__.TranslationRecognitionResult(translations, this.privRequestSession.requestId, resultReason, serviceResult.Text, serviceResult.Duration, offset, serviceResult.Translation.FailureReason, JSON.stringify(serviceResult), properties);\n    const ev = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationRecognitionEventArgs(result, offset, this.privRequestSession.sessionId);\n    return ev;\n  }\n  sendSynthesisAudio(audio, sessionId) {\n    const reason = undefined === audio ? _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.SynthesizingAudioCompleted : _sdk_Exports__WEBPACK_IMPORTED_MODULE_5__.ResultReason.SynthesizingAudio;\n    const result = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_12__.TranslationSynthesisResult(reason, audio);\n    const retEvent = new _sdk_Exports__WEBPACK_IMPORTED_MODULE_13__.TranslationSynthesisEventArgs(result, sessionId);\n    if (!!this.privTranslationRecognizer.synthesizing) {\n      try {\n        this.privTranslationRecognizer.synthesizing(this.privTranslationRecognizer, retEvent);\n        /* eslint-disable no-empty */\n      } catch (error) {\n        // Not going to let errors in the event handler\n        // trip things up.\n      }\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationStatus\": () => (/* binding */ TranslationStatus)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines translation status.\n * @class TranslationStatus\n */\nvar TranslationStatus;\n(function (TranslationStatus) {\n  /**\n   * @member TranslationStatus.Success\n   */\n  TranslationStatus[TranslationStatus[\"Success\"] = 0] = \"Success\";\n  /**\n   * @member TranslationStatus.Error\n   */\n  TranslationStatus[TranslationStatus[\"Error\"] = 1] = \"Error\";\n})(TranslationStatus || (TranslationStatus = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationStatus.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WebsocketMessageFormatter\": () => (/* binding */ WebsocketMessageFormatter)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nconst CRLF = \"\\r\\n\";\nclass WebsocketMessageFormatter {\n  toConnectionMessage(message) {\n    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n    try {\n      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n        const textMessage = message.textContent;\n        let headers = {};\n        let body = null;\n        if (textMessage) {\n          const headerBodySplit = textMessage.split(\"\\r\\n\\r\\n\");\n          if (headerBodySplit && headerBodySplit.length > 0) {\n            headers = this.parseHeaders(headerBodySplit[0]);\n            if (headerBodySplit.length > 1) {\n              body = headerBodySplit[1];\n            }\n          }\n        }\n        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ConnectionMessage(message.messageType, body, headers, message.id));\n      } else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n        const binaryMessage = message.binaryContent;\n        let headers = {};\n        let body = null;\n        if (!binaryMessage || binaryMessage.byteLength < 2) {\n          throw new Error(\"Invalid binary message format. Header length missing.\");\n        }\n        const dataView = new DataView(binaryMessage);\n        const headerLength = dataView.getInt16(0);\n        if (binaryMessage.byteLength < headerLength + 2) {\n          throw new Error(\"Invalid binary message format. Header content missing.\");\n        }\n        let headersString = \"\";\n        for (let i = 0; i < headerLength; i++) {\n          headersString += String.fromCharCode(dataView.getInt8(i + 2));\n        }\n        headers = this.parseHeaders(headersString);\n        if (binaryMessage.byteLength > headerLength + 2) {\n          body = binaryMessage.slice(2 + headerLength);\n        }\n        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.ConnectionMessage(message.messageType, body, headers, message.id));\n      }\n    } catch (e) {\n      deferral.reject(`Error formatting the message. Error: ${e}`);\n    }\n    return deferral.promise;\n  }\n  fromConnectionMessage(message) {\n    const deferral = new _common_Exports__WEBPACK_IMPORTED_MODULE_0__.Deferred();\n    try {\n      if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n        const payload = `${this.makeHeaders(message)}${CRLF}${message.textBody ? message.textBody : \"\"}`;\n        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text, payload, message.id));\n      } else if (message.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n        const headersString = this.makeHeaders(message);\n        const content = message.binaryBody;\n        const headerBuffer = this.stringToArrayBuffer(headersString);\n        const headerInt8Array = new Int8Array(headerBuffer);\n        const headerLength = headerInt8Array.byteLength;\n        const payloadInt8Array = new Int8Array(2 + headerLength + (content ? content.byteLength : 0));\n        payloadInt8Array[0] = headerLength >> 8 & 0xff;\n        payloadInt8Array[1] = headerLength & 0xff;\n        payloadInt8Array.set(headerInt8Array, 2);\n        if (content) {\n          const bodyInt8Array = new Int8Array(content);\n          payloadInt8Array.set(bodyInt8Array, 2 + headerLength);\n        }\n        const payload = payloadInt8Array.buffer;\n        deferral.resolve(new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.RawWebsocketMessage(_common_Exports__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary, payload, message.id));\n      }\n    } catch (e) {\n      deferral.reject(`Error formatting the message. ${e}`);\n    }\n    return deferral.promise;\n  }\n  makeHeaders(message) {\n    let headersString = \"\";\n    if (message.headers) {\n      for (const header in message.headers) {\n        if (header) {\n          headersString += `${header}: ${message.headers[header]}${CRLF}`;\n        }\n      }\n    }\n    return headersString;\n  }\n  parseHeaders(headersString) {\n    const headers = {};\n    if (headersString) {\n      const headerMatches = headersString.match(/[^\\r\\n]+/g);\n      if (headers) {\n        for (const header of headerMatches) {\n          if (header) {\n            const separatorIndex = header.indexOf(\":\");\n            const headerName = separatorIndex > 0 ? header.substr(0, separatorIndex).trim().toLowerCase() : header;\n            const headerValue = separatorIndex > 0 && header.length > separatorIndex + 1 ? header.substr(separatorIndex + 1).trim() : \"\";\n            headers[headerName] = headerValue;\n          }\n        }\n      }\n    }\n    return headers;\n  }\n  stringToArrayBuffer(str) {\n    const buffer = new ArrayBuffer(str.length);\n    const view = new DataView(buffer);\n    for (let i = 0; i < str.length; i++) {\n      view.setUint8(i, str.charCodeAt(i));\n    }\n    return buffer;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/WebsocketMessageFormatter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioSourceErrorEvent\": () => (/* binding */ AudioSourceErrorEvent),\n/* harmony export */   \"AudioSourceEvent\": () => (/* binding */ AudioSourceEvent),\n/* harmony export */   \"AudioSourceInitializingEvent\": () => (/* binding */ AudioSourceInitializingEvent),\n/* harmony export */   \"AudioSourceOffEvent\": () => (/* binding */ AudioSourceOffEvent),\n/* harmony export */   \"AudioSourceReadyEvent\": () => (/* binding */ AudioSourceReadyEvent),\n/* harmony export */   \"AudioStreamNodeAttachedEvent\": () => (/* binding */ AudioStreamNodeAttachedEvent),\n/* harmony export */   \"AudioStreamNodeAttachingEvent\": () => (/* binding */ AudioStreamNodeAttachingEvent),\n/* harmony export */   \"AudioStreamNodeDetachedEvent\": () => (/* binding */ AudioStreamNodeDetachedEvent),\n/* harmony export */   \"AudioStreamNodeErrorEvent\": () => (/* binding */ AudioStreamNodeErrorEvent),\n/* harmony export */   \"AudioStreamNodeEvent\": () => (/* binding */ AudioStreamNodeEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass AudioSourceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName, audioSourceId) {\n    let eventType = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info;\n    super(eventName, eventType);\n    this.privAudioSourceId = audioSourceId;\n  }\n  get audioSourceId() {\n    return this.privAudioSourceId;\n  }\n}\nclass AudioSourceInitializingEvent extends AudioSourceEvent {\n  constructor(audioSourceId) {\n    super(\"AudioSourceInitializingEvent\", audioSourceId);\n  }\n}\nclass AudioSourceReadyEvent extends AudioSourceEvent {\n  constructor(audioSourceId) {\n    super(\"AudioSourceReadyEvent\", audioSourceId);\n  }\n}\nclass AudioSourceOffEvent extends AudioSourceEvent {\n  constructor(audioSourceId) {\n    super(\"AudioSourceOffEvent\", audioSourceId);\n  }\n}\nclass AudioSourceErrorEvent extends AudioSourceEvent {\n  constructor(audioSourceId, error) {\n    super(\"AudioSourceErrorEvent\", audioSourceId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n    this.privError = error;\n  }\n  get error() {\n    return this.privError;\n  }\n}\nclass AudioStreamNodeEvent extends AudioSourceEvent {\n  constructor(eventName, audioSourceId, audioNodeId) {\n    super(eventName, audioSourceId);\n    this.privAudioNodeId = audioNodeId;\n  }\n  get audioNodeId() {\n    return this.privAudioNodeId;\n  }\n}\nclass AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {\n  constructor(audioSourceId, audioNodeId) {\n    super(\"AudioStreamNodeAttachingEvent\", audioSourceId, audioNodeId);\n  }\n}\nclass AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {\n  constructor(audioSourceId, audioNodeId) {\n    super(\"AudioStreamNodeAttachedEvent\", audioSourceId, audioNodeId);\n  }\n}\nclass AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {\n  constructor(audioSourceId, audioNodeId) {\n    super(\"AudioStreamNodeDetachedEvent\", audioSourceId, audioNodeId);\n  }\n}\nclass AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {\n  constructor(audioSourceId, audioNodeId, error) {\n    super(\"AudioStreamNodeErrorEvent\", audioSourceId, audioNodeId);\n    this.privError = error;\n  }\n  get error() {\n    return this.privError;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BackgroundEvent\": () => (/* binding */ BackgroundEvent)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass BackgroundEvent extends _Exports__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(error) {\n    super(\"BackgroundEvent\", _Exports__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n    this.privError = error;\n  }\n  get error() {\n    return this.privError;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ChunkedArrayBufferStream\": () => (/* binding */ ChunkedArrayBufferStream)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ChunkedArrayBufferStream extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Stream {\n  constructor(targetChunkSize, streamId) {\n    super(streamId);\n    this.privTargetChunkSize = targetChunkSize;\n    this.privNextBufferReadyBytes = 0;\n  }\n  writeStreamChunk(chunk) {\n    // No pending write, and the buffer is the right size so write it.\n    if (chunk.isEnd || 0 === this.privNextBufferReadyBytes && chunk.buffer.byteLength === this.privTargetChunkSize) {\n      super.writeStreamChunk(chunk);\n      return;\n    }\n    let bytesCopiedFromBuffer = 0;\n    while (bytesCopiedFromBuffer < chunk.buffer.byteLength) {\n      // Fill the next buffer.\n      if (undefined === this.privNextBufferToWrite) {\n        this.privNextBufferToWrite = new ArrayBuffer(this.privTargetChunkSize);\n        this.privNextBufferStartTime = chunk.timeReceived;\n      }\n      // Find out how many bytes we can copy into the read buffer.\n      const bytesToCopy = Math.min(chunk.buffer.byteLength - bytesCopiedFromBuffer, this.privTargetChunkSize - this.privNextBufferReadyBytes);\n      const targetView = new Uint8Array(this.privNextBufferToWrite);\n      const sourceView = new Uint8Array(chunk.buffer.slice(bytesCopiedFromBuffer, bytesToCopy + bytesCopiedFromBuffer));\n      targetView.set(sourceView, this.privNextBufferReadyBytes);\n      this.privNextBufferReadyBytes += bytesToCopy;\n      bytesCopiedFromBuffer += bytesToCopy;\n      // Are we ready to write?\n      if (this.privNextBufferReadyBytes === this.privTargetChunkSize) {\n        super.writeStreamChunk({\n          buffer: this.privNextBufferToWrite,\n          isEnd: false,\n          timeReceived: this.privNextBufferStartTime\n        });\n        this.privNextBufferReadyBytes = 0;\n        this.privNextBufferToWrite = undefined;\n      }\n    }\n  }\n  close() {\n    // Send whatever is pending, then close the base class.\n    if (0 !== this.privNextBufferReadyBytes && !this.isClosed) {\n      super.writeStreamChunk({\n        buffer: this.privNextBufferToWrite.slice(0, this.privNextBufferReadyBytes),\n        isEnd: false,\n        timeReceived: this.privNextBufferStartTime\n      });\n    }\n    super.close();\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionClosedEvent\": () => (/* binding */ ConnectionClosedEvent),\n/* harmony export */   \"ConnectionErrorEvent\": () => (/* binding */ ConnectionErrorEvent),\n/* harmony export */   \"ConnectionEstablishErrorEvent\": () => (/* binding */ ConnectionEstablishErrorEvent),\n/* harmony export */   \"ConnectionEstablishedEvent\": () => (/* binding */ ConnectionEstablishedEvent),\n/* harmony export */   \"ConnectionEvent\": () => (/* binding */ ConnectionEvent),\n/* harmony export */   \"ConnectionMessageReceivedEvent\": () => (/* binding */ ConnectionMessageReceivedEvent),\n/* harmony export */   \"ConnectionMessageSentEvent\": () => (/* binding */ ConnectionMessageSentEvent),\n/* harmony export */   \"ConnectionStartEvent\": () => (/* binding */ ConnectionStartEvent),\n/* harmony export */   \"ServiceEvent\": () => (/* binding */ ServiceEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass ServiceEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName, jsonstring) {\n    let eventType = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info;\n    super(eventName, eventType);\n    this.privJsonResult = jsonstring;\n  }\n  get jsonString() {\n    return this.privJsonResult;\n  }\n}\nclass ConnectionEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName, connectionId) {\n    let eventType = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info;\n    super(eventName, eventType);\n    this.privConnectionId = connectionId;\n  }\n  get connectionId() {\n    return this.privConnectionId;\n  }\n}\nclass ConnectionStartEvent extends ConnectionEvent {\n  constructor(connectionId, uri, headers) {\n    super(\"ConnectionStartEvent\", connectionId);\n    this.privUri = uri;\n    this.privHeaders = headers;\n  }\n  get uri() {\n    return this.privUri;\n  }\n  get headers() {\n    return this.privHeaders;\n  }\n}\nclass ConnectionEstablishedEvent extends ConnectionEvent {\n  constructor(connectionId) {\n    super(\"ConnectionEstablishedEvent\", connectionId);\n  }\n}\nclass ConnectionClosedEvent extends ConnectionEvent {\n  constructor(connectionId, statusCode, reason) {\n    super(\"ConnectionClosedEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug);\n    this.privReason = reason;\n    this.privStatusCode = statusCode;\n  }\n  get reason() {\n    return this.privReason;\n  }\n  get statusCode() {\n    return this.privStatusCode;\n  }\n}\nclass ConnectionErrorEvent extends ConnectionEvent {\n  constructor(connectionId, message, type) {\n    super(\"ConnectionErrorEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug);\n    this.privMessage = message;\n    this.privType = type;\n  }\n  get message() {\n    return this.privMessage;\n  }\n  get type() {\n    return this.privType;\n  }\n}\nclass ConnectionEstablishErrorEvent extends ConnectionEvent {\n  constructor(connectionId, statuscode, reason) {\n    super(\"ConnectionEstablishErrorEvent\", connectionId, _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Error);\n    this.privStatusCode = statuscode;\n    this.privReason = reason;\n  }\n  get reason() {\n    return this.privReason;\n  }\n  get statusCode() {\n    return this.privStatusCode;\n  }\n}\nclass ConnectionMessageReceivedEvent extends ConnectionEvent {\n  constructor(connectionId, networkReceivedTimeISO, message) {\n    super(\"ConnectionMessageReceivedEvent\", connectionId);\n    this.privNetworkReceivedTime = networkReceivedTimeISO;\n    this.privMessage = message;\n  }\n  get networkReceivedTime() {\n    return this.privNetworkReceivedTime;\n  }\n  get message() {\n    return this.privMessage;\n  }\n}\nclass ConnectionMessageSentEvent extends ConnectionEvent {\n  constructor(connectionId, networkSentTimeISO, message) {\n    super(\"ConnectionMessageSentEvent\", connectionId);\n    this.privNetworkSentTime = networkSentTimeISO;\n    this.privMessage = message;\n  }\n  get networkSentTime() {\n    return this.privNetworkSentTime;\n  }\n  get message() {\n    return this.privMessage;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionMessage\": () => (/* binding */ ConnectionMessage),\n/* harmony export */   \"MessageType\": () => (/* binding */ MessageType)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-return */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nvar MessageType;\n(function (MessageType) {\n  MessageType[MessageType[\"Text\"] = 0] = \"Text\";\n  MessageType[MessageType[\"Binary\"] = 1] = \"Binary\";\n})(MessageType || (MessageType = {}));\nclass ConnectionMessage {\n  constructor(messageType, body, headers, id) {\n    this.privBody = null;\n    if (messageType === MessageType.Text && body && !(typeof body === \"string\")) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be a string\");\n    }\n    if (messageType === MessageType.Binary && body && !(body instanceof ArrayBuffer)) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be ArrayBuffer\");\n    }\n    this.privMessageType = messageType;\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment\n    this.privBody = body;\n    this.privHeaders = headers ? headers : {};\n    this.privId = id ? id : (0,_Guid__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n    switch (this.messageType) {\n      case MessageType.Binary:\n        this.privSize = this.binaryBody !== null ? this.binaryBody.byteLength : 0;\n        break;\n      case MessageType.Text:\n        this.privSize = this.textBody.length;\n    }\n  }\n  get messageType() {\n    return this.privMessageType;\n  }\n  get headers() {\n    return this.privHeaders;\n  }\n  get body() {\n    return this.privBody;\n  }\n  get textBody() {\n    if (this.privMessageType === MessageType.Binary) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for binary message\");\n    }\n    return this.privBody;\n  }\n  get binaryBody() {\n    if (this.privMessageType === MessageType.Text) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for text message\");\n    }\n    return this.privBody;\n  }\n  get id() {\n    return this.privId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionOpenResponse\": () => (/* binding */ ConnectionOpenResponse)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ConnectionOpenResponse {\n  constructor(statusCode, reason) {\n    this.privStatusCode = statusCode;\n    this.privReason = reason;\n  }\n  get statusCode() {\n    return this.privStatusCode;\n  }\n  get reason() {\n    return this.privReason;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionOpenResponse.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogEvent\": () => (/* binding */ DialogEvent),\n/* harmony export */   \"SendingAgentContextMessageEvent\": () => (/* binding */ SendingAgentContextMessageEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass DialogEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName) {\n    let eventType = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Info;\n    super(eventName, eventType);\n  }\n}\nclass SendingAgentContextMessageEvent extends DialogEvent {\n  constructor(agentConfig) {\n    super(\"SendingAgentContextMessageEvent\");\n    this.privAgentConfig = agentConfig;\n  }\n  get agentConfig() {\n    return this.privAgentConfig;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/DialogEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ArgumentNullError\": () => (/* binding */ ArgumentNullError),\n/* harmony export */   \"InvalidOperationError\": () => (/* binding */ InvalidOperationError),\n/* harmony export */   \"ObjectDisposedError\": () => (/* binding */ ObjectDisposedError)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n/**\n * The error that is thrown when an argument passed in is null.\n *\n * @export\n * @class ArgumentNullError\n * @extends {Error}\n */\nclass ArgumentNullError extends Error {\n  /**\n   * Creates an instance of ArgumentNullError.\n   *\n   * @param {string} argumentName - Name of the argument that is null\n   *\n   * @memberOf ArgumentNullError\n   */\n  constructor(argumentName) {\n    super(argumentName);\n    this.name = \"ArgumentNull\";\n    this.message = argumentName;\n  }\n}\n/**\n * The error that is thrown when an invalid operation is performed in the code.\n *\n * @export\n * @class InvalidOperationError\n * @extends {Error}\n */\nclass InvalidOperationError extends Error {\n  /**\n   * Creates an instance of InvalidOperationError.\n   *\n   * @param {string} error - The error\n   *\n   * @memberOf InvalidOperationError\n   */\n  constructor(error) {\n    super(error);\n    this.name = \"InvalidOperation\";\n    this.message = error;\n  }\n}\n/**\n * The error that is thrown when an object is disposed.\n *\n * @export\n * @class ObjectDisposedError\n * @extends {Error}\n */\nclass ObjectDisposedError extends Error {\n  /**\n   * Creates an instance of ObjectDisposedError.\n   *\n   * @param {string} objectName - The object that is disposed\n   * @param {string} error - The error\n   *\n   * @memberOf ObjectDisposedError\n   */\n  constructor(objectName, error) {\n    super(error);\n    this.name = objectName + \"ObjectDisposed\";\n    this.message = error;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EventSource\": () => (/* binding */ EventSource)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass EventSource {\n  constructor(metadata) {\n    this.privEventListeners = {};\n    this.privIsDisposed = false;\n    this.privConsoleListener = undefined;\n    this.privMetadata = metadata;\n  }\n  onEvent(event) {\n    if (this.isDisposed()) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ObjectDisposedError(\"EventSource\");\n    }\n    if (this.metadata) {\n      for (const paramName in this.metadata) {\n        if (paramName) {\n          if (event.metadata) {\n            if (!event.metadata[paramName]) {\n              event.metadata[paramName] = this.metadata[paramName];\n            }\n          }\n        }\n      }\n    }\n    for (const eventId in this.privEventListeners) {\n      if (eventId && this.privEventListeners[eventId]) {\n        this.privEventListeners[eventId](event);\n      }\n    }\n  }\n  attach(onEventCallback) {\n    const id = (0,_Guid__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n    this.privEventListeners[id] = onEventCallback;\n    return {\n      detach: () => {\n        delete this.privEventListeners[id];\n        return Promise.resolve();\n      }\n    };\n  }\n  attachListener(listener) {\n    return this.attach(e => listener.onEvent(e));\n  }\n  attachConsoleListener(listener) {\n    if (!!this.privConsoleListener) {\n      void this.privConsoleListener.detach(); // Detach implementation for eventListeners is synchronous\n    }\n\n    this.privConsoleListener = this.attach(e => listener.onEvent(e));\n    return this.privConsoleListener;\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  dispose() {\n    this.privEventListeners = null;\n    this.privIsDisposed = true;\n  }\n  get metadata() {\n    return this.privMetadata;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Events\": () => (/* binding */ Events)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _EventSource__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./EventSource */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass Events {\n  static setEventSource(eventSource) {\n    if (!eventSource) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"eventSource\");\n    }\n    Events.privInstance = eventSource;\n  }\n  static get instance() {\n    return Events.privInstance;\n  }\n}\nEvents.privInstance = new _EventSource__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGuid\": () => (/* binding */ createGuid),\n/* harmony export */   \"createNoDashGuid\": () => (/* binding */ createNoDashGuid)\n/* harmony export */ });\n/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! uuid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/v4.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nconst createGuid = () => (0,uuid__WEBPACK_IMPORTED_MODULE_0__[\"default\"])();\nconst createNoDashGuid = () => createGuid().replace(new RegExp(\"-\", \"g\"), \"\").toUpperCase();\n\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionState\": () => (/* binding */ ConnectionState)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar ConnectionState;\n(function (ConnectionState) {\n  ConnectionState[ConnectionState[\"None\"] = 0] = \"None\";\n  ConnectionState[ConnectionState[\"Connected\"] = 1] = \"Connected\";\n  ConnectionState[ConnectionState[\"Connecting\"] = 2] = \"Connecting\";\n  ConnectionState[ConnectionState[\"Disconnected\"] = 3] = \"Disconnected\";\n})(ConnectionState || (ConnectionState = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/IConnection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"List\": () => (/* binding */ List)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass List {\n  constructor(list) {\n    this.privSubscriptionIdCounter = 0;\n    this.privAddSubscriptions = {};\n    this.privRemoveSubscriptions = {};\n    this.privDisposedSubscriptions = {};\n    this.privDisposeReason = null;\n    this.privList = [];\n    // copy the list rather than taking as is.\n    if (list) {\n      for (const item of list) {\n        this.privList.push(item);\n      }\n    }\n  }\n  get(itemIndex) {\n    this.throwIfDisposed();\n    return this.privList[itemIndex];\n  }\n  first() {\n    return this.get(0);\n  }\n  last() {\n    return this.get(this.length() - 1);\n  }\n  add(item) {\n    this.throwIfDisposed();\n    this.insertAt(this.privList.length, item);\n  }\n  insertAt(index, item) {\n    this.throwIfDisposed();\n    if (index === 0) {\n      this.privList.unshift(item);\n    } else if (index === this.privList.length) {\n      this.privList.push(item);\n    } else {\n      this.privList.splice(index, 0, item);\n    }\n    this.triggerSubscriptions(this.privAddSubscriptions);\n  }\n  removeFirst() {\n    this.throwIfDisposed();\n    return this.removeAt(0);\n  }\n  removeLast() {\n    this.throwIfDisposed();\n    return this.removeAt(this.length() - 1);\n  }\n  removeAt(index) {\n    this.throwIfDisposed();\n    return this.remove(index, 1)[0];\n  }\n  remove(index, count) {\n    this.throwIfDisposed();\n    const removedElements = this.privList.splice(index, count);\n    this.triggerSubscriptions(this.privRemoveSubscriptions);\n    return removedElements;\n  }\n  clear() {\n    this.throwIfDisposed();\n    this.remove(0, this.length());\n  }\n  length() {\n    this.throwIfDisposed();\n    return this.privList.length;\n  }\n  onAdded(addedCallback) {\n    this.throwIfDisposed();\n    const subscriptionId = this.privSubscriptionIdCounter++;\n    this.privAddSubscriptions[subscriptionId] = addedCallback;\n    return {\n      detach: () => {\n        delete this.privAddSubscriptions[subscriptionId];\n        return Promise.resolve();\n      }\n    };\n  }\n  onRemoved(removedCallback) {\n    this.throwIfDisposed();\n    const subscriptionId = this.privSubscriptionIdCounter++;\n    this.privRemoveSubscriptions[subscriptionId] = removedCallback;\n    return {\n      detach: () => {\n        delete this.privRemoveSubscriptions[subscriptionId];\n        return Promise.resolve();\n      }\n    };\n  }\n  onDisposed(disposedCallback) {\n    this.throwIfDisposed();\n    const subscriptionId = this.privSubscriptionIdCounter++;\n    this.privDisposedSubscriptions[subscriptionId] = disposedCallback;\n    return {\n      detach: () => {\n        delete this.privDisposedSubscriptions[subscriptionId];\n        return Promise.resolve();\n      }\n    };\n  }\n  join(seperator) {\n    this.throwIfDisposed();\n    return this.privList.join(seperator);\n  }\n  toArray() {\n    const cloneCopy = Array();\n    this.privList.forEach(val => {\n      cloneCopy.push(val);\n    });\n    return cloneCopy;\n  }\n  any(callback) {\n    this.throwIfDisposed();\n    if (callback) {\n      return this.where(callback).length() > 0;\n    } else {\n      return this.length() > 0;\n    }\n  }\n  all(callback) {\n    this.throwIfDisposed();\n    return this.where(callback).length() === this.length();\n  }\n  forEach(callback) {\n    this.throwIfDisposed();\n    for (let i = 0; i < this.length(); i++) {\n      callback(this.privList[i], i);\n    }\n  }\n  select(callback) {\n    this.throwIfDisposed();\n    const selectList = [];\n    for (let i = 0; i < this.privList.length; i++) {\n      selectList.push(callback(this.privList[i], i));\n    }\n    return new List(selectList);\n  }\n  where(callback) {\n    this.throwIfDisposed();\n    const filteredList = new List();\n    for (let i = 0; i < this.privList.length; i++) {\n      if (callback(this.privList[i], i)) {\n        filteredList.add(this.privList[i]);\n      }\n    }\n    return filteredList;\n  }\n  orderBy(compareFn) {\n    this.throwIfDisposed();\n    const clonedArray = this.toArray();\n    const orderedArray = clonedArray.sort(compareFn);\n    return new List(orderedArray);\n  }\n  orderByDesc(compareFn) {\n    this.throwIfDisposed();\n    return this.orderBy((a, b) => compareFn(b, a));\n  }\n  clone() {\n    this.throwIfDisposed();\n    return new List(this.toArray());\n  }\n  concat(list) {\n    this.throwIfDisposed();\n    return new List(this.privList.concat(list.toArray()));\n  }\n  concatArray(array) {\n    this.throwIfDisposed();\n    return new List(this.privList.concat(array));\n  }\n  isDisposed() {\n    return this.privList == null;\n  }\n  dispose(reason) {\n    if (!this.isDisposed()) {\n      this.privDisposeReason = reason;\n      this.privList = null;\n      this.privAddSubscriptions = null;\n      this.privRemoveSubscriptions = null;\n      this.triggerSubscriptions(this.privDisposedSubscriptions);\n    }\n  }\n  throwIfDisposed() {\n    if (this.isDisposed()) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ObjectDisposedError(\"List\", this.privDisposeReason);\n    }\n  }\n  triggerSubscriptions(subscriptions) {\n    if (subscriptions) {\n      for (const subscriptionId in subscriptions) {\n        if (subscriptionId) {\n          subscriptions[subscriptionId]();\n        }\n      }\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OCSPCacheEntryExpiredEvent\": () => (/* binding */ OCSPCacheEntryExpiredEvent),\n/* harmony export */   \"OCSPCacheEntryNeedsRefreshEvent\": () => (/* binding */ OCSPCacheEntryNeedsRefreshEvent),\n/* harmony export */   \"OCSPCacheFetchErrorEvent\": () => (/* binding */ OCSPCacheFetchErrorEvent),\n/* harmony export */   \"OCSPCacheHitEvent\": () => (/* binding */ OCSPCacheHitEvent),\n/* harmony export */   \"OCSPCacheMissEvent\": () => (/* binding */ OCSPCacheMissEvent),\n/* harmony export */   \"OCSPCacheUpdateCompleteEvent\": () => (/* binding */ OCSPCacheUpdateCompleteEvent),\n/* harmony export */   \"OCSPCacheUpdateErrorEvent\": () => (/* binding */ OCSPCacheUpdateErrorEvent),\n/* harmony export */   \"OCSPCacheUpdateNeededEvent\": () => (/* binding */ OCSPCacheUpdateNeededEvent),\n/* harmony export */   \"OCSPDiskCacheHitEvent\": () => (/* binding */ OCSPDiskCacheHitEvent),\n/* harmony export */   \"OCSPDiskCacheStoreEvent\": () => (/* binding */ OCSPDiskCacheStoreEvent),\n/* harmony export */   \"OCSPEvent\": () => (/* binding */ OCSPEvent),\n/* harmony export */   \"OCSPMemoryCacheHitEvent\": () => (/* binding */ OCSPMemoryCacheHitEvent),\n/* harmony export */   \"OCSPMemoryCacheStoreEvent\": () => (/* binding */ OCSPMemoryCacheStoreEvent),\n/* harmony export */   \"OCSPResponseRetrievedEvent\": () => (/* binding */ OCSPResponseRetrievedEvent),\n/* harmony export */   \"OCSPStapleReceivedEvent\": () => (/* binding */ OCSPStapleReceivedEvent),\n/* harmony export */   \"OCSPVerificationFailedEvent\": () => (/* binding */ OCSPVerificationFailedEvent),\n/* harmony export */   \"OCSPWSUpgradeStartedEvent\": () => (/* binding */ OCSPWSUpgradeStartedEvent)\n/* harmony export */ });\n/* harmony import */ var _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PlatformEvent */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\nclass OCSPEvent extends _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.PlatformEvent {\n  constructor(eventName, eventType, signature) {\n    super(eventName, eventType);\n    this.privSignature = signature;\n  }\n}\nclass OCSPMemoryCacheHitEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPMemoryCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPCacheMissEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPCacheMissEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPDiskCacheHitEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPDiskCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPCacheUpdateNeededEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPCacheUpdateNeededEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPMemoryCacheStoreEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPMemoryCacheStoreEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPDiskCacheStoreEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPDiskCacheStoreEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPCacheUpdateCompleteEvent extends OCSPEvent {\n  constructor(signature) {\n    super(\"OCSPCacheUpdateCompleteEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, signature);\n  }\n}\nclass OCSPStapleReceivedEvent extends OCSPEvent {\n  constructor() {\n    super(\"OCSPStapleReceivedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, \"\");\n  }\n}\nclass OCSPWSUpgradeStartedEvent extends OCSPEvent {\n  constructor(serialNumber) {\n    super(\"OCSPWSUpgradeStartedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n  }\n}\nclass OCSPCacheEntryExpiredEvent extends OCSPEvent {\n  constructor(serialNumber, expireTime) {\n    super(\"OCSPCacheEntryExpiredEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    this.privExpireTime = expireTime;\n  }\n}\nclass OCSPCacheEntryNeedsRefreshEvent extends OCSPEvent {\n  constructor(serialNumber, startTime, expireTime) {\n    super(\"OCSPCacheEntryNeedsRefreshEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    this.privExpireTime = expireTime;\n    this.privStartTime = startTime;\n  }\n}\nclass OCSPCacheHitEvent extends OCSPEvent {\n  constructor(serialNumber, startTime, expireTime) {\n    super(\"OCSPCacheHitEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    this.privExpireTime = expireTime;\n    this.privExpireTimeString = new Date(expireTime).toLocaleDateString();\n    this.privStartTime = startTime;\n    this.privStartTimeString = new Date(startTime).toLocaleTimeString();\n  }\n}\nclass OCSPVerificationFailedEvent extends OCSPEvent {\n  constructor(serialNumber, error) {\n    super(\"OCSPVerificationFailedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    this.privError = error;\n  }\n}\nclass OCSPCacheFetchErrorEvent extends OCSPEvent {\n  constructor(serialNumber, error) {\n    super(\"OCSPCacheFetchErrorEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    this.privError = error;\n  }\n}\nclass OCSPResponseRetrievedEvent extends OCSPEvent {\n  constructor(serialNumber) {\n    super(\"OCSPResponseRetrievedEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n  }\n}\nclass OCSPCacheUpdateErrorEvent extends OCSPEvent {\n  constructor(serialNumber, error) {\n    super(\"OCSPCacheUpdateErrorEvent\", _PlatformEvent__WEBPACK_IMPORTED_MODULE_0__.EventType.Debug, serialNumber);\n    this.privError = error;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/OCSPEvents.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EventType\": () => (/* binding */ EventType),\n/* harmony export */   \"PlatformEvent\": () => (/* binding */ PlatformEvent)\n/* harmony export */ });\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nvar EventType;\n(function (EventType) {\n  EventType[EventType[\"Debug\"] = 0] = \"Debug\";\n  EventType[EventType[\"Info\"] = 1] = \"Info\";\n  EventType[EventType[\"Warning\"] = 2] = \"Warning\";\n  EventType[EventType[\"Error\"] = 3] = \"Error\";\n  EventType[EventType[\"None\"] = 4] = \"None\";\n})(EventType || (EventType = {}));\nclass PlatformEvent {\n  constructor(eventName, eventType) {\n    this.privName = eventName;\n    this.privEventId = (0,_Guid__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privEventTime = new Date().toISOString();\n    this.privEventType = eventType;\n    this.privMetadata = {};\n  }\n  get name() {\n    return this.privName;\n  }\n  get eventId() {\n    return this.privEventId;\n  }\n  get eventTime() {\n    return this.privEventTime;\n  }\n  get eventType() {\n    return this.privEventType;\n  }\n  get metadata() {\n    return this.privMetadata;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Deferred\": () => (/* binding */ Deferred),\n/* harmony export */   \"PromiseResult\": () => (/* binding */ PromiseResult),\n/* harmony export */   \"PromiseResultEventSource\": () => (/* binding */ PromiseResultEventSource),\n/* harmony export */   \"PromiseState\": () => (/* binding */ PromiseState),\n/* harmony export */   \"Sink\": () => (/* binding */ Sink),\n/* harmony export */   \"marshalPromiseToCallbacks\": () => (/* binding */ marshalPromiseToCallbacks)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file, @typescript-eslint/typedef */\nvar PromiseState;\n(function (PromiseState) {\n  PromiseState[PromiseState[\"None\"] = 0] = \"None\";\n  PromiseState[PromiseState[\"Resolved\"] = 1] = \"Resolved\";\n  PromiseState[PromiseState[\"Rejected\"] = 2] = \"Rejected\";\n})(PromiseState || (PromiseState = {}));\nclass PromiseResult {\n  constructor(promiseResultEventSource) {\n    this.throwIfError = () => {\n      if (this.isError) {\n        throw this.error;\n      }\n    };\n    promiseResultEventSource.on(result => {\n      if (!this.privIsCompleted) {\n        this.privIsCompleted = true;\n        this.privIsError = false;\n        this.privResult = result;\n      }\n    }, error => {\n      if (!this.privIsCompleted) {\n        this.privIsCompleted = true;\n        this.privIsError = true;\n        this.privError = error;\n      }\n    });\n  }\n  get isCompleted() {\n    return this.privIsCompleted;\n  }\n  get isError() {\n    return this.privIsError;\n  }\n  get error() {\n    return this.privError;\n  }\n  get result() {\n    return this.privResult;\n  }\n}\nclass PromiseResultEventSource {\n  constructor() {\n    this.setResult = result => {\n      this.privOnSetResult(result);\n    };\n    this.setError = error => {\n      this.privOnSetError(error);\n    };\n    this.on = (onSetResult, onSetError) => {\n      this.privOnSetResult = onSetResult;\n      this.privOnSetError = onSetError;\n    };\n  }\n}\nclass Deferred {\n  constructor() {\n    this.resolve = result => {\n      this.privResolve(result);\n      return this;\n    };\n    this.reject = error => {\n      this.privReject(error);\n      return this;\n    };\n    // eslint-disable-next-line @typescript-eslint/explicit-function-return-type\n    this.privPromise = new Promise((resolve, reject) => {\n      this.privResolve = resolve;\n      this.privReject = reject;\n    });\n  }\n  get promise() {\n    return this.privPromise;\n  }\n}\nclass Sink {\n  constructor() {\n    this.privState = PromiseState.None;\n    this.privPromiseResult = null;\n    this.privPromiseResultEvents = null;\n    this.privSuccessHandlers = [];\n    this.privErrorHandlers = [];\n    this.privPromiseResultEvents = new PromiseResultEventSource();\n    this.privPromiseResult = new PromiseResult(this.privPromiseResultEvents);\n  }\n  get state() {\n    return this.privState;\n  }\n  get result() {\n    return this.privPromiseResult;\n  }\n  resolve(result) {\n    if (this.privState !== PromiseState.None) {\n      throw new Error(\"'Cannot resolve a completed promise'\");\n    }\n    this.privState = PromiseState.Resolved;\n    this.privPromiseResultEvents.setResult(result);\n    for (let i = 0; i < this.privSuccessHandlers.length; i++) {\n      this.executeSuccessCallback(result, this.privSuccessHandlers[i], this.privErrorHandlers[i]);\n    }\n    this.detachHandlers();\n  }\n  reject(error) {\n    if (this.privState !== PromiseState.None) {\n      throw new Error(\"'Cannot reject a completed promise'\");\n    }\n    this.privState = PromiseState.Rejected;\n    this.privPromiseResultEvents.setError(error);\n    for (const errorHandler of this.privErrorHandlers) {\n      this.executeErrorCallback(error, errorHandler);\n    }\n    this.detachHandlers();\n  }\n  on(successCallback, errorCallback) {\n    if (successCallback == null) {\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n      successCallback = () => {};\n    }\n    if (this.privState === PromiseState.None) {\n      this.privSuccessHandlers.push(successCallback);\n      this.privErrorHandlers.push(errorCallback);\n    } else {\n      if (this.privState === PromiseState.Resolved) {\n        this.executeSuccessCallback(this.privPromiseResult.result, successCallback, errorCallback);\n      } else if (this.privState === PromiseState.Rejected) {\n        this.executeErrorCallback(this.privPromiseResult.error, errorCallback);\n      }\n      this.detachHandlers();\n    }\n  }\n  executeSuccessCallback(result, successCallback, errorCallback) {\n    try {\n      successCallback(result);\n    } catch (e) {\n      this.executeErrorCallback(`'Unhandled callback error: ${e}'`, errorCallback);\n    }\n  }\n  executeErrorCallback(error, errorCallback) {\n    if (errorCallback) {\n      try {\n        errorCallback(error);\n      } catch (e) {\n        throw new Error(`'Unhandled callback error: ${e}. InnerError: ${error}'`);\n      }\n    } else {\n      throw new Error(`'Unhandled error: ${error}'`);\n    }\n  }\n  detachHandlers() {\n    this.privErrorHandlers = [];\n    this.privSuccessHandlers = [];\n  }\n}\n// eslint-disable-next-line prefer-arrow/prefer-arrow-functions\nfunction marshalPromiseToCallbacks(promise, cb, err) {\n  promise.then(val => {\n    try {\n      if (!!cb) {\n        cb(val);\n      }\n    } catch (error) {\n      if (!!err) {\n        try {\n          if (error instanceof Error) {\n            const typedError = error;\n            err(typedError.name + \": \" + typedError.message);\n          } else {\n            err(error);\n          }\n          // eslint-disable-next-line no-empty\n        } catch (error) {}\n      }\n    }\n  }, error => {\n    if (!!err) {\n      try {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n        // eslint-disable-next-line no-empty\n      } catch (error) {}\n    }\n  });\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Queue\": () => (/* binding */ Queue)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _List__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./List */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/List.js\");\n/* harmony import */ var _Promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Promise */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\nvar SubscriberType;\n(function (SubscriberType) {\n  SubscriberType[SubscriberType[\"Dequeue\"] = 0] = \"Dequeue\";\n  SubscriberType[SubscriberType[\"Peek\"] = 1] = \"Peek\";\n})(SubscriberType || (SubscriberType = {}));\nclass Queue {\n  constructor(list) {\n    this.privPromiseStore = new _List__WEBPACK_IMPORTED_MODULE_0__.List();\n    this.privIsDrainInProgress = false;\n    this.privIsDisposing = false;\n    this.privDisposeReason = null;\n    this.privList = list ? list : new _List__WEBPACK_IMPORTED_MODULE_0__.List();\n    this.privDetachables = [];\n    this.privSubscribers = new _List__WEBPACK_IMPORTED_MODULE_0__.List();\n    this.privDetachables.push(this.privList.onAdded(() => this.drain()));\n  }\n  enqueue(item) {\n    this.throwIfDispose();\n    this.enqueueFromPromise(new Promise(resolve => resolve(item)));\n  }\n  enqueueFromPromise(promise) {\n    this.throwIfDispose();\n    promise.then(val => {\n      this.privList.add(val);\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n    }, () => {});\n  }\n  dequeue() {\n    this.throwIfDispose();\n    const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    if (this.privSubscribers) {\n      this.privSubscribers.add({\n        deferral: deferredSubscriber,\n        type: SubscriberType.Dequeue\n      });\n      this.drain();\n    }\n    return deferredSubscriber.promise;\n  }\n  peek() {\n    this.throwIfDispose();\n    const deferredSubscriber = new _Promise__WEBPACK_IMPORTED_MODULE_1__.Deferred();\n    const subs = this.privSubscribers;\n    if (subs) {\n      this.privSubscribers.add({\n        deferral: deferredSubscriber,\n        type: SubscriberType.Peek\n      });\n      this.drain();\n    }\n    return deferredSubscriber.promise;\n  }\n  length() {\n    this.throwIfDispose();\n    return this.privList.length();\n  }\n  isDisposed() {\n    return this.privSubscribers == null;\n  }\n  drainAndDispose(pendingItemProcessor, reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.isDisposed() && !this.privIsDisposing) {\n        this.privDisposeReason = reason;\n        this.privIsDisposing = true;\n        const subs = this.privSubscribers;\n        if (subs) {\n          while (subs.length() > 0) {\n            const subscriber = subs.removeFirst();\n            // TODO: this needs work (Resolve(null) instead?).\n            subscriber.deferral.resolve(undefined);\n            // subscriber.deferral.reject(\"Disposed\");\n          }\n          // note: this block assumes cooperative multitasking, i.e.,\n          // between the if-statement and the assignment there are no\n          // thread switches.\n          // Reason is that between the initial const = this.; and this\n          // point there is the derral.resolve() operation that might have\n          // caused recursive calls to the Queue, especially, calling\n          // Dispose() on the queue alredy (which would reset the var\n          // here to null!).\n          // That should generally hold true for javascript...\n          if (this.privSubscribers === subs) {\n            this.privSubscribers = subs;\n          }\n        }\n        for (const detachable of this.privDetachables) {\n          yield detachable.detach();\n        }\n        if (this.privPromiseStore.length() > 0 && pendingItemProcessor) {\n          const promiseArray = [];\n          this.privPromiseStore.toArray().forEach(wrapper => {\n            promiseArray.push(wrapper);\n          });\n          return Promise.all(promiseArray).finally(() => {\n            this.privSubscribers = null;\n            this.privList.forEach(item => {\n              pendingItemProcessor(item);\n            });\n            this.privList = null;\n            return;\n          }).then();\n        } else {\n          this.privSubscribers = null;\n          this.privList = null;\n        }\n      }\n    });\n  }\n  dispose(reason) {\n    return __awaiter(this, void 0, void 0, function* () {\n      yield this.drainAndDispose(null, reason);\n    });\n  }\n  drain() {\n    if (!this.privIsDrainInProgress && !this.privIsDisposing) {\n      this.privIsDrainInProgress = true;\n      const subs = this.privSubscribers;\n      const lists = this.privList;\n      if (subs && lists) {\n        while (lists.length() > 0 && subs.length() > 0 && !this.privIsDisposing) {\n          const subscriber = subs.removeFirst();\n          if (subscriber.type === SubscriberType.Peek) {\n            subscriber.deferral.resolve(lists.first());\n          } else {\n            const dequeuedItem = lists.removeFirst();\n            subscriber.deferral.resolve(dequeuedItem);\n          }\n        }\n        // note: this block assumes cooperative multitasking, i.e.,\n        // between the if-statement and the assignment there are no\n        // thread switches.\n        // Reason is that between the initial const = this.; and this\n        // point there is the derral.resolve() operation that might have\n        // caused recursive calls to the Queue, especially, calling\n        // Dispose() on the queue alredy (which would reset the var\n        // here to null!).\n        // That should generally hold true for javascript...\n        if (this.privSubscribers === subs) {\n          this.privSubscribers = subs;\n        }\n        // note: this block assumes cooperative multitasking, i.e.,\n        // between the if-statement and the assignment there are no\n        // thread switches.\n        // Reason is that between the initial const = this.; and this\n        // point there is the derral.resolve() operation that might have\n        // caused recursive calls to the Queue, especially, calling\n        // Dispose() on the queue alredy (which would reset the var\n        // here to null!).\n        // That should generally hold true for javascript...\n        if (this.privList === lists) {\n          this.privList = lists;\n        }\n      }\n      this.privIsDrainInProgress = false;\n    }\n  }\n  throwIfDispose() {\n    if (this.isDisposed()) {\n      if (this.privDisposeReason) {\n        throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(this.privDisposeReason);\n      }\n      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.ObjectDisposedError(\"Queue\");\n    } else if (this.privIsDisposing) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(\"Queue disposing\");\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RawWebsocketMessage\": () => (/* binding */ RawWebsocketMessage)\n/* harmony export */ });\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* eslint-disable @typescript-eslint/no-unsafe-assignment */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\nclass RawWebsocketMessage {\n  constructor(messageType, payload, id) {\n    this.privPayload = null;\n    if (!payload) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.ArgumentNullError(\"payload\");\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n    if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary && payload.__proto__.constructor.name !== \"ArrayBuffer\") {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be ArrayBuffer\");\n    }\n    if (messageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text && !(typeof payload === \"string\")) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Payload must be a string\");\n    }\n    this.privMessageType = messageType;\n    this.privPayload = payload;\n    this.privId = id ? id : (0,_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();\n  }\n  get messageType() {\n    return this.privMessageType;\n  }\n  get payload() {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n    return this.privPayload;\n  }\n  get textContent() {\n    if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Binary) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for binary message\");\n    }\n    return this.privPayload;\n  }\n  get binaryContent() {\n    if (this.privMessageType === _ConnectionMessage__WEBPACK_IMPORTED_MODULE_1__.MessageType.Text) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_0__.InvalidOperationError(\"Not supported for text message\");\n    }\n    return this.privPayload;\n  }\n  get id() {\n    return this.privId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RawWebsocketMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RiffPcmEncoder\": () => (/* binding */ RiffPcmEncoder)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass RiffPcmEncoder {\n  constructor(actualSampleRate, desiredSampleRate) {\n    this.privActualSampleRate = actualSampleRate;\n    this.privDesiredSampleRate = desiredSampleRate;\n  }\n  encode(actualAudioFrame) {\n    const audioFrame = this.downSampleAudioFrame(actualAudioFrame, this.privActualSampleRate, this.privDesiredSampleRate);\n    if (!audioFrame) {\n      return null;\n    }\n    const audioLength = audioFrame.length * 2;\n    const buffer = new ArrayBuffer(audioLength);\n    const view = new DataView(buffer);\n    this.floatTo16BitPCM(view, 0, audioFrame);\n    return buffer;\n  }\n  setString(view, offset, str) {\n    for (let i = 0; i < str.length; i++) {\n      view.setUint8(offset + i, str.charCodeAt(i));\n    }\n  }\n  floatTo16BitPCM(view, offset, input) {\n    for (let i = 0; i < input.length; i++, offset += 2) {\n      const s = Math.max(-1, Math.min(1, input[i]));\n      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);\n    }\n  }\n  downSampleAudioFrame(srcFrame, srcRate, dstRate) {\n    if (!srcFrame) {\n      return null;\n    }\n    if (dstRate === srcRate || dstRate > srcRate) {\n      return srcFrame;\n    }\n    const ratio = srcRate / dstRate;\n    const dstLength = Math.round(srcFrame.length / ratio);\n    const dstFrame = new Float32Array(dstLength);\n    let srcOffset = 0;\n    let dstOffset = 0;\n    while (dstOffset < dstLength) {\n      const nextSrcOffset = Math.round((dstOffset + 1) * ratio);\n      let accum = 0;\n      let count = 0;\n      while (srcOffset < nextSrcOffset && srcOffset < srcFrame.length) {\n        accum += srcFrame[srcOffset++];\n        count++;\n      }\n      dstFrame[dstOffset++] = accum / count;\n    }\n    return dstFrame;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/RiffPcmEncoder.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Stream\": () => (/* binding */ Stream)\n/* harmony export */ });\n/* harmony import */ var _Error__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Guid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _Queue__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Queue */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\nclass Stream {\n  constructor(streamId) {\n    this.privIsWriteEnded = false;\n    this.privIsReadEnded = false;\n    this.privId = streamId ? streamId : (0,_Guid__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_1__.Queue();\n  }\n  get isClosed() {\n    return this.privIsWriteEnded;\n  }\n  get isReadEnded() {\n    return this.privIsReadEnded;\n  }\n  get id() {\n    return this.privId;\n  }\n  close() {\n    if (!this.privIsWriteEnded) {\n      this.writeStreamChunk({\n        buffer: null,\n        isEnd: true,\n        timeReceived: Date.now()\n      });\n      this.privIsWriteEnded = true;\n    }\n  }\n  writeStreamChunk(streamChunk) {\n    this.throwIfClosed();\n    if (!this.privReaderQueue.isDisposed()) {\n      try {\n        this.privReaderQueue.enqueue(streamChunk);\n      } catch (e) {\n        // Do nothing\n      }\n    }\n  }\n  read() {\n    if (this.privIsReadEnded) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(\"Stream read has already finished\");\n    }\n    return this.privReaderQueue.dequeue().then(streamChunk => __awaiter(this, void 0, void 0, function* () {\n      if (streamChunk === undefined || streamChunk.isEnd) {\n        yield this.privReaderQueue.dispose(\"End of stream reached\");\n      }\n      return streamChunk;\n    }));\n  }\n  readEnded() {\n    if (!this.privIsReadEnded) {\n      this.privIsReadEnded = true;\n      this.privReaderQueue = new _Queue__WEBPACK_IMPORTED_MODULE_1__.Queue();\n    }\n  }\n  throwIfClosed() {\n    if (this.privIsWriteEnded) {\n      throw new _Error__WEBPACK_IMPORTED_MODULE_2__.InvalidOperationError(\"Stream closed\");\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Timeout\": () => (/* binding */ Timeout)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass Timeout {\n  static load() {\n    // Prefilling the Maps with a function indexed by zero is necessary to be compliant with the specification.\n    const scheduledTimeoutFunctions = new Map([[0, () => {}]]); // eslint-disable-line @typescript-eslint/no-empty-function\n    const unhandledRequests = new Map();\n    // eslint-disable-next-line\n    const workerScript = `!function(e){var t={};function n(r){if(t[r])return t[r].exports;var o=t[r]={i:r,l:!1,exports:{}};return e[r].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=e,n.c=t,n.d=function(e,t,r){n.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:r})},n.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},n.t=function(e,t){if(1&t&&(e=n(e)),8&t)return e;if(4&t&&\"object\"==typeof e&&e&&e.__esModule)return e;var r=Object.create(null);if(n.r(r),Object.defineProperty(r,\"default\",{enumerable:!0,value:e}),2&t&&\"string\"!=typeof e)for(var o in e)n.d(r,o,function(t){return e[t]}.bind(null,o));return r},n.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return n.d(t,\"a\",t),t},n.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},n.p=\"\",n(n.s=14)}([function(e,t,n){\"use strict\";n.d(t,\"a\",(function(){return i})),n.d(t,\"b\",(function(){return u})),n.d(t,\"c\",(function(){return a})),n.d(t,\"d\",(function(){return d}));const r=new Map,o=new Map,i=e=>{const t=r.get(e);if(void 0===t)throw new Error('There is no interval scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),r.delete(e)},u=e=>{const t=o.get(e);if(void 0===t)throw new Error('There is no timeout scheduled with the given id \"'.concat(e,'\".'));clearTimeout(t),o.delete(e)},f=(e,t)=>{let n,r;if(\"performance\"in self){const o=performance.now();n=o,r=e-Math.max(0,o-t)}else n=Date.now(),r=e;return{expected:n+r,remainingDelay:r}},c=(e,t,n,r)=>{const o=\"performance\"in self?performance.now():Date.now();o>n?postMessage({id:null,method:\"call\",params:{timerId:t}}):e.set(t,setTimeout(c,n-o,e,t,n))},a=(e,t,n)=>{const{expected:o,remainingDelay:i}=f(e,n);r.set(t,setTimeout(c,i,r,t,o))},d=(e,t,n)=>{const{expected:r,remainingDelay:i}=f(e,n);o.set(t,setTimeout(c,i,o,t,r))}},function(e,t,n){\"use strict\";n.r(t);var r=n(2);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(3);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(4);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o);var f=n(5);for(var o in f)\"default\"!==o&&function(e){n.d(t,e,(function(){return f[e]}))}(o);var c=n(6);for(var o in c)\"default\"!==o&&function(e){n.d(t,e,(function(){return c[e]}))}(o);var a=n(7);for(var o in a)\"default\"!==o&&function(e){n.d(t,e,(function(){return a[e]}))}(o);var d=n(8);for(var o in d)\"default\"!==o&&function(e){n.d(t,e,(function(){return d[e]}))}(o);var s=n(9);for(var o in s)\"default\"!==o&&function(e){n.d(t,e,(function(){return s[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(11);for(var o in r)\"default\"!==o&&function(e){n.d(t,e,(function(){return r[e]}))}(o);var i=n(12);for(var o in i)\"default\"!==o&&function(e){n.d(t,e,(function(){return i[e]}))}(o);var u=n(13);for(var o in u)\"default\"!==o&&function(e){n.d(t,e,(function(){return u[e]}))}(o)},function(e,t){},function(e,t){},function(e,t){},function(e,t,n){\"use strict\";n.r(t);var r=n(0),o=n(1);for(var i in o)\"default\"!==i&&function(e){n.d(t,e,(function(){return o[e]}))}(i);var u=n(10);for(var i in u)\"default\"!==i&&function(e){n.d(t,e,(function(){return u[e]}))}(i);addEventListener(\"message\",({data:e})=>{try{if(\"clear\"===e.method){const{id:t,params:{timerId:n}}=e;Object(r.b)(n),postMessage({error:null,id:t})}else{if(\"set\"!==e.method)throw new Error('The given method \"'.concat(e.method,'\" is not supported'));{const{params:{delay:t,now:n,timerId:o}}=e;Object(r.d)(t,o,n)}}}catch(t){postMessage({error:{message:t.message},id:e.id,result:null})}})}]);`;\n    const workerUrl = \"data:text/javascript;base64,\" + btoa(workerScript);\n    const worker = new Worker(workerUrl);\n    worker.addEventListener(\"message\", _ref => {\n      let {\n        data\n      } = _ref;\n      if (Timeout.isCallNotification(data)) {\n        const {\n          params: {\n            timerId\n          }\n        } = data;\n        const idOrFunc = scheduledTimeoutFunctions.get(timerId);\n        if (typeof idOrFunc === \"number\") {\n          const unhandledTimerId = unhandledRequests.get(idOrFunc);\n          if (unhandledTimerId === undefined || unhandledTimerId !== timerId) {\n            throw new Error(\"The timer is in an undefined state.\");\n          }\n        } else if (typeof idOrFunc !== \"undefined\") {\n          idOrFunc();\n          // A timeout can be safely deleted because it is only called once.\n          scheduledTimeoutFunctions.delete(timerId);\n        } else {\n          throw new Error(\"The timer is in an undefined state.\");\n        }\n      } else if (Timeout.isClearResponse(data)) {\n        const {\n          id\n        } = data;\n        const unhandledTimerId = unhandledRequests.get(id);\n        if (unhandledTimerId === undefined) {\n          throw new Error(\"The timer is in an undefined state.\");\n        }\n        unhandledRequests.delete(id);\n        scheduledTimeoutFunctions.delete(unhandledTimerId);\n      } else {\n        const {\n          error: {\n            message\n          }\n        } = data;\n        throw new Error(message);\n      }\n    });\n    const clearTimeout = timerId => {\n      const id = Math.random();\n      unhandledRequests.set(id, timerId);\n      scheduledTimeoutFunctions.set(timerId, id);\n      worker.postMessage({\n        id,\n        method: \"clear\",\n        params: {\n          timerId\n        }\n      });\n    };\n    const setTimeout = (func, delay) => {\n      const timerId = Math.random();\n      scheduledTimeoutFunctions.set(timerId, func);\n      worker.postMessage({\n        id: null,\n        method: \"set\",\n        params: {\n          delay,\n          now: performance.now(),\n          timerId\n        }\n      });\n      return timerId;\n    };\n    return {\n      clearTimeout,\n      setTimeout\n    };\n  }\n  static loadWorkerTimers() {\n    return () => {\n      if (Timeout.workerTimers !== null) {\n        return Timeout.workerTimers;\n      }\n      Timeout.workerTimers = Timeout.load();\n      return Timeout.workerTimers;\n    };\n  }\n  static isCallNotification(message) {\n    return message.method !== undefined && message.method === \"call\";\n  }\n  static isClearResponse(message) {\n    return message.error === null && typeof message.id === \"number\";\n  }\n}\nTimeout.workerTimers = null;\nTimeout.clearTimeout = timerId => Timeout.timers().clearTimeout(timerId);\nTimeout.setTimeout = (func, delay) => Timeout.timers().setTimeout(func, delay);\nTimeout.timers = Timeout.loadWorkerTimers();\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Timeout.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ActivityReceivedEventArgs\": () => (/* binding */ ActivityReceivedEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of received message/events.\n * @class ActivityReceivedEventArgs\n */\nclass ActivityReceivedEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {any} activity - The activity..\n   */\n  constructor(activity, audioStream) {\n    this.privActivity = activity;\n    this.privAudioStream = audioStream;\n  }\n  /**\n   * Gets the received activity\n   * @member ActivityReceivedEventArgs.prototype.activity\n   * @function\n   * @public\n   * @returns {any} the received activity.\n   */\n  get activity() {\n    return this.privActivity;\n  }\n  get audioStream() {\n    return this.privAudioStream;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioConfig\": () => (/* binding */ AudioConfig),\n/* harmony export */   \"AudioConfigImpl\": () => (/* binding */ AudioConfigImpl),\n/* harmony export */   \"AudioOutputConfigImpl\": () => (/* binding */ AudioOutputConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/PCMRecorder.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/MicAudioSource.js\");\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/FileAudioSource.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js\");\n/* harmony import */ var _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./AudioInputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js\");\n/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _AudioFileWriter__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./AudioFileWriter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n/**\n * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).\n * @class AudioConfig\n * Updated in version 1.11.0\n */\nclass AudioConfig {\n  /**\n   * Creates an AudioConfig object representing the default microphone on the system.\n   * @member AudioConfig.fromDefaultMicrophoneInput\n   * @function\n   * @public\n   * @returns {AudioConfig} The audio input configuration being created.\n   */\n  static fromDefaultMicrophoneInput() {\n    const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(true);\n    return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder));\n  }\n  /**\n   * Creates an AudioConfig object representing a microphone with the specified device ID.\n   * @member AudioConfig.fromMicrophoneInput\n   * @function\n   * @public\n   * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.\n   * Default microphone is used the value is omitted.\n   * @returns {AudioConfig} The audio input configuration being created.\n   */\n  static fromMicrophoneInput(deviceId) {\n    const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(true);\n    return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder, deviceId));\n  }\n  /**\n   * Creates an AudioConfig object representing the specified file.\n   * @member AudioConfig.fromWavFileInput\n   * @function\n   * @public\n   * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM is supported.\n   * @returns {AudioConfig} The audio input configuration being created.\n   */\n  static fromWavFileInput(file) {\n    let name = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : \"unnamedBuffer.wav\";\n    return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_2__.FileAudioSource(file, name));\n  }\n  /**\n   * Creates an AudioConfig object representing the specified stream.\n   * @member AudioConfig.fromStreamInput\n   * @function\n   * @public\n   * @param {AudioInputStream | PullAudioInputStreamCallback | MediaStream} audioStream - Specifies the custom audio input\n   * stream. Currently, only WAV / PCM is supported.\n   * @returns {AudioConfig} The audio input configuration being created.\n   */\n  static fromStreamInput(audioStream) {\n    if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__.PullAudioInputStreamCallback) {\n      return new AudioConfigImpl(new _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__.PullAudioInputStreamImpl(audioStream));\n    }\n    if (audioStream instanceof _AudioInputStream__WEBPACK_IMPORTED_MODULE_4__.AudioInputStream) {\n      return new AudioConfigImpl(audioStream);\n    }\n    if (typeof MediaStream !== \"undefined\" && audioStream instanceof MediaStream) {\n      const pcmRecorder = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.PcmRecorder(false);\n      return new AudioConfigImpl(new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_1__.MicAudioSource(pcmRecorder, null, null, audioStream));\n    }\n    throw new Error(\"Not Supported Type\");\n  }\n  /**\n   * Creates an AudioConfig object representing the default speaker.\n   * @member AudioConfig.fromDefaultSpeakerOutput\n   * @function\n   * @public\n   * @returns {AudioConfig} The audio output configuration being created.\n   * Added in version 1.11.0\n   */\n  static fromDefaultSpeakerOutput() {\n    return new AudioOutputConfigImpl(new _Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerAudioDestination());\n  }\n  /**\n   * Creates an AudioConfig object representing the custom IPlayer object.\n   * You can use the IPlayer object to control pause, resume, etc.\n   * @member AudioConfig.fromSpeakerOutput\n   * @function\n   * @public\n   * @param {IPlayer} player - the IPlayer object for playback.\n   * @returns {AudioConfig} The audio output configuration being created.\n   * Added in version 1.12.0\n   */\n  static fromSpeakerOutput(player) {\n    if (player === undefined) {\n      return AudioConfig.fromDefaultSpeakerOutput();\n    }\n    if (player instanceof _Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerAudioDestination) {\n      return new AudioOutputConfigImpl(player);\n    }\n    throw new Error(\"Not Supported Type\");\n  }\n  /**\n   * Creates an AudioConfig object representing a specified output audio file\n   * @member AudioConfig.fromAudioFileOutput\n   * @function\n   * @public\n   * @param {PathLike} filename - the filename of the output audio file\n   * @returns {AudioConfig} The audio output configuration being created.\n   * Added in version 1.11.0\n   */\n  static fromAudioFileOutput(filename) {\n    return new AudioOutputConfigImpl(new _AudioFileWriter__WEBPACK_IMPORTED_MODULE_6__.AudioFileWriter(filename));\n  }\n  /**\n   * Creates an AudioConfig object representing a specified audio output stream\n   * @member AudioConfig.fromStreamOutput\n   * @function\n   * @public\n   * @param {AudioOutputStream | PushAudioOutputStreamCallback} audioStream - Specifies the custom audio output\n   * stream.\n   * @returns {AudioConfig} The audio output configuration being created.\n   * Added in version 1.11.0\n   */\n  static fromStreamOutput(audioStream) {\n    if (audioStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_7__.PushAudioOutputStreamCallback) {\n      return new AudioOutputConfigImpl(new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PushAudioOutputStreamImpl(audioStream));\n    }\n    if (audioStream instanceof _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PushAudioOutputStream) {\n      return new AudioOutputConfigImpl(audioStream);\n    }\n    if (audioStream instanceof _AudioOutputStream__WEBPACK_IMPORTED_MODULE_8__.PullAudioOutputStream) {\n      return new AudioOutputConfigImpl(audioStream);\n    }\n    throw new Error(\"Not Supported Type\");\n  }\n}\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class AudioConfigImpl\n */\nclass AudioConfigImpl extends AudioConfig {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {IAudioSource} source - An audio source.\n   */\n  constructor(source) {\n    super();\n    this.privSource = source;\n  }\n  /**\n   * Format information for the audio\n   */\n  get format() {\n    return this.privSource.format;\n  }\n  /**\n   * @member AudioConfigImpl.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, err) {\n    this.privSource.turnOff().then(() => {\n      if (!!cb) {\n        cb();\n      }\n    }, error => {\n      if (!!err) {\n        err(error);\n      }\n    });\n  }\n  /**\n   * @member AudioConfigImpl.prototype.id\n   * @function\n   * @public\n   */\n  id() {\n    return this.privSource.id();\n  }\n  /**\n   * @member AudioConfigImpl.prototype.blob\n   * @function\n   * @public\n   */\n  get blob() {\n    return this.privSource.blob;\n  }\n  /**\n   * @member AudioConfigImpl.prototype.turnOn\n   * @function\n   * @public\n   * @returns {Promise<void>} A promise.\n   */\n  turnOn() {\n    return this.privSource.turnOn();\n  }\n  /**\n   * @member AudioConfigImpl.prototype.attach\n   * @function\n   * @public\n   * @param {string} audioNodeId - The audio node id.\n   * @returns {Promise<IAudioStreamNode>} A promise.\n   */\n  attach(audioNodeId) {\n    return this.privSource.attach(audioNodeId);\n  }\n  /**\n   * @member AudioConfigImpl.prototype.detach\n   * @function\n   * @public\n   * @param {string} audioNodeId - The audio node id.\n   */\n  detach(audioNodeId) {\n    return this.privSource.detach(audioNodeId);\n  }\n  /**\n   * @member AudioConfigImpl.prototype.turnOff\n   * @function\n   * @public\n   * @returns {Promise<void>} A promise.\n   */\n  turnOff() {\n    return this.privSource.turnOff();\n  }\n  /**\n   * @member AudioConfigImpl.prototype.events\n   * @function\n   * @public\n   * @returns {EventSource<AudioSourceEvent>} An event source for audio events.\n   */\n  get events() {\n    return this.privSource.events;\n  }\n  setProperty(name, value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_9__.Contracts.throwIfNull(value, \"value\");\n    if (undefined !== this.privSource.setProperty) {\n      this.privSource.setProperty(name, value);\n    } else {\n      throw new Error(\"This AudioConfig instance does not support setting properties.\");\n    }\n  }\n  getProperty(name, def) {\n    if (undefined !== this.privSource.getProperty) {\n      return this.privSource.getProperty(name, def);\n    } else {\n      throw new Error(\"This AudioConfig instance does not support getting properties.\");\n    }\n    return def;\n  }\n  get deviceInfo() {\n    return this.privSource.deviceInfo;\n  }\n}\nclass AudioOutputConfigImpl extends AudioConfig {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {IAudioDestination} destination - An audio destination.\n   */\n  constructor(destination) {\n    super();\n    this.privDestination = destination;\n  }\n  set format(format) {\n    this.privDestination.format = format;\n  }\n  write(buffer) {\n    this.privDestination.write(buffer);\n  }\n  close() {\n    this.privDestination.close();\n  }\n  id() {\n    return this.privDestination.id();\n  }\n  setProperty() {\n    throw new Error(\"This AudioConfig instance does not support setting properties.\");\n  }\n  getProperty() {\n    throw new Error(\"This AudioConfig instance does not support getting properties.\");\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioFileWriter\": () => (/* binding */ AudioFileWriter)\n/* harmony export */ });\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! fs */ \"?9463\");\n/* harmony import */ var fs__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(fs__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\nclass AudioFileWriter {\n  constructor(filename) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(fs__WEBPACK_IMPORTED_MODULE_0__.openSync, \"\\nFile System access not available, please use Push or PullAudioOutputStream\");\n    this.privFd = fs__WEBPACK_IMPORTED_MODULE_0__.openSync(filename, \"w\");\n  }\n  set format(format) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNotUndefined(this.privAudioFormat, \"format is already set\");\n    this.privAudioFormat = format;\n    let headerOffset = 0;\n    if (this.privAudioFormat.hasHeader) {\n      headerOffset = this.privAudioFormat.header.byteLength;\n    }\n    if (this.privFd !== undefined) {\n      this.privWriteStream = fs__WEBPACK_IMPORTED_MODULE_0__.createWriteStream(\"\", {\n        fd: this.privFd,\n        start: headerOffset,\n        autoClose: false\n      });\n    }\n  }\n  write(buffer) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privAudioFormat, \"must set format before writing.\");\n    if (this.privWriteStream !== undefined) {\n      this.privWriteStream.write(new Uint8Array(buffer.slice(0)));\n    }\n  }\n  close() {\n    if (this.privFd !== undefined) {\n      this.privWriteStream.on(\"finish\", () => {\n        if (this.privAudioFormat.hasHeader) {\n          this.privAudioFormat.updateHeader(this.privWriteStream.bytesWritten);\n          fs__WEBPACK_IMPORTED_MODULE_0__.writeSync(this.privFd, new Int8Array(this.privAudioFormat.header), 0, this.privAudioFormat.header.byteLength, 0);\n        }\n        fs__WEBPACK_IMPORTED_MODULE_0__.closeSync(this.privFd);\n        this.privFd = undefined;\n      });\n      this.privWriteStream.end();\n    }\n  }\n  id() {\n    return this.privId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioInputStream\": () => (/* binding */ AudioInputStream),\n/* harmony export */   \"PullAudioInputStream\": () => (/* binding */ PullAudioInputStream),\n/* harmony export */   \"PullAudioInputStreamImpl\": () => (/* binding */ PullAudioInputStreamImpl),\n/* harmony export */   \"PushAudioInputStream\": () => (/* binding */ PushAudioInputStream),\n/* harmony export */   \"PushAudioInputStreamImpl\": () => (/* binding */ PushAudioInputStreamImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/EventSource.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ChunkedArrayBufferStream.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/AudioSourceEvents.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Guid__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common/Guid */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @class AudioInputStream\n */\nclass AudioInputStream {\n  /**\n   * Creates and initializes an instance.\n   * @constructor\n   */\n  constructor() {\n    return;\n  }\n  /**\n   * Creates a memory backed PushAudioInputStream with the specified audio format.\n   * @member AudioInputStream.createPushStream\n   * @function\n   * @public\n   * @param {AudioStreamFormat} format - The audio data format in which audio will be\n   * written to the push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n   * @returns {PushAudioInputStream} The audio input stream being created.\n   */\n  static createPushStream(format) {\n    return PushAudioInputStream.create(format);\n  }\n  /**\n   * Creates a PullAudioInputStream that delegates to the specified callback interface for read()\n   * and close() methods.\n   * @member AudioInputStream.createPullStream\n   * @function\n   * @public\n   * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from\n   * PullAudioInputStreamCallback\n   * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from\n   * the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n   * @returns {PullAudioInputStream} The audio input stream being created.\n   */\n  static createPullStream(callback, format) {\n    return PullAudioInputStream.create(callback, format);\n    // throw new Error(\"Oops\");\n  }\n}\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @class PushAudioInputStream\n */\nclass PushAudioInputStream extends AudioInputStream {\n  /**\n   * Creates a memory backed PushAudioInputStream with the specified audio format.\n   * @member PushAudioInputStream.create\n   * @function\n   * @public\n   * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the\n   * push audio stream's write() method (Required if format is not 16 kHz 16bit mono PCM).\n   * @returns {PushAudioInputStream} The push audio input stream being created.\n   */\n  static create(format) {\n    return new PushAudioInputStreamImpl(format);\n  }\n}\n/**\n * Represents memory backed push audio input stream used for custom audio input configurations.\n * @private\n * @class PushAudioInputStreamImpl\n */\nclass PushAudioInputStreamImpl extends PushAudioInputStream {\n  /**\n   * Creates and initalizes an instance with the given values.\n   * @constructor\n   * @param {AudioStreamFormat} format - The audio stream format.\n   */\n  constructor(format) {\n    super();\n    if (format === undefined) {\n      this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl.getDefaultInputFormat();\n    } else {\n      this.privFormat = format;\n    }\n    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n    this.privId = (0,_common_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();\n    this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.ChunkedArrayBufferStream(this.privFormat.avgBytesPerSec / 10);\n  }\n  /**\n   * Format information for the audio\n   */\n  get format() {\n    return Promise.resolve(this.privFormat);\n  }\n  /**\n   * Writes the audio data specified by making an internal copy of the data.\n   * @member PushAudioInputStreamImpl.prototype.write\n   * @function\n   * @public\n   * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n   */\n  write(dataBuffer) {\n    this.privStream.writeStreamChunk({\n      buffer: dataBuffer,\n      isEnd: false,\n      timeReceived: Date.now()\n    });\n  }\n  /**\n   * Closes the stream.\n   * @member PushAudioInputStreamImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    this.privStream.close();\n  }\n  id() {\n    return this.privId;\n  }\n  get blob() {\n    return this.attach(\"id\").then(audioNode => {\n      const data = [];\n      let bufferData = Buffer.from(\"\");\n      const readCycle = () => audioNode.read().then(audioStreamChunk => {\n        if (!audioStreamChunk || audioStreamChunk.isEnd) {\n          if (typeof XMLHttpRequest !== \"undefined\" && typeof Blob !== \"undefined\") {\n            return Promise.resolve(new Blob(data));\n          } else {\n            return Promise.resolve(Buffer.from(bufferData));\n          }\n        } else {\n          if (typeof Blob !== \"undefined\") {\n            data.push(audioStreamChunk.buffer);\n          } else {\n            bufferData = Buffer.concat([bufferData, this.toBuffer(audioStreamChunk.buffer)]);\n          }\n          return readCycle();\n        }\n      });\n      return readCycle();\n    });\n  }\n  turnOn() {\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceInitializingEvent(this.privId)); // no stream id\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceReadyEvent(this.privId));\n    return;\n  }\n  attach(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n      yield this.turnOn();\n      const stream = this.privStream;\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n      return {\n        detach: () => __awaiter(this, void 0, void 0, function* () {\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n          return this.turnOff();\n        }),\n        id: () => audioNodeId,\n        read: () => stream.read()\n      };\n    });\n  }\n  detach(audioNodeId) {\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n  }\n  turnOff() {\n    return;\n  }\n  get events() {\n    return this.privEvents;\n  }\n  get deviceInfo() {\n    return Promise.resolve({\n      bitspersample: this.privFormat.bitsPerSample,\n      channelcount: this.privFormat.channels,\n      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.connectivity.Unknown,\n      manufacturer: \"Speech SDK\",\n      model: \"PushStream\",\n      samplerate: this.privFormat.samplesPerSec,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.type.Stream\n    });\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);\n  }\n  toBuffer(arrayBuffer) {\n    const buf = Buffer.alloc(arrayBuffer.byteLength);\n    const view = new Uint8Array(arrayBuffer);\n    for (let i = 0; i < buf.length; ++i) {\n      buf[i] = view[i];\n    }\n    return buf;\n  }\n}\n/*\n * Represents audio input stream used for custom audio input configurations.\n * @class PullAudioInputStream\n */\nclass PullAudioInputStream extends AudioInputStream {\n  /**\n   * Creates and initializes and instance.\n   * @constructor\n   */\n  constructor() {\n    super();\n  }\n  /**\n   * Creates a PullAudioInputStream that delegates to the specified callback interface for\n   * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n   * @member PullAudioInputStream.create\n   * @function\n   * @public\n   * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n   * derived from PullAudioInputStreamCustomCallback\n   * @param {AudioStreamFormat} format - The audio data format in which audio will be\n   * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n   * @returns {PullAudioInputStream} The push audio input stream being created.\n   */\n  static create(callback, format) {\n    return new PullAudioInputStreamImpl(callback, format);\n  }\n}\n/**\n * Represents audio input stream used for custom audio input configurations.\n * @private\n * @class PullAudioInputStreamImpl\n */\nclass PullAudioInputStreamImpl extends PullAudioInputStream {\n  /**\n   * Creates a PullAudioInputStream that delegates to the specified callback interface for\n   * read() and close() methods, using the default format (16 kHz 16bit mono PCM).\n   * @constructor\n   * @param {PullAudioInputStreamCallback} callback - The custom audio input object,\n   * derived from PullAudioInputStreamCustomCallback\n   * @param {AudioStreamFormat} format - The audio data format in which audio will be\n   * returned from the callback's read() method (Required if format is not 16 kHz 16bit mono PCM).\n   */\n  constructor(callback, format) {\n    super();\n    if (undefined === format) {\n      this.privFormat = _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormat.getDefaultInputFormat();\n    } else {\n      this.privFormat = format;\n    }\n    this.privEvents = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.EventSource();\n    this.privId = (0,_common_Guid__WEBPACK_IMPORTED_MODULE_2__.createNoDashGuid)();\n    this.privCallback = callback;\n    this.privIsClosed = false;\n    this.privBufferSize = this.privFormat.avgBytesPerSec / 10;\n  }\n  /**\n   * Format information for the audio\n   */\n  get format() {\n    return Promise.resolve(this.privFormat);\n  }\n  /**\n   * Closes the stream.\n   * @member PullAudioInputStreamImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    this.privIsClosed = true;\n    this.privCallback.close();\n  }\n  id() {\n    return this.privId;\n  }\n  get blob() {\n    return Promise.reject(\"Not implemented\");\n  }\n  turnOn() {\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceInitializingEvent(this.privId)); // no stream id\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioSourceReadyEvent(this.privId));\n    return;\n  }\n  attach(audioNodeId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachingEvent(this.privId, audioNodeId));\n      yield this.turnOn();\n      this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeAttachedEvent(this.privId, audioNodeId));\n      return {\n        detach: () => {\n          this.privCallback.close();\n          this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n          return this.turnOff();\n        },\n        id: () => audioNodeId,\n        read: () => {\n          let totalBytes = 0;\n          let transmitBuff;\n          // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n          while (totalBytes < this.privBufferSize) {\n            // Sizing the read buffer to the delta between the perfect size and what's left means we won't ever get too much\n            // data back.\n            const readBuff = new ArrayBuffer(this.privBufferSize - totalBytes);\n            const pulledBytes = this.privCallback.read(readBuff);\n            // If there is no return buffer yet defined, set the return buffer to the that was just populated.\n            // This was, if we have enough data there's no copy penalty, but if we don't we have a buffer that's the\n            // preferred size allocated.\n            if (undefined === transmitBuff) {\n              transmitBuff = readBuff;\n            } else {\n              // Not the first bite at the apple, so fill the return buffer with the data we got back.\n              const intView = new Int8Array(transmitBuff);\n              intView.set(new Int8Array(readBuff), totalBytes);\n            }\n            // If there are no bytes to read, just break out and be done.\n            if (0 === pulledBytes) {\n              break;\n            }\n            totalBytes += pulledBytes;\n          }\n          return Promise.resolve({\n            buffer: transmitBuff.slice(0, totalBytes),\n            isEnd: this.privIsClosed || totalBytes === 0,\n            timeReceived: Date.now()\n          });\n        }\n      };\n    });\n  }\n  detach(audioNodeId) {\n    this.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.AudioStreamNodeDetachedEvent(this.privId, audioNodeId));\n  }\n  turnOff() {\n    return;\n  }\n  get events() {\n    return this.privEvents;\n  }\n  get deviceInfo() {\n    return Promise.resolve({\n      bitspersample: this.privFormat.bitsPerSample,\n      channelcount: this.privFormat.channels,\n      connectivity: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.connectivity.Unknown,\n      manufacturer: \"Speech SDK\",\n      model: \"PullStream\",\n      samplerate: this.privFormat.samplesPerSec,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.type.Stream\n    });\n  }\n  onEvent(event) {\n    this.privEvents.onEvent(event);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_6__.Events.instance.onEvent(event);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioOutputFormatImpl\": () => (/* binding */ AudioOutputFormatImpl)\n/* harmony export */ });\n/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../SpeechSynthesisOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * @private\n * @class AudioOutputFormatImpl\n * Updated in version 1.17.0\n */\n// eslint-disable-next-line max-classes-per-file\nclass AudioOutputFormatImpl extends _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl {\n  /**\n   * Creates an instance with the given values.\n   * @constructor\n   * @param formatTag\n   * @param {number} channels - Number of channels.\n   * @param {number} samplesPerSec - Samples per second.\n   * @param {number} avgBytesPerSec - Average bytes per second.\n   * @param {number} blockAlign - Block alignment.\n   * @param {number} bitsPerSample - Bits per sample.\n   * @param {string} audioFormatString - Audio format string\n   * @param {string} requestAudioFormatString - Audio format string sent to service.\n   * @param {boolean} hasHeader - If the format has header or not.\n   */\n  constructor(formatTag, channels, samplesPerSec, avgBytesPerSec, blockAlign, bitsPerSample, audioFormatString, requestAudioFormatString, hasHeader) {\n    super(samplesPerSec, bitsPerSample, channels, formatTag);\n    this.formatTag = formatTag;\n    this.avgBytesPerSec = avgBytesPerSec;\n    this.blockAlign = blockAlign;\n    this.priAudioFormatString = audioFormatString;\n    this.priRequestAudioFormatString = requestAudioFormatString;\n    this.priHasHeader = hasHeader;\n  }\n  static fromSpeechSynthesisOutputFormat(speechSynthesisOutputFormat) {\n    if (speechSynthesisOutputFormat === undefined) {\n      return AudioOutputFormatImpl.getDefaultOutputFormat();\n    }\n    return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(AudioOutputFormatImpl.SpeechSynthesisOutputFormatToString[speechSynthesisOutputFormat]);\n  }\n  static fromSpeechSynthesisOutputFormatString(speechSynthesisOutputFormatString) {\n    switch (speechSynthesisOutputFormatString) {\n      case \"raw-8khz-8bit-mono-mulaw\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"riff-16khz-16kbps-mono-siren\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, \"audio-16khz-16kbps-mono-siren\", true);\n      case \"audio-16khz-16kbps-mono-siren\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.Siren, 1, 16000, 2000, 40, 0, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-16khz-32kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 32 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-16khz-128kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 128 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-16khz-64kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 16000, 64 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-24khz-48kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 48 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-24khz-96kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-24khz-160kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 24000, 160 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"raw-16khz-16bit-mono-truesilk\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.SILKSkype, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"riff-8khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", true);\n      case \"riff-24khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", true);\n      case \"riff-8khz-8bit-mono-mulaw\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-mulaw\", true);\n      case \"raw-16khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, speechSynthesisOutputFormatString, \"raw-16khz-16bit-mono-pcm\", false);\n      case \"raw-24khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, \"raw-24khz-16bit-mono-pcm\", false);\n      case \"raw-8khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 8000, 16000, 2, 16, speechSynthesisOutputFormatString, \"raw-8khz-16bit-mono-pcm\", false);\n      case \"ogg-16khz-16bit-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 16000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"ogg-24khz-16bit-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 24000, 8192, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"raw-48khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", false);\n      case \"riff-48khz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 48000, 96000, 2, 16, speechSynthesisOutputFormatString, \"raw-48khz-16bit-mono-pcm\", true);\n      case \"audio-48khz-96kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 48000, 96 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-48khz-192kbitrate-mono-mp3\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3, 1, 48000, 192 << 7, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"ogg-48khz-16bit-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS, 1, 48000, 12000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"webm-16khz-16bit-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"webm-24khz-16bit-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"webm-24khz-16bit-24kbps-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-16khz-16bit-32kbps-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 16000, 4000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-24khz-16bit-48kbps-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 24000, 6000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-24khz-16bit-24kbps-mono-opus\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OPUS, 1, 24000, 3000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-24khz-16bit-mono-flac\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC, 1, 24000, 24000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"audio-48khz-16bit-mono-flac\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC, 1, 48000, 30000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"raw-24khz-16bit-mono-truesilk\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.SILKSkype, 1, 24000, 48000, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"raw-8khz-8bit-mono-alaw\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"riff-8khz-8bit-mono-alaw\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw, 1, 8000, 8000, 1, 8, speechSynthesisOutputFormatString, \"raw-8khz-8bit-mono-alaw\", true);\n      case \"raw-22050hz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"riff-22050hz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 22050, 44100, 2, 16, speechSynthesisOutputFormatString, \"raw-22050hz-16bit-mono-pcm\", true);\n      case \"raw-44100hz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, speechSynthesisOutputFormatString, false);\n      case \"riff-44100hz-16bit-mono-pcm\":\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 44100, 88200, 2, 16, speechSynthesisOutputFormatString, \"raw-44100hz-16bit-mono-pcm\", true);\n      case \"riff-16khz-16bit-mono-pcm\":\n      default:\n        return new AudioOutputFormatImpl(_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM, 1, 16000, 32000, 2, 16, \"riff-16khz-16bit-mono-pcm\", \"raw-16khz-16bit-mono-pcm\", true);\n    }\n  }\n  static getDefaultOutputFormat() {\n    return AudioOutputFormatImpl.fromSpeechSynthesisOutputFormatString(typeof window !== \"undefined\" ? \"audio-24khz-48kbitrate-mono-mp3\" : \"riff-16khz-16bit-mono-pcm\");\n  }\n  /**\n   * Specifies if this audio output format has a header\n   * @boolean AudioOutputFormatImpl.prototype.hasHeader\n   * @function\n   * @public\n   */\n  get hasHeader() {\n    return this.priHasHeader;\n  }\n  /**\n   * Specifies the header of this format\n   * @ArrayBuffer AudioOutputFormatImpl.prototype.header\n   * @function\n   * @public\n   */\n  get header() {\n    if (this.hasHeader) {\n      return this.privHeader;\n    }\n    return undefined;\n  }\n  /**\n   * Updates the header based on the audio length\n   * @member AudioOutputFormatImpl.updateHeader\n   * @function\n   * @public\n   * @param {number} audioLength - the audio length\n   */\n  updateHeader(audioLength) {\n    if (this.priHasHeader) {\n      const view = new DataView(this.privHeader);\n      view.setUint32(4, audioLength + this.privHeader.byteLength - 8, true);\n      view.setUint32(40, audioLength, true);\n    }\n  }\n  /**\n   * Specifies the audio format string to be sent to the service\n   * @string AudioOutputFormatImpl.prototype.requestAudioFormatString\n   * @function\n   * @public\n   */\n  get requestAudioFormatString() {\n    return this.priRequestAudioFormatString;\n  }\n}\nAudioOutputFormatImpl.SpeechSynthesisOutputFormatToString = {\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw]: \"raw-8khz-8bit-mono-mulaw\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren]: \"riff-16khz-16kbps-mono-siren\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren]: \"audio-16khz-16kbps-mono-siren\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3]: \"audio-16khz-32kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3]: \"audio-16khz-128kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3]: \"audio-16khz-64kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3]: \"audio-24khz-48kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3]: \"audio-24khz-96kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3]: \"audio-24khz-160kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk]: \"raw-16khz-16bit-mono-truesilk\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm]: \"riff-16khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm]: \"riff-8khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm]: \"riff-24khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw]: \"riff-8khz-8bit-mono-mulaw\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm]: \"raw-16khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm]: \"raw-24khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm]: \"raw-8khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus]: \"ogg-16khz-16bit-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus]: \"ogg-24khz-16bit-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm]: \"raw-48khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm]: \"riff-48khz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3]: \"audio-48khz-96kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3]: \"audio-48khz-192kbitrate-mono-mp3\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus]: \"ogg-48khz-16bit-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus]: \"webm-16khz-16bit-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus]: \"webm-24khz-16bit-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus]: \"webm-24khz-16bit-24kbps-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk]: \"raw-24khz-16bit-mono-truesilk\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw]: \"raw-8khz-8bit-mono-alaw\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw]: \"riff-8khz-8bit-mono-alaw\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus]: \"audio-16khz-16bit-32kbps-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus]: \"audio-24khz-16bit-48kbps-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus]: \"audio-24khz-16bit-24kbps-mono-opus\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm]: \"raw-22050hz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm]: \"riff-22050hz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm]: \"raw-44100hz-16bit-mono-pcm\",\n  [_SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_1__.SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm]: \"riff-44100hz-16bit-mono-pcm\"\n};\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioOutputStream\": () => (/* binding */ AudioOutputStream),\n/* harmony export */   \"PullAudioOutputStream\": () => (/* binding */ PullAudioOutputStream),\n/* harmony export */   \"PullAudioOutputStreamImpl\": () => (/* binding */ PullAudioOutputStreamImpl),\n/* harmony export */   \"PushAudioOutputStream\": () => (/* binding */ PushAudioOutputStream),\n/* harmony export */   \"PushAudioOutputStreamImpl\": () => (/* binding */ PushAudioOutputStreamImpl)\n/* harmony export */ });\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Stream.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @class AudioOutputStream\n */\nclass AudioOutputStream {\n  /**\n   * Creates and initializes an instance.\n   * @constructor\n   */\n  constructor() {\n    return;\n  }\n  /**\n   * Creates a memory backed PullAudioOutputStream with the specified audio format.\n   * @member AudioOutputStream.createPullStream\n   * @function\n   * @public\n   * @returns {PullAudioOutputStream} The audio output stream being created.\n   */\n  static createPullStream() {\n    return PullAudioOutputStream.create();\n  }\n}\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @class PullAudioOutputStream\n */\nclass PullAudioOutputStream extends AudioOutputStream {\n  /**\n   * Creates a memory backed PullAudioOutputStream with the specified audio format.\n   * @member PullAudioOutputStream.create\n   * @function\n   * @public\n   * @returns {PullAudioOutputStream} The push audio output stream being created.\n   */\n  static create() {\n    return new PullAudioOutputStreamImpl();\n  }\n}\n/**\n * Represents memory backed push audio output stream used for custom audio output configurations.\n * @private\n * @class PullAudioOutputStreamImpl\n */\nclass PullAudioOutputStreamImpl extends PullAudioOutputStream {\n  /**\n   * Creates and initializes an instance with the given values.\n   * @constructor\n   */\n  constructor() {\n    super();\n    this.privId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privStream = new _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Stream();\n  }\n  /**\n   * Sets the format information to the stream. For internal use only.\n   * @param {AudioStreamFormat} format - the format to be set.\n   */\n  set format(format) {\n    if (format === undefined || format === null) {\n      this.privFormat = _AudioOutputFormat__WEBPACK_IMPORTED_MODULE_2__.AudioOutputFormatImpl.getDefaultOutputFormat();\n    }\n    this.privFormat = format;\n  }\n  /**\n   * Format information for the audio\n   */\n  get format() {\n    return this.privFormat;\n  }\n  /**\n   * Checks if the stream is closed\n   * @member PullAudioOutputStreamImpl.prototype.isClosed\n   * @property\n   * @public\n   */\n  get isClosed() {\n    return this.privStream.isClosed;\n  }\n  /**\n   * Gets the id of the stream\n   * @member PullAudioOutputStreamImpl.prototype.id\n   * @property\n   * @public\n   */\n  id() {\n    return this.privId;\n  }\n  /**\n   * Reads audio data from the internal buffer.\n   * @member PullAudioOutputStreamImpl.prototype.read\n   * @function\n   * @public\n   * @param {ArrayBuffer} dataBuffer - An ArrayBuffer to store the read data.\n   * @returns {Promise<number>} - Audio buffer length has been read.\n   */\n  read(dataBuffer) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const intView = new Int8Array(dataBuffer);\n      let totalBytes = 0;\n      if (this.privLastChunkView !== undefined) {\n        if (this.privLastChunkView.length > dataBuffer.byteLength) {\n          intView.set(this.privLastChunkView.slice(0, dataBuffer.byteLength));\n          this.privLastChunkView = this.privLastChunkView.slice(dataBuffer.byteLength);\n          return Promise.resolve(dataBuffer.byteLength);\n        }\n        intView.set(this.privLastChunkView);\n        totalBytes = this.privLastChunkView.length;\n        this.privLastChunkView = undefined;\n      }\n      // Until we have the minimum number of bytes to send in a transmission, keep asking for more.\n      while (totalBytes < dataBuffer.byteLength && !this.privStream.isReadEnded) {\n        const chunk = yield this.privStream.read();\n        if (chunk !== undefined && !chunk.isEnd) {\n          let tmpBuffer;\n          if (chunk.buffer.byteLength > dataBuffer.byteLength - totalBytes) {\n            tmpBuffer = chunk.buffer.slice(0, dataBuffer.byteLength - totalBytes);\n            this.privLastChunkView = new Int8Array(chunk.buffer.slice(dataBuffer.byteLength - totalBytes));\n          } else {\n            tmpBuffer = chunk.buffer;\n          }\n          intView.set(new Int8Array(tmpBuffer), totalBytes);\n          totalBytes += tmpBuffer.byteLength;\n        } else {\n          this.privStream.readEnded();\n        }\n      }\n      return totalBytes;\n    });\n  }\n  /**\n   * Writes the audio data specified by making an internal copy of the data.\n   * @member PullAudioOutputStreamImpl.prototype.write\n   * @function\n   * @public\n   * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.\n   */\n  write(dataBuffer) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_3__.Contracts.throwIfNullOrUndefined(this.privStream, \"must set format before writing\");\n    this.privStream.writeStreamChunk({\n      buffer: dataBuffer,\n      isEnd: false,\n      timeReceived: Date.now()\n    });\n  }\n  /**\n   * Closes the stream.\n   * @member PullAudioOutputStreamImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    this.privStream.close();\n  }\n}\n/*\n * Represents audio output stream used for custom audio output configurations.\n * @class PushAudioOutputStream\n */\nclass PushAudioOutputStream extends AudioOutputStream {\n  /**\n   * Creates and initializes and instance.\n   * @constructor\n   */\n  constructor() {\n    super();\n  }\n  /**\n   * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n   * write() and close() methods.\n   * @member PushAudioOutputStream.create\n   * @function\n   * @public\n   * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n   * derived from PushAudioOutputStreamCallback\n   * @returns {PushAudioOutputStream} The push audio output stream being created.\n   */\n  static create(callback) {\n    return new PushAudioOutputStreamImpl(callback);\n  }\n}\n/**\n * Represents audio output stream used for custom audio output configurations.\n * @private\n * @class PushAudioOutputStreamImpl\n */\nclass PushAudioOutputStreamImpl extends PushAudioOutputStream {\n  /**\n   * Creates a PushAudioOutputStream that delegates to the specified callback interface for\n   * read() and close() methods.\n   * @constructor\n   * @param {PushAudioOutputStreamCallback} callback - The custom audio output object,\n   * derived from PushAudioOutputStreamCallback\n   */\n  constructor(callback) {\n    super();\n    this.privId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.createNoDashGuid)();\n    this.privCallback = callback;\n  }\n  // eslint-disable-next-line @typescript-eslint/no-empty-function\n  set format(format) {}\n  write(buffer) {\n    if (!!this.privCallback.write) {\n      this.privCallback.write(buffer);\n    }\n  }\n  close() {\n    if (!!this.privCallback.close) {\n      this.privCallback.close();\n    }\n  }\n  id() {\n    return this.privId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioFormatTag\": () => (/* binding */ AudioFormatTag),\n/* harmony export */   \"AudioStreamFormat\": () => (/* binding */ AudioStreamFormat),\n/* harmony export */   \"AudioStreamFormatImpl\": () => (/* binding */ AudioStreamFormatImpl)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// eslint-disable-next-line max-classes-per-file\nvar AudioFormatTag;\n(function (AudioFormatTag) {\n  AudioFormatTag[AudioFormatTag[\"PCM\"] = 1] = \"PCM\";\n  AudioFormatTag[AudioFormatTag[\"MuLaw\"] = 2] = \"MuLaw\";\n  AudioFormatTag[AudioFormatTag[\"Siren\"] = 3] = \"Siren\";\n  AudioFormatTag[AudioFormatTag[\"MP3\"] = 4] = \"MP3\";\n  AudioFormatTag[AudioFormatTag[\"SILKSkype\"] = 5] = \"SILKSkype\";\n  AudioFormatTag[AudioFormatTag[\"OGG_OPUS\"] = 6] = \"OGG_OPUS\";\n  AudioFormatTag[AudioFormatTag[\"WEBM_OPUS\"] = 7] = \"WEBM_OPUS\";\n  AudioFormatTag[AudioFormatTag[\"ALaw\"] = 8] = \"ALaw\";\n  AudioFormatTag[AudioFormatTag[\"FLAC\"] = 9] = \"FLAC\";\n  AudioFormatTag[AudioFormatTag[\"OPUS\"] = 10] = \"OPUS\";\n})(AudioFormatTag || (AudioFormatTag = {}));\n/**\n * Represents audio stream format used for custom audio input configurations.\n * @class AudioStreamFormat\n */\nclass AudioStreamFormat {\n  /**\n   * Creates an audio stream format object representing the default audio stream\n   * format (16KHz 16bit mono PCM).\n   * @member AudioStreamFormat.getDefaultInputFormat\n   * @function\n   * @public\n   * @returns {AudioStreamFormat} The audio stream format being created.\n   */\n  static getDefaultInputFormat() {\n    return AudioStreamFormatImpl.getDefaultInputFormat();\n  }\n  /**\n   * Creates an audio stream format object with the specified format characteristics.\n   * @member AudioStreamFormat.getWaveFormat\n   * @function\n   * @public\n   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n   * @param {number} bitsPerSample - Bits per sample, typically 16.\n   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n   * uses one channel and stereo data uses two channels.\n   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n   * @returns {AudioStreamFormat} The audio stream format being created.\n   */\n  static getWaveFormat(samplesPerSecond, bitsPerSample, channels, format) {\n    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels, format);\n  }\n  /**\n   * Creates an audio stream format object with the specified pcm waveformat characteristics.\n   * @member AudioStreamFormat.getWaveFormatPCM\n   * @function\n   * @public\n   * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).\n   * @param {number} bitsPerSample - Bits per sample, typically 16.\n   * @param {number} channels - Number of channels in the waveform-audio data. Monaural data\n   * uses one channel and stereo data uses two channels.\n   * @returns {AudioStreamFormat} The audio stream format being created.\n   */\n  static getWaveFormatPCM(samplesPerSecond, bitsPerSample, channels) {\n    return new AudioStreamFormatImpl(samplesPerSecond, bitsPerSample, channels);\n  }\n}\n/**\n * @private\n * @class AudioStreamFormatImpl\n */\nclass AudioStreamFormatImpl extends AudioStreamFormat {\n  /**\n   * Creates an instance with the given values.\n   * @constructor\n   * @param {number} samplesPerSec - Samples per second.\n   * @param {number} bitsPerSample - Bits per sample.\n   * @param {number} channels - Number of channels.\n   * @param {AudioFormatTag} format - Audio format (PCM, alaw or mulaw).\n   */\n  constructor() {\n    let samplesPerSec = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 16000;\n    let bitsPerSample = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 16;\n    let channels = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n    let format = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : AudioFormatTag.PCM;\n    super();\n    let isWavFormat = true;\n    /* 1 for PCM; 6 for alaw; 7 for mulaw */\n    switch (format) {\n      case AudioFormatTag.PCM:\n        this.formatTag = 1;\n        break;\n      case AudioFormatTag.ALaw:\n        this.formatTag = 6;\n        break;\n      case AudioFormatTag.MuLaw:\n        this.formatTag = 7;\n        break;\n      default:\n        isWavFormat = false;\n    }\n    this.bitsPerSample = bitsPerSample;\n    this.samplesPerSec = samplesPerSec;\n    this.channels = channels;\n    this.avgBytesPerSec = this.samplesPerSec * this.channels * (this.bitsPerSample / 8);\n    this.blockAlign = this.channels * Math.max(this.bitsPerSample, 8);\n    if (isWavFormat) {\n      this.privHeader = new ArrayBuffer(44);\n      // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/DataView\n      const view = new DataView(this.privHeader);\n      /* RIFF identifier */\n      this.setString(view, 0, \"RIFF\");\n      /* file length */\n      view.setUint32(4, 0, true);\n      /* RIFF type & Format */\n      this.setString(view, 8, \"WAVEfmt \");\n      /* format chunk length */\n      view.setUint32(16, 16, true);\n      /* audio format */\n      view.setUint16(20, this.formatTag, true);\n      /* channel count */\n      view.setUint16(22, this.channels, true);\n      /* sample rate */\n      view.setUint32(24, this.samplesPerSec, true);\n      /* byte rate (sample rate * block align) */\n      view.setUint32(28, this.avgBytesPerSec, true);\n      /* block align (channel count * bytes per sample) */\n      view.setUint16(32, this.channels * (this.bitsPerSample / 8), true);\n      /* bits per sample */\n      view.setUint16(34, this.bitsPerSample, true);\n      /* data chunk identifier */\n      this.setString(view, 36, \"data\");\n      /* data chunk length */\n      view.setUint32(40, 0, true);\n    }\n  }\n  /**\n   * Retrieves the default input format.\n   * @member AudioStreamFormatImpl.getDefaultInputFormat\n   * @function\n   * @public\n   * @returns {AudioStreamFormatImpl} The default input format.\n   */\n  static getDefaultInputFormat() {\n    return new AudioStreamFormatImpl();\n  }\n  /**\n   * Creates an audio context appropriate to current browser\n   * @member AudioStreamFormatImpl.getAudioContext\n   * @function\n   * @public\n   * @returns {AudioContext} An audio context instance\n   */\n  /* eslint-disable */\n  static getAudioContext(sampleRate) {\n    // Workaround for Speech SDK bug in Safari.\n    const AudioContext = window.AudioContext // our preferred impl\n    || window.webkitAudioContext // fallback, mostly when on Safari\n    || false; // could not find.\n    // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext\n    if (!!AudioContext) {\n      if (sampleRate !== undefined && navigator.mediaDevices.getSupportedConstraints().sampleRate) {\n        return new AudioContext({\n          sampleRate\n        });\n      } else {\n        return new AudioContext();\n      }\n    } else {\n      throw new Error(\"Browser does not support Web Audio API (AudioContext is not available).\");\n    }\n  }\n  /* eslint-enable */\n  /**\n   * Closes the configuration object.\n   * @member AudioStreamFormatImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return;\n  }\n  get header() {\n    return this.privHeader;\n  }\n  setString(view, offset, str) {\n    for (let i = 0; i < str.length; i++) {\n      view.setUint8(offset + i, str.charCodeAt(i));\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseAudioPlayer\": () => (/* binding */ BaseAudioPlayer)\n/* harmony export */ });\n/* harmony import */ var _common_Error__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Error */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Error.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n/**\n * Base audio player class\n * TODO: Plays only PCM for now.\n * @class\n */\nclass BaseAudioPlayer {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {AudioStreamFormat} audioFormat audio stream format recognized by the player.\n   */\n  constructor(audioFormat) {\n    this.audioContext = null;\n    this.gainNode = null;\n    this.autoUpdateBufferTimer = 0;\n    if (audioFormat === undefined) {\n      audioFormat = _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormat.getDefaultInputFormat();\n    }\n    this.init(audioFormat);\n  }\n  /**\n   * play Audio sample\n   * @param newAudioData audio data to be played.\n   */\n  playAudioSample(newAudioData, cb, err) {\n    try {\n      this.ensureInitializedContext();\n      const audioData = this.formatAudioData(newAudioData);\n      const newSamplesData = new Float32Array(this.samples.length + audioData.length);\n      newSamplesData.set(this.samples, 0);\n      newSamplesData.set(audioData, this.samples.length);\n      this.samples = newSamplesData;\n      if (!!cb) {\n        cb();\n      }\n    } catch (e) {\n      if (!!err) {\n        err(e);\n      }\n    }\n  }\n  /**\n   * stops audio and clears the buffers\n   */\n  stopAudio(cb, err) {\n    if (this.audioContext !== null) {\n      this.samples = new Float32Array();\n      // eslint-disable-next-line @typescript-eslint/no-unsafe-argument\n      clearInterval(this.autoUpdateBufferTimer);\n      this.audioContext.close().then(() => {\n        if (!!cb) {\n          cb();\n        }\n      }, error => {\n        if (!!err) {\n          err(error);\n        }\n      });\n      this.audioContext = null;\n    }\n  }\n  init(audioFormat) {\n    this.audioFormat = audioFormat;\n    this.samples = new Float32Array();\n  }\n  ensureInitializedContext() {\n    if (this.audioContext === null) {\n      this.createAudioContext();\n      const timerPeriod = 200;\n      this.autoUpdateBufferTimer = setInterval(() => {\n        this.updateAudioBuffer();\n      }, timerPeriod);\n    }\n  }\n  createAudioContext() {\n    // new ((window as any).AudioContext || (window as any).webkitAudioContext)();\n    this.audioContext = _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioStreamFormatImpl.getAudioContext();\n    // TODO: Various examples shows this gain node, it does not seem to be needed unless we plan\n    // to control the volume, not likely\n    this.gainNode = this.audioContext.createGain();\n    this.gainNode.gain.value = 1;\n    this.gainNode.connect(this.audioContext.destination);\n    this.startTime = this.audioContext.currentTime;\n  }\n  formatAudioData(audioData) {\n    switch (this.audioFormat.bitsPerSample) {\n      case 8:\n        return this.formatArrayBuffer(new Int8Array(audioData), 128);\n      case 16:\n        return this.formatArrayBuffer(new Int16Array(audioData), 32768);\n      case 32:\n        return this.formatArrayBuffer(new Int32Array(audioData), 2147483648);\n      default:\n        throw new _common_Error__WEBPACK_IMPORTED_MODULE_1__.InvalidOperationError(\"Only WAVE_FORMAT_PCM (8/16/32 bps) format supported at this time\");\n    }\n  }\n  formatArrayBuffer(audioData, maxValue) {\n    const float32Data = new Float32Array(audioData.length);\n    for (let i = 0; i < audioData.length; i++) {\n      float32Data[i] = audioData[i] / maxValue;\n    }\n    return float32Data;\n  }\n  updateAudioBuffer() {\n    if (this.samples.length === 0) {\n      return;\n    }\n    const channelCount = this.audioFormat.channels;\n    const bufferSource = this.audioContext.createBufferSource();\n    const frameCount = this.samples.length / channelCount;\n    const audioBuffer = this.audioContext.createBuffer(channelCount, frameCount, this.audioFormat.samplesPerSec);\n    // TODO: Should we do the conversion in the pushAudioSample instead?\n    for (let channel = 0; channel < channelCount; channel++) {\n      // Fill in individual channel data\n      let channelOffset = channel;\n      const audioData = audioBuffer.getChannelData(channel);\n      for (let i = 0; i < this.samples.length; i++, channelOffset += channelCount) {\n        audioData[i] = this.samples[channelOffset];\n      }\n    }\n    if (this.startTime < this.audioContext.currentTime) {\n      this.startTime = this.audioContext.currentTime;\n    }\n    bufferSource.buffer = audioBuffer;\n    bufferSource.connect(this.gainNode);\n    bufferSource.start(this.startTime);\n    // Make sure we play the next sample after the current one.\n    this.startTime += audioBuffer.duration;\n    // Clear the samples for the next pushed data.\n    this.samples = new Float32Array();\n  }\n  playAudio(audioData) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.audioContext === null) {\n        this.createAudioContext();\n      }\n      const source = this.audioContext.createBufferSource();\n      const destination = this.audioContext.destination;\n      yield this.audioContext.decodeAudioData(audioData, newBuffer => {\n        source.buffer = newBuffer;\n        source.connect(destination);\n        source.start(0);\n      });\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PullAudioInputStreamCallback\": () => (/* binding */ PullAudioInputStreamCallback)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (read() and close()) for\n * custom audio input streams).\n * @class PullAudioInputStreamCallback\n */\nclass PullAudioInputStreamCallback {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PushAudioOutputStreamCallback\": () => (/* binding */ PushAudioOutputStreamCallback)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * An abstract base class that defines callback methods (write() and close()) for\n * custom audio output streams).\n * @class PushAudioOutputStreamCallback\n */\nclass PushAudioOutputStreamCallback {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerAudioDestination\": () => (/* binding */ SpeakerAudioDestination)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/BackgroundError.js\");\n/* harmony import */ var _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\nconst MediaDurationPlaceholderSeconds = 60 * 30;\nconst AudioFormatToMimeType = {\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM]: \"audio/wav\",\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw]: \"audio/x-wav\",\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MP3]: \"audio/mpeg\",\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.OGG_OPUS]: \"audio/ogg\",\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.WEBM_OPUS]: \"audio/webm; codecs=opus\",\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw]: \"audio/x-wav\",\n  [_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.FLAC]: \"audio/flac\"\n};\n/**\n * Represents the speaker playback audio destination, which only works in browser.\n * Note: the SDK will try to use <a href=\"https://www.w3.org/TR/media-source/\">Media Source Extensions</a> to play audio.\n * Mp3 format has better supports on Microsoft Edge, Chrome and Safari (desktop), so, it's better to specify mp3 format for playback.\n * @class SpeakerAudioDestination\n * Updated in version 1.17.0\n */\nclass SpeakerAudioDestination {\n  constructor(audioDestinationId) {\n    this.privPlaybackStarted = false;\n    this.privAppendingToBuffer = false;\n    this.privMediaSourceOpened = false;\n    this.privBytesReceived = 0;\n    this.privId = audioDestinationId ? audioDestinationId : (0,_common_Exports__WEBPACK_IMPORTED_MODULE_1__.createNoDashGuid)();\n    this.privIsPaused = false;\n    this.privIsClosed = false;\n  }\n  id() {\n    return this.privId;\n  }\n  write(buffer, cb, err) {\n    if (this.privAudioBuffer !== undefined) {\n      this.privAudioBuffer.push(buffer);\n      this.updateSourceBuffer().then(() => {\n        if (!!cb) {\n          cb();\n        }\n      }, error => {\n        if (!!err) {\n          err(error);\n        }\n      });\n    } else if (this.privAudioOutputStream !== undefined) {\n      this.privAudioOutputStream.write(buffer);\n      this.privBytesReceived += buffer.byteLength;\n    }\n  }\n  close(cb, err) {\n    this.privIsClosed = true;\n    if (this.privSourceBuffer !== undefined) {\n      this.handleSourceBufferUpdateEnd().then(() => {\n        if (!!cb) {\n          cb();\n        }\n      }, error => {\n        if (!!err) {\n          err(error);\n        }\n      });\n    } else if (this.privAudioOutputStream !== undefined && typeof window !== \"undefined\") {\n      if ((this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.PCM || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.MuLaw || this.privFormat.formatTag === _AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag.ALaw) && this.privFormat.hasHeader === false) {\n        // eslint-disable-next-line no-console\n        console.warn(\"Play back is not supported for raw PCM, mulaw or alaw format without header.\");\n        if (!!this.onAudioEnd) {\n          this.onAudioEnd(this);\n        }\n      } else {\n        let receivedAudio = new ArrayBuffer(this.privBytesReceived);\n        this.privAudioOutputStream.read(receivedAudio).then(() => {\n          receivedAudio = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.SynthesisAdapterBase.addHeader(receivedAudio, this.privFormat);\n          const audioBlob = new Blob([receivedAudio], {\n            type: AudioFormatToMimeType[this.privFormat.formatTag]\n          });\n          this.privAudio.src = window.URL.createObjectURL(audioBlob);\n          this.notifyPlayback().then(() => {\n            if (!!cb) {\n              cb();\n            }\n          }, error => {\n            if (!!err) {\n              err(error);\n            }\n          });\n        }, error => {\n          if (!!err) {\n            err(error);\n          }\n        });\n      }\n    } else {\n      // unsupported format, call onAudioEnd directly.\n      if (!!this.onAudioEnd) {\n        this.onAudioEnd(this);\n      }\n    }\n  }\n  set format(format) {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n    if (typeof AudioContext !== \"undefined\" || typeof window !== \"undefined\" && typeof window.webkitAudioContext !== \"undefined\") {\n      this.privFormat = format;\n      const mimeType = AudioFormatToMimeType[this.privFormat.formatTag];\n      if (mimeType === undefined) {\n        // eslint-disable-next-line no-console\n        console.warn(`Unknown mimeType for format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag[this.privFormat.formatTag]}; playback is not supported.`);\n      } else if (typeof MediaSource !== \"undefined\" && MediaSource.isTypeSupported(mimeType)) {\n        this.privAudio = new Audio();\n        this.privAudioBuffer = [];\n        this.privMediaSource = new MediaSource();\n        this.privAudio.src = URL.createObjectURL(this.privMediaSource);\n        this.privAudio.load();\n        this.privMediaSource.onsourceopen = () => {\n          this.privMediaSourceOpened = true;\n          this.privMediaSource.duration = MediaDurationPlaceholderSeconds;\n          this.privSourceBuffer = this.privMediaSource.addSourceBuffer(mimeType);\n          this.privSourceBuffer.onupdate = () => {\n            this.updateSourceBuffer().catch(reason => {\n              _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));\n            });\n          };\n          this.privSourceBuffer.onupdateend = () => {\n            this.handleSourceBufferUpdateEnd().catch(reason => {\n              _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));\n            });\n          };\n          this.privSourceBuffer.onupdatestart = () => {\n            this.privAppendingToBuffer = false;\n          };\n        };\n        this.updateSourceBuffer().catch(reason => {\n          _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Events.instance.onEvent(new _common_Exports__WEBPACK_IMPORTED_MODULE_4__.BackgroundEvent(reason));\n        });\n      } else {\n        // eslint-disable-next-line no-console\n        console.warn(`Format ${_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_0__.AudioFormatTag[this.privFormat.formatTag]} could not be played by MSE, streaming playback is not enabled.`);\n        this.privAudioOutputStream = new _AudioOutputStream__WEBPACK_IMPORTED_MODULE_5__.PullAudioOutputStreamImpl();\n        this.privAudioOutputStream.format = this.privFormat;\n        this.privAudio = new Audio();\n      }\n    }\n  }\n  get volume() {\n    var _a, _b;\n    return (_b = (_a = this.privAudio) === null || _a === void 0 ? void 0 : _a.volume) !== null && _b !== void 0 ? _b : -1;\n  }\n  set volume(volume) {\n    if (!!this.privAudio) {\n      this.privAudio.volume = volume;\n    }\n  }\n  mute() {\n    if (!!this.privAudio) {\n      this.privAudio.muted = true;\n    }\n  }\n  unmute() {\n    if (!!this.privAudio) {\n      this.privAudio.muted = false;\n    }\n  }\n  get isClosed() {\n    return this.privIsClosed;\n  }\n  get currentTime() {\n    if (this.privAudio !== undefined) {\n      return this.privAudio.currentTime;\n    }\n    return -1;\n  }\n  pause() {\n    if (!this.privIsPaused && this.privAudio !== undefined) {\n      this.privAudio.pause();\n      this.privIsPaused = true;\n    }\n  }\n  resume(cb, err) {\n    if (this.privIsPaused && this.privAudio !== undefined) {\n      this.privAudio.play().then(() => {\n        if (!!cb) {\n          cb();\n        }\n      }, error => {\n        if (!!err) {\n          err(error);\n        }\n      });\n      this.privIsPaused = false;\n    }\n  }\n  get internalAudio() {\n    return this.privAudio;\n  }\n  updateSourceBuffer() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privAudioBuffer !== undefined && this.privAudioBuffer.length > 0 && this.sourceBufferAvailable()) {\n        this.privAppendingToBuffer = true;\n        const binary = this.privAudioBuffer.shift();\n        try {\n          this.privSourceBuffer.appendBuffer(binary);\n        } catch (error) {\n          this.privAudioBuffer.unshift(binary);\n          // eslint-disable-next-line no-console\n          console.log(\"buffer filled, pausing addition of binaries until space is made\");\n          return;\n        }\n        yield this.notifyPlayback();\n      } else if (this.canEndStream()) {\n        yield this.handleSourceBufferUpdateEnd();\n      }\n    });\n  }\n  handleSourceBufferUpdateEnd() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.canEndStream() && this.sourceBufferAvailable()) {\n        this.privMediaSource.endOfStream();\n        yield this.notifyPlayback();\n      }\n    });\n  }\n  notifyPlayback() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privPlaybackStarted && this.privAudio !== undefined) {\n        this.privPlaybackStarted = true;\n        if (!!this.onAudioStart) {\n          this.onAudioStart(this);\n        }\n        this.privAudio.onended = () => {\n          if (!!this.onAudioEnd) {\n            this.onAudioEnd(this);\n          }\n        };\n        if (!this.privIsPaused) {\n          yield this.privAudio.play();\n        }\n      }\n    });\n  }\n  canEndStream() {\n    return this.isClosed && this.privSourceBuffer !== undefined && this.privAudioBuffer.length === 0 && this.privMediaSourceOpened && !this.privAppendingToBuffer && this.privMediaSource.readyState === \"open\";\n  }\n  sourceBufferAvailable() {\n    return this.privSourceBuffer !== undefined && !this.privSourceBuffer.updating;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoDetectSourceLanguageConfig\": () => (/* binding */ AutoDetectSourceLanguageConfig)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LanguageIdMode */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js\");\n/* harmony import */ var _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./LanguageIdPriority */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n/**\n * Language auto detect configuration.\n * @class AutoDetectSourceLanguageConfig\n * Added in version 1.13.0.\n */\nclass AutoDetectSourceLanguageConfig {\n  constructor() {\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AtStartLanguageIdPriority, \"Latency\");\n    this.privLanguageIdMode = _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode.AtStart;\n  }\n  /**\n   * @member AutoDetectSourceLanguageConfig.fromOpenRange\n   * @function\n   * @public\n   * Only [[SpeechSynthesizer]] supports source language auto detection from open range,\n   * for [[Recognizer]], please use AutoDetectSourceLanguageConfig with specific source languages.\n   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with open range.\n   */\n  static fromOpenRange() {\n    const config = new AutoDetectSourceLanguageConfig();\n    config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.AutoDetectSourceLanguagesOpenRangeOptionName);\n    return config;\n  }\n  /**\n   * @member AutoDetectSourceLanguageConfig.fromLanguages\n   * @function\n   * @public\n   * @param {string[]} languages Comma-separated string of languages (eg. \"en-US,fr-FR\") to populate properties of config.\n   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given languages.\n   */\n  static fromLanguages(languages) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_4__.Contracts.throwIfArrayEmptyOrWhitespace(languages, \"languages\");\n    const config = new AutoDetectSourceLanguageConfig();\n    config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, languages.join());\n    return config;\n  }\n  /**\n   * @member AutoDetectSourceLanguageConfig.fromSourceLanguageConfigs\n   * @function\n   * @public\n   * @param {SourceLanguageConfig[]} configs SourceLanguageConfigs to populate properties of config.\n   * @return {AutoDetectSourceLanguageConfig} Instance of AutoDetectSourceLanguageConfig\n   * @summary Creates an instance of the AutoDetectSourceLanguageConfig with given SourceLanguageConfigs.\n   */\n  static fromSourceLanguageConfigs(configs) {\n    if (configs.length < 1) {\n      throw new Error(\"Expected non-empty SourceLanguageConfig array.\");\n    }\n    const autoConfig = new AutoDetectSourceLanguageConfig();\n    const langs = [];\n    configs.forEach(config => {\n      langs.push(config.language);\n      if (config.endpointId !== undefined && config.endpointId !== \"\") {\n        const customProperty = config.language + _Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId.toString();\n        autoConfig.properties.setProperty(customProperty, config.endpointId);\n      }\n    });\n    autoConfig.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, langs.join());\n    return autoConfig;\n  }\n  /**\n   * @member AutoDetectSourceLanguageConfig.prototype.properties\n   * @function\n   * @public\n   * @return {PropertyCollection} Properties of the config.\n   * @summary Gets an auto detected language config properties\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * @member AutoDetectSourceLanguageConfig.prototype.mode\n   * @function\n   * @public\n   * @param {LanguageIdMode} mode LID mode desired.\n   * @summary Sets LID operation to desired mode\n   */\n  set mode(mode) {\n    if (mode === _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode.Continuous) {\n      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, \"2\");\n      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority, \"Latency\");\n    } else {\n      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecognitionEndpointVersion, \"1\");\n      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority, undefined);\n    }\n    this.privLanguageIdMode = mode;\n  }\n  /**\n   * @member AutoDetectSourceLanguageConfig.prototype.priority\n   * @function\n   * @public\n   * @param {LanguageIdPriority} priority LID priority desired.\n   * @summary Sets LID operation to desired priority\n   */\n  set priority(priority) {\n    if (priority === _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_5__.LanguageIdPriority.Accuracy) {\n      if (this.privLanguageIdMode !== _LanguageIdMode__WEBPACK_IMPORTED_MODULE_2__.LanguageIdMode.Continuous) {\n        // Accuracy not allowed for continuous mode\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AtStartLanguageIdPriority, \"Accuracy\");\n      }\n    } else {\n      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority, \"Latency\");\n      this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AtStartLanguageIdPriority, \"Latency\");\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoDetectSourceLanguageResult\": () => (/* binding */ AutoDetectSourceLanguageResult)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Output format\n * @class AutoDetectSourceLanguageResult\n */\nclass AutoDetectSourceLanguageResult {\n  constructor(language, languageDetectionConfidence) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(language, \"language\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(languageDetectionConfidence, \"languageDetectionConfidence\");\n    this.privLanguage = language;\n    this.privLanguageDetectionConfidence = languageDetectionConfidence;\n  }\n  /**\n   * Creates an instance of AutoDetectSourceLanguageResult object from a SpeechRecognitionResult instance.\n   * @member AutoDetectSourceLanguageResult.fromResult\n   * @function\n   * @public\n   * @param {SpeechRecognitionResult} result - The recognition result.\n   * @returns {AutoDetectSourceLanguageResult} AutoDetectSourceLanguageResult object being created.\n   */\n  static fromResult(result) {\n    return new AutoDetectSourceLanguageResult(result.language, result.languageDetectionConfidence);\n  }\n  get language() {\n    return this.privLanguage;\n  }\n  get languageDetectionConfidence() {\n    return this.privLanguageDetectionConfidence;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BotFrameworkConfig\": () => (/* binding */ BotFrameworkConfig)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DialogServiceConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.\n * @class BotFrameworkConfig\n */\nclass BotFrameworkConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl {\n  /**\n   * Creates an instance of BotFrameworkConfig.\n   */\n  constructor() {\n    super();\n  }\n  /**\n   * Creates a bot framework configuration instance with the provided subscription information.\n   * @member BotFrameworkConfig.fromSubscription\n   * @function\n   * @public\n   * @param subscription Subscription key associated with the bot\n   * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n   * resource name.\n   * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n   */\n  static fromSubscription(subscription, region, botId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(subscription, \"subscription\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscription);\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);\n    if (botId) {\n      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, botId);\n    }\n    return botFrameworkConfig;\n  }\n  /**\n   * Creates a bot framework configuration instance for the specified authorization token and region.\n   * Note: The caller must ensure that an authorization token is valid. Before an authorization token expires, the\n   * caller must refresh it by setting the authorizationToken property on the corresponding\n   * DialogServiceConnector instance created with this config. The contents of configuration objects are copied\n   * when connectors are created, so setting authorizationToken on a DialogServiceConnector will not update the\n   * original configuration's authorization token. Create a new configuration instance or set the\n   * SpeechServiceAuthorization_Token property to update an existing instance if it will be used to create\n   * further DialogServiceConnectors.\n   * @member BotFrameworkConfig.fromAuthorizationToken\n   * @function\n   * @public\n   * @param authorizationToken The authorization token associated with the bot\n   * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n   * resource name.\n   * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n   */\n  static fromAuthorizationToken(authorizationToken, region, botId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);\n    if (botId) {\n      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, botId);\n    }\n    return botFrameworkConfig;\n  }\n  /**\n   * Creates an instance of a BotFrameworkConfig.\n   * This method is intended only for users who use a non-default service host. The standard resource path will be\n   * assumed. For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n   * Note: To use an authorization token with fromHost, use fromHost(URL) and then set the AuthorizationToken\n   * property on the created BotFrameworkConfig instance.\n   * Note: Added in version 1.15.0.\n   * @member BotFrameworkConfig.fromHost\n   * @function\n   * @public\n   * @param {URL | string} host - If a URL is provided, the fully-qualified host with protocol (e.g.\n   * wss://your.host.com:1234) will be used. If a string is provided, it will be embedded in\n   * wss://{host}.convai.speech.azure.us.\n   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization\n   * token must be set.\n   * @param botId Optional. Identifier for using a specific bot within an Azure resource group. Equivalent to the\n   * resource name.\n   * @returns {BotFrameworkConfig} A new bot framework configuration instance.\n   */\n  static fromHost(host, subscriptionKey, botId) {\n    void botId;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(host, \"host\");\n    const resolvedHost = host instanceof URL ? host : new URL(`wss://${host}.convai.speech.azure.us`);\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(resolvedHost, \"resolvedHost\");\n    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Host, resolvedHost.toString());\n    if (undefined !== subscriptionKey) {\n      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    }\n    return botFrameworkConfig;\n  }\n  /**\n   * Creates an instance of a BotFrameworkConfig.\n   * This method is intended only for users who use a non-standard service endpoint or parameters.\n   * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n   * fromEndpoint method, and then set authorizationToken=\"token\" on the created BotFrameworkConfig instance to\n   * use the authorization token.\n   * Note: Added in version 1.15.0.\n   * @member BotFrameworkConfig.fromEndpoint\n   * @function\n   * @public\n   * @param {URL} endpoint - The service endpoint to connect to.\n   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization\n   * token must be set.\n   * @returns {BotFrameworkConfig} - A new bot framework configuration instance using the provided endpoint.\n   */\n  static fromEndpoint(endpoint, subscriptionKey) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(endpoint, \"endpoint\");\n    const botFrameworkConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.BotFramework);\n    botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.toString());\n    if (undefined !== subscriptionKey) {\n      botFrameworkConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    }\n    return botFrameworkConfig;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationDetails\": () => (/* binding */ CancellationDetails)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/EnumTranslation.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationDetailsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetails\n */\nclass CancellationDetails extends _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationDetailsBase {\n  constructor(reason, errorDetails, errorCode) {\n    super(reason, errorDetails, errorCode);\n  }\n  /**\n   * Creates an instance of CancellationDetails object for the canceled RecognitionResult.\n   * @member CancellationDetails.fromResult\n   * @function\n   * @public\n   * @param {RecognitionResult | SpeechSynthesisResult} result - The result that was canceled.\n   * @returns {CancellationDetails} The cancellation details object being created.\n   */\n  static fromResult(result) {\n    let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.CancellationReason.Error;\n    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode.NoError;\n    if (result instanceof _Exports__WEBPACK_IMPORTED_MODULE_3__.RecognitionResult && !!result.json) {\n      const simpleSpeech = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.SimpleSpeechPhrase.fromJSON(result.json);\n      reason = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.EnumTranslation.implTranslateCancelResult(simpleSpeech.RecognitionStatus);\n    }\n    if (!!result.properties) {\n      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCode.NoError])];\n    }\n    return new CancellationDetails(reason, result.errorDetails || _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.EnumTranslation.implTranslateErrorDetails(errorCode), errorCode);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationDetailsBase\": () => (/* binding */ CancellationDetailsBase)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Contains detailed information about why a result was canceled.\n * @class CancellationDetailsBase\n */\nclass CancellationDetailsBase {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {CancellationReason} reason - The cancellation reason.\n   * @param {string} errorDetails - The error details, if provided.\n   */\n  constructor(reason, errorDetails, errorCode) {\n    this.privReason = reason;\n    this.privErrorDetails = errorDetails;\n    this.privErrorCode = errorCode;\n  }\n  /**\n   * The reason the recognition was canceled.\n   * @member CancellationDetailsBase.prototype.reason\n   * @function\n   * @public\n   * @returns {CancellationReason} Specifies the reason canceled.\n   */\n  get reason() {\n    return this.privReason;\n  }\n  /**\n   * In case of an unsuccessful recognition, provides details of the occurred error.\n   * @member CancellationDetailsBase.prototype.errorDetails\n   * @function\n   * @public\n   * @returns {string} A String that represents the error details.\n   */\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n  /**\n   * The error code in case of an unsuccessful recognition.\n   * Added in version 1.1.0.\n   * @return An error code that represents the error reason.\n   */\n  get ErrorCode() {\n    return this.privErrorCode;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationErrorCode\": () => (/* binding */ CancellationErrorCode)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines error code in case that CancellationReason is Error.\n * Added in version 1.1.0.\n */\nvar CancellationErrorCode;\n(function (CancellationErrorCode) {\n  /**\n   * Indicates that no error occurred during speech recognition.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"NoError\"] = 0] = \"NoError\";\n  /**\n   * Indicates an authentication error.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"AuthenticationFailure\"] = 1] = \"AuthenticationFailure\";\n  /**\n   * Indicates that one or more recognition parameters are invalid.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"BadRequestParameters\"] = 2] = \"BadRequestParameters\";\n  /**\n   * Indicates that the number of parallel requests exceeded the number of allowed\n   * concurrent transcriptions for the subscription.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"TooManyRequests\"] = 3] = \"TooManyRequests\";\n  /**\n   * Indicates a connection error.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"ConnectionFailure\"] = 4] = \"ConnectionFailure\";\n  /**\n   * Indicates a time-out error when waiting for response from service.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"ServiceTimeout\"] = 5] = \"ServiceTimeout\";\n  /**\n   * Indicates that an error is returned by the service.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"ServiceError\"] = 6] = \"ServiceError\";\n  /**\n   * Indicates an unexpected runtime error.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"RuntimeError\"] = 7] = \"RuntimeError\";\n  /**\n   * Indicates an quota overrun on existing key.\n   */\n  CancellationErrorCode[CancellationErrorCode[\"Forbidden\"] = 8] = \"Forbidden\";\n})(CancellationErrorCode || (CancellationErrorCode = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationEventArgsBase\": () => (/* binding */ CancellationEventArgsBase)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines content of a CancellationEvent.\n * @class CancellationEventArgsBase\n */\nclass CancellationEventArgsBase extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {CancellationReason} reason - The cancellation reason.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {number} offset - The offset.\n   * @param {string} sessionId - The session id.\n   */\n  constructor(reason, errorDetails, errorCode, offset, sessionId) {\n    super(offset, sessionId);\n    this.privReason = reason;\n    this.privErrorDetails = errorDetails;\n    this.privErrorCode = errorCode;\n  }\n  /**\n   * The reason the recognition was canceled.\n   * @member CancellationEventArgsBase.prototype.reason\n   * @function\n   * @public\n   * @returns {CancellationReason} Specifies the reason canceled.\n   */\n  get reason() {\n    return this.privReason;\n  }\n  /**\n   * The error code in case of an unsuccessful operation.\n   * @return An error code that represents the error reason.\n   */\n  get errorCode() {\n    return this.privErrorCode;\n  }\n  /**\n   * In case of an unsuccessful operation, provides details of the occurred error.\n   * @member CancellationEventArgsBase.prototype.errorDetails\n   * @function\n   * @public\n   * @returns {string} A String that represents the error details.\n   */\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CancellationReason\": () => (/* binding */ CancellationReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might be canceled.\n * @class CancellationReason\n */\nvar CancellationReason;\n(function (CancellationReason) {\n  /**\n   * Indicates that an error occurred during speech recognition.\n   * @member CancellationReason.Error\n   */\n  CancellationReason[CancellationReason[\"Error\"] = 0] = \"Error\";\n  /**\n   * Indicates that the end of the audio stream was reached.\n   * @member CancellationReason.EndOfStream\n   */\n  CancellationReason[CancellationReason[\"EndOfStream\"] = 1] = \"EndOfStream\";\n})(CancellationReason || (CancellationReason = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Connection\": () => (/* binding */ Connection)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n\n\n\n\n/**\n * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.\n * By default, a Recognizer autonomously manages connection to service when needed.\n * The Connection class provides additional methods for users to explicitly open or close a connection and\n * to subscribe to connection status changes.\n * The use of Connection is optional, and mainly for scenarios where fine tuning of application\n * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection\n * in advance before starting recognition on the Recognizer associated with this Connection.\n * If the Recognizer needs to connect or disconnect to service, it will\n * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection\n * status via Connected/Disconnected events.\n * Added in version 1.2.1.\n */\nclass Connection {\n  /**\n   * Gets the Connection instance from the specified recognizer.\n   * @param recognizer The recognizer associated with the connection.\n   * @return The Connection instance of the recognizer.\n   */\n  static fromRecognizer(recognizer) {\n    const recoBase = recognizer.internalData;\n    const ret = new Connection();\n    ret.privInternalData = recoBase;\n    ret.setupEvents();\n    return ret;\n  }\n  /**\n   * Gets the Connection instance from the specified synthesizer.\n   * @param synthesizer The synthesizer associated with the connection.\n   * @return The Connection instance of the synthesizer.\n   */\n  static fromSynthesizer(synthesizer) {\n    const synthBase = synthesizer.internalData;\n    const ret = new Connection();\n    ret.privInternalData = synthBase;\n    ret.setupEvents();\n    return ret;\n  }\n  /**\n   * Starts to set up connection to the service.\n   * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the\n   * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect\n   *\n   * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n   * be notified when the connection is established.\n   */\n  openConnection(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.connect(), cb, err);\n  }\n  /**\n   * Closes the connection the service.\n   * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.\n   *\n   * If closeConnection() is called during recognition, recognition will fail and cancel with an error.\n   */\n  closeConnection(cb, err) {\n    if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisAdapterBase) {\n      throw new Error(\"Disconnecting a synthesizer's connection is currently not supported\");\n    } else {\n      (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.disconnect(), cb, err);\n    }\n  }\n  /**\n   * Appends a parameter in a message to service.\n   * Added in version 1.12.1.\n   * @param path The path of the network message.\n   * @param propertyName Name of the property\n   * @param propertyValue Value of the property. This is a json string.\n   */\n  setMessageProperty(path, propertyName, propertyValue) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(propertyName, \"propertyName\");\n    if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase) {\n      if (path.toLowerCase() !== \"speech.context\") {\n        throw new Error(\"Only speech.context message property sets are currently supported for recognizer\");\n      } else {\n        this.privInternalData.speechContext.setSection(propertyName, propertyValue);\n      }\n    } else if (this.privInternalData instanceof _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.SynthesisAdapterBase) {\n      if (path.toLowerCase() !== \"synthesis.context\") {\n        throw new Error(\"Only synthesis.context message property sets are currently supported for synthesizer\");\n      } else {\n        this.privInternalData.synthesisContext.setSection(propertyName, propertyValue);\n      }\n    }\n  }\n  /**\n   * Sends a message to the speech service.\n   * Added in version 1.13.0.\n   * @param path The WebSocket path of the message\n   * @param payload The payload of the message. This is a json string or a ArrayBuffer.\n   * @param success A callback to indicate success.\n   * @param error A callback to indicate an error.\n   */\n  sendMessageAsync(path, payload, success, error) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_0__.marshalPromiseToCallbacks)(this.privInternalData.sendNetworkMessage(path, payload), success, error);\n  }\n  /**\n   * Dispose of associated resources.\n   */\n  close() {\n    /* eslint-disable no-empty */\n  }\n  setupEvents() {\n    this.privEventListener = this.privInternalData.connectionEvents.attach(connectionEvent => {\n      if (connectionEvent.name === \"ConnectionEstablishedEvent\") {\n        if (!!this.connected) {\n          this.connected(new _Exports__WEBPACK_IMPORTED_MODULE_4__.ConnectionEventArgs(connectionEvent.connectionId));\n        }\n      } else if (connectionEvent.name === \"ConnectionClosedEvent\") {\n        if (!!this.disconnected) {\n          this.disconnected(new _Exports__WEBPACK_IMPORTED_MODULE_4__.ConnectionEventArgs(connectionEvent.connectionId));\n        }\n      } else if (connectionEvent.name === \"ConnectionMessageSentEvent\") {\n        if (!!this.messageSent) {\n          this.messageSent(new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConnectionMessageEventArgs(new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__.ConnectionMessageImpl(connectionEvent.message)));\n        }\n      } else if (connectionEvent.name === \"ConnectionMessageReceivedEvent\") {\n        if (!!this.messageReceived) {\n          this.messageReceived(new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConnectionMessageEventArgs(new _ConnectionMessage__WEBPACK_IMPORTED_MODULE_6__.ConnectionMessageImpl(connectionEvent.message)));\n        }\n      }\n    });\n    this.privServiceEventListener = this.privInternalData.serviceEvents.attach(e => {\n      if (!!this.receivedServiceMessage) {\n        this.receivedServiceMessage(new _Exports__WEBPACK_IMPORTED_MODULE_7__.ServiceEventArgs(e.jsonString, e.name));\n      }\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionEventArgs\": () => (/* binding */ ConnectionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n/**\n * Defines payload for connection events like Connected/Disconnected.\n * Added in version 1.2.0\n */\nclass ConnectionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionMessage\": () => (/* binding */ ConnectionMessage),\n/* harmony export */   \"ConnectionMessageImpl\": () => (/* binding */ ConnectionMessageImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common.speech/HeaderNames */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/HeaderNames.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/ConnectionMessage.js\");\n/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PropertyCollection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n// eslint-disable-next-line max-classes-per-file\n\n\n\n\n/**\n * ConnectionMessage represents implementation specific messages sent to and received from\n * the speech service. These messages are provided for debugging purposes and should not\n * be used for production use cases with the Azure Cognitive Services Speech Service.\n * Messages sent to and received from the Speech Service are subject to change without\n * notice. This includes message contents, headers, payloads, ordering, etc.\n * Added in version 1.11.0.\n */\nclass ConnectionMessage {}\nclass ConnectionMessageImpl {\n  constructor(message) {\n    this.privConnectionMessage = message;\n    this.privProperties = new _PropertyCollection__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n    if (!!this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId]) {\n      this.privProperties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Speech_SessionId, this.privConnectionMessage.headers[_common_speech_HeaderNames__WEBPACK_IMPORTED_MODULE_1__.HeaderNames.ConnectionId]);\n    }\n    Object.keys(this.privConnectionMessage.headers).forEach(header => {\n      this.privProperties.setProperty(header, this.privConnectionMessage.headers[header]);\n    });\n  }\n  /**\n   * The message path.\n   */\n  get path() {\n    return this.privConnectionMessage.headers[Object.keys(this.privConnectionMessage.headers).find(key => key.toLowerCase() === \"path\".toLowerCase())];\n  }\n  /**\n   * Checks to see if the ConnectionMessage is a text message.\n   * See also IsBinaryMessage().\n   */\n  get isTextMessage() {\n    return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Text;\n  }\n  /**\n   * Checks to see if the ConnectionMessage is a binary message.\n   * See also GetBinaryMessage().\n   */\n  get isBinaryMessage() {\n    return this.privConnectionMessage.messageType === _common_Exports__WEBPACK_IMPORTED_MODULE_3__.MessageType.Binary;\n  }\n  /**\n   * Gets the text message payload. Typically the text message content-type is\n   * application/json. To determine other content-types use\n   * Properties.GetProperty(\"Content-Type\").\n   */\n  get TextMessage() {\n    return this.privConnectionMessage.textBody;\n  }\n  /**\n   * Gets the binary message payload.\n   */\n  get binaryMessage() {\n    return this.privConnectionMessage.binaryBody;\n  }\n  /**\n   * A collection of properties and their values defined for this <see cref=\"ConnectionMessage\"/>.\n   * Message headers can be accessed via this collection (e.g. \"Content-Type\").\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Returns a string that represents the connection message.\n   */\n  toString() {\n    return \"\";\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConnectionMessageEventArgs\": () => (/* binding */ ConnectionMessageEventArgs)\n/* harmony export */ });\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\nclass ConnectionMessageEventArgs {\n  constructor(message) {\n    this.privConnectionMessage = message;\n  }\n  /**\n   * Gets the <see cref=\"ConnectionMessage\"/> associated with this <see cref=\"ConnectionMessageEventArgs\"/>.\n   */\n  get message() {\n    return this.privConnectionMessage;\n  }\n  /**\n   * Returns a string that represents the connection message event.\n   */\n  toString() {\n    return \"Message: \" + this.privConnectionMessage.toString();\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Contracts\": () => (/* binding */ Contracts)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * @class Contracts\n * @private\n */\nclass Contracts {\n  static throwIfNullOrUndefined(param, name) {\n    if (param === undefined || param === null) {\n      throw new Error(\"throwIfNullOrUndefined:\" + name);\n    }\n  }\n  static throwIfNull(param, name) {\n    if (param === null) {\n      throw new Error(\"throwIfNull:\" + name);\n    }\n  }\n  static throwIfNullOrWhitespace(param, name) {\n    Contracts.throwIfNullOrUndefined(param, name);\n    if ((\"\" + param).trim().length < 1) {\n      throw new Error(\"throwIfNullOrWhitespace:\" + name);\n    }\n  }\n  static throwIfDisposed(isDisposed) {\n    if (isDisposed) {\n      throw new Error(\"the object is already disposed\");\n    }\n  }\n  static throwIfArrayEmptyOrWhitespace(array, name) {\n    Contracts.throwIfNullOrUndefined(array, name);\n    if (array.length === 0) {\n      throw new Error(\"throwIfArrayEmptyOrWhitespace:\" + name);\n    }\n    for (const item of array) {\n      Contracts.throwIfNullOrWhitespace(item, name);\n    }\n  }\n  static throwIfFileDoesNotExist(param, name) {\n    Contracts.throwIfNullOrWhitespace(param, name);\n    // TODO check for file existence.\n  }\n\n  static throwIfNotUndefined(param, name) {\n    if (param !== undefined) {\n      throw new Error(\"throwIfNotUndefined:\" + name);\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranscriptionCanceledEventArgs\": () => (/* binding */ ConversationTranscriptionCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines content of a RecognitionErrorEvent.\n * @class ConversationTranscriptionCanceledEventArgs\n */\nclass ConversationTranscriptionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CustomCommandsConfig\": () => (/* binding */ CustomCommandsConfig)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./DialogServiceConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n/**\n * Class that defines configurations for the dialog service connector object for using a CustomCommands backend.\n * @class CustomCommandsConfig\n */\nclass CustomCommandsConfig extends _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl {\n  /**\n   * Creates an instance of CustomCommandsConfig.\n   */\n  constructor() {\n    super();\n  }\n  /**\n   * Creates an instance of the bot framework config with the specified subscription and region.\n   * @member CustomCommandsConfig.fromSubscription\n   * @function\n   * @public\n   * @param applicationId Speech Commands application id.\n   * @param subscription Subscription key associated with the bot\n   * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {CustomCommandsConfig} A new bot framework config.\n   */\n  static fromSubscription(applicationId, subscription, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(applicationId, \"applicationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(subscription, \"subscription\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.CustomCommands);\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, applicationId);\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscription);\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);\n    return customCommandsConfig;\n  }\n  /**\n   * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.\n   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n   * expires, the caller needs to refresh it by calling this setter with a new valid token.\n   * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.\n   * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer\n   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n   * @member CustomCommandsConfig.fromAuthorizationToken\n   * @function\n   * @public\n   * @param applicationId Speech Commands application id.\n   * @param authorizationToken The authorization token associated with the application.\n   * @param region The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {CustomCommandsConfig} A new speech commands config.\n   */\n  static fromAuthorizationToken(applicationId, authorizationToken, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(applicationId, \"applicationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const customCommandsConfig = new _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfigImpl();\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_DialogType, _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_0__.DialogServiceConfig.DialogTypes.CustomCommands);\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, applicationId);\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n    customCommandsConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);\n    return customCommandsConfig;\n  }\n  /**\n   * Sets the corresponding backend application identifier.\n   * @member CustomCommandsConfig.prototype.Conversation_ApplicationId\n   * @function\n   * @public\n   * @param {string} value - The application identifier to set.\n   */\n  set applicationId(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId, value);\n  }\n  /**\n   * Gets the corresponding backend application identifier.\n   * @member CustomCommandsConfig.prototype.Conversation_ApplicationId\n   * @function\n   * @public\n   * @param {string} value - The application identifier to get.\n   */\n  get applicationId() {\n    return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.Conversation_ApplicationId);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Diagnostics\": () => (/* binding */ Diagnostics)\n/* harmony export */ });\n/* harmony import */ var _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.browser/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.browser/ConsoleLoggingListener.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Events.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n\n/**\n * Defines diagnostics API for managing console output\n * Added in version 1.21.0\n */\nclass Diagnostics {\n  static SetLoggingLevel(logLevel) {\n    this.privListener = new _common_browser_Exports__WEBPACK_IMPORTED_MODULE_0__.ConsoleLoggingListener(logLevel);\n    _common_Exports__WEBPACK_IMPORTED_MODULE_1__.Events.instance.attachConsoleListener(this.privListener);\n  }\n  static SetLogOutputPath(path) {\n    if (typeof window === \"undefined\") {\n      if (!!this.privListener) {\n        this.privListener.logPath = path;\n      }\n    } else {\n      throw new Error(\"File system logging not available in browser.\");\n    }\n  }\n}\nDiagnostics.privListener = undefined;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceConfig\": () => (/* binding */ DialogServiceConfig),\n/* harmony export */   \"DialogServiceConfigImpl\": () => (/* binding */ DialogServiceConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n/**\n * Class that defines base configurations for dialog service connector\n * @class DialogServiceConfig\n */\nclass DialogServiceConfig {\n  /**\n   * Creates an instance of DialogService config.\n   * @constructor\n   */\n  constructor() {\n    return;\n  }\n  /**\n   * Sets the corresponding backend application identifier.\n   * @member DialogServiceConfig.prototype.Conversation_ApplicationId\n   * @function\n   * @public\n   * @param {string} value - The application identifier to set.\n   */\n  // eslint-disable-next-line @typescript-eslint/no-empty-function\n  set applicationId(value) {}\n  static get DialogTypes() {\n    return {\n      BotFramework: \"bot_framework\",\n      CustomCommands: \"custom_commands\"\n    };\n  }\n}\n/**\n * Dialog Service configuration.\n * @class DialogServiceConfigImpl\n */\nclass DialogServiceConfigImpl extends DialogServiceConfig {\n  /**\n   * Creates an instance of dialogService config.\n   */\n  constructor() {\n    super();\n    this.privSpeechConfig = new _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechConfigImpl();\n  }\n  /**\n   * Provides access to custom properties.\n   * @member DialogServiceConfigImpl.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The properties.\n   */\n  get properties() {\n    return this.privSpeechConfig.properties;\n  }\n  /**\n   * Gets the speech recognition language.\n   * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   */\n  get speechRecognitionLanguage() {\n    return this.privSpeechConfig.speechRecognitionLanguage;\n  }\n  /**\n   * Sets the speech recognition language.\n   * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @param {string} value - The language to set.\n   */\n  set speechRecognitionLanguage(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n    this.privSpeechConfig.speechRecognitionLanguage = value;\n  }\n  get outputFormat() {\n    return this.privSpeechConfig.outputFormat;\n  }\n  set outputFormat(value) {\n    this.privSpeechConfig.outputFormat = value;\n  }\n  /**\n   * Sets a named property as value\n   * @member DialogServiceConfigImpl.prototype.setProperty\n   * @function\n   * @public\n   * @param {PropertyId | string} name - The property to set.\n   * @param {string} value - The value.\n   */\n  setProperty(name, value) {\n    this.privSpeechConfig.setProperty(name, value);\n  }\n  /**\n   * Sets a named property as value\n   * @member DialogServiceConfigImpl.prototype.getProperty\n   * @function\n   * @public\n   * @param {PropertyId | string} name - The property to get.\n   * @param {string} def - The default value to return in case the property is not known.\n   * @returns {string} The current value, or provided default, of the given property.\n   */\n  getProperty(name, def) {\n    void def;\n    return this.privSpeechConfig.getProperty(name);\n  }\n  /**\n   * Sets the proxy configuration.\n   * Only relevant in Node.js environments.\n   * Added in version 1.4.0.\n   * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)\n   * @param proxyPort The port number of the proxy server.\n   * @param proxyUserName The user name of the proxy server.\n   * @param proxyPassword The password of the proxy server.\n   */\n  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyHostName, proxyHostName);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPort, `${proxyPort}`);\n    if (proxyUserName) {\n      this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyUserName, proxyUserName);\n    }\n    if (proxyPassword) {\n      this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPassword, proxyPassword);\n    }\n  }\n  setServiceProperty(name, value, channel) {\n    void channel;\n    this.privSpeechConfig.setServiceProperty(name, value);\n  }\n  /**\n   * Dispose of associated resources.\n   * @member DialogServiceConfigImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DialogServiceConnector\": () => (/* binding */ DialogServiceConnector)\n/* harmony export */ });\n/* harmony import */ var _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/DialogConnectorFactory */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogConnectorFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/DialogServiceAdapter.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\n\n/**\n * Dialog Service Connector\n * @class DialogServiceConnector\n */\nclass DialogServiceConnector extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n  /**\n   * Initializes an instance of the DialogServiceConnector.\n   * @constructor\n   * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.\n   * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer\n   */\n  constructor(dialogConfig, audioConfig) {\n    const dialogServiceConfigImpl = dialogConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(dialogConfig, \"dialogConfig\");\n    super(audioConfig, dialogServiceConfigImpl.properties, new _common_speech_DialogConnectorFactory__WEBPACK_IMPORTED_MODULE_2__.DialogConnectionFactory());\n    this.isTurnComplete = true;\n    this.privIsDisposed = false;\n    this.privProperties = dialogServiceConfigImpl.properties.clone();\n    const agentConfig = this.buildAgentConfig();\n    this.privReco.agentConfig.set(agentConfig);\n  }\n  /**\n   * Starts a connection to the service.\n   * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.\n   *\n   * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to\n   * be notified when the connection is established.\n   * @member DialogServiceConnector.prototype.connect\n   * @function\n   * @public\n   */\n  connect(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.privReco.connect(), cb, err);\n  }\n  /**\n   * Closes the connection the service.\n   * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.\n   *\n   * If disconnect() is called during a recognition, recognition will fail and cancel with an error.\n   */\n  disconnect(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.privReco.disconnect(), cb, err);\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member DialogServiceConnector.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Sets the authorization token used to communicate with the service.\n   * @member DialogServiceConnector.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n  set authorizationToken(token) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * The collection of properties and their values defined for this DialogServiceConnector.\n   * @member DialogServiceConnector.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /** Gets the template for the activity generated by service from speech.\n   * Properties from the template will be stamped on the generated activity.\n   * It can be empty\n   */\n  get speechActivityTemplate() {\n    return this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Speech_Activity_Template);\n  }\n  /** Sets the template for the activity generated by service from speech.\n   * Properties from the template will be stamped on the generated activity.\n   * It can be null or empty.\n   * Note: it has to be a valid Json object.\n   */\n  set speechActivityTemplate(speechActivityTemplate) {\n    this.properties.setProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Speech_Activity_Template, speechActivityTemplate);\n  }\n  /**\n   * Starts recognition and stops after the first utterance is recognized.\n   * @member DialogServiceConnector.prototype.listenOnceAsync\n   * @function\n   * @public\n   * @param cb - Callback that received the result when the reco has completed.\n   * @param err - Callback invoked in case of an error.\n   */\n  listenOnceAsync(cb, err) {\n    if (this.isTurnComplete) {\n      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n      const callbackHolder = () => __awaiter(this, void 0, void 0, function* () {\n        yield this.privReco.connect();\n        yield this.implRecognizerStop();\n        this.isTurnComplete = false;\n        const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Deferred();\n        yield this.privReco.recognize(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation, ret.resolve, ret.reject);\n        const e = yield ret.promise;\n        yield this.implRecognizerStop();\n        return e;\n      });\n      const retPromise = callbackHolder();\n      retPromise.catch(() => {\n        // Destroy the recognizer.\n        // We've done all we can here.\n        // eslint-disable-next-line @typescript-eslint/no-empty-function\n        this.dispose(true).catch(() => {});\n      });\n      (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(retPromise.finally(() => {\n        this.isTurnComplete = true;\n      }), cb, err);\n    }\n  }\n  sendActivityAsync(activity, cb, errCb) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.privReco.sendMessage(activity), cb, errCb);\n  }\n  /**\n   * closes all external resources held by an instance of this class.\n   * @member DialogServiceConnector.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privIsDisposed);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.dispose(true), cb, err);\n  }\n  dispose(disposing) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privIsDisposed) {\n        return;\n      }\n      if (disposing) {\n        this.privIsDisposed = true;\n        yield this.implRecognizerStop();\n        yield _super.dispose.call(this, disposing);\n      }\n    });\n  }\n  createRecognizerConfig(speechConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.privProperties);\n  }\n  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n    const audioSource = audioConfig;\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.DialogServiceAdapter(authentication, connectionFactory, audioSource, recognizerConfig, this);\n  }\n  buildAgentConfig() {\n    const communicationType = this.properties.getProperty(\"Conversation_Communication_Type\", \"Default\");\n    return {\n      botInfo: {\n        commType: communicationType,\n        commandsCulture: undefined,\n        connectionId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Agent_Connection_Id),\n        conversationId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_Conversation_Id, undefined),\n        fromId: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.Conversation_From_Id, undefined),\n        ttsAudioFormat: this.properties.getProperty(_PropertyId__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)\n      },\n      version: 0.2\n    };\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ActivityReceivedEventArgs\": () => (/* reexport safe */ _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__.ActivityReceivedEventArgs),\n/* harmony export */   \"AudioConfig\": () => (/* reexport safe */ _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__.AudioConfig),\n/* harmony export */   \"AudioFormatTag\": () => (/* reexport safe */ _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__.AudioFormatTag),\n/* harmony export */   \"AudioInputStream\": () => (/* reexport safe */ _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__.AudioInputStream),\n/* harmony export */   \"AudioOutputStream\": () => (/* reexport safe */ _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.AudioOutputStream),\n/* harmony export */   \"AudioStreamFormat\": () => (/* reexport safe */ _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__.AudioStreamFormat),\n/* harmony export */   \"AutoDetectSourceLanguageConfig\": () => (/* reexport safe */ _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__.AutoDetectSourceLanguageConfig),\n/* harmony export */   \"AutoDetectSourceLanguageResult\": () => (/* reexport safe */ _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__.AutoDetectSourceLanguageResult),\n/* harmony export */   \"BaseAudioPlayer\": () => (/* reexport safe */ _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__.BaseAudioPlayer),\n/* harmony export */   \"BotFrameworkConfig\": () => (/* reexport safe */ _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__.BotFrameworkConfig),\n/* harmony export */   \"CancellationDetails\": () => (/* reexport safe */ _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__.CancellationDetails),\n/* harmony export */   \"CancellationDetailsBase\": () => (/* reexport safe */ _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__.CancellationDetailsBase),\n/* harmony export */   \"CancellationErrorCode\": () => (/* reexport safe */ _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__.CancellationErrorCode),\n/* harmony export */   \"CancellationReason\": () => (/* reexport safe */ _CancellationReason__WEBPACK_IMPORTED_MODULE_4__.CancellationReason),\n/* harmony export */   \"Connection\": () => (/* reexport safe */ _Connection__WEBPACK_IMPORTED_MODULE_42__.Connection),\n/* harmony export */   \"ConnectionEventArgs\": () => (/* reexport safe */ _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__.ConnectionEventArgs),\n/* harmony export */   \"ConnectionMessage\": () => (/* reexport safe */ _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__.ConnectionMessage),\n/* harmony export */   \"ConnectionMessageEventArgs\": () => (/* reexport safe */ _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__.ConnectionMessageEventArgs),\n/* harmony export */   \"Conversation\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__.Conversation),\n/* harmony export */   \"ConversationExpirationEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_68__.ConversationExpirationEventArgs),\n/* harmony export */   \"ConversationParticipantsChangedEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_69__.ConversationParticipantsChangedEventArgs),\n/* harmony export */   \"ConversationTranscriber\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_74__.ConversationTranscriber),\n/* harmony export */   \"ConversationTranscriptionCanceledEventArgs\": () => (/* reexport safe */ _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_89__.ConversationTranscriptionCanceledEventArgs),\n/* harmony export */   \"ConversationTranscriptionEventArgs\": () => (/* reexport safe */ _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__.ConversationTranscriptionEventArgs),\n/* harmony export */   \"ConversationTranslationCanceledEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_70__.ConversationTranslationCanceledEventArgs),\n/* harmony export */   \"ConversationTranslationEventArgs\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_71__.ConversationTranslationEventArgs),\n/* harmony export */   \"ConversationTranslationResult\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_72__.ConversationTranslationResult),\n/* harmony export */   \"ConversationTranslator\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_73__.ConversationTranslator),\n/* harmony export */   \"CustomCommandsConfig\": () => (/* reexport safe */ _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__.CustomCommandsConfig),\n/* harmony export */   \"Diagnostics\": () => (/* reexport safe */ _Diagnostics__WEBPACK_IMPORTED_MODULE_96__.Diagnostics),\n/* harmony export */   \"DialogServiceConfig\": () => (/* reexport safe */ _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__.DialogServiceConfig),\n/* harmony export */   \"DialogServiceConnector\": () => (/* reexport safe */ _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__.DialogServiceConnector),\n/* harmony export */   \"IntentRecognitionCanceledEventArgs\": () => (/* reexport safe */ _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__.IntentRecognitionCanceledEventArgs),\n/* harmony export */   \"IntentRecognitionEventArgs\": () => (/* reexport safe */ _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__.IntentRecognitionEventArgs),\n/* harmony export */   \"IntentRecognitionResult\": () => (/* reexport safe */ _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__.IntentRecognitionResult),\n/* harmony export */   \"IntentRecognizer\": () => (/* reexport safe */ _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__.IntentRecognizer),\n/* harmony export */   \"KeywordRecognitionModel\": () => (/* reexport safe */ _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__.KeywordRecognitionModel),\n/* harmony export */   \"LanguageIdMode\": () => (/* reexport safe */ _LanguageIdMode__WEBPACK_IMPORTED_MODULE_94__.LanguageIdMode),\n/* harmony export */   \"LanguageIdPriority\": () => (/* reexport safe */ _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_95__.LanguageIdPriority),\n/* harmony export */   \"LanguageUnderstandingModel\": () => (/* reexport safe */ _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__.LanguageUnderstandingModel),\n/* harmony export */   \"LogLevel\": () => (/* reexport safe */ _LogLevel__WEBPACK_IMPORTED_MODULE_97__.EventType),\n/* harmony export */   \"NoMatchDetails\": () => (/* reexport safe */ _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__.NoMatchDetails),\n/* harmony export */   \"NoMatchReason\": () => (/* reexport safe */ _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__.NoMatchReason),\n/* harmony export */   \"OutputFormat\": () => (/* reexport safe */ _OutputFormat__WEBPACK_IMPORTED_MODULE_10__.OutputFormat),\n/* harmony export */   \"Participant\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_75__.Participant),\n/* harmony export */   \"ParticipantChangedReason\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_76__.ParticipantChangedReason),\n/* harmony export */   \"PhraseListGrammar\": () => (/* reexport safe */ _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__.PhraseListGrammar),\n/* harmony export */   \"ProfanityOption\": () => (/* reexport safe */ _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__.ProfanityOption),\n/* harmony export */   \"PronunciationAssessmentConfig\": () => (/* reexport safe */ _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_92__.PronunciationAssessmentConfig),\n/* harmony export */   \"PronunciationAssessmentGradingSystem\": () => (/* reexport safe */ _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_90__.PronunciationAssessmentGradingSystem),\n/* harmony export */   \"PronunciationAssessmentGranularity\": () => (/* reexport safe */ _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_91__.PronunciationAssessmentGranularity),\n/* harmony export */   \"PronunciationAssessmentResult\": () => (/* reexport safe */ _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_93__.PronunciationAssessmentResult),\n/* harmony export */   \"PropertyCollection\": () => (/* reexport safe */ _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__.PropertyCollection),\n/* harmony export */   \"PropertyId\": () => (/* reexport safe */ _PropertyId__WEBPACK_IMPORTED_MODULE_26__.PropertyId),\n/* harmony export */   \"PullAudioInputStream\": () => (/* reexport safe */ _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__.PullAudioInputStream),\n/* harmony export */   \"PullAudioInputStreamCallback\": () => (/* reexport safe */ _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__.PullAudioInputStreamCallback),\n/* harmony export */   \"PullAudioOutputStream\": () => (/* reexport safe */ _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PullAudioOutputStream),\n/* harmony export */   \"PushAudioInputStream\": () => (/* reexport safe */ _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__.PushAudioInputStream),\n/* harmony export */   \"PushAudioOutputStream\": () => (/* reexport safe */ _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__.PushAudioOutputStream),\n/* harmony export */   \"PushAudioOutputStreamCallback\": () => (/* reexport safe */ _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__.PushAudioOutputStreamCallback),\n/* harmony export */   \"RecognitionEventArgs\": () => (/* reexport safe */ _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__.RecognitionEventArgs),\n/* harmony export */   \"RecognitionResult\": () => (/* reexport safe */ _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__.RecognitionResult),\n/* harmony export */   \"Recognizer\": () => (/* reexport safe */ _Recognizer__WEBPACK_IMPORTED_MODULE_27__.Recognizer),\n/* harmony export */   \"ResultReason\": () => (/* reexport safe */ _ResultReason__WEBPACK_IMPORTED_MODULE_22__.ResultReason),\n/* harmony export */   \"ServiceEventArgs\": () => (/* reexport safe */ _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__.ServiceEventArgs),\n/* harmony export */   \"ServicePropertyChannel\": () => (/* reexport safe */ _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__.ServicePropertyChannel),\n/* harmony export */   \"SessionEventArgs\": () => (/* reexport safe */ _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__.SessionEventArgs),\n/* harmony export */   \"SourceLanguageConfig\": () => (/* reexport safe */ _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__.SourceLanguageConfig),\n/* harmony export */   \"SpeakerAudioDestination\": () => (/* reexport safe */ _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_88__.SpeakerAudioDestination),\n/* harmony export */   \"SpeakerIdentificationModel\": () => (/* reexport safe */ _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__.SpeakerIdentificationModel),\n/* harmony export */   \"SpeakerRecognitionCancellationDetails\": () => (/* reexport safe */ _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__.SpeakerRecognitionCancellationDetails),\n/* harmony export */   \"SpeakerRecognitionResult\": () => (/* reexport safe */ _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__.SpeakerRecognitionResult),\n/* harmony export */   \"SpeakerRecognitionResultType\": () => (/* reexport safe */ _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__.SpeakerRecognitionResultType),\n/* harmony export */   \"SpeakerRecognizer\": () => (/* reexport safe */ _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__.SpeakerRecognizer),\n/* harmony export */   \"SpeakerVerificationModel\": () => (/* reexport safe */ _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__.SpeakerVerificationModel),\n/* harmony export */   \"SpeechConfig\": () => (/* reexport safe */ _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__.SpeechConfig),\n/* harmony export */   \"SpeechConfigImpl\": () => (/* reexport safe */ _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__.SpeechConfigImpl),\n/* harmony export */   \"SpeechRecognitionCanceledEventArgs\": () => (/* reexport safe */ _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__.SpeechRecognitionCanceledEventArgs),\n/* harmony export */   \"SpeechRecognitionEventArgs\": () => (/* reexport safe */ _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__.SpeechRecognitionEventArgs),\n/* harmony export */   \"SpeechRecognitionResult\": () => (/* reexport safe */ _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__.SpeechRecognitionResult),\n/* harmony export */   \"SpeechRecognizer\": () => (/* reexport safe */ _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__.SpeechRecognizer),\n/* harmony export */   \"SpeechSynthesisBookmarkEventArgs\": () => (/* reexport safe */ _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_83__.SpeechSynthesisBookmarkEventArgs),\n/* harmony export */   \"SpeechSynthesisBoundaryType\": () => (/* reexport safe */ _SpeechSynthesisBoundaryType__WEBPACK_IMPORTED_MODULE_85__.SpeechSynthesisBoundaryType),\n/* harmony export */   \"SpeechSynthesisEventArgs\": () => (/* reexport safe */ _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_81__.SpeechSynthesisEventArgs),\n/* harmony export */   \"SpeechSynthesisOutputFormat\": () => (/* reexport safe */ _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_77__.SpeechSynthesisOutputFormat),\n/* harmony export */   \"SpeechSynthesisResult\": () => (/* reexport safe */ _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_80__.SpeechSynthesisResult),\n/* harmony export */   \"SpeechSynthesisVisemeEventArgs\": () => (/* reexport safe */ _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_84__.SpeechSynthesisVisemeEventArgs),\n/* harmony export */   \"SpeechSynthesisWordBoundaryEventArgs\": () => (/* reexport safe */ _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_82__.SpeechSynthesisWordBoundaryEventArgs),\n/* harmony export */   \"SpeechSynthesizer\": () => (/* reexport safe */ _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_78__.SpeechSynthesizer),\n/* harmony export */   \"SpeechTranslationConfig\": () => (/* reexport safe */ _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__.SpeechTranslationConfig),\n/* harmony export */   \"SpeechTranslationConfigImpl\": () => (/* reexport safe */ _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__.SpeechTranslationConfigImpl),\n/* harmony export */   \"SynthesisResult\": () => (/* reexport safe */ _SynthesisResult__WEBPACK_IMPORTED_MODULE_79__.SynthesisResult),\n/* harmony export */   \"SynthesisVoicesResult\": () => (/* reexport safe */ _SynthesisVoicesResult__WEBPACK_IMPORTED_MODULE_86__.SynthesisVoicesResult),\n/* harmony export */   \"TranslationRecognitionCanceledEventArgs\": () => (/* reexport safe */ _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__.TranslationRecognitionCanceledEventArgs),\n/* harmony export */   \"TranslationRecognitionEventArgs\": () => (/* reexport safe */ _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__.TranslationRecognitionEventArgs),\n/* harmony export */   \"TranslationRecognitionResult\": () => (/* reexport safe */ _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__.TranslationRecognitionResult),\n/* harmony export */   \"TranslationRecognizer\": () => (/* reexport safe */ _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__.TranslationRecognizer),\n/* harmony export */   \"TranslationSynthesisEventArgs\": () => (/* reexport safe */ _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__.TranslationSynthesisEventArgs),\n/* harmony export */   \"TranslationSynthesisResult\": () => (/* reexport safe */ _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__.TranslationSynthesisResult),\n/* harmony export */   \"Translations\": () => (/* reexport safe */ _Translations__WEBPACK_IMPORTED_MODULE_32__.Translations),\n/* harmony export */   \"TurnStatusReceivedEventArgs\": () => (/* reexport safe */ _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__.TurnStatusReceivedEventArgs),\n/* harmony export */   \"User\": () => (/* reexport safe */ _Transcription_Exports__WEBPACK_IMPORTED_MODULE_75__.User),\n/* harmony export */   \"VoiceInfo\": () => (/* reexport safe */ _VoiceInfo__WEBPACK_IMPORTED_MODULE_87__.VoiceInfo),\n/* harmony export */   \"VoiceProfile\": () => (/* reexport safe */ _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__.VoiceProfile),\n/* harmony export */   \"VoiceProfileCancellationDetails\": () => (/* reexport safe */ _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__.VoiceProfileCancellationDetails),\n/* harmony export */   \"VoiceProfileClient\": () => (/* reexport safe */ _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__.VoiceProfileClient),\n/* harmony export */   \"VoiceProfileEnrollmentCancellationDetails\": () => (/* reexport safe */ _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__.VoiceProfileEnrollmentCancellationDetails),\n/* harmony export */   \"VoiceProfileEnrollmentResult\": () => (/* reexport safe */ _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__.VoiceProfileEnrollmentResult),\n/* harmony export */   \"VoiceProfilePhraseResult\": () => (/* reexport safe */ _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__.VoiceProfilePhraseResult),\n/* harmony export */   \"VoiceProfileResult\": () => (/* reexport safe */ _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__.VoiceProfileResult),\n/* harmony export */   \"VoiceProfileType\": () => (/* reexport safe */ _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__.VoiceProfileType)\n/* harmony export */ });\n/* harmony import */ var _Audio_AudioConfig__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Audio/AudioConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony import */ var _Audio_AudioStreamFormat__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Audio/AudioStreamFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioStreamFormat.js\");\n/* harmony import */ var _Audio_AudioInputStream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Audio/AudioInputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioInputStream.js\");\n/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Audio/AudioOutputStream */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _CancellationReason__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./CancellationReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _Audio_PullAudioInputStreamCallback__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Audio/PullAudioInputStreamCallback */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PullAudioInputStreamCallback.js\");\n/* harmony import */ var _Audio_PushAudioOutputStreamCallback__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Audio/PushAudioOutputStreamCallback */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js\");\n/* harmony import */ var _KeywordRecognitionModel__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./KeywordRecognitionModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js\");\n/* harmony import */ var _SessionEventArgs__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./SessionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n/* harmony import */ var _RecognitionEventArgs__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./RecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n/* harmony import */ var _OutputFormat__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./OutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _IntentRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./IntentRecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js\");\n/* harmony import */ var _RecognitionResult__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./RecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js\");\n/* harmony import */ var _SpeechRecognitionResult__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SpeechRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n/* harmony import */ var _IntentRecognitionResult__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./IntentRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js\");\n/* harmony import */ var _LanguageUnderstandingModel__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./LanguageUnderstandingModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js\");\n/* harmony import */ var _SpeechRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./SpeechRecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js\");\n/* harmony import */ var _SpeechRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./SpeechRecognitionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _TranslationRecognitionEventArgs__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./TranslationRecognitionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js\");\n/* harmony import */ var _TranslationSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./TranslationSynthesisEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js\");\n/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./TranslationRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n/* harmony import */ var _TranslationSynthesisResult__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./TranslationSynthesisResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js\");\n/* harmony import */ var _ResultReason__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./ResultReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _SpeechConfig__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./SpeechConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js\");\n/* harmony import */ var _SpeechTranslationConfig__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./SpeechTranslationConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js\");\n/* harmony import */ var _PropertyCollection__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./PropertyCollection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _PropertyId__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./PropertyId */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Recognizer__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./Recognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _SpeechRecognizer__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./SpeechRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js\");\n/* harmony import */ var _IntentRecognizer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./IntentRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js\");\n/* harmony import */ var _VoiceProfileType__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./VoiceProfileType */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n/* harmony import */ var _TranslationRecognizer__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./TranslationRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js\");\n/* harmony import */ var _Translations__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./Translations */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js\");\n/* harmony import */ var _NoMatchReason__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./NoMatchReason */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js\");\n/* harmony import */ var _NoMatchDetails__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./NoMatchDetails */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js\");\n/* harmony import */ var _TranslationRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./TranslationRecognitionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _IntentRecognitionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./IntentRecognitionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js\");\n/* harmony import */ var _CancellationDetailsBase__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./CancellationDetailsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _CancellationDetails__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./CancellationDetails */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetails.js\");\n/* harmony import */ var _CancellationErrorCodes__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./CancellationErrorCodes */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _ConnectionEventArgs__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./ConnectionEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionEventArgs.js\");\n/* harmony import */ var _ServiceEventArgs__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./ServiceEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js\");\n/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./Connection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n/* harmony import */ var _PhraseListGrammar__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./PhraseListGrammar */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js\");\n/* harmony import */ var _DialogServiceConfig__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./DialogServiceConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConfig.js\");\n/* harmony import */ var _BotFrameworkConfig__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./BotFrameworkConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/BotFrameworkConfig.js\");\n/* harmony import */ var _CustomCommandsConfig__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./CustomCommandsConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CustomCommandsConfig.js\");\n/* harmony import */ var _DialogServiceConnector__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./DialogServiceConnector */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/DialogServiceConnector.js\");\n/* harmony import */ var _ActivityReceivedEventArgs__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./ActivityReceivedEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ActivityReceivedEventArgs.js\");\n/* harmony import */ var _TurnStatusReceivedEventArgs__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./TurnStatusReceivedEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js\");\n/* harmony import */ var _ServicePropertyChannel__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./ServicePropertyChannel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js\");\n/* harmony import */ var _ProfanityOption__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./ProfanityOption */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony import */ var _Audio_BaseAudioPlayer__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./Audio/BaseAudioPlayer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/BaseAudioPlayer.js\");\n/* harmony import */ var _ConnectionMessageEventArgs__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./ConnectionMessageEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessageEventArgs.js\");\n/* harmony import */ var _ConnectionMessage__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./ConnectionMessage */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConnectionMessage.js\");\n/* harmony import */ var _VoiceProfile__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./VoiceProfile */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js\");\n/* harmony import */ var _VoiceProfileEnrollmentResult__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./VoiceProfileEnrollmentResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js\");\n/* harmony import */ var _VoiceProfileResult__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./VoiceProfileResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js\");\n/* harmony import */ var _VoiceProfilePhraseResult__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./VoiceProfilePhraseResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js\");\n/* harmony import */ var _VoiceProfileClient__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./VoiceProfileClient */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js\");\n/* harmony import */ var _SpeakerRecognizer__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./SpeakerRecognizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js\");\n/* harmony import */ var _SpeakerIdentificationModel__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./SpeakerIdentificationModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js\");\n/* harmony import */ var _SpeakerVerificationModel__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./SpeakerVerificationModel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js\");\n/* harmony import */ var _AutoDetectSourceLanguageConfig__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./AutoDetectSourceLanguageConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageConfig.js\");\n/* harmony import */ var _AutoDetectSourceLanguageResult__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./AutoDetectSourceLanguageResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/AutoDetectSourceLanguageResult.js\");\n/* harmony import */ var _SourceLanguageConfig__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./SourceLanguageConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js\");\n/* harmony import */ var _SpeakerRecognitionResult__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./SpeakerRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js\");\n/* harmony import */ var _Transcription_Exports__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./Transcription/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js\");\n/* harmony import */ var _SpeechSynthesisOutputFormat__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./SpeechSynthesisOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n/* harmony import */ var _SpeechSynthesizer__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./SpeechSynthesizer */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js\");\n/* harmony import */ var _SynthesisResult__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./SynthesisResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js\");\n/* harmony import */ var _SpeechSynthesisResult__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./SpeechSynthesisResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js\");\n/* harmony import */ var _SpeechSynthesisEventArgs__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./SpeechSynthesisEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js\");\n/* harmony import */ var _SpeechSynthesisWordBoundaryEventArgs__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./SpeechSynthesisWordBoundaryEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js\");\n/* harmony import */ var _SpeechSynthesisBookmarkEventArgs__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./SpeechSynthesisBookmarkEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js\");\n/* harmony import */ var _SpeechSynthesisVisemeEventArgs__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./SpeechSynthesisVisemeEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js\");\n/* harmony import */ var _SpeechSynthesisBoundaryType__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./SpeechSynthesisBoundaryType */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js\");\n/* harmony import */ var _SynthesisVoicesResult__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./SynthesisVoicesResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js\");\n/* harmony import */ var _VoiceInfo__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./VoiceInfo */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js\");\n/* harmony import */ var _Audio_SpeakerAudioDestination__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./Audio/SpeakerAudioDestination */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/SpeakerAudioDestination.js\");\n/* harmony import */ var _ConversationTranscriptionCanceledEventArgs__WEBPACK_IMPORTED_MODULE_89__ = __webpack_require__(/*! ./ConversationTranscriptionCanceledEventArgs */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ConversationTranscriptionCanceledEventArgs.js\");\n/* harmony import */ var _PronunciationAssessmentGradingSystem__WEBPACK_IMPORTED_MODULE_90__ = __webpack_require__(/*! ./PronunciationAssessmentGradingSystem */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js\");\n/* harmony import */ var _PronunciationAssessmentGranularity__WEBPACK_IMPORTED_MODULE_91__ = __webpack_require__(/*! ./PronunciationAssessmentGranularity */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js\");\n/* harmony import */ var _PronunciationAssessmentConfig__WEBPACK_IMPORTED_MODULE_92__ = __webpack_require__(/*! ./PronunciationAssessmentConfig */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js\");\n/* harmony import */ var _PronunciationAssessmentResult__WEBPACK_IMPORTED_MODULE_93__ = __webpack_require__(/*! ./PronunciationAssessmentResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js\");\n/* harmony import */ var _LanguageIdMode__WEBPACK_IMPORTED_MODULE_94__ = __webpack_require__(/*! ./LanguageIdMode */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js\");\n/* harmony import */ var _LanguageIdPriority__WEBPACK_IMPORTED_MODULE_95__ = __webpack_require__(/*! ./LanguageIdPriority */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js\");\n/* harmony import */ var _Diagnostics__WEBPACK_IMPORTED_MODULE_96__ = __webpack_require__(/*! ./Diagnostics */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Diagnostics.js\");\n/* harmony import */ var _LogLevel__WEBPACK_IMPORTED_MODULE_97__ = __webpack_require__(/*! ./LogLevel */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/PlatformEvent.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Exports.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognitionCanceledEventArgs\": () => (/* binding */ IntentRecognitionCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Define payload of intent recognition canceled result events.\n * @class IntentRecognitionCanceledEventArgs\n */\nclass IntentRecognitionCanceledEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.IntentRecognitionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {CancellationReason} result - The result of the intent recognition.\n   * @param {string} offset - The offset.\n   * @param {IntentRecognitionResult} sessionId - The session id.\n   */\n  constructor(reason, errorDetails, errorCode, result, offset, sessionId) {\n    super(result, offset, sessionId);\n    this.privReason = reason;\n    this.privErrorDetails = errorDetails;\n    this.privErrorCode = errorCode;\n  }\n  /**\n   * The reason the recognition was canceled.\n   * @member IntentRecognitionCanceledEventArgs.prototype.reason\n   * @function\n   * @public\n   * @returns {CancellationReason} Specifies the reason canceled.\n   */\n  get reason() {\n    return this.privReason;\n  }\n  /**\n   * The error code in case of an unsuccessful recognition.\n   * Added in version 1.1.0.\n   * @return An error code that represents the error reason.\n   */\n  get errorCode() {\n    return this.privErrorCode;\n  }\n  /**\n   * In case of an unsuccessful recognition, provides details of the occurred error.\n   * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails\n   * @function\n   * @public\n   * @returns {string} A String that represents the error details.\n   */\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognitionEventArgs\": () => (/* binding */ IntentRecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Intent recognition result event arguments.\n * @class\n */\nclass IntentRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param result - The result of the intent recognition.\n   * @param offset - The offset.\n   * @param sessionId - The session id.\n   */\n  constructor(result, offset, sessionId) {\n    super(offset, sessionId);\n    this.privResult = result;\n  }\n  /**\n   * Represents the intent recognition result.\n   * @member IntentRecognitionEventArgs.prototype.result\n   * @function\n   * @public\n   * @returns {IntentRecognitionResult} Represents the intent recognition result.\n   */\n  get result() {\n    return this.privResult;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognitionResult\": () => (/* binding */ IntentRecognitionResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Intent recognition result.\n * @class\n */\nclass IntentRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognitionResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param intentId - The intent id.\n   * @param resultId - The result id.\n   * @param reason - The reason.\n   * @param text - The recognized text.\n   * @param duration - The duration.\n   * @param offset - The offset into the stream.\n   * @param language - Primary Language detected, if provided.\n   * @param languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n   * @param errorDetails - Error details, if provided.\n   * @param json - Additional Json, if provided.\n   * @param properties - Additional properties, if provided.\n   */\n  constructor(intentId, resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, undefined, errorDetails, json, properties);\n    this.privIntentId = intentId;\n  }\n  /**\n   * A String that represents the intent identifier being recognized.\n   * @member IntentRecognitionResult.prototype.intentId\n   * @function\n   * @public\n   * @returns {string} A String that represents the intent identifier being recognized.\n   */\n  get intentId() {\n    return this.privIntentId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntentRecognizer\": () => (/* binding */ IntentRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentConnectionFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/AddedLmIntent.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/IntentServiceRecognizer.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n/**\n * Intent recognizer.\n * @class\n */\nclass IntentRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n  /**\n   * Initializes an instance of the IntentRecognizer.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - The set of configuration properties.\n   * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer\n   */\n  constructor(speechConfig, audioConfig) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(speechConfig, \"speechConfig\");\n    const configImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(configImpl, \"speechConfig\");\n    super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.IntentConnectionFactory());\n    this.privAddedIntents = [];\n    this.privAddedLmIntents = {};\n    this.privDisposedIntentRecognizer = false;\n    this.privProperties = configImpl.properties;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n  }\n  /**\n   * Gets the spoken language of recognition.\n   * @member IntentRecognizer.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @returns {string} the spoken language of recognition.\n   */\n  get speechRecognitionLanguage() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage);\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member IntentRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.\n   * @member IntentRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} value - Authorization token.\n   */\n  set authorizationToken(value) {\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token, value);\n  }\n  /**\n   * The collection of properties and their values defined for this IntentRecognizer.\n   * @member IntentRecognizer.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their\n   * values defined for this IntentRecognizer.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Starts intent recognition, and stops after the first utterance is recognized.\n   * The task returns the recognition text and intent as result.\n   * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n   * so it is suitable only for single shot recognition like command or query.\n   * For long-running recognition, use StartContinuousRecognitionAsync() instead.\n   * @member IntentRecognizer.prototype.recognizeOnceAsync\n   * @function\n   * @public\n   * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.\n   * @param err - Callback invoked in case of an error.\n   */\n  recognizeOnceAsync(cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n    if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {\n      const context = this.buildSpeechContext();\n      this.privReco.speechContext.setSection(\"intent\", context.Intent);\n      this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);\n      const intentReco = this.privReco;\n      intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);\n    }\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Interactive), cb, err);\n  }\n  /**\n   * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n   * User must subscribe to events to receive recognition results.\n   * @member IntentRecognizer.prototype.startContinuousRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the recognition has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  startContinuousRecognitionAsync(cb, err) {\n    if (Object.keys(this.privAddedLmIntents).length !== 0 || undefined !== this.privUmbrellaIntent) {\n      const context = this.buildSpeechContext();\n      this.privReco.speechContext.setSection(\"intent\", context.Intent);\n      this.privReco.dynamicGrammar.addReferenceGrammar(context.ReferenceGrammars);\n      const intentReco = this.privReco;\n      intentReco.setIntents(this.privAddedLmIntents, this.privUmbrellaIntent);\n    }\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);\n  }\n  /**\n   * Stops continuous intent recognition.\n   * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the recognition has stopped.\n   * @param err - Callback invoked in case of an error.\n   */\n  stopContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n  }\n  /**\n   * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.\n   * User must subscribe to events to receive recognition results.\n   * Note: Key word spotting functionality is only available on the Speech Devices SDK.\n   * This functionality is currently not included in the SDK itself.\n   * @member IntentRecognizer.prototype.startKeywordRecognitionAsync\n   * @function\n   * @public\n   * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.\n   * @param cb - Callback invoked once the recognition has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  startKeywordRecognitionAsync(model, cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, \"model\");\n    if (!!err) {\n      err(\"Not yet implemented.\");\n    }\n  }\n  /**\n   * Stops continuous speech recognition.\n   * Note: Key word spotting functionality is only available on the Speech Devices SDK.\n   * This functionality is currently not included in the SDK itself.\n   * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the recognition has stopped.\n   * @param err - Callback invoked in case of an error.\n   */\n  stopKeywordRecognitionAsync(cb, err) {\n    if (!!cb) {\n      try {\n        cb();\n      } catch (e) {\n        if (!!err) {\n          err(e);\n        }\n      }\n    }\n  }\n  /**\n   * Adds a phrase that should be recognized as intent.\n   * @member IntentRecognizer.prototype.addIntent\n   * @function\n   * @public\n   * @param {string} intentId - A String that represents the identifier of the intent to be recognized.\n   * @param {string} phrase - A String that specifies the phrase representing the intent.\n   */\n  addIntent(simplePhrase, intentId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(intentId, \"intentId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(simplePhrase, \"simplePhrase\");\n    this.privAddedIntents.push([intentId, simplePhrase]);\n  }\n  /**\n   * Adds an intent from Language Understanding service for recognition.\n   * @member IntentRecognizer.prototype.addIntentWithLanguageModel\n   * @function\n   * @public\n   * @param {string} intentId - A String that represents the identifier of the intent\n   * to be recognized. Ignored if intentName is empty.\n   * @param {string} model - The intent model from Language Understanding service.\n   * @param {string} intentName - The intent name defined in the intent model. If it\n   * is empty, all intent names defined in the model will be added.\n   */\n  addIntentWithLanguageModel(intentId, model, intentName) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(intentId, \"intentId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, \"model\");\n    const modelImpl = model;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(modelImpl.appId, \"model.appId\");\n    this.privAddedLmIntents[intentId] = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.AddedLmIntent(modelImpl, intentName);\n  }\n  /**\n   * @summary Adds all intents from the specified Language Understanding Model.\n   * @member IntentRecognizer.prototype.addAllIntents\n   * @function\n   * @public\n   * @function\n   * @public\n   * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.\n   * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.\n   */\n  addAllIntents(model, intentId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, \"model\");\n    const modelImpl = model;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(modelImpl.appId, \"model.appId\");\n    this.privUmbrellaIntent = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.AddedLmIntent(modelImpl, intentId);\n  }\n  /**\n   * closes all external resources held by an instance of this class.\n   * @member IntentRecognizer.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, errorCb) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedIntentRecognizer);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n  }\n  createRecognizerConfig(speechConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.properties);\n  }\n  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n    const audioImpl = audioConfig;\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.IntentServiceRecognizer(authentication, connectionFactory, audioImpl, recognizerConfig, this);\n  }\n  dispose(disposing) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposedIntentRecognizer) {\n        return;\n      }\n      if (disposing) {\n        this.privDisposedIntentRecognizer = true;\n        yield _super.dispose.call(this, disposing);\n      }\n    });\n  }\n  buildSpeechContext() {\n    let appId;\n    let region;\n    let subscriptionKey;\n    const refGrammers = [];\n    if (undefined !== this.privUmbrellaIntent) {\n      appId = this.privUmbrellaIntent.modelImpl.appId;\n      region = this.privUmbrellaIntent.modelImpl.region;\n      subscriptionKey = this.privUmbrellaIntent.modelImpl.subscriptionKey;\n    }\n    // Build the reference grammer array.\n    for (const intentId of Object.keys(this.privAddedLmIntents)) {\n      const addedLmIntent = this.privAddedLmIntents[intentId];\n      // validate all the same model, region, and key...\n      if (appId === undefined) {\n        appId = addedLmIntent.modelImpl.appId;\n      } else {\n        if (appId !== addedLmIntent.modelImpl.appId) {\n          throw new Error(\"Intents must all be from the same LUIS model\");\n        }\n      }\n      if (region === undefined) {\n        region = addedLmIntent.modelImpl.region;\n      } else {\n        if (region !== addedLmIntent.modelImpl.region) {\n          throw new Error(\"Intents must all be from the same LUIS model in a single region\");\n        }\n      }\n      if (subscriptionKey === undefined) {\n        subscriptionKey = addedLmIntent.modelImpl.subscriptionKey;\n      } else {\n        if (subscriptionKey !== addedLmIntent.modelImpl.subscriptionKey) {\n          throw new Error(\"Intents must all use the same subscription key\");\n        }\n      }\n      const grammer = \"luis/\" + appId + \"-PRODUCTION#\" + intentId;\n      refGrammers.push(grammer);\n    }\n    return {\n      Intent: {\n        id: appId,\n        key: subscriptionKey === undefined ? this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_Key]) : subscriptionKey,\n        provider: \"LUIS\"\n      },\n      ReferenceGrammars: undefined === this.privUmbrellaIntent ? refGrammers : [\"luis/\" + appId + \"-PRODUCTION\"]\n    };\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/IntentRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"KeywordRecognitionModel\": () => (/* binding */ KeywordRecognitionModel)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents a keyword recognition model for recognizing when\n * the user says a keyword to initiate further speech recognition.\n * @class KeywordRecognitionModel\n */\nclass KeywordRecognitionModel {\n  /**\n   * Create and initializes a new instance.\n   * @constructor\n   */\n  constructor() {\n    this.privDisposed = false;\n    return;\n  }\n  /**\n   * Creates a keyword recognition model using the specified filename.\n   * @member KeywordRecognitionModel.fromFile\n   * @function\n   * @public\n   * @param {string} fileName - A string that represents file name for the keyword recognition model.\n   * Note, the file can point to a zip file in which case the model\n   * will be extracted from the zip.\n   * @returns {KeywordRecognitionModel} The keyword recognition model being created.\n   */\n  static fromFile(fileName) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfFileDoesNotExist(fileName, \"fileName\");\n    throw new Error(\"Not yet implemented.\");\n  }\n  /**\n   * Creates a keyword recognition model using the specified filename.\n   * @member KeywordRecognitionModel.fromStream\n   * @function\n   * @public\n   * @param {string} file - A File that represents file for the keyword recognition model.\n   * Note, the file can point to a zip file in which case the model will be extracted from the zip.\n   * @returns {KeywordRecognitionModel} The keyword recognition model being created.\n   */\n  static fromStream(file) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(file, \"file\");\n    throw new Error(\"Not yet implemented.\");\n  }\n  /**\n   * Dispose of associated resources.\n   * @member KeywordRecognitionModel.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    if (this.privDisposed) {\n      return;\n    }\n    this.privDisposed = true;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/KeywordRecognitionModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LanguageIdMode\": () => (/* binding */ LanguageIdMode)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Language Identification mode\n * @class LanguageIdMode\n */\nvar LanguageIdMode;\n(function (LanguageIdMode) {\n  /**\n   * Detect language at audio start\n   * @member LanguageIdMode.AtStart\n   */\n  LanguageIdMode[LanguageIdMode[\"AtStart\"] = 0] = \"AtStart\";\n  /**\n   * Continuously detect language\n   * @member LanguageIdMode.Continuous\n   */\n  LanguageIdMode[LanguageIdMode[\"Continuous\"] = 1] = \"Continuous\";\n})(LanguageIdMode || (LanguageIdMode = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdMode.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LanguageIdPriority\": () => (/* binding */ LanguageIdPriority)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Language Identification priority\n * @class LanguageIdPriority\n */\nvar LanguageIdPriority;\n(function (LanguageIdPriority) {\n  /**\n   * Prioritize Accuracy for Language Id (does not work for continuous mode LID)\n   * @member LanguageIdPriority.Accuracy\n   */\n  LanguageIdPriority[LanguageIdPriority[\"Accuracy\"] = 0] = \"Accuracy\";\n  /**\n   * Prioritize latency for Language Id\n   * @member LanguageIdPriority.Latency\n   */\n  LanguageIdPriority[LanguageIdPriority[\"Latency\"] = 1] = \"Latency\";\n})(LanguageIdPriority || (LanguageIdPriority = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageIdPriority.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LanguageUnderstandingModel\": () => (/* binding */ LanguageUnderstandingModel),\n/* harmony export */   \"LanguageUnderstandingModelImpl\": () => (/* binding */ LanguageUnderstandingModelImpl)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// eslint-disable-next-line max-classes-per-file\n\n/**\n * Language understanding model\n * @class LanguageUnderstandingModel\n */\nclass LanguageUnderstandingModel {\n  /**\n   * Creates and initializes a new instance\n   * @constructor\n   */\n  constructor() {\n    return;\n  }\n  /**\n   * Creates an language understanding model using the specified endpoint.\n   * @member LanguageUnderstandingModel.fromEndpoint\n   * @function\n   * @public\n   * @param {URL} uri - A String that represents the endpoint of the language understanding model.\n   * @returns {LanguageUnderstandingModel} The language understanding model being created.\n   */\n  static fromEndpoint(uri) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(uri, \"uri\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(uri.hostname, \"uri\");\n    const langModelImp = new LanguageUnderstandingModelImpl();\n    // Need to extract the app ID from the URL.\n    // URL is in the format: https://<region>.api.cognitive.microsoft.com/luis/v2.0/apps/<Guid>?subscription-key=<key>&timezoneOffset=-360\n    // Start tearing the string apart.\n    // region can be extracted from the host name.\n    const firstDot = uri.host.indexOf(\".\");\n    if (-1 === firstDot) {\n      throw new Error(\"Could not determine region from endpoint\");\n    }\n    langModelImp.region = uri.host.substr(0, firstDot);\n    // Now the app ID.\n    const lastSegment = uri.pathname.lastIndexOf(\"/\") + 1;\n    if (-1 === lastSegment) {\n      throw new Error(\"Could not determine appId from endpoint\");\n    }\n    langModelImp.appId = uri.pathname.substr(lastSegment);\n    // And finally the key.\n    langModelImp.subscriptionKey = uri.searchParams.get(\"subscription-key\");\n    if (undefined === langModelImp.subscriptionKey) {\n      throw new Error(\"Could not determine subscription key from endpoint\");\n    }\n    return langModelImp;\n  }\n  /**\n   * Creates an language understanding model using the application id of Language Understanding service.\n   * @member LanguageUnderstandingModel.fromAppId\n   * @function\n   * @public\n   * @param {string} appId - A String that represents the application id of Language Understanding service.\n   * @returns {LanguageUnderstandingModel} The language understanding model being created.\n   */\n  static fromAppId(appId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(appId, \"appId\");\n    const langModelImp = new LanguageUnderstandingModelImpl();\n    langModelImp.appId = appId;\n    return langModelImp;\n  }\n  /**\n   * Creates a language understanding model using hostname, subscription key and application\n   * id of Language Understanding service.\n   * @member LanguageUnderstandingModel.fromSubscription\n   * @function\n   * @public\n   * @param {string} subscriptionKey - A String that represents the subscription key of\n   * Language Understanding service.\n   * @param {string} appId - A String that represents the application id of Language\n   * Understanding service.\n   * @param {LanguageUnderstandingModel} region - A String that represents the region\n   * of the Language Understanding service (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {LanguageUnderstandingModel} The language understanding model being created.\n   */\n  static fromSubscription(subscriptionKey, appId, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(appId, \"appId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const langModelImp = new LanguageUnderstandingModelImpl();\n    langModelImp.appId = appId;\n    langModelImp.region = region;\n    langModelImp.subscriptionKey = subscriptionKey;\n    return langModelImp;\n  }\n}\n/**\n * @private\n * @class LanguageUnderstandingModelImpl\n */\nclass LanguageUnderstandingModelImpl extends LanguageUnderstandingModel {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/LanguageUnderstandingModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"NoMatchDetails\": () => (/* binding */ NoMatchDetails)\n/* harmony export */ });\n/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../src/common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/SimpleSpeechPhrase.js\");\n/* harmony import */ var _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../src/common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/Enums.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Contains detailed information for NoMatch recognition results.\n * @class NoMatchDetails\n */\nclass NoMatchDetails {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {NoMatchReason} reason - The no-match reason.\n   */\n  constructor(reason) {\n    this.privReason = reason;\n  }\n  /**\n   * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.\n   * @member NoMatchDetails.fromResult\n   * @function\n   * @public\n   * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}\n   * result - The recognition result that was not recognized.\n   * @returns {NoMatchDetails} The no match details object being created.\n   */\n  static fromResult(result) {\n    const simpleSpeech = _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_0__.SimpleSpeechPhrase.fromJSON(result.json);\n    let reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.NotRecognized;\n    switch (simpleSpeech.RecognitionStatus) {\n      case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.BabbleTimeout:\n        reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.InitialBabbleTimeout;\n        break;\n      case _src_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.RecognitionStatus.InitialSilenceTimeout:\n        reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.InitialSilenceTimeout;\n        break;\n      default:\n        reason = _Exports__WEBPACK_IMPORTED_MODULE_1__.NoMatchReason.NotRecognized;\n        break;\n    }\n    return new NoMatchDetails(reason);\n  }\n  /**\n   * The reason the recognition was canceled.\n   * @member NoMatchDetails.prototype.reason\n   * @function\n   * @public\n   * @returns {NoMatchReason} Specifies the reason canceled.\n   */\n  get reason() {\n    return this.privReason;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchDetails.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"NoMatchReason\": () => (/* binding */ NoMatchReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might not be recognized.\n * @class NoMatchReason\n */\nvar NoMatchReason;\n(function (NoMatchReason) {\n  /**\n   * Indicates that speech was detected, but not recognized.\n   * @member NoMatchReason.NotRecognized\n   */\n  NoMatchReason[NoMatchReason[\"NotRecognized\"] = 0] = \"NotRecognized\";\n  /**\n   * Indicates that the start of the audio stream contained only silence,\n   * and the service timed out waiting for speech.\n   * @member NoMatchReason.InitialSilenceTimeout\n   */\n  NoMatchReason[NoMatchReason[\"InitialSilenceTimeout\"] = 1] = \"InitialSilenceTimeout\";\n  /**\n   * Indicates that the start of the audio stream contained only noise,\n   * and the service timed out waiting for speech.\n   * @member NoMatchReason.InitialBabbleTimeout\n   */\n  NoMatchReason[NoMatchReason[\"InitialBabbleTimeout\"] = 2] = \"InitialBabbleTimeout\";\n})(NoMatchReason || (NoMatchReason = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/NoMatchReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OutputFormat\": () => (/* binding */ OutputFormat)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define Speech Recognizer output formats.\n * @class OutputFormat\n */\nvar OutputFormat;\n(function (OutputFormat) {\n  /**\n   * @member OutputFormat.Simple\n   */\n  OutputFormat[OutputFormat[\"Simple\"] = 0] = \"Simple\";\n  /**\n   * @member OutputFormat.Detailed\n   */\n  OutputFormat[OutputFormat[\"Detailed\"] = 1] = \"Detailed\";\n})(OutputFormat || (OutputFormat = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PhraseListGrammar\": () => (/* binding */ PhraseListGrammar)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Allows additions of new phrases to improve speech recognition.\n *\n * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect\n * to the speech service.\n */\nclass PhraseListGrammar {\n  constructor(recogBase) {\n    this.privGrammerBuilder = recogBase.dynamicGrammar;\n  }\n  /**\n   * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.\n   * @param recognizer The recognizer to add phrase lists to.\n   */\n  static fromRecognizer(recognizer) {\n    const recoBase = recognizer.internalData;\n    return new PhraseListGrammar(recoBase);\n  }\n  /**\n   * Adds a single phrase to the current recognizer.\n   * @param phrase Phrase to add.\n   */\n  addPhrase(phrase) {\n    this.privGrammerBuilder.addPhrase(phrase);\n  }\n  /**\n   * Adds multiple phrases to the current recognizer.\n   * @param phrases Array of phrases to add.\n   */\n  addPhrases(phrases) {\n    this.privGrammerBuilder.addPhrase(phrases);\n  }\n  /**\n   * Clears all phrases added to the current recognizer.\n   */\n  clear() {\n    this.privGrammerBuilder.clearPhrases();\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PhraseListGrammar.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ProfanityOption\": () => (/* binding */ ProfanityOption)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n/**\n * Profanity option.\n * Added in version 1.7.0.\n */\nvar ProfanityOption;\n(function (ProfanityOption) {\n  ProfanityOption[ProfanityOption[\"Masked\"] = 0] = \"Masked\";\n  ProfanityOption[ProfanityOption[\"Removed\"] = 1] = \"Removed\";\n  ProfanityOption[ProfanityOption[\"Raw\"] = 2] = \"Raw\";\n})(ProfanityOption || (ProfanityOption = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PronunciationAssessmentConfig\": () => (/* binding */ PronunciationAssessmentConfig)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Pronunciation assessment configuration.\n * @class PronunciationAssessmentConfig\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentConfig {\n  /**\n   * PronunciationAssessmentConfig constructor.\n   * @constructor\n   * @param {string} referenceText\n   * @param gradingSystem\n   * @param granularity\n   * @param enableMiscue\n   */\n  constructor(referenceText) {\n    let gradingSystem = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : _Exports__WEBPACK_IMPORTED_MODULE_0__.PronunciationAssessmentGradingSystem.FivePoint;\n    let granularity = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : _Exports__WEBPACK_IMPORTED_MODULE_1__.PronunciationAssessmentGranularity.Phoneme;\n    let enableMiscue = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : false;\n    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(referenceText, \"referenceText\");\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText, referenceText);\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_GradingSystem, _Exports__WEBPACK_IMPORTED_MODULE_0__.PronunciationAssessmentGradingSystem[gradingSystem]);\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Granularity, _Exports__WEBPACK_IMPORTED_MODULE_1__.PronunciationAssessmentGranularity[granularity]);\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_EnableMiscue, String(enableMiscue));\n  }\n  /**\n   * @member PronunciationAssessmentConfig.fromJSON\n   * @function\n   * @public\n   * @param {string} json The json string containing the pronunciation assessment parameters.\n   * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n   * @summary Creates an instance of the PronunciationAssessmentConfig from json.\n   */\n  static fromJSON(json) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(json, \"json\");\n    const config = new PronunciationAssessmentConfig(\"\");\n    config.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();\n    config.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Json, json);\n    return config;\n  }\n  toJSON() {\n    this.updateJson();\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Params);\n  }\n  applyTo(recognizer) {\n    this.updateJson();\n    const recoBase = recognizer.internalData;\n    recoBase.speechContext.setPronunciationAssessmentParams(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Params));\n  }\n  /**\n   * Gets the reference text.\n   * @member PronunciationAssessmentConfig.prototype.referenceText\n   * @function\n   * @public\n   * @returns {string} Reference text.\n   */\n  get referenceText() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText);\n  }\n  /**\n   * Gets/Sets the reference text.\n   * @member PronunciationAssessmentConfig.prototype.referenceText\n   * @function\n   * @public\n   * @param {string} referenceText - Reference text.\n   */\n  set referenceText(referenceText) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(referenceText, \"referenceText\");\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText, referenceText);\n  }\n  /**\n   * Sets the phoneme alphabet.\n   * The valid values are \"SAPI\" (default) and \"IPA\".\n   * Added in version 1.20.0\n   * @member PronunciationAssessmentConfig.prototype.phonemeAlphabet\n   * @function\n   * @public\n   * @param {string} phonemeAlphabet - Phoneme alphabet.\n   */\n  set phonemeAlphabet(phonemeAlphabet) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrWhitespace(phonemeAlphabet, \"phonemeAlphabet\");\n    this.privPhonemeAlphabet = phonemeAlphabet;\n  }\n  /**\n   * Sets the nbest phoneme count\n   * Added in version 1.20.0\n   * @member PronunciationAssessmentConfig.prototype.nbestPhonemeCount\n   * @function\n   * @public\n   * @param {number} nbestPhonemeCount - NBest phoneme count.\n   */\n  set nbestPhonemeCount(nbestPhonemeCount) {\n    this.privNBestPhonemeCount = nbestPhonemeCount;\n  }\n  /**\n   * @member PronunciationAssessmentConfig.prototype.properties\n   * @function\n   * @public\n   * @return {PropertyCollection} Properties of the config.\n   * @summary Gets a pronunciation assessment config properties\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  updateJson() {\n    const jsonString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Json, \"{}\");\n    const paramsJson = JSON.parse(jsonString);\n    const referenceText = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_ReferenceText);\n    if (referenceText) {\n      paramsJson.referenceText = referenceText;\n    }\n    const gradingSystem = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_GradingSystem);\n    if (gradingSystem) {\n      paramsJson.gradingSystem = gradingSystem;\n    }\n    const granularity = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Granularity);\n    if (granularity) {\n      paramsJson.granularity = granularity;\n    }\n    if (this.privPhonemeAlphabet) {\n      paramsJson.phonemeAlphabet = this.privPhonemeAlphabet;\n    }\n    if (this.privNBestPhonemeCount) {\n      paramsJson.nbestPhonemeCount = this.privNBestPhonemeCount;\n    }\n    // always set dimension to Comprehensive\n    paramsJson.dimension = \"Comprehensive\";\n    const enableMiscueString = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_EnableMiscue);\n    if (enableMiscueString === \"true\") {\n      paramsJson.enableMiscue = true;\n    } else if (enableMiscueString === \"false\") {\n      paramsJson.enableMiscue = false;\n    }\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.PronunciationAssessment_Params, JSON.stringify(paramsJson));\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PronunciationAssessmentGradingSystem\": () => (/* binding */ PronunciationAssessmentGradingSystem)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the point system for pronunciation score calibration; default value is FivePoint.\n * Added in version 1.15.0\n * @class PronunciationAssessmentGradingSystem\n */\nvar PronunciationAssessmentGradingSystem;\n(function (PronunciationAssessmentGradingSystem) {\n  /**\n   * Five point calibration\n   * @member PronunciationAssessmentGradingSystem.FivePoint\n   */\n  PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem[\"FivePoint\"] = 1] = \"FivePoint\";\n  /**\n   * Hundred mark\n   * @member PronunciationAssessmentGradingSystem.HundredMark\n   */\n  PronunciationAssessmentGradingSystem[PronunciationAssessmentGradingSystem[\"HundredMark\"] = 2] = \"HundredMark\";\n})(PronunciationAssessmentGradingSystem || (PronunciationAssessmentGradingSystem = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGradingSystem.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PronunciationAssessmentGranularity\": () => (/* binding */ PronunciationAssessmentGranularity)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the pronunciation evaluation granularity; default value is Phoneme.\n * Added in version 1.15.0\n * @class PronunciationAssessmentGranularity\n */\nvar PronunciationAssessmentGranularity;\n(function (PronunciationAssessmentGranularity) {\n  /**\n   * Shows the score on the full text, word and phoneme level\n   * @member PronunciationAssessmentGranularity.Phoneme\n   */\n  PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"Phoneme\"] = 1] = \"Phoneme\";\n  /**\n   * Shows the score on the full text and word level\n   * @member PronunciationAssessmentGranularity.Word\n   */\n  PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"Word\"] = 2] = \"Word\";\n  /**\n   * Shows the score on the full text level only\n   * @member PronunciationAssessmentGranularity.FullText\n   */\n  PronunciationAssessmentGranularity[PronunciationAssessmentGranularity[\"FullText\"] = 3] = \"FullText\";\n})(PronunciationAssessmentGranularity || (PronunciationAssessmentGranularity = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentGranularity.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PronunciationAssessmentResult\": () => (/* binding */ PronunciationAssessmentResult)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Pronunciation assessment results.\n * @class PronunciationAssessmentResult\n * Added in version 1.15.0.\n */\nclass PronunciationAssessmentResult {\n  constructor(jsonString) {\n    const j = JSON.parse(jsonString);\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(j.NBest[0], \"NBest\");\n    this.privPronJson = j.NBest[0];\n  }\n  /**\n   * @member PronunciationAssessmentResult.fromResult\n   * @function\n   * @public\n   * @param {RecognitionResult} result The recognition result.\n   * @return {PronunciationAssessmentConfig} Instance of PronunciationAssessmentConfig\n   * @summary Creates an instance of the PronunciationAssessmentResult from recognition result.\n   */\n  static fromResult(result) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(result, \"result\");\n    const json = result.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_JsonResult);\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(json, \"json\");\n    return new PronunciationAssessmentResult(json);\n  }\n  /**\n   * Gets the detail result of pronunciation assessment.\n   * @member PronunciationAssessmentConfig.prototype.detailResult\n   * @function\n   * @public\n   * @returns {DetailResult} detail result.\n   */\n  get detailResult() {\n    return this.privPronJson;\n  }\n  /**\n   * The score indicating the pronunciation accuracy of the given speech, which indicates\n   * how closely the phonemes match a native speaker's pronunciation.\n   * @member PronunciationAssessmentResult.prototype.accuracyScore\n   * @function\n   * @public\n   * @returns {number} Accuracy score.\n   */\n  get accuracyScore() {\n    return this.detailResult.PronunciationAssessment.AccuracyScore;\n  }\n  /**\n   * The overall score indicating the pronunciation quality of the given speech.\n   * This is calculated from AccuracyScore, FluencyScore and CompletenessScore with weight.\n   * @member PronunciationAssessmentResult.prototype.pronunciationScore\n   * @function\n   * @public\n   * @returns {number} Pronunciation score.\n   */\n  get pronunciationScore() {\n    return this.detailResult.PronunciationAssessment.PronScore;\n  }\n  /**\n   * The score indicating the completeness of the given speech by calculating the ratio of pronounced words towards entire input.\n   * @member PronunciationAssessmentResult.prototype.completenessScore\n   * @function\n   * @public\n   * @returns {number} Completeness score.\n   */\n  get completenessScore() {\n    return this.detailResult.PronunciationAssessment.CompletenessScore;\n  }\n  /**\n   * The score indicating the fluency of the given speech.\n   * @member PronunciationAssessmentResult.prototype.fluencyScore\n   * @function\n   * @public\n   * @returns {number} Fluency score.\n   */\n  get fluencyScore() {\n    return this.detailResult.PronunciationAssessment.FluencyScore;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PronunciationAssessmentResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PropertyCollection\": () => (/* binding */ PropertyCollection)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents collection of properties and their values.\n * @class PropertyCollection\n */\nclass PropertyCollection {\n  constructor() {\n    this.privKeys = [];\n    this.privValues = [];\n  }\n  /**\n   * Returns the property value in type String.\n   * Currently only String, int and bool are allowed.\n   * If the name is not available, the specified defaultValue is returned.\n   * @member PropertyCollection.prototype.getProperty\n   * @function\n   * @public\n   * @param {string} key - The parameter name.\n   * @param {string | number | boolean} def - The default value which is returned if the parameter\n   * is not available in the collection.\n   * @returns {string} value of the parameter.\n   */\n  getProperty(key, def) {\n    let keyToUse;\n    if (typeof key === \"string\") {\n      keyToUse = key;\n    } else {\n      keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId[key];\n    }\n    for (let n = 0; n < this.privKeys.length; n++) {\n      if (this.privKeys[n] === keyToUse) {\n        return this.privValues[n];\n      }\n    }\n    if (def === undefined) {\n      return undefined;\n    }\n    return String(def);\n  }\n  /**\n   * Sets the String value of the parameter specified by name.\n   * @member PropertyCollection.prototype.setProperty\n   * @function\n   * @public\n   * @param {string} key - The parameter name.\n   * @param {string} value - The value of the parameter.\n   */\n  setProperty(key, value) {\n    let keyToUse;\n    if (typeof key === \"string\") {\n      keyToUse = key;\n    } else {\n      keyToUse = _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyId[key];\n    }\n    for (let n = 0; n < this.privKeys.length; n++) {\n      if (this.privKeys[n] === keyToUse) {\n        this.privValues[n] = value;\n        return;\n      }\n    }\n    this.privKeys.push(keyToUse);\n    this.privValues.push(value);\n  }\n  /**\n   * Clones the collection.\n   * @member PropertyCollection.prototype.clone\n   * @function\n   * @public\n   * @returns {PropertyCollection} A copy of the collection.\n   */\n  clone() {\n    const clonedMap = new PropertyCollection();\n    for (let n = 0; n < this.privKeys.length; n++) {\n      clonedMap.privKeys.push(this.privKeys[n]);\n      clonedMap.privValues.push(this.privValues[n]);\n    }\n    return clonedMap;\n  }\n  /**\n   * Merges this set of properties into another, no overwrites.\n   * @member PropertyCollection.prototype.mergeTo\n   * @function\n   * @public\n   * @param {PropertyCollection}  destinationCollection - The collection to merge into.\n   */\n  mergeTo(destinationCollection) {\n    this.privKeys.forEach(key => {\n      if (destinationCollection.getProperty(key, undefined) === undefined) {\n        const value = this.getProperty(key);\n        destinationCollection.setProperty(key, value);\n      }\n    });\n  }\n  /**\n   * Get the keys in Property Collection.\n   * @member PropertyCollection.prototype.keys\n   * @function\n   * @public\n   * @returns {string []} Keys in the collection.\n   */\n  get keys() {\n    return this.privKeys;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PropertyId\": () => (/* binding */ PropertyId)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines speech property ids.\n * @class PropertyId\n */\nvar PropertyId;\n(function (PropertyId) {\n  /**\n   * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to\n   * specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]].\n   * @member PropertyId.SpeechServiceConnection_Key\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Key\"] = 0] = \"SpeechServiceConnection_Key\";\n  /**\n   * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.fromEndpoint]].\n   * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.\n   * @member PropertyId.SpeechServiceConnection_Endpoint\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Endpoint\"] = 1] = \"SpeechServiceConnection_Endpoint\";\n  /**\n   * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to\n   * use this property directly.\n   * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].\n   * @member PropertyId.SpeechServiceConnection_Region\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Region\"] = 2] = \"SpeechServiceConnection_Region\";\n  /**\n   * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromAuthorizationToken]], [[SpeechRecognizer.authorizationToken]],\n   * [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]], [[SpeakerRecognizer.authorizationToken]].\n   * @member PropertyId.SpeechServiceAuthorization_Token\n   */\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Token\"] = 3] = \"SpeechServiceAuthorization_Token\";\n  /**\n   * The Cognitive Services Speech Service authorization type. Currently unused.\n   * @member PropertyId.SpeechServiceAuthorization_Type\n   */\n  PropertyId[PropertyId[\"SpeechServiceAuthorization_Type\"] = 4] = \"SpeechServiceAuthorization_Type\";\n  /**\n   * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't\n   * have to use this property directly.\n   * Instead, use [[SpeechConfig.endpointId]].\n   * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.\n   * @member PropertyId.SpeechServiceConnection_EndpointId\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndpointId\"] = 5] = \"SpeechServiceConnection_EndpointId\";\n  /**\n   * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,\n   * you shouldn't have to use this property directly.\n   * Instead use [[SpeechTranslationConfig.addTargetLanguage]],\n   * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].\n   * @member PropertyId.SpeechServiceConnection_TranslationToLanguages\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationToLanguages\"] = 6] = \"SpeechServiceConnection_TranslationToLanguages\";\n  /**\n   * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead, use [[SpeechTranslationConfig.voiceName]].\n   * NOTE: Valid voice names can be found <a href=\"https://aka.ms/csspeech/voicenames\">here</a>.\n   * @member PropertyId.SpeechServiceConnection_TranslationVoice\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationVoice\"] = 7] = \"SpeechServiceConnection_TranslationVoice\";\n  /**\n   * Translation features.\n   * @member PropertyId.SpeechServiceConnection_TranslationFeatures\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_TranslationFeatures\"] = 8] = \"SpeechServiceConnection_TranslationFeatures\";\n  /**\n   * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[LanguageUnderstandingModel]].\n   * @member PropertyId.SpeechServiceConnection_IntentRegion\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_IntentRegion\"] = 9] = \"SpeechServiceConnection_IntentRegion\";\n  /**\n   * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyHostName\"] = 10] = \"SpeechServiceConnection_ProxyHostName\";\n  /**\n   * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPort\"] = 11] = \"SpeechServiceConnection_ProxyPort\";\n  /**\n   * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyUserName\"] = 12] = \"SpeechServiceConnection_ProxyUserName\";\n  /**\n   * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.\n   * You shouldn't have to use this property directly.\n   * Instead use <see cref=\"SpeechConfig.SetProxy(string,int,string,string)\"/>.\n   * Added in version 1.4.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ProxyPassword\"] = 13] = \"SpeechServiceConnection_ProxyPassword\";\n  /**\n   * The Cognitive Services Speech Service recognition Mode. Can be \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\".\n   * This property is intended to be read-only. The SDK is using it internally.\n   * @member PropertyId.SpeechServiceConnection_RecoMode\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoMode\"] = 14] = \"SpeechServiceConnection_RecoMode\";\n  /**\n   * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property\n   * directly.\n   * Instead, use [[SpeechConfig.speechRecognitionLanguage]].\n   * @member PropertyId.SpeechServiceConnection_RecoLanguage\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecoLanguage\"] = 15] = \"SpeechServiceConnection_RecoLanguage\";\n  /**\n   * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream\n   * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this\n   * property directly.\n   * Instead use [[SessionEventArgs.sessionId]].\n   * @member PropertyId.Speech_SessionId\n   */\n  PropertyId[PropertyId[\"Speech_SessionId\"] = 16] = \"Speech_SessionId\";\n  /**\n   * The spoken language to be synthesized (e.g. en-US)\n   * @member PropertyId.SpeechServiceConnection_SynthLanguage\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthLanguage\"] = 17] = \"SpeechServiceConnection_SynthLanguage\";\n  /**\n   * The name of the TTS voice to be used for speech synthesis\n   * @member PropertyId.SpeechServiceConnection_SynthVoice\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthVoice\"] = 18] = \"SpeechServiceConnection_SynthVoice\";\n  /**\n   * The string to specify TTS output audio format\n   * @member PropertyId.SpeechServiceConnection_SynthOutputFormat\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_SynthOutputFormat\"] = 19] = \"SpeechServiceConnection_SynthOutputFormat\";\n  /**\n   * The list of comma separated languages used as possible source languages\n   * Added in version 1.13.0\n   * @member PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_AutoDetectSourceLanguages\"] = 20] = \"SpeechServiceConnection_AutoDetectSourceLanguages\";\n  /**\n   * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have\n   * to use this property directly.\n   * Instead use [[SpeechConfig.outputFormat]].\n   * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestDetailedResultTrueFalse\"] = 21] = \"SpeechServiceResponse_RequestDetailedResultTrueFalse\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity level. Currently unused.\n   * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestProfanityFilterTrueFalse\"] = 22] = \"SpeechServiceResponse_RequestProfanityFilterTrueFalse\";\n  /**\n   * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.\n   * @member PropertyId.SpeechServiceResponse_JsonResult\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonResult\"] = 23] = \"SpeechServiceResponse_JsonResult\";\n  /**\n   * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to\n   * use this property directly. Instead use [[CancellationDetails.errorDetails]].\n   * @member PropertyId.SpeechServiceResponse_JsonErrorDetails\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_JsonErrorDetails\"] = 24] = \"SpeechServiceResponse_JsonErrorDetails\";\n  /**\n   * The cancellation reason. Currently unused.\n   * @member PropertyId.CancellationDetails_Reason\n   */\n  PropertyId[PropertyId[\"CancellationDetails_Reason\"] = 25] = \"CancellationDetails_Reason\";\n  /**\n   * The cancellation text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonText\n   */\n  PropertyId[PropertyId[\"CancellationDetails_ReasonText\"] = 26] = \"CancellationDetails_ReasonText\";\n  /**\n   * The Cancellation detailed text. Currently unused.\n   * @member PropertyId.CancellationDetails_ReasonDetailedText\n   */\n  PropertyId[PropertyId[\"CancellationDetails_ReasonDetailedText\"] = 27] = \"CancellationDetails_ReasonDetailedText\";\n  /**\n   * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]\n   * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult\n   */\n  PropertyId[PropertyId[\"LanguageUnderstandingServiceResponse_JsonResult\"] = 28] = \"LanguageUnderstandingServiceResponse_JsonResult\";\n  /**\n   * The URL string built from speech configuration.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * NOTE: Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Url\"] = 29] = \"SpeechServiceConnection_Url\";\n  /**\n   * The initial silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_InitialSilenceTimeoutMs\"] = 30] = \"SpeechServiceConnection_InitialSilenceTimeoutMs\";\n  /**\n   * The end silence timeout value (in milliseconds) used by the service.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EndSilenceTimeoutMs\"] = 31] = \"SpeechServiceConnection_EndSilenceTimeoutMs\";\n  /**\n   * A duration of detected silence, measured in milliseconds, after which speech-to-text will determine a spoken\n   * phrase has ended and generate a final Recognized result. Configuring this timeout may be helpful in situations\n   * where spoken input is significantly faster or slower than usual and default segmentation behavior consistently\n   * yields results that are too long or too short. Segmentation timeout values that are inappropriately high or low\n   * can negatively affect speech-to-text accuracy; this property should be carefully configured and the resulting\n   * behavior should be thoroughly validated as intended.\n   *\n   * For more information about timeout configuration that includes discussion of default behaviors, please visit\n   * https://aka.ms/csspeech/timeouts.\n   *\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"Speech_SegmentationSilenceTimeoutMs\"] = 32] = \"Speech_SegmentationSilenceTimeoutMs\";\n  /**\n   * A boolean value specifying whether audio logging is enabled in the service or not.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_EnableAudioLogging\"] = 33] = \"SpeechServiceConnection_EnableAudioLogging\";\n  /**\n   * A string value representing the priority for single language detection.\n   * Allowed values include \"Latency\" and \"Accuracy\"\n   * Added in version 1.21.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_AtStartLanguageIdPriority\"] = 34] = \"SpeechServiceConnection_AtStartLanguageIdPriority\";\n  /**\n   * A string value representing the priority for continuous language detection.\n   * \"Latency\" is default, \"Accuracy\" is currently not allowed for continuous LID\n   * Added in version 1.21.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_ContinuousLanguageIdPriority\"] = 35] = \"SpeechServiceConnection_ContinuousLanguageIdPriority\";\n  /**\n   * A string value representing the desired endpoint version to target for Speech Recognition.\n   * Added in version 1.21.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_RecognitionEndpointVersion\"] = 36] = \"SpeechServiceConnection_RecognitionEndpointVersion\";\n  /**\n   * The requested Cognitive Services Speech Service response output profanity setting.\n   * Allowed values are \"masked\", \"removed\", and \"raw\".\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_ProfanityOption\"] = 37] = \"SpeechServiceResponse_ProfanityOption\";\n  /**\n   * A string value specifying which post processing option should be used by service.\n   * Allowed values are \"TrueText\".\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_PostProcessingOption\"] = 38] = \"SpeechServiceResponse_PostProcessingOption\";\n  /**\n   * A boolean value specifying whether to include word-level timestamps in the response result.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordLevelTimestamps\"] = 39] = \"SpeechServiceResponse_RequestWordLevelTimestamps\";\n  /**\n   * The number of times a word has to be in partial results to be returned.\n   * Added in version 1.7.0\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_StablePartialResultThreshold\"] = 40] = \"SpeechServiceResponse_StablePartialResultThreshold\";\n  /**\n   * A string value specifying the output format option in the response result. Internal use only.\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_OutputFormatOption\"] = 41] = \"SpeechServiceResponse_OutputFormatOption\";\n  /**\n   * A boolean value to request for stabilizing translation partial results by omitting words in the end.\n   * Added in version 1.7.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_TranslationRequestStablePartialResult\"] = 42] = \"SpeechServiceResponse_TranslationRequestStablePartialResult\";\n  /**\n   * A boolean value specifying whether to request WordBoundary events.\n   * @member PropertyId.SpeechServiceResponse_RequestWordBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestWordBoundary\"] = 43] = \"SpeechServiceResponse_RequestWordBoundary\";\n  /**\n   * A boolean value specifying whether to request punctuation boundary in WordBoundary Events. Default is true.\n   * @member PropertyId.SpeechServiceResponse_RequestPunctuationBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestPunctuationBoundary\"] = 44] = \"SpeechServiceResponse_RequestPunctuationBoundary\";\n  /**\n   * A boolean value specifying whether to request sentence boundary in WordBoundary Events. Default is false.\n   * @member PropertyId.SpeechServiceResponse_RequestSentenceBoundary\n   * Added in version 1.21.0.\n   */\n  PropertyId[PropertyId[\"SpeechServiceResponse_RequestSentenceBoundary\"] = 45] = \"SpeechServiceResponse_RequestSentenceBoundary\";\n  /**\n   * Identifier used to connect to the backend service.\n   * @member PropertyId.Conversation_ApplicationId\n   */\n  PropertyId[PropertyId[\"Conversation_ApplicationId\"] = 46] = \"Conversation_ApplicationId\";\n  /**\n   * Type of dialog backend to connect to.\n   * @member PropertyId.Conversation_DialogType\n   */\n  PropertyId[PropertyId[\"Conversation_DialogType\"] = 47] = \"Conversation_DialogType\";\n  /**\n   * Silence timeout for listening\n   * @member PropertyId.Conversation_Initial_Silence_Timeout\n   */\n  PropertyId[PropertyId[\"Conversation_Initial_Silence_Timeout\"] = 48] = \"Conversation_Initial_Silence_Timeout\";\n  /**\n   * From Id to add to speech recognition activities.\n   * @member PropertyId.Conversation_From_Id\n   */\n  PropertyId[PropertyId[\"Conversation_From_Id\"] = 49] = \"Conversation_From_Id\";\n  /**\n   * ConversationId for the session.\n   * @member PropertyId.Conversation_Conversation_Id\n   */\n  PropertyId[PropertyId[\"Conversation_Conversation_Id\"] = 50] = \"Conversation_Conversation_Id\";\n  /**\n   * Comma separated list of custom voice deployment ids.\n   * @member PropertyId.Conversation_Custom_Voice_Deployment_Ids\n   */\n  PropertyId[PropertyId[\"Conversation_Custom_Voice_Deployment_Ids\"] = 51] = \"Conversation_Custom_Voice_Deployment_Ids\";\n  /**\n   * Speech activity template, stamp properties from the template on the activity generated by the service for speech.\n   * @member PropertyId.Conversation_Speech_Activity_Template\n   * Added in version 1.10.0.\n   */\n  PropertyId[PropertyId[\"Conversation_Speech_Activity_Template\"] = 52] = \"Conversation_Speech_Activity_Template\";\n  /**\n   * Enables or disables the receipt of turn status messages as obtained on the turnStatusReceived event.\n   * @member PropertyId.Conversation_Request_Bot_Status_Messages\n   * Added in version 1.15.0.\n   */\n  PropertyId[PropertyId[\"Conversation_Request_Bot_Status_Messages\"] = 53] = \"Conversation_Request_Bot_Status_Messages\";\n  /**\n   * Specifies the connection ID to be provided in the Agent configuration message, e.g. a Direct Line token for\n   * channel authentication.\n   * Added in version 1.15.1.\n   */\n  PropertyId[PropertyId[\"Conversation_Agent_Connection_Id\"] = 54] = \"Conversation_Agent_Connection_Id\";\n  /**\n   * The Cognitive Services Speech Service host (url). Under normal circumstances, you shouldn't have to use this property directly.\n   * Instead, use [[SpeechConfig.fromHost]].\n   */\n  PropertyId[PropertyId[\"SpeechServiceConnection_Host\"] = 55] = \"SpeechServiceConnection_Host\";\n  /**\n   * Set the host for service calls to the Conversation Translator REST management and websocket calls.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Host\"] = 56] = \"ConversationTranslator_Host\";\n  /**\n   * Optionally set the the host's display name.\n   * Used when joining a conversation.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Name\"] = 57] = \"ConversationTranslator_Name\";\n  /**\n   * Optionally set a value for the X-CorrelationId request header.\n   * Used for troubleshooting errors in the server logs. It should be a valid guid.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_CorrelationId\"] = 58] = \"ConversationTranslator_CorrelationId\";\n  /**\n   * Set the conversation token to be sent to the speech service. This enables the\n   * service to service call from the speech service to the Conversation Translator service for relaying\n   * recognitions. For internal use.\n   */\n  PropertyId[PropertyId[\"ConversationTranslator_Token\"] = 59] = \"ConversationTranslator_Token\";\n  /**\n   * The reference text of the audio for pronunciation evaluation.\n   * For this and the following pronunciation assessment parameters, see\n   * https://docs.microsoft.com/azure/cognitive-services/speech-service/rest-speech-to-text#pronunciation-assessment-parameters for details.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_ReferenceText\"] = 60] = \"PronunciationAssessment_ReferenceText\";\n  /**\n   * The point system for pronunciation score calibration (FivePoint or HundredMark).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_GradingSystem\"] = 61] = \"PronunciationAssessment_GradingSystem\";\n  /**\n   * The pronunciation evaluation granularity (Phoneme, Word, or FullText).\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Granularity\"] = 62] = \"PronunciationAssessment_Granularity\";\n  /**\n   * Defines if enable miscue calculation.\n   * With this enabled, the pronounced words will be compared to the reference text,\n   * and will be marked with omission/insertion based on the comparison. The default setting is False.\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_EnableMiscue\"] = 63] = \"PronunciationAssessment_EnableMiscue\";\n  /**\n   * The json string of pronunciation assessment parameters\n   * Under normal circumstances, you shouldn't have to use this property directly.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Json\"] = 64] = \"PronunciationAssessment_Json\";\n  /**\n   * Pronunciation assessment parameters.\n   * This property is intended to be read-only. The SDK is using it internally.\n   * Added in version 1.15.0\n   */\n  PropertyId[PropertyId[\"PronunciationAssessment_Params\"] = 65] = \"PronunciationAssessment_Params\";\n  /**\n   * Version of Speaker Recognition API to use.\n   * Added in version 1.18.0\n   */\n  PropertyId[PropertyId[\"SpeakerRecognition_Api_Version\"] = 66] = \"SpeakerRecognition_Api_Version\";\n})(PropertyId || (PropertyId = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RecognitionEventArgs\": () => (/* binding */ RecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines payload for session events like Speech Start/End Detected\n * @class\n */\nclass RecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {number} offset - The offset.\n   * @param {string} sessionId - The session id.\n   */\n  constructor(offset, sessionId) {\n    super(sessionId);\n    this.privOffset = offset;\n  }\n  /**\n   * Represents the message offset\n   * @member RecognitionEventArgs.prototype.offset\n   * @function\n   * @public\n   */\n  get offset() {\n    return this.privOffset;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"RecognitionResult\": () => (/* binding */ RecognitionResult)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines result of speech recognition.\n * @class RecognitionResult\n */\nclass RecognitionResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} resultId - The result id.\n   * @param {ResultReason} reason - The reason.\n   * @param {string} text - The recognized text.\n   * @param {number} duration - The duration.\n   * @param {number} offset - The offset into the stream.\n   * @param {string} language - Primary Language detected, if provided.\n   * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {string} json - Additional Json, if provided.\n   * @param {PropertyCollection} properties - Additional properties, if provided.\n   */\n  constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties) {\n    this.privResultId = resultId;\n    this.privReason = reason;\n    this.privText = text;\n    this.privDuration = duration;\n    this.privOffset = offset;\n    this.privLanguage = language;\n    this.privLanguageDetectionConfidence = languageDetectionConfidence;\n    this.privErrorDetails = errorDetails;\n    this.privJson = json;\n    this.privProperties = properties;\n  }\n  /**\n   * Specifies the result identifier.\n   * @member RecognitionResult.prototype.resultId\n   * @function\n   * @public\n   * @returns {string} Specifies the result identifier.\n   */\n  get resultId() {\n    return this.privResultId;\n  }\n  /**\n   * Specifies status of the result.\n   * @member RecognitionResult.prototype.reason\n   * @function\n   * @public\n   * @returns {ResultReason} Specifies status of the result.\n   */\n  get reason() {\n    return this.privReason;\n  }\n  /**\n   * Presents the recognized text in the result.\n   * @member RecognitionResult.prototype.text\n   * @function\n   * @public\n   * @returns {string} Presents the recognized text in the result.\n   */\n  get text() {\n    return this.privText;\n  }\n  /**\n   * Duration of recognized speech in 100 nano second increments.\n   * @member RecognitionResult.prototype.duration\n   * @function\n   * @public\n   * @returns {number} Duration of recognized speech in 100 nano second increments.\n   */\n  get duration() {\n    return this.privDuration;\n  }\n  /**\n   * Offset of recognized speech in 100 nano second increments.\n   * @member RecognitionResult.prototype.offset\n   * @function\n   * @public\n   * @returns {number} Offset of recognized speech in 100 nano second increments.\n   */\n  get offset() {\n    return this.privOffset;\n  }\n  /**\n   * Primary Language detected.\n   * @member RecognitionResult.prototype.language\n   * @function\n   * @public\n   * @returns {string} language detected.\n   */\n  get language() {\n    return this.privLanguage;\n  }\n  /**\n   * Primary Language detection confidence (Unknown, Low, Medium, High).\n   * @member RecognitionResult.prototype.languageDetectionConfidence\n   * @function\n   * @public\n   * @returns {string} detection confidence strength.\n   */\n  get languageDetectionConfidence() {\n    return this.privLanguageDetectionConfidence;\n  }\n  /**\n   * In case of an unsuccessful recognition, provides details of the occurred error.\n   * @member RecognitionResult.prototype.errorDetails\n   * @function\n   * @public\n   * @returns {string} a brief description of an error.\n   */\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n  /**\n   * A string containing Json serialized recognition result as it was received from the service.\n   * @member RecognitionResult.prototype.json\n   * @function\n   * @private\n   * @returns {string} Json serialized representation of the result.\n   */\n  get json() {\n    return this.privJson;\n  }\n  /**\n   * The set of properties exposed in the result.\n   * @member RecognitionResult.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The set of properties exposed in the result.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Recognizer\": () => (/* binding */ Recognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceRecognizerBase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n/**\n * Defines the base class Recognizer which mainly contains common event handlers.\n * @class Recognizer\n */\nclass Recognizer {\n  /**\n   * Creates and initializes an instance of a Recognizer\n   * @constructor\n   * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer\n   */\n  constructor(audioConfig, properties, connectionFactory) {\n    this.audioConfig = audioConfig !== undefined ? audioConfig : _Exports__WEBPACK_IMPORTED_MODULE_0__.AudioConfig.fromDefaultMicrophoneInput();\n    this.privDisposed = false;\n    this.privProperties = properties.clone();\n    this.privConnectionFactory = connectionFactory;\n    this.implCommonRecognizerSetup();\n  }\n  /**\n   * Dispose of associated resources.\n   * @member Recognizer.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, errorCb) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_2__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n  }\n  /**\n   * @Internal\n   * Internal data member to support fromRecognizer* pattern methods on other classes.\n   * Do not use externally, object returned will change without warning or notice.\n   */\n  get internalData() {\n    return this.privReco;\n  }\n  /**\n   * This method performs cleanup of resources.\n   * The Boolean parameter disposing indicates whether the method is called\n   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n   * Derived classes should override this method to dispose resource if needed.\n   * @member Recognizer.prototype.dispose\n   * @function\n   * @public\n   * @param {boolean} disposing - Flag to request disposal.\n   */\n  dispose(disposing) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposed) {\n        return;\n      }\n      this.privDisposed = true;\n      if (disposing) {\n        if (this.privReco) {\n          yield this.privReco.audioSource.turnOff();\n          yield this.privReco.dispose();\n        }\n      }\n    });\n  }\n  /**\n   * This method returns the current state of the telemetry setting.\n   * @member Recognizer.prototype.telemetryEnabled\n   * @function\n   * @public\n   * @returns true if the telemetry is enabled, false otherwise.\n   */\n  static get telemetryEnabled() {\n    return _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase.telemetryDataEnabled;\n  }\n  /**\n   * This method globally enables or disables telemetry.\n   * @member Recognizer.prototype.enableTelemetry\n   * @function\n   * @public\n   * @param enabled - Global setting for telemetry collection.\n   * If set to true, telemetry information like microphone errors,\n   * recognition errors are collected and sent to Microsoft.\n   * If set to false, no telemetry is sent to Microsoft.\n   */\n  static enableTelemetry(enabled) {\n    _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.ServiceRecognizerBase.telemetryDataEnabled = enabled;\n  }\n  // Does the generic recognizer setup that is common across all recognizer types.\n  implCommonRecognizerSetup() {\n    let osPlatform = typeof window !== \"undefined\" ? \"Browser\" : \"Node\";\n    let osName = \"unknown\";\n    let osVersion = \"unknown\";\n    if (typeof navigator !== \"undefined\") {\n      osPlatform = osPlatform + \"/\" + navigator.platform;\n      osName = navigator.userAgent;\n      osVersion = navigator.appVersion;\n    }\n    const recognizerConfig = this.createRecognizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.SpeechServiceConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OS(osPlatform, osName, osVersion))));\n    this.privReco = this.createServiceRecognizer(Recognizer.getAuthFromProperties(this.privProperties), this.privConnectionFactory, this.audioConfig, recognizerConfig);\n  }\n  recognizeOnceAsyncImpl(recognitionMode) {\n    return __awaiter(this, void 0, void 0, function* () {\n      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n      const ret = new _common_Exports__WEBPACK_IMPORTED_MODULE_2__.Deferred();\n      yield this.implRecognizerStop();\n      yield this.privReco.recognize(recognitionMode, ret.resolve, ret.reject);\n      const result = yield ret.promise;\n      yield this.implRecognizerStop();\n      return result;\n    });\n  }\n  startContinuousRecognitionAsyncImpl(recognitionMode) {\n    return __awaiter(this, void 0, void 0, function* () {\n      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n      yield this.implRecognizerStop();\n      yield this.privReco.recognize(recognitionMode, undefined, undefined);\n    });\n  }\n  stopContinuousRecognitionAsyncImpl() {\n    return __awaiter(this, void 0, void 0, function* () {\n      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposed);\n      yield this.implRecognizerStop();\n    });\n  }\n  implRecognizerStop() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privReco) {\n        yield this.privReco.stopRecognizing();\n      }\n      return;\n    });\n  }\n  static getAuthFromProperties(properties) {\n    const subscriptionKey = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceConnection_Key, undefined);\n    const authentication = subscriptionKey && subscriptionKey !== \"\" ? new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.CognitiveTokenAuthentication(() => {\n      const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, undefined);\n      return Promise.resolve(authorizationToken);\n    }, () => {\n      const authorizationToken = properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceAuthorization_Token, undefined);\n      return Promise.resolve(authorizationToken);\n    });\n    return authentication;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ResultReason\": () => (/* binding */ ResultReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the possible reasons a recognition result might be generated.\n * @class ResultReason\n */\nvar ResultReason;\n(function (ResultReason) {\n  /**\n   * Indicates speech could not be recognized. More details\n   * can be found in the NoMatchDetails object.\n   * @member ResultReason.NoMatch\n   */\n  ResultReason[ResultReason[\"NoMatch\"] = 0] = \"NoMatch\";\n  /**\n   * Indicates that the recognition was canceled. More details\n   * can be found using the CancellationDetails object.\n   * @member ResultReason.Canceled\n   */\n  ResultReason[ResultReason[\"Canceled\"] = 1] = \"Canceled\";\n  /**\n   * Indicates the speech result contains hypothesis text.\n   * @member ResultReason.RecognizedSpeech\n   */\n  ResultReason[ResultReason[\"RecognizingSpeech\"] = 2] = \"RecognizingSpeech\";\n  /**\n   * Indicates the speech result contains final text that has been recognized.\n   * Speech Recognition is now complete for this phrase.\n   * @member ResultReason.RecognizedSpeech\n   */\n  ResultReason[ResultReason[\"RecognizedSpeech\"] = 3] = \"RecognizedSpeech\";\n  /**\n   * Indicates the speech result contains a finalized acceptance of a provided keyword.\n   * Speech recognition will continue unless otherwise configured.\n   * @member ResultReason.RecognizedKeyword\n   */\n  ResultReason[ResultReason[\"RecognizedKeyword\"] = 4] = \"RecognizedKeyword\";\n  /**\n   * Indicates the intent result contains hypothesis text and intent.\n   * @member ResultReason.RecognizingIntent\n   */\n  ResultReason[ResultReason[\"RecognizingIntent\"] = 5] = \"RecognizingIntent\";\n  /**\n   * Indicates the intent result contains final text and intent.\n   * Speech Recognition and Intent determination are now complete for this phrase.\n   * @member ResultReason.RecognizedIntent\n   */\n  ResultReason[ResultReason[\"RecognizedIntent\"] = 6] = \"RecognizedIntent\";\n  /**\n   * Indicates the translation result contains hypothesis text and its translation(s).\n   * @member ResultReason.TranslatingSpeech\n   */\n  ResultReason[ResultReason[\"TranslatingSpeech\"] = 7] = \"TranslatingSpeech\";\n  /**\n   * Indicates the translation result contains final text and corresponding translation(s).\n   * Speech Recognition and Translation are now complete for this phrase.\n   * @member ResultReason.TranslatedSpeech\n   */\n  ResultReason[ResultReason[\"TranslatedSpeech\"] = 8] = \"TranslatedSpeech\";\n  /**\n   * Indicates the synthesized audio result contains a non-zero amount of audio data\n   * @member ResultReason.SynthesizingAudio\n   */\n  ResultReason[ResultReason[\"SynthesizingAudio\"] = 9] = \"SynthesizingAudio\";\n  /**\n   * Indicates the synthesized audio is now complete for this phrase.\n   * @member ResultReason.SynthesizingAudioCompleted\n   */\n  ResultReason[ResultReason[\"SynthesizingAudioCompleted\"] = 10] = \"SynthesizingAudioCompleted\";\n  /**\n   * Indicates the speech synthesis is now started\n   * @member ResultReason.SynthesizingAudioStarted\n   */\n  ResultReason[ResultReason[\"SynthesizingAudioStarted\"] = 11] = \"SynthesizingAudioStarted\";\n  /**\n   * Indicates the voice profile is being enrolled and customers need to send more audio to create a voice profile.\n   * @member ResultReason.EnrollingVoiceProfile\n   */\n  ResultReason[ResultReason[\"EnrollingVoiceProfile\"] = 12] = \"EnrollingVoiceProfile\";\n  /**\n   * Indicates the voice profile has been enrolled.\n   * @member ResultReason.EnrolledVoiceProfile\n   */\n  ResultReason[ResultReason[\"EnrolledVoiceProfile\"] = 13] = \"EnrolledVoiceProfile\";\n  /**\n   * Indicates successful identification of some speakers.\n   * @member ResultReason.RecognizedSpeakers\n   */\n  ResultReason[ResultReason[\"RecognizedSpeakers\"] = 14] = \"RecognizedSpeakers\";\n  /**\n   * Indicates successfully verified one speaker.\n   * @member ResultReason.RecognizedSpeaker\n   */\n  ResultReason[ResultReason[\"RecognizedSpeaker\"] = 15] = \"RecognizedSpeaker\";\n  /**\n   * Indicates a voice profile has been reset successfully.\n   * @member ResultReason.ResetVoiceProfile\n   */\n  ResultReason[ResultReason[\"ResetVoiceProfile\"] = 16] = \"ResetVoiceProfile\";\n  /**\n   * Indicates a voice profile has been deleted successfully.\n   * @member ResultReason.DeletedVoiceProfile\n   */\n  ResultReason[ResultReason[\"DeletedVoiceProfile\"] = 17] = \"DeletedVoiceProfile\";\n  /**\n   * Indicates synthesis voices list has been successfully retrieved.\n   * @member ResultReason.VoicesListRetrieved\n   */\n  ResultReason[ResultReason[\"VoicesListRetrieved\"] = 18] = \"VoicesListRetrieved\";\n})(ResultReason || (ResultReason = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServiceEventArgs\": () => (/* binding */ ServiceEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n//\n// Copyright (c) Microsoft. All rights reserved.\n// Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n//\n\n/**\n * Defines payload for any Service message event\n * Added in version 1.9.0\n */\nclass ServiceEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} json - json payload of the USP message.\n   */\n  constructor(json, name, sessionId) {\n    super(sessionId);\n    this.privJsonResult = json;\n    this.privEventName = name;\n  }\n  get jsonString() {\n    return this.privJsonResult;\n  }\n  get eventName() {\n    return this.privEventName;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServiceEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ServicePropertyChannel\": () => (/* binding */ ServicePropertyChannel)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT license.\n/**\n * Defines channels used to pass property settings to service.\n * Added in version 1.7.0.\n */\nvar ServicePropertyChannel;\n(function (ServicePropertyChannel) {\n  /**\n   * Uses URI query parameter to pass property settings to service.\n   */\n  ServicePropertyChannel[ServicePropertyChannel[\"UriQueryParameter\"] = 0] = \"UriQueryParameter\";\n})(ServicePropertyChannel || (ServicePropertyChannel = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ServicePropertyChannel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SessionEventArgs\": () => (/* binding */ SessionEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.\n * @class SessionEventArgs\n */\nclass SessionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} sessionId - The session id.\n   */\n  constructor(sessionId) {\n    this.privSessionId = sessionId;\n  }\n  /**\n   * Represents the session identifier.\n   * @member SessionEventArgs.prototype.sessionId\n   * @function\n   * @public\n   * @returns {string} Represents the session identifier.\n   */\n  get sessionId() {\n    return this.privSessionId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SourceLanguageConfig\": () => (/* binding */ SourceLanguageConfig)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Source Language configuration.\n * @class SourceLanguageConfig\n */\nclass SourceLanguageConfig {\n  constructor(language, endpointId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(language, \"language\");\n    this.privLanguage = language;\n    this.privEndpointId = endpointId;\n  }\n  /**\n   * @member SourceLanguageConfig.fromLanguage\n   * @function\n   * @public\n   * @param {string} language language (eg. \"en-US\") value of config.\n   * @param {string?} endpointId endpointId of model bound to given language of config.\n   * @return {SourceLanguageConfig} Instance of SourceLanguageConfig\n   * @summary Creates an instance of the SourceLanguageConfig with the given language and optional endpointId.\n   * Added in version 1.13.0.\n   */\n  static fromLanguage(language, endpointId) {\n    return new SourceLanguageConfig(language, endpointId);\n  }\n  get language() {\n    return this.privLanguage;\n  }\n  get endpointId() {\n    return this.privEndpointId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SourceLanguageConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerIdentificationModel\": () => (/* binding */ SpeakerIdentificationModel)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Defines SpeakerIdentificationModel class for Speaker Recognition\n * Model contains a set of profiles against which to identify speaker(s)\n * @class SpeakerIdentificationModel\n */\nclass SpeakerIdentificationModel {\n  constructor(profiles) {\n    this.privVoiceProfiles = [];\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(profiles, \"VoiceProfiles\");\n    if (profiles.length === 0) {\n      throw new Error(\"Empty Voice Profiles array\");\n    }\n    profiles.forEach(profile => {\n      if (profile.profileType !== _Exports__WEBPACK_IMPORTED_MODULE_1__.VoiceProfileType.TextIndependentIdentification) {\n        throw new Error(\"Identification model can only be created from Identification profile: \" + profile.profileId);\n      }\n      this.privVoiceProfiles.push(profile);\n    });\n  }\n  static fromProfiles(profiles) {\n    return new SpeakerIdentificationModel(profiles);\n  }\n  get voiceProfileIds() {\n    return this.privVoiceProfiles.map(profile => profile.profileId).join(\",\");\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerRecognitionCancellationDetails\": () => (/* binding */ SpeakerRecognitionCancellationDetails),\n/* harmony export */   \"SpeakerRecognitionResult\": () => (/* binding */ SpeakerRecognitionResult),\n/* harmony export */   \"SpeakerRecognitionResultType\": () => (/* binding */ SpeakerRecognitionResultType)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\nvar SpeakerRecognitionResultType;\n(function (SpeakerRecognitionResultType) {\n  SpeakerRecognitionResultType[SpeakerRecognitionResultType[\"Verify\"] = 0] = \"Verify\";\n  SpeakerRecognitionResultType[SpeakerRecognitionResultType[\"Identify\"] = 1] = \"Identify\";\n})(SpeakerRecognitionResultType || (SpeakerRecognitionResultType = {}));\n/**\n * Output format\n * @class SpeakerRecognitionResult\n */\nclass SpeakerRecognitionResult {\n  constructor(resultType, data, profileId) {\n    let resultReason = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.RecognizedSpeaker;\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyCollection();\n    this.privReason = resultReason;\n    if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.Canceled) {\n      if (resultType === SpeakerRecognitionResultType.Identify) {\n        const json = JSON.parse(data);\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(json, \"JSON\");\n        this.privProfileId = json.identifiedProfile.profileId;\n        this.privScore = json.identifiedProfile.score;\n      } else {\n        const json = JSON.parse(data);\n        _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(json, \"JSON\");\n        this.privScore = json.score;\n        if (json.recognitionResult.toLowerCase() !== \"accept\") {\n          this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_0__.ResultReason.NoMatch;\n        }\n        if (profileId !== undefined && profileId !== \"\") {\n          this.privProfileId = profileId;\n        }\n      }\n    } else {\n      const json = JSON.parse(data);\n      _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(json, \"JSON\");\n      this.privErrorDetails = json.statusText;\n      this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.ServiceError]);\n    }\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_5__.PropertyId.SpeechServiceResponse_JsonResult, data);\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  get reason() {\n    return this.privReason;\n  }\n  get profileId() {\n    return this.privProfileId;\n  }\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n  get score() {\n    return this.privScore;\n  }\n}\n/**\n * @class SpeakerRecognitionCancellationDetails\n */\nclass SpeakerRecognitionCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationDetailsBase {\n  constructor(reason, errorDetails, errorCode) {\n    super(reason, errorDetails, errorCode);\n  }\n  /**\n   * Creates an instance of SpeakerRecognitionCancellationDetails object for the canceled SpeakerRecognitionResult\n   * @member SpeakerRecognitionCancellationDetails.fromResult\n   * @function\n   * @public\n   * @param {SpeakerRecognitionResult} result - The result that was canceled.\n   * @returns {SpeakerRecognitionCancellationDetails} The cancellation details object being created.\n   */\n  static fromResult(result) {\n    const reason = _Exports__WEBPACK_IMPORTED_MODULE_7__.CancellationReason.Error;\n    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.NoError;\n    if (!!result.properties) {\n      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.NoError])];\n    }\n    return new SpeakerRecognitionCancellationDetails(reason, result.errorDetails, errorCode);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerRecognizer\": () => (/* binding */ SpeakerRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerIdentificationModel.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognitionResult.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n/**\n * Defines SpeakerRecognizer class for Speaker Recognition\n * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)\n * @class SpeakerRecognizer\n */\nclass SpeakerRecognizer {\n  /**\n   * SpeakerRecognizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - An set of initial properties for this recognizer (authentication key, region, &c)\n   */\n  constructor(speechConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n    this.privAudioConfigImpl = audioConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(this.privAudioConfigImpl, \"audioConfig\");\n    this.privProperties = speechConfigImpl.properties.clone();\n    this.implSRSetup();\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member SpeakerRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member SpeakerRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n  set authorizationToken(token) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * The collection of properties and their values defined for this SpeakerRecognizer.\n   * @member SpeakerRecognizer.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeakerRecognizer.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Get recognition result for model using given audio\n   * @member SpeakerRecognizer.prototype.recognizeOnceAsync\n   * @function\n   * @public\n   * @async\n   * @param {SpeakerIdentificationModel} model Model containing Voice Profiles to be identified\n   * @param cb - Callback invoked once result is returned.\n   * @param err - Callback invoked in case of an error.\n   */\n  recognizeOnceAsync(model) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (model instanceof _Exports__WEBPACK_IMPORTED_MODULE_2__.SpeakerIdentificationModel) {\n        const responsePromise = this.privAdapter.identifySpeaker(model, this.privAudioConfigImpl);\n        return this.getResult(responsePromise, _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeakerRecognitionResultType.Identify, undefined);\n      } else if (model instanceof _Exports__WEBPACK_IMPORTED_MODULE_4__.SpeakerVerificationModel) {\n        const responsePromise = this.privAdapter.verifySpeaker(model, this.privAudioConfigImpl);\n        return this.getResult(responsePromise, _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeakerRecognitionResultType.Verify, model.voiceProfile.profileId);\n      } else {\n        throw new Error(\"SpeakerRecognizer.recognizeOnce: Unexpected model type\");\n      }\n    });\n  }\n  /**\n   * Included for compatibility\n   * @member SpeakerRecognizer.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return;\n  }\n  // Does class setup, swiped from Recognizer.\n  implSRSetup() {\n    let osPlatform = typeof window !== \"undefined\" ? \"Browser\" : \"Node\";\n    let osName = \"unknown\";\n    let osVersion = \"unknown\";\n    if (typeof navigator !== \"undefined\") {\n      osPlatform = osPlatform + \"/\" + navigator.platform;\n      osName = navigator.userAgent;\n      osVersion = navigator.appVersion;\n    }\n    const recognizerConfig = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.SpeakerRecognitionConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.OS(osPlatform, osName, osVersion)), this.privProperties);\n    this.privAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.SpeakerIdMessageAdapter(recognizerConfig);\n  }\n  getResult(responsePromise, resultType, profileId) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const response = yield responsePromise;\n      return new _Exports__WEBPACK_IMPORTED_MODULE_3__.SpeakerRecognitionResult(resultType, response.data, profileId, response.ok ? _Exports__WEBPACK_IMPORTED_MODULE_8__.ResultReason.RecognizedSpeaker : _Exports__WEBPACK_IMPORTED_MODULE_8__.ResultReason.Canceled);\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeakerVerificationModel\": () => (/* binding */ SpeakerVerificationModel)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Defines SpeakerVerificationModel class for Speaker Recognition\n * Model contains a profile against which to verify a speaker\n * @class SpeakerVerificationModel\n */\nclass SpeakerVerificationModel {\n  constructor(profile) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(profile, \"VoiceProfile\");\n    if (profile.profileType === _Exports__WEBPACK_IMPORTED_MODULE_1__.VoiceProfileType.TextIndependentIdentification) {\n      throw new Error(\"Verification model cannot be created from Identification profile\");\n    }\n    this.privVoiceProfile = profile;\n  }\n  static fromProfile(profile) {\n    return new SpeakerVerificationModel(profile);\n  }\n  get voiceProfile() {\n    return this.privVoiceProfile;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeakerVerificationModel.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechConfig\": () => (/* binding */ SpeechConfig),\n/* harmony export */   \"SpeechConfigImpl\": () => (/* binding */ SpeechConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Speech configuration.\n * @class SpeechConfig\n */\nclass SpeechConfig {\n  /**\n   * Creates and initializes an instance.\n   * @constructor\n   */\n  constructor() {\n    return;\n  }\n  /**\n   * Static instance of SpeechConfig returned by passing subscriptionKey and service region.\n   * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n   * @member SpeechConfig.fromSubscription\n   * @function\n   * @public\n   * @param {string} subscriptionKey - The subscription key.\n   * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {SpeechConfig} The speech factory\n   */\n  static fromSubscription(subscriptionKey, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const speechImpl = new SpeechConfigImpl();\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, region);\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion, region);\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    return speechImpl;\n  }\n  /**\n   * Creates an instance of the speech config with specified endpoint and subscription key.\n   * This method is intended only for users who use a non-standard service endpoint or parameters.\n   * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.\n   * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.\n   * For example, if language is defined in the uri as query parameter \"language=de-DE\", and also set by\n   * SpeechConfig.speechRecognitionLanguage = \"en-US\", the language setting in uri takes precedence,\n   * and the effective language is \"de-DE\". Only the parameters that are not specified in the\n   * endpoint URL can be set by other APIs.\n   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n   * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n   * use the authorization token.\n   * @member SpeechConfig.fromEndpoint\n   * @function\n   * @public\n   * @param {URL} endpoint - The service endpoint to connect to.\n   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n   * @returns {SpeechConfig} A speech factory instance.\n   */\n  static fromEndpoint(endpoint, subscriptionKey) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(endpoint, \"endpoint\");\n    const speechImpl = new SpeechConfigImpl();\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);\n    if (undefined !== subscriptionKey) {\n      speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    }\n    return speechImpl;\n  }\n  /**\n   * Creates an instance of the speech config with specified host and subscription key.\n   * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n   * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n   * Note: To use an authorization token with fromHost, use fromHost(URL),\n   * and then set the AuthorizationToken property on the created SpeechConfig instance.\n   * Note: Added in version 1.9.0.\n   * @member SpeechConfig.fromHost\n   * @function\n   * @public\n   * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n   * @returns {SpeechConfig} A speech factory instance.\n   */\n  static fromHost(hostName, subscriptionKey) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(hostName, \"hostName\");\n    const speechImpl = new SpeechConfigImpl();\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n    if (undefined !== subscriptionKey) {\n      speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    }\n    return speechImpl;\n  }\n  /**\n   * Creates an instance of the speech factory with specified initial authorization token and region.\n   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n   * expires, the caller needs to refresh it by calling this setter with a new valid token.\n   * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want\n   * to use the Intent recognizer. As configuration values are copied when creating a new recognizer,\n   * the new token value will not apply to recognizers that have already been created. For recognizers\n   * that have been created before, you need to set authorization token of the corresponding recognizer\n   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n   * @member SpeechConfig.fromAuthorizationToken\n   * @function\n   * @public\n   * @param {string} authorizationToken - The initial authorization token.\n   * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {SpeechConfig} A speech factory instance.\n   */\n  static fromAuthorizationToken(authorizationToken, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(authorizationToken, \"authorizationToken\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const speechImpl = new SpeechConfigImpl();\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region, region);\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_IntentRegion, region);\n    speechImpl.authorizationToken = authorizationToken;\n    return speechImpl;\n  }\n  /**\n   * Closes the configuration.\n   * @member SpeechConfig.prototype.close\n   * @function\n   * @public\n   */\n  // eslint-disable-next-line @typescript-eslint/no-empty-function\n  close() {}\n}\n/**\n * @public\n * @class SpeechConfigImpl\n */\nclass SpeechConfigImpl extends SpeechConfig {\n  constructor() {\n    super();\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection();\n    this.speechRecognitionLanguage = \"en-US\"; // Should we have a default?\n    this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat.Simple;\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  get endPoint() {\n    return new URL(this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Endpoint));\n  }\n  get subscriptionKey() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Key);\n  }\n  get region() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_Region);\n  }\n  get authorizationToken() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  set authorizationToken(value) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token, value);\n  }\n  get speechRecognitionLanguage() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage);\n  }\n  set speechRecognitionLanguage(value) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_RecoLanguage, value);\n  }\n  get autoDetectSourceLanguages() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages);\n  }\n  set autoDetectSourceLanguages(value) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages, value);\n  }\n  get outputFormat() {\n    return _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat[this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, undefined)];\n  }\n  set outputFormat(value) {\n    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.OutputFormat[value]);\n  }\n  get endpointId() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId);\n  }\n  set endpointId(value) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EndpointId, value);\n  }\n  setProperty(name, value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(value, \"value\");\n    this.privProperties.setProperty(name, value);\n  }\n  getProperty(name, def) {\n    return this.privProperties.getProperty(name, def);\n  }\n  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);\n  }\n  setServiceProperty(name, value) {\n    const currentProperties = JSON.parse(this.privProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ServicePropertiesPropertyName, \"{}\"));\n    currentProperties[name] = value;\n    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ServicePropertiesPropertyName, JSON.stringify(currentProperties));\n  }\n  setProfanity(profanity) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_5__.ProfanityOption[profanity]);\n  }\n  enableAudioLogging() {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_EnableAudioLogging, \"true\");\n  }\n  requestWordLevelTimestamps() {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n  }\n  enableDictation() {\n    this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ForceDictationPropertyName, \"true\");\n  }\n  clone() {\n    const ret = new SpeechConfigImpl();\n    ret.privProperties = this.privProperties.clone();\n    return ret;\n  }\n  get speechSynthesisLanguage() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthLanguage);\n  }\n  set speechSynthesisLanguage(language) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthLanguage, language);\n  }\n  get speechSynthesisVoiceName() {\n    return this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthVoice);\n  }\n  set speechSynthesisVoiceName(voice) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthVoice, voice);\n  }\n  get speechSynthesisOutputFormat() {\n    return _Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechSynthesisOutputFormat[this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];\n  }\n  set speechSynthesisOutputFormat(format) {\n    this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_6__.SpeechSynthesisOutputFormat[format]);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechRecognitionCanceledEventArgs\": () => (/* binding */ SpeechRecognitionCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\nclass SpeechRecognitionCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranscriptionEventArgs\": () => (/* binding */ ConversationTranscriptionEventArgs),\n/* harmony export */   \"SpeechRecognitionEventArgs\": () => (/* binding */ SpeechRecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n/**\n * Defines contents of speech recognizing/recognized event.\n * @class SpeechRecognitionEventArgs\n */\nclass SpeechRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {SpeechRecognitionResult} result - The speech recognition result.\n   * @param {number} offset - The offset.\n   * @param {string} sessionId - The session id.\n   */\n  constructor(result, offset, sessionId) {\n    super(offset, sessionId);\n    this.privResult = result;\n  }\n  /**\n   * Specifies the recognition result.\n   * @member SpeechRecognitionEventArgs.prototype.result\n   * @function\n   * @public\n   * @returns {SpeechRecognitionResult} the recognition result.\n   */\n  get result() {\n    return this.privResult;\n  }\n}\n/**\n * Defines contents of conversation transcribed/transcribing event.\n * @class ConversationTranscriptionEventArgs\n */\nclass ConversationTranscriptionEventArgs extends SpeechRecognitionEventArgs {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechRecognitionResult\": () => (/* binding */ SpeechRecognitionResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech recognition.\n * @class SpeechRecognitionResult\n */\nclass SpeechRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @public\n   * @param {string} resultId - The result id.\n   * @param {ResultReason} reason - The reason.\n   * @param {string} text - The recognized text.\n   * @param {number} duration - The duration.\n   * @param {number} offset - The offset into the stream.\n   * @param {string} language - Primary Language detected, if provided.\n   * @param {string} languageDetectionConfidence - Primary Language confidence (\"Unknown,\" \"Low,\" \"Medium,\" \"High\"...), if provided.\n   * @param {string} speakerId - speaker id for conversation transcription, if provided.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {string} json - Additional Json, if provided.\n   * @param {PropertyCollection} properties - Additional properties, if provided.\n   */\n  constructor(resultId, reason, text, duration, offset, language, languageDetectionConfidence, speakerId, errorDetails, json, properties) {\n    super(resultId, reason, text, duration, offset, language, languageDetectionConfidence, errorDetails, json, properties);\n    this.privSpeakerId = speakerId;\n  }\n  /**\n   * speaker id from conversation transcription/id scenarios\n   * @member SpeechRecognitionResult.prototype.speakerId\n   * @function\n   * @public\n   * @returns {string} id of speaker in given result\n   */\n  get speakerId() {\n    return this.privSpeakerId;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechRecognizer\": () => (/* binding */ SpeechRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechConnectionFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechServiceRecognizer.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n/**\n * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.\n * @class SpeechRecognizer\n */\nclass SpeechRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n  /**\n   * SpeechRecognizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n   */\n  constructor(speechConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(speechConfigImpl.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    super(audioConfig, speechConfigImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.SpeechConnectionFactory());\n    this.privDisposedRecognizer = false;\n  }\n  /**\n   * SpeechRecognizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - an set of initial properties for this recognizer\n   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the recognizer\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n   */\n  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n    const recognizer = new SpeechRecognizer(speechConfig, audioConfig);\n    return recognizer;\n  }\n  /**\n   * Gets the endpoint id of a customized speech model that is used for speech recognition.\n   * @member SpeechRecognizer.prototype.endpointId\n   * @function\n   * @public\n   * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.\n   */\n  get endpointId() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId, \"00000000-0000-0000-0000-000000000000\");\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member SpeechRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member SpeechRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n  set authorizationToken(token) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * Gets the spoken language of recognition.\n   * @member SpeechRecognizer.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @returns {string} The spoken language of recognition.\n   */\n  get speechRecognitionLanguage() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);\n  }\n  /**\n   * Gets the output format of recognition.\n   * @member SpeechRecognizer.prototype.outputFormat\n   * @function\n   * @public\n   * @returns {OutputFormat} The output format of recognition.\n   */\n  get outputFormat() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    if (this.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]) === _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat[_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple]) {\n      return _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Simple;\n    } else {\n      return _Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormat.Detailed;\n    }\n  }\n  /**\n   * The collection of properties and their values defined for this SpeechRecognizer.\n   * @member SpeechRecognizer.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Starts speech recognition, and stops after the first utterance is recognized.\n   * The task returns the recognition text as result.\n   * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,\n   * so it is suitable only for single shot recognition\n   * like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.\n   * @member SpeechRecognizer.prototype.recognizeOnceAsync\n   * @function\n   * @public\n   * @param cb - Callback that received the SpeechRecognitionResult.\n   * @param err - Callback invoked in case of an error.\n   */\n  recognizeOnceAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognitionMode.Interactive), cb, err);\n  }\n  /**\n   * Starts speech recognition, until stopContinuousRecognitionAsync() is called.\n   * User must subscribe to events to receive recognition results.\n   * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the recognition has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  startContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognitionMode.Conversation), cb, err);\n  }\n  /**\n   * Stops continuous speech recognition.\n   * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the recognition has stopped.\n   * @param err - Callback invoked in case of an error.\n   */\n  stopContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n  }\n  /**\n   * Starts speech recognition with keyword spotting, until\n   * stopKeywordRecognitionAsync() is called.\n   * User must subscribe to events to receive recognition results.\n   * Note: Key word spotting functionality is only available on the\n   * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n   * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync\n   * @function\n   * @public\n   * @param {KeywordRecognitionModel} model The keyword recognition model that\n   * specifies the keyword to be recognized.\n   * @param cb - Callback invoked once the recognition has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  startKeywordRecognitionAsync(model, cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(model, \"model\");\n    if (!!err) {\n      err(\"Not yet implemented.\");\n    }\n  }\n  /**\n   * Stops continuous speech recognition.\n   * Note: Key word spotting functionality is only available on the\n   * Speech Devices SDK. This functionality is currently not included in the SDK itself.\n   * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the recognition has stopped.\n   * @param err - Callback invoked in case of an error.\n   */\n  stopKeywordRecognitionAsync(cb) {\n    if (!!cb) {\n      cb();\n    }\n  }\n  /**\n   * closes all external resources held by an instance of this class.\n   * @member SpeechRecognizer.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, errorCb) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n  }\n  /**\n   * Disposes any resources held by the object.\n   * @member SpeechRecognizer.prototype.dispose\n   * @function\n   * @public\n   * @param {boolean} disposing - true if disposing the object.\n   */\n  dispose(disposing) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposedRecognizer) {\n        return;\n      }\n      if (disposing) {\n        this.privDisposedRecognizer = true;\n        yield this.implRecognizerStop();\n      }\n      yield _super.dispose.call(this, disposing);\n    });\n  }\n  createRecognizerConfig(speechConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.RecognizerConfig(speechConfig, this.properties);\n  }\n  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n    const configImpl = audioConfig;\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.SpeechServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisBookmarkEventArgs\": () => (/* binding */ SpeechSynthesisBookmarkEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis bookmark event.\n * @class SpeechSynthesisBookmarkEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisBookmarkEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {number} audioOffset - The audio offset.\n   * @param {string} text - The bookmark text.\n   */\n  constructor(audioOffset, text) {\n    this.privAudioOffset = audioOffset;\n    this.privText = text;\n  }\n  /**\n   * Specifies the audio offset.\n   * @member SpeechSynthesisBookmarkEventArgs.prototype.audioOffset\n   * @function\n   * @public\n   * @returns {number} the audio offset.\n   */\n  get audioOffset() {\n    return this.privAudioOffset;\n  }\n  /**\n   * Specifies the bookmark.\n   * @member SpeechSynthesisBookmarkEventArgs.prototype.text\n   * @function\n   * @public\n   * @returns {string} the bookmark text.\n   */\n  get text() {\n    return this.privText;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBookmarkEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisBoundaryType\": () => (/* binding */ SpeechSynthesisBoundaryType)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the boundary type of speech synthesis boundary event.\n * @class SpeechSynthesisBoundaryType\n * Added in version 1.21.0\n */\nvar SpeechSynthesisBoundaryType;\n(function (SpeechSynthesisBoundaryType) {\n  /**\n   * Indicates the boundary text is a word.\n   * @member SpeechSynthesisBoundaryType.Word\n   */\n  SpeechSynthesisBoundaryType[\"Word\"] = \"WordBoundary\";\n  /**\n   * Indicates the boundary text is a punctuation.\n   * @member SpeechSynthesisBoundaryType.Punctuation\n   */\n  SpeechSynthesisBoundaryType[\"Punctuation\"] = \"PunctuationBoundary\";\n  /**\n   * Indicates the boundary text is a sentence.\n   * @member SpeechSynthesisBoundaryType.Sentence\n   */\n  SpeechSynthesisBoundaryType[\"Sentence\"] = \"SentenceBoundary\";\n})(SpeechSynthesisBoundaryType || (SpeechSynthesisBoundaryType = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisBoundaryType.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisEventArgs\": () => (/* binding */ SpeechSynthesisEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis events.\n * @class SpeechSynthesisEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {SpeechSynthesisResult} result - The speech synthesis result.\n   */\n  constructor(result) {\n    this.privResult = result;\n  }\n  /**\n   * Specifies the synthesis result.\n   * @member SpeechSynthesisEventArgs.prototype.result\n   * @function\n   * @public\n   * @returns {SpeechSynthesisResult} the synthesis result.\n   */\n  get result() {\n    return this.privResult;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisOutputFormat\": () => (/* binding */ SpeechSynthesisOutputFormat)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define speech synthesis audio output formats.\n * @enum SpeechSynthesisOutputFormat\n * Updated in version 1.17.0\n */\nvar SpeechSynthesisOutputFormat;\n(function (SpeechSynthesisOutputFormat) {\n  /**\n   * raw-8khz-8bit-mono-mulaw\n   * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoMULaw,\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoMULaw\"] = 0] = \"Raw8Khz8BitMonoMULaw\";\n  /**\n   * riff-16khz-16kbps-mono-siren\n   * @note Unsupported by the service. Do not use this value.\n   * @member SpeechSynthesisOutputFormat.Riff16Khz16KbpsMonoSiren\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16KbpsMonoSiren\"] = 1] = \"Riff16Khz16KbpsMonoSiren\";\n  /**\n   * audio-16khz-16kbps-mono-siren\n   * @note Unsupported by the service. Do not use this value.\n   * @member SpeechSynthesisOutputFormat.Audio16Khz16KbpsMonoSiren\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16KbpsMonoSiren\"] = 2] = \"Audio16Khz16KbpsMonoSiren\";\n  /**\n   * audio-16khz-32kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz32KBitRateMonoMp3\"] = 3] = \"Audio16Khz32KBitRateMonoMp3\";\n  /**\n   * audio-16khz-128kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio16Khz128KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz128KBitRateMonoMp3\"] = 4] = \"Audio16Khz128KBitRateMonoMp3\";\n  /**\n   * audio-16khz-64kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio16Khz64KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz64KBitRateMonoMp3\"] = 5] = \"Audio16Khz64KBitRateMonoMp3\";\n  /**\n   * audio-24khz-48kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio24Khz48KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz48KBitRateMonoMp3\"] = 6] = \"Audio24Khz48KBitRateMonoMp3\";\n  /**\n   * audio-24khz-96kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio24Khz96KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz96KBitRateMonoMp3\"] = 7] = \"Audio24Khz96KBitRateMonoMp3\";\n  /**\n   * audio-24khz-160kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio24Khz160KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz160KBitRateMonoMp3\"] = 8] = \"Audio24Khz160KBitRateMonoMp3\";\n  /**\n   * raw-16khz-16bit-mono-truesilk\n   * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoTrueSilk\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoTrueSilk\"] = 9] = \"Raw16Khz16BitMonoTrueSilk\";\n  /**\n   * riff-16khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Riff16Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff16Khz16BitMonoPcm\"] = 10] = \"Riff16Khz16BitMonoPcm\";\n  /**\n   * riff-8khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Riff8Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz16BitMonoPcm\"] = 11] = \"Riff8Khz16BitMonoPcm\";\n  /**\n   * riff-24khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff24Khz16BitMonoPcm\"] = 12] = \"Riff24Khz16BitMonoPcm\";\n  /**\n   * riff-8khz-8bit-mono-mulaw\n   * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoMULaw\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoMULaw\"] = 13] = \"Riff8Khz8BitMonoMULaw\";\n  /**\n   * raw-16khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw16Khz16BitMonoPcm\"] = 14] = \"Raw16Khz16BitMonoPcm\";\n  /**\n   * raw-24khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoPcm\"] = 15] = \"Raw24Khz16BitMonoPcm\";\n  /**\n   * raw-8khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Raw8Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz16BitMonoPcm\"] = 16] = \"Raw8Khz16BitMonoPcm\";\n  /**\n   * ogg-16khz-16bit-mono-opus\n   * @member SpeechSynthesisOutputFormat.Ogg16Khz16BitMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg16Khz16BitMonoOpus\"] = 17] = \"Ogg16Khz16BitMonoOpus\";\n  /**\n   * ogg-24khz-16bit-mono-opus\n   * @member SpeechSynthesisOutputFormat.Ogg24Khz16BitMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg24Khz16BitMonoOpus\"] = 18] = \"Ogg24Khz16BitMonoOpus\";\n  /**\n   * raw-48khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Raw48Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw48Khz16BitMonoPcm\"] = 19] = \"Raw48Khz16BitMonoPcm\";\n  /**\n   * riff-48khz-16bit-mono-pcm\n   * @member SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff48Khz16BitMonoPcm\"] = 20] = \"Riff48Khz16BitMonoPcm\";\n  /**\n   * audio-48khz-96kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio48Khz96KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz96KBitRateMonoMp3\"] = 21] = \"Audio48Khz96KBitRateMonoMp3\";\n  /**\n   * audio-48khz-192kbitrate-mono-mp3\n   * @member SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio48Khz192KBitRateMonoMp3\"] = 22] = \"Audio48Khz192KBitRateMonoMp3\";\n  /**\n   * ogg-48khz-16bit-mono-opus\n   * Added in version 1.16.0\n   * @member SpeechSynthesisOutputFormat.Ogg48Khz16BitMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Ogg48Khz16BitMonoOpus\"] = 23] = \"Ogg48Khz16BitMonoOpus\";\n  /**\n   * webm-16khz-16bit-mono-opus\n   * Added in version 1.16.0\n   * @member SpeechSynthesisOutputFormat.Webm16Khz16BitMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm16Khz16BitMonoOpus\"] = 24] = \"Webm16Khz16BitMonoOpus\";\n  /**\n   * webm-24khz-16bit-mono-opus\n   * Added in version 1.16.0\n   * @member SpeechSynthesisOutputFormat.Webm24Khz16BitMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16BitMonoOpus\"] = 25] = \"Webm24Khz16BitMonoOpus\";\n  /**\n   * raw-24khz-16bit-mono-truesilk\n   * Added in version 1.17.0\n   * @member SpeechSynthesisOutputFormat.Raw24Khz16BitMonoTrueSilk\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw24Khz16BitMonoTrueSilk\"] = 26] = \"Raw24Khz16BitMonoTrueSilk\";\n  /**\n   * raw-8khz-8bit-mono-alaw\n   * Added in version 1.17.0\n   * @member SpeechSynthesisOutputFormat.Raw8Khz8BitMonoALaw\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw8Khz8BitMonoALaw\"] = 27] = \"Raw8Khz8BitMonoALaw\";\n  /**\n   * riff-8khz-8bit-mono-alaw\n   * Added in version 1.17.0\n   * @member SpeechSynthesisOutputFormat.Riff8Khz8BitMonoALaw\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff8Khz8BitMonoALaw\"] = 28] = \"Riff8Khz8BitMonoALaw\";\n  /**\n   * webm-24khz-16bit-24kbps-mono-opus\n   * Audio compressed by OPUS codec in a webm container, with bitrate of 24kbps, optimized for IoT scenario.\n   * Added in version 1.19.0\n   * @member SpeechSynthesisOutputFormat.Webm24Khz16Bit24KbpsMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Webm24Khz16Bit24KbpsMonoOpus\"] = 29] = \"Webm24Khz16Bit24KbpsMonoOpus\";\n  /**\n   * audio-16khz-16bit-32kbps-mono-opus\n   * Audio compressed by OPUS codec without container, with bitrate of 32kbps.\n   * Added in version 1.20.0\n   * @member SpeechSynthesisOutputFormat.Audio16Khz16Bit32KbpsMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio16Khz16Bit32KbpsMonoOpus\"] = 30] = \"Audio16Khz16Bit32KbpsMonoOpus\";\n  /**\n   * audio-24khz-16bit-48kbps-mono-opus\n   * Audio compressed by OPUS codec without container, with bitrate of 48kbps.\n   * Added in version 1.20.0\n   * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit48KbpsMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit48KbpsMonoOpus\"] = 31] = \"Audio24Khz16Bit48KbpsMonoOpus\";\n  /**\n   * audio-24khz-16bit-24kbps-mono-opus\n   * Audio compressed by OPUS codec without container, with bitrate of 24kbps.\n   * Added in version 1.20.0\n   * @member SpeechSynthesisOutputFormat.Audio24Khz16Bit24KbpsMonoOpus\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Audio24Khz16Bit24KbpsMonoOpus\"] = 32] = \"Audio24Khz16Bit24KbpsMonoOpus\";\n  /**\n   * raw-22050hz-16bit-mono-pcm\n   * Raw PCM audio at 22050Hz sampling rate and 16-bit depth.\n   * Added in version 1.22.0\n   * @member SpeechSynthesisOutputFormat.Raw22050Hz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw22050Hz16BitMonoPcm\"] = 33] = \"Raw22050Hz16BitMonoPcm\";\n  /**\n   * riff-22050hz-16bit-mono-pcm\n   * PCM audio at 22050Hz sampling rate and 16-bit depth, with RIFF header.\n   * Added in version 1.22.0\n   * @member SpeechSynthesisOutputFormat.Riff22050Hz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff22050Hz16BitMonoPcm\"] = 34] = \"Riff22050Hz16BitMonoPcm\";\n  /**\n   * raw-44100hz-16bit-mono-pcm\n   * Raw PCM audio at 44100Hz sampling rate and 16-bit depth.\n   * Added in version 1.22.0\n   * @member SpeechSynthesisOutputFormat.Raw44100Hz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Raw44100Hz16BitMonoPcm\"] = 35] = \"Raw44100Hz16BitMonoPcm\";\n  /**\n   * riff-44100hz-16bit-mono-pcm\n   * PCM audio at 44100Hz sampling rate and 16-bit depth, with RIFF header.\n   * Added in version 1.22.0\n   * @member SpeechSynthesisOutputFormat.Riff44100Hz16BitMonoPcm\n   */\n  SpeechSynthesisOutputFormat[SpeechSynthesisOutputFormat[\"Riff44100Hz16BitMonoPcm\"] = 36] = \"Riff44100Hz16BitMonoPcm\";\n})(SpeechSynthesisOutputFormat || (SpeechSynthesisOutputFormat = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisResult\": () => (/* binding */ SpeechSynthesisResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech synthesis.\n * @class SpeechSynthesisResult\n * Added in version 1.11.0\n */\nclass SpeechSynthesisResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} resultId - The result id.\n   * @param {ResultReason} reason - The reason.\n   * @param {ArrayBuffer} audioData - The synthesized audio binary.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {PropertyCollection} properties - Additional properties, if provided.\n   * @param {number} audioDuration - The audio duration.\n   */\n  constructor(resultId, reason, audioData, errorDetails, properties, audioDuration) {\n    super(resultId, reason, errorDetails, properties);\n    this.privAudioData = audioData;\n    this.privAudioDuration = audioDuration;\n  }\n  /**\n   * The synthesized audio data\n   * @member SpeechSynthesisResult.prototype.audioData\n   * @function\n   * @public\n   * @returns {ArrayBuffer} The synthesized audio data.\n   */\n  get audioData() {\n    return this.privAudioData;\n  }\n  /**\n   * The time duration of synthesized audio, in ticks (100 nanoseconds).\n   * @member SpeechSynthesisResult.prototype.audioDuration\n   * @function\n   * @public\n   * @returns {number} The time duration of synthesized audio.\n   */\n  get audioDuration() {\n    return this.privAudioDuration;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisVisemeEventArgs\": () => (/* binding */ SpeechSynthesisVisemeEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis viseme event.\n * @class SpeechSynthesisVisemeEventArgs\n * Added in version 1.16.0\n */\nclass SpeechSynthesisVisemeEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {number} audioOffset - The audio offset.\n   * @param {number} visemeId - The viseme ID.\n   * @param {string} animation - The animation, could be in svg or other format.\n   */\n  constructor(audioOffset, visemeId, animation) {\n    this.privAudioOffset = audioOffset;\n    this.privVisemeId = visemeId;\n    this.privAnimation = animation;\n  }\n  /**\n   * Specifies the audio offset.\n   * @member SpeechSynthesisVisemeEventArgs.prototype.audioOffset\n   * @function\n   * @public\n   * @returns {number} the audio offset.\n   */\n  get audioOffset() {\n    return this.privAudioOffset;\n  }\n  /**\n   * Specifies the viseme ID.\n   * @member SpeechSynthesisVisemeEventArgs.prototype.visemeId\n   * @function\n   * @public\n   * @returns {number} the viseme ID.\n   */\n  get visemeId() {\n    return this.privVisemeId;\n  }\n  /**\n   * Specifies the animation.\n   * @member SpeechSynthesisVisemeEventArgs.prototype.animation\n   * @function\n   * @public\n   * @returns {string} the animation, could be in svg or other format.\n   */\n  get animation() {\n    return this.privAnimation;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisVisemeEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesisWordBoundaryEventArgs\": () => (/* binding */ SpeechSynthesisWordBoundaryEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines contents of speech synthesis word boundary event.\n * @class SpeechSynthesisWordBoundaryEventArgs\n * Added in version 1.11.0\n */\nclass SpeechSynthesisWordBoundaryEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {number} audioOffset - The audio offset.\n   * @param {number} duration - The audio duration.\n   * @param {string} text - The text.\n   * @param {number} wordLength - The length of the word.\n   * @param {number} textOffset - The text offset.\n   * @param {SpeechSynthesisBoundaryType} boundaryType - The boundary type\n   */\n  constructor(audioOffset, duration, text, wordLength, textOffset, boundaryType) {\n    this.privAudioOffset = audioOffset;\n    this.privDuration = duration;\n    this.privText = text;\n    this.privWordLength = wordLength;\n    this.privTextOffset = textOffset;\n    this.privBoundaryType = boundaryType;\n  }\n  /**\n   * Specifies the audio offset.\n   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.audioOffset\n   * @function\n   * @public\n   * @returns {number} the audio offset.\n   */\n  get audioOffset() {\n    return this.privAudioOffset;\n  }\n  /**\n   * Specifies the duration, in ticks (100 nanoseconds).\n   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.duration\n   * @function\n   * @public\n   * @returns {number} Duration in 100 nanosecond increments.\n   */\n  get duration() {\n    return this.privDuration;\n  }\n  /**\n   * Specifies the text of the word boundary event.\n   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.text\n   * @function\n   * @public\n   * @returns {string} the text.\n   */\n  get text() {\n    return this.privText;\n  }\n  /**\n   * Specifies the word length\n   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.wordLength\n   * @function\n   * @public\n   * @returns {number} the word length\n   */\n  get wordLength() {\n    return this.privWordLength;\n  }\n  /**\n   * Specifies the text offset.\n   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.textOffset\n   * @function\n   * @public\n   * @returns {number} the text offset.\n   */\n  get textOffset() {\n    return this.privTextOffset;\n  }\n  /**\n   * Specifies the boundary type.\n   * @member SpeechSynthesisWordBoundaryEventArgs.prototype.boundaryType\n   * @function\n   * @public\n   * @returns {SpeechSynthesisBoundaryType} the boundary type.\n   */\n  get boundaryType() {\n    return this.privBoundaryType;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisWordBoundaryEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechSynthesizer\": () => (/* binding */ SpeechSynthesizer),\n/* harmony export */   \"SynthesisRequest\": () => (/* binding */ SynthesisRequest)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeechSynthesisConnectionFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisAdapterBase.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveSubscriptionKeyAuthentication.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/CognitiveTokenAuthentication.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SynthesisRestAdapter.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Queue.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Guid.js\");\n/* harmony import */ var _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./Audio/AudioFileWriter */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioFileWriter.js\");\n/* harmony import */ var _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Audio/AudioOutputFormat */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputFormat.js\");\n/* harmony import */ var _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioOutputStream.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/PushAudioOutputStreamCallback.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js\");\n/* eslint-disable @typescript-eslint/no-empty-function */\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\n\n\n/**\n * Defines the class SpeechSynthesizer for text to speech.\n * Updated in version 1.16.0\n * @class SpeechSynthesizer\n */\nclass SpeechSynthesizer {\n  /**\n   * SpeechSynthesizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer.\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer.\n   */\n  constructor(speechConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n    if (audioConfig !== null) {\n      if (audioConfig === undefined) {\n        this.audioConfig = typeof window === \"undefined\" ? undefined : _Exports__WEBPACK_IMPORTED_MODULE_1__.AudioConfig.fromDefaultSpeakerOutput();\n      } else {\n        this.audioConfig = audioConfig;\n      }\n    }\n    this.privProperties = speechConfigImpl.properties.clone();\n    this.privDisposed = false;\n    this.privSynthesizing = false;\n    this.privConnectionFactory = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.SpeechSynthesisConnectionFactory();\n    this.synthesisRequestQueue = new _common_Exports__WEBPACK_IMPORTED_MODULE_3__.Queue();\n    this.implCommonSynthesizeSetup();\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member SpeechSynthesizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member SpeechSynthesizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n  set authorizationToken(token) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * The collection of properties and their values defined for this SpeechSynthesizer.\n   * @member SpeechSynthesizer.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechSynthesizer.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Indicates if auto detect source language is enabled\n   * @member SpeechSynthesizer.prototype.properties\n   * @function\n   * @public\n   * @returns {boolean} if auto detect source language is enabled\n   */\n  get autoDetectSourceLanguage() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages) === _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.AutoDetectSourceLanguagesOpenRangeOptionName;\n  }\n  /**\n   * SpeechSynthesizer constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - an set of initial properties for this synthesizer\n   * @param {AutoDetectSourceLanguageConfig} autoDetectSourceLanguageConfig - An source language detection configuration associated with the synthesizer\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the synthesizer\n   */\n  static FromConfig(speechConfig, autoDetectSourceLanguageConfig, audioConfig) {\n    const speechConfigImpl = speechConfig;\n    autoDetectSourceLanguageConfig.properties.mergeTo(speechConfigImpl.properties);\n    return new SpeechSynthesizer(speechConfig, audioConfig);\n  }\n  buildSsml(text) {\n    const languageToDefaultVoice = {\n      [\"af-ZA\"]: \"af-ZA-AdriNeural\",\n      [\"am-ET\"]: \"am-ET-AmehaNeural\",\n      [\"ar-AE\"]: \"ar-AE-FatimaNeural\",\n      [\"ar-BH\"]: \"ar-BH-AliNeural\",\n      [\"ar-DZ\"]: \"ar-DZ-AminaNeural\",\n      [\"ar-EG\"]: \"ar-EG-SalmaNeural\",\n      [\"ar-IQ\"]: \"ar-IQ-BasselNeural\",\n      [\"ar-JO\"]: \"ar-JO-SanaNeural\",\n      [\"ar-KW\"]: \"ar-KW-FahedNeural\",\n      [\"ar-LY\"]: \"ar-LY-ImanNeural\",\n      [\"ar-MA\"]: \"ar-MA-JamalNeural\",\n      [\"ar-QA\"]: \"ar-QA-AmalNeural\",\n      [\"ar-SA\"]: \"ar-SA-HamedNeural\",\n      [\"ar-SY\"]: \"ar-SY-AmanyNeural\",\n      [\"ar-TN\"]: \"ar-TN-HediNeural\",\n      [\"ar-YE\"]: \"ar-YE-MaryamNeural\",\n      [\"bg-BG\"]: \"bg-BG-BorislavNeural\",\n      [\"bn-BD\"]: \"bn-BD-NabanitaNeural\",\n      [\"bn-IN\"]: \"bn-IN-BashkarNeural\",\n      [\"ca-ES\"]: \"ca-ES-JoanaNeural\",\n      [\"cs-CZ\"]: \"cs-CZ-AntoninNeural\",\n      [\"cy-GB\"]: \"cy-GB-AledNeural\",\n      [\"da-DK\"]: \"da-DK-ChristelNeural\",\n      [\"de-AT\"]: \"de-AT-IngridNeural\",\n      [\"de-CH\"]: \"de-CH-JanNeural\",\n      [\"de-DE\"]: \"de-DE-KatjaNeural\",\n      [\"el-GR\"]: \"el-GR-AthinaNeural\",\n      [\"en-AU\"]: \"en-AU-NatashaNeural\",\n      [\"en-CA\"]: \"en-CA-ClaraNeural\",\n      [\"en-GB\"]: \"en-GB-LibbyNeural\",\n      [\"en-HK\"]: \"en-HK-SamNeural\",\n      [\"en-IE\"]: \"en-IE-ConnorNeural\",\n      [\"en-IN\"]: \"en-IN-NeerjaNeural\",\n      [\"en-KE\"]: \"en-KE-AsiliaNeural\",\n      [\"en-NG\"]: \"en-NG-AbeoNeural\",\n      [\"en-NZ\"]: \"en-NZ-MitchellNeural\",\n      [\"en-PH\"]: \"en-PH-JamesNeural\",\n      [\"en-SG\"]: \"en-SG-LunaNeural\",\n      [\"en-TZ\"]: \"en-TZ-ElimuNeural\",\n      [\"en-US\"]: \"en-US-JennyNeural\",\n      [\"en-ZA\"]: \"en-ZA-LeahNeural\",\n      [\"es-AR\"]: \"es-AR-ElenaNeural\",\n      [\"es-BO\"]: \"es-BO-MarceloNeural\",\n      [\"es-CL\"]: \"es-CL-CatalinaNeural\",\n      [\"es-CO\"]: \"es-CO-GonzaloNeural\",\n      [\"es-CR\"]: \"es-CR-JuanNeural\",\n      [\"es-CU\"]: \"es-CU-BelkysNeural\",\n      [\"es-DO\"]: \"es-DO-EmilioNeural\",\n      [\"es-EC\"]: \"es-EC-AndreaNeural\",\n      [\"es-ES\"]: \"es-ES-AlvaroNeural\",\n      [\"es-GQ\"]: \"es-GQ-JavierNeural\",\n      [\"es-GT\"]: \"es-GT-AndresNeural\",\n      [\"es-HN\"]: \"es-HN-CarlosNeural\",\n      [\"es-MX\"]: \"es-MX-DaliaNeural\",\n      [\"es-NI\"]: \"es-NI-FedericoNeural\",\n      [\"es-PA\"]: \"es-PA-MargaritaNeural\",\n      [\"es-PE\"]: \"es-PE-AlexNeural\",\n      [\"es-PR\"]: \"es-PR-KarinaNeural\",\n      [\"es-PY\"]: \"es-PY-MarioNeural\",\n      [\"es-SV\"]: \"es-SV-LorenaNeural\",\n      [\"es-US\"]: \"es-US-AlonsoNeural\",\n      [\"es-UY\"]: \"es-UY-MateoNeural\",\n      [\"es-VE\"]: \"es-VE-PaolaNeural\",\n      [\"et-EE\"]: \"et-EE-AnuNeural\",\n      [\"fa-IR\"]: \"fa-IR-DilaraNeural\",\n      [\"fi-FI\"]: \"fi-FI-SelmaNeural\",\n      [\"fil-PH\"]: \"fil-PH-AngeloNeural\",\n      [\"fr-BE\"]: \"fr-BE-CharlineNeural\",\n      [\"fr-CA\"]: \"fr-CA-SylvieNeural\",\n      [\"fr-CH\"]: \"fr-CH-ArianeNeural\",\n      [\"fr-FR\"]: \"fr-FR-DeniseNeural\",\n      [\"ga-IE\"]: \"ga-IE-ColmNeural\",\n      [\"gl-ES\"]: \"gl-ES-RoiNeural\",\n      [\"gu-IN\"]: \"gu-IN-DhwaniNeural\",\n      [\"he-IL\"]: \"he-IL-AvriNeural\",\n      [\"hi-IN\"]: \"hi-IN-MadhurNeural\",\n      [\"hr-HR\"]: \"hr-HR-GabrijelaNeural\",\n      [\"hu-HU\"]: \"hu-HU-NoemiNeural\",\n      [\"id-ID\"]: \"id-ID-ArdiNeural\",\n      [\"is-IS\"]: \"is-IS-GudrunNeural\",\n      [\"it-IT\"]: \"it-IT-IsabellaNeural\",\n      [\"ja-JP\"]: \"ja-JP-NanamiNeural\",\n      [\"jv-ID\"]: \"jv-ID-DimasNeural\",\n      [\"kk-KZ\"]: \"kk-KZ-AigulNeural\",\n      [\"km-KH\"]: \"km-KH-PisethNeural\",\n      [\"kn-IN\"]: \"kn-IN-GaganNeural\",\n      [\"ko-KR\"]: \"ko-KR-SunHiNeural\",\n      [\"lo-LA\"]: \"lo-LA-ChanthavongNeural\",\n      [\"lt-LT\"]: \"lt-LT-LeonasNeural\",\n      [\"lv-LV\"]: \"lv-LV-EveritaNeural\",\n      [\"mk-MK\"]: \"mk-MK-AleksandarNeural\",\n      [\"ml-IN\"]: \"ml-IN-MidhunNeural\",\n      [\"mr-IN\"]: \"mr-IN-AarohiNeural\",\n      [\"ms-MY\"]: \"ms-MY-OsmanNeural\",\n      [\"mt-MT\"]: \"mt-MT-GraceNeural\",\n      [\"my-MM\"]: \"my-MM-NilarNeural\",\n      [\"nb-NO\"]: \"nb-NO-PernilleNeural\",\n      [\"nl-BE\"]: \"nl-BE-ArnaudNeural\",\n      [\"nl-NL\"]: \"nl-NL-ColetteNeural\",\n      [\"pl-PL\"]: \"pl-PL-AgnieszkaNeural\",\n      [\"ps-AF\"]: \"ps-AF-GulNawazNeural\",\n      [\"pt-BR\"]: \"pt-BR-FranciscaNeural\",\n      [\"pt-PT\"]: \"pt-PT-DuarteNeural\",\n      [\"ro-RO\"]: \"ro-RO-AlinaNeural\",\n      [\"ru-RU\"]: \"ru-RU-SvetlanaNeural\",\n      [\"si-LK\"]: \"si-LK-SameeraNeural\",\n      [\"sk-SK\"]: \"sk-SK-LukasNeural\",\n      [\"sl-SI\"]: \"sl-SI-PetraNeural\",\n      [\"so-SO\"]: \"so-SO-MuuseNeural\",\n      [\"sr-RS\"]: \"sr-RS-NicholasNeural\",\n      [\"su-ID\"]: \"su-ID-JajangNeural\",\n      [\"sv-SE\"]: \"sv-SE-SofieNeural\",\n      [\"sw-KE\"]: \"sw-KE-RafikiNeural\",\n      [\"sw-TZ\"]: \"sw-TZ-DaudiNeural\",\n      [\"ta-IN\"]: \"ta-IN-PallaviNeural\",\n      [\"ta-LK\"]: \"ta-LK-KumarNeural\",\n      [\"ta-SG\"]: \"ta-SG-AnbuNeural\",\n      [\"te-IN\"]: \"te-IN-MohanNeural\",\n      [\"th-TH\"]: \"th-TH-PremwadeeNeural\",\n      [\"tr-TR\"]: \"tr-TR-AhmetNeural\",\n      [\"uk-UA\"]: \"uk-UA-OstapNeural\",\n      [\"ur-IN\"]: \"ur-IN-GulNeural\",\n      [\"ur-PK\"]: \"ur-PK-AsadNeural\",\n      [\"uz-UZ\"]: \"uz-UZ-MadinaNeural\",\n      [\"vi-VN\"]: \"vi-VN-HoaiMyNeural\",\n      [\"zh-CN\"]: \"zh-CN-XiaoxiaoNeural\",\n      [\"zh-HK\"]: \"zh-HK-HiuMaanNeural\",\n      [\"zh-TW\"]: \"zh-TW-HsiaoChenNeural\",\n      [\"zu-ZA\"]: \"zu-ZA-ThandoNeural\"\n    };\n    let language = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthLanguage, \"en-US\");\n    let voice = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthVoice, \"\");\n    let ssml = SpeechSynthesizer.XMLEncode(text);\n    if (this.autoDetectSourceLanguage) {\n      language = \"en-US\";\n    } else {\n      voice = voice || languageToDefaultVoice[language];\n    }\n    if (voice) {\n      ssml = `<voice name='${voice}'>${ssml}</voice>`;\n    }\n    ssml = `<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xmlns:mstts='http://www.w3.org/2001/mstts' xmlns:emo='http://www.w3.org/2009/10/emotionml' xml:lang='${language}'>${ssml}</speak>`;\n    return ssml;\n  }\n  /**\n   * Executes speech synthesis on plain text.\n   * The task returns the synthesis result.\n   * @member SpeechSynthesizer.prototype.speakTextAsync\n   * @function\n   * @public\n   * @param text - Text to be synthesized.\n   * @param cb - Callback that received the SpeechSynthesisResult.\n   * @param err - Callback invoked in case of an error.\n   * @param stream - AudioOutputStream to receive the synthesized audio.\n   */\n  speakTextAsync(text, cb, err, stream) {\n    this.speakImpl(text, false, cb, err, stream);\n  }\n  /**\n   * Executes speech synthesis on SSML.\n   * The task returns the synthesis result.\n   * @member SpeechSynthesizer.prototype.speakSsmlAsync\n   * @function\n   * @public\n   * @param ssml - SSML to be synthesized.\n   * @param cb - Callback that received the SpeechSynthesisResult.\n   * @param err - Callback invoked in case of an error.\n   * @param stream - AudioOutputStream to receive the synthesized audio.\n   */\n  speakSsmlAsync(ssml, cb, err, stream) {\n    this.speakImpl(ssml, true, cb, err, stream);\n  }\n  /**\n   * Get list of synthesis voices available.\n   * The task returns the synthesis voice result.\n   * @member SpeechSynthesizer.prototype.getVoicesAsync\n   * @function\n   * @async\n   * @public\n   * @param locale - Locale of voices in BCP-47 format; if left empty, get all available voices.\n   * @return {Promise<SynthesisVoicesResult>} - Promise of a SynthesisVoicesResult.\n   */\n  getVoicesAsync() {\n    let locale = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : \"\";\n    return __awaiter(this, void 0, void 0, function* () {\n      return this.getVoices(locale);\n    });\n  }\n  /**\n   * Dispose of associated resources.\n   * @member SpeechSynthesizer.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privDisposed);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_6__.marshalPromiseToCallbacks)(this.dispose(true), cb, err);\n  }\n  /**\n   * @Internal\n   * Do not use externally, object returned will change without warning or notice.\n   */\n  get internalData() {\n    return this.privAdapter;\n  }\n  /**\n   * This method performs cleanup of resources.\n   * The Boolean parameter disposing indicates whether the method is called\n   * from Dispose (if disposing is true) or from the finalizer (if disposing is false).\n   * Derived classes should override this method to dispose resource if needed.\n   * @member SpeechSynthesizer.prototype.dispose\n   * @function\n   * @public\n   * @param {boolean} disposing - Flag to request disposal.\n   */\n  dispose(disposing) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposed) {\n        return;\n      }\n      if (disposing) {\n        if (this.privAdapter) {\n          yield this.privAdapter.dispose();\n        }\n      }\n      this.privDisposed = true;\n    });\n  }\n  //\n  // ################################################################################################################\n  // IMPLEMENTATION.\n  // Move to independent class\n  // ################################################################################################################\n  //\n  createSynthesizerConfig(speechConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.SynthesizerConfig(speechConfig, this.privProperties);\n  }\n  // Creates the synthesis adapter\n  createSynthesisAdapter(authentication, connectionFactory, audioConfig, synthesizerConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.SynthesisAdapterBase(authentication, connectionFactory, synthesizerConfig, this, this.audioConfig);\n  }\n  implCommonSynthesizeSetup() {\n    let osPlatform = typeof window !== \"undefined\" ? \"Browser\" : \"Node\";\n    let osName = \"unknown\";\n    let osVersion = \"unknown\";\n    if (typeof navigator !== \"undefined\") {\n      osPlatform = osPlatform + \"/\" + navigator.platform;\n      osName = navigator.userAgent;\n      osVersion = navigator.appVersion;\n    }\n    const synthesizerConfig = this.createSynthesizerConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeechServiceConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.OS(osPlatform, osName, osVersion))));\n    const subscriptionKey = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_Key, undefined);\n    const authentication = subscriptionKey && subscriptionKey !== \"\" ? new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_10__.CognitiveSubscriptionKeyAuthentication(subscriptionKey) : new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__.CognitiveTokenAuthentication(() => {\n      const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, undefined);\n      return Promise.resolve(authorizationToken);\n    }, () => {\n      const authorizationToken = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceAuthorization_Token, undefined);\n      return Promise.resolve(authorizationToken);\n    });\n    this.privAdapter = this.createSynthesisAdapter(authentication, this.privConnectionFactory, this.audioConfig, synthesizerConfig);\n    this.privAdapter.audioOutputFormat = _Audio_AudioOutputFormat__WEBPACK_IMPORTED_MODULE_12__.AudioOutputFormatImpl.fromSpeechSynthesisOutputFormat(_Exports__WEBPACK_IMPORTED_MODULE_13__.SpeechSynthesisOutputFormat[this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_4__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)]);\n    this.privRestAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_14__.SynthesisRestAdapter(synthesizerConfig, authentication);\n  }\n  speakImpl(text, IsSsml, cb, err, dataStream) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privDisposed);\n      const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.createNoDashGuid)();\n      let audioDestination;\n      if (dataStream instanceof _Exports__WEBPACK_IMPORTED_MODULE_16__.PushAudioOutputStreamCallback) {\n        audioDestination = new _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_17__.PushAudioOutputStreamImpl(dataStream);\n      } else if (dataStream instanceof _Audio_AudioOutputStream__WEBPACK_IMPORTED_MODULE_17__.PullAudioOutputStream) {\n        audioDestination = dataStream;\n      } else if (dataStream !== undefined) {\n        audioDestination = new _Audio_AudioFileWriter__WEBPACK_IMPORTED_MODULE_18__.AudioFileWriter(dataStream);\n      } else {\n        audioDestination = undefined;\n      }\n      this.synthesisRequestQueue.enqueue(new SynthesisRequest(requestId, text, IsSsml, e => {\n        this.privSynthesizing = false;\n        if (!!cb) {\n          try {\n            cb(e);\n          } catch (e) {\n            if (!!err) {\n              err(e);\n            }\n          }\n        }\n        cb = undefined;\n        /* eslint-disable no-empty */\n        this.adapterSpeak().catch(() => {});\n      }, e => {\n        if (!!err) {\n          err(e);\n        }\n      }, audioDestination));\n      /* eslint-disable no-empty-function */\n      this.adapterSpeak().catch(() => {});\n    } catch (error) {\n      if (!!err) {\n        if (error instanceof Error) {\n          const typedError = error;\n          err(typedError.name + \": \" + typedError.message);\n        } else {\n          err(error);\n        }\n      }\n      // Destroy the synthesizer.\n      /* eslint-disable no-empty */\n      this.dispose(true).catch(() => {});\n    }\n  }\n  getVoices(locale) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const requestId = (0,_common_Exports__WEBPACK_IMPORTED_MODULE_15__.createNoDashGuid)();\n      const response = yield this.privRestAdapter.getVoicesList(requestId);\n      if (response.ok && Array.isArray(response.json)) {\n        let json = response.json;\n        if (!!locale && locale.length > 0) {\n          json = json.filter(item => !!item.Locale && item.Locale.toLowerCase() === locale.toLowerCase());\n        }\n        return new _Exports__WEBPACK_IMPORTED_MODULE_19__.SynthesisVoicesResult(requestId, json, undefined);\n      } else {\n        return new _Exports__WEBPACK_IMPORTED_MODULE_19__.SynthesisVoicesResult(requestId, undefined, `Error: ${response.status}: ${response.statusText}`);\n      }\n    });\n  }\n  adapterSpeak() {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!this.privDisposed && !this.privSynthesizing) {\n        this.privSynthesizing = true;\n        const request = yield this.synthesisRequestQueue.dequeue();\n        return this.privAdapter.Speak(request.text, request.isSSML, request.requestId, request.cb, request.err, request.dataStream);\n      }\n    });\n  }\n  static XMLEncode(text) {\n    return text.replace(/&/g, \"&amp;\").replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\").replace(/\"/g, \"&quot;\").replace(/'/g, \"&apos;\");\n  }\n}\nclass SynthesisRequest {\n  constructor(requestId, text, isSSML, cb, err, dataStream) {\n    this.requestId = requestId;\n    this.text = text;\n    this.isSSML = isSSML;\n    this.cb = cb;\n    this.err = err;\n    this.dataStream = dataStream;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SpeechTranslationConfig\": () => (/* binding */ SpeechTranslationConfig),\n/* harmony export */   \"SpeechTranslationConfigImpl\": () => (/* binding */ SpeechTranslationConfigImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/OutputFormat.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechSynthesisOutputFormat.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Speech translation configuration.\n * @class SpeechTranslationConfig\n */\nclass SpeechTranslationConfig extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechConfig {\n  /**\n   * Creates an instance of recognizer config.\n   */\n  constructor() {\n    super();\n  }\n  /**\n   * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.\n   * @member SpeechTranslationConfig.fromSubscription\n   * @function\n   * @public\n   * @param {string} subscriptionKey - The subscription key.\n   * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {SpeechTranslationConfig} The speech translation config.\n   */\n  static fromSubscription(subscriptionKey, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(subscriptionKey, \"subscriptionKey\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const ret = new SpeechTranslationConfigImpl();\n    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);\n    return ret;\n  }\n  /**\n   * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.\n   * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token\n   * expires, the caller needs to refresh it by setting the property authorizationToken with a new\n   * valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance\n   * will encounter errors during recognition.\n   * As configuration values are copied when creating a new recognizer, the new token value will not apply\n   * to recognizers that have already been created.\n   * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer\n   * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.\n   * @member SpeechTranslationConfig.fromAuthorizationToken\n   * @function\n   * @public\n   * @param {string} authorizationToken - The authorization token.\n   * @param {string} region - The region name (see the <a href=\"https://aka.ms/csspeech/region\">region page</a>).\n   * @returns {SpeechTranslationConfig} The speech translation config.\n   */\n  static fromAuthorizationToken(authorizationToken, region) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(authorizationToken, \"authorizationToken\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(region, \"region\");\n    const ret = new SpeechTranslationConfigImpl();\n    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region, region);\n    return ret;\n  }\n  /**\n   * Creates an instance of the speech config with specified host and subscription key.\n   * This method is intended only for users who use a non-default service host. Standard resource path will be assumed.\n   * For services with a non-standard resource path or no path at all, use fromEndpoint instead.\n   * Note: Query parameters are not allowed in the host URI and must be set by other APIs.\n   * Note: To use an authorization token with fromHost, use fromHost(URL),\n   * and then set the AuthorizationToken property on the created SpeechConfig instance.\n   * Note: Added in version 1.9.0.\n   * @member SpeechConfig.fromHost\n   * @function\n   * @public\n   * @param {URL} host - The service endpoint to connect to. Format is \"protocol://host:port\" where \":port\" is optional.\n   * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.\n   * @returns {SpeechConfig} A speech factory instance.\n   */\n  static fromHost(hostName, subscriptionKey) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(hostName, \"hostName\");\n    const speechImpl = new SpeechTranslationConfigImpl();\n    speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Host, hostName.protocol + \"//\" + hostName.hostname + (hostName.port === \"\" ? \"\" : \":\" + hostName.port));\n    if (undefined !== subscriptionKey) {\n      speechImpl.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    }\n    return speechImpl;\n  }\n  /**\n   * Creates an instance of the speech translation config with specified endpoint and subscription key.\n   * This method is intended only for users who use a non-standard service endpoint or paramters.\n   * Note: The query properties specified in the endpoint URL are not changed, even if they are\n   * set by any other APIs. For example, if language is defined in the uri as query parameter\n   * \"language=de-DE\", and also set by the speechRecognitionLanguage property, the language\n   * setting in uri takes precedence, and the effective language is \"de-DE\".\n   * Only the properties that are not specified in the endpoint URL can be set by other APIs.\n   * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the\n   * fromEndpoint method, and then set authorizationToken=\"token\" on the created SpeechConfig instance to\n   * use the authorization token.\n   * @member SpeechTranslationConfig.fromEndpoint\n   * @function\n   * @public\n   * @param {URL} endpoint - The service endpoint to connect to.\n   * @param {string} subscriptionKey - The subscription key.\n   * @returns {SpeechTranslationConfig} A speech config instance.\n   */\n  static fromEndpoint(endpoint, subscriptionKey) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(endpoint, \"endpoint\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(subscriptionKey, \"subscriptionKey\");\n    const ret = new SpeechTranslationConfigImpl();\n    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Endpoint, endpoint.href);\n    ret.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key, subscriptionKey);\n    return ret;\n  }\n}\n/**\n * @private\n * @class SpeechTranslationConfigImpl\n */\nclass SpeechTranslationConfigImpl extends SpeechTranslationConfig {\n  constructor() {\n    super();\n    this.privSpeechProperties = new _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyCollection();\n    this.outputFormat = _Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat.Simple;\n  }\n  /**\n   * Gets/Sets the authorization token.\n   * If this is set, subscription key is ignored.\n   * User needs to make sure the provided authorization token is valid and not expired.\n   * @member SpeechTranslationConfigImpl.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} value - The authorization token.\n   */\n  set authorizationToken(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, value);\n  }\n  /**\n   * Sets the speech recognition language.\n   * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @param {string} value - The authorization token.\n   */\n  set speechRecognitionLanguage(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage, value);\n  }\n  /**\n   * Gets the speech recognition language.\n   * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @return {string} The speechRecognitionLanguage.\n   */\n  get speechRecognitionLanguage() {\n    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n  }\n  /**\n   * @member SpeechTranslationConfigImpl.prototype.subscriptionKey\n   * @function\n   * @public\n   */\n  get subscriptionKey() {\n    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Key]);\n  }\n  /**\n   * Gets the output format\n   * @member SpeechTranslationConfigImpl.prototype.outputFormat\n   * @function\n   * @public\n   */\n  get outputFormat() {\n    // eslint-disable-next-line\n    return _Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormatPropertyName, undefined)];\n  }\n  /**\n   * Gets/Sets the output format\n   * @member SpeechTranslationConfigImpl.prototype.outputFormat\n   * @function\n   * @public\n   */\n  set outputFormat(value) {\n    this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.OutputFormatPropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.OutputFormat[value]);\n  }\n  /**\n   * Gets the endpoint id.\n   * @member SpeechTranslationConfigImpl.prototype.endpointId\n   * @function\n   * @public\n   */\n  get endpointId() {\n    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId);\n  }\n  /**\n   * Gets/Sets the endpoint id.\n   * @member SpeechTranslationConfigImpl.prototype.endpointId\n   * @function\n   * @public\n   */\n  set endpointId(value) {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EndpointId, value);\n  }\n  /**\n   * Add a (text) target language to translate into.\n   * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage\n   * @function\n   * @public\n   * @param {string} value - The language such as de-DE\n   */\n  addTargetLanguage(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n    const languages = this.targetLanguages;\n    languages.push(value);\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n  }\n  /**\n   * Gets the (text) target language to translate into.\n   * @member SpeechTranslationConfigImpl.prototype.targetLanguages\n   * @function\n   * @public\n   * @param {string} value - The language such as de-DE\n   */\n  get targetLanguages() {\n    if (this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n      return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n    } else {\n      return [];\n    }\n  }\n  /**\n   * Gets the voice name.\n   * @member SpeechTranslationConfigImpl.prototype.voiceName\n   * @function\n   * @public\n   */\n  get voiceName() {\n    return this.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationVoice]);\n  }\n  /**\n   * Gets/Sets the voice of the translated language, enable voice synthesis output.\n   * @member SpeechTranslationConfigImpl.prototype.voiceName\n   * @function\n   * @public\n   * @param {string} value - The name of the voice.\n   */\n  set voiceName(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(value, \"value\");\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_TranslationVoice, value);\n  }\n  /**\n   * Provides the region.\n   * @member SpeechTranslationConfigImpl.prototype.region\n   * @function\n   * @public\n   * @returns {string} The region.\n   */\n  get region() {\n    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_Region);\n  }\n  setProxy(proxyHostName, proxyPort, proxyUserName, proxyPassword) {\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyHostName], proxyHostName);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPort], proxyPort);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyUserName], proxyUserName);\n    this.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_ProxyPassword], proxyPassword);\n  }\n  /**\n   * Gets an arbitrary property value.\n   * @member SpeechTranslationConfigImpl.prototype.getProperty\n   * @function\n   * @public\n   * @param {string} name - The name of the property.\n   * @param {string} def - The default value of the property in case it is not set.\n   * @returns {string} The value of the property.\n   */\n  getProperty(name, def) {\n    return this.privSpeechProperties.getProperty(name, def);\n  }\n  /**\n   * Gets/Sets an arbitrary property value.\n   * @member SpeechTranslationConfigImpl.prototype.setProperty\n   * @function\n   * @public\n   * @param {string} name - The name of the property.\n   * @param {string} value - The value of the property.\n   */\n  setProperty(name, value) {\n    this.privSpeechProperties.setProperty(name, value);\n  }\n  /**\n   * Provides access to custom properties.\n   * @member SpeechTranslationConfigImpl.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The properties.\n   */\n  get properties() {\n    return this.privSpeechProperties;\n  }\n  /**\n   * Dispose of associated resources.\n   * @member SpeechTranslationConfigImpl.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return;\n  }\n  setServiceProperty(name, value) {\n    const currentProperties = JSON.parse(this.privSpeechProperties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ServicePropertiesPropertyName, \"{}\"));\n    currentProperties[name] = value;\n    this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ServicePropertiesPropertyName, JSON.stringify(currentProperties));\n  }\n  setProfanity(profanity) {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_ProfanityOption, _Exports__WEBPACK_IMPORTED_MODULE_6__.ProfanityOption[profanity]);\n  }\n  enableAudioLogging() {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_EnableAudioLogging, \"true\");\n  }\n  requestWordLevelTimestamps() {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps, \"true\");\n  }\n  enableDictation() {\n    this.privSpeechProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ForceDictationPropertyName, \"true\");\n  }\n  get speechSynthesisLanguage() {\n    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthLanguage);\n  }\n  set speechSynthesisLanguage(language) {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthLanguage, language);\n  }\n  get speechSynthesisVoiceName() {\n    return this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthVoice);\n  }\n  set speechSynthesisVoiceName(voice) {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthVoice, voice);\n  }\n  get speechSynthesisOutputFormat() {\n    // eslint-disable-next-line\n    return _Exports__WEBPACK_IMPORTED_MODULE_7__.SpeechSynthesisOutputFormat[this.privSpeechProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthOutputFormat, undefined)];\n  }\n  set speechSynthesisOutputFormat(format) {\n    this.privSpeechProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_SynthOutputFormat, _Exports__WEBPACK_IMPORTED_MODULE_7__.SpeechSynthesisOutputFormat[format]);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisResult\": () => (/* binding */ SynthesisResult)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Base class for synthesis results\n * @class SynthesisResult\n * Added in version 1.20.0\n */\nclass SynthesisResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} resultId - The result id.\n   * @param {ResultReason} reason - The reason.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {PropertyCollection} properties - Additional properties, if provided.\n   */\n  constructor(resultId, reason, errorDetails, properties) {\n    this.privResultId = resultId;\n    this.privReason = reason;\n    this.privErrorDetails = errorDetails;\n    this.privProperties = properties;\n  }\n  /**\n   * Specifies the result identifier.\n   * @member SynthesisResult.prototype.resultId\n   * @function\n   * @public\n   * @returns {string} Specifies the result identifier.\n   */\n  get resultId() {\n    return this.privResultId;\n  }\n  /**\n   * Specifies status of the result.\n   * @member SynthesisResult.prototype.reason\n   * @function\n   * @public\n   * @returns {ResultReason} Specifies status of the result.\n   */\n  get reason() {\n    return this.privReason;\n  }\n  /**\n   * In case of an unsuccessful synthesis, provides details of the occurred error.\n   * @member SynthesisResult.prototype.errorDetails\n   * @function\n   * @public\n   * @returns {string} a brief description of an error.\n   */\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n  /**\n   * The set of properties exposed in the result.\n   * @member SynthesisResult.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The set of properties exposed in the result.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisVoicesResult\": () => (/* binding */ SynthesisVoicesResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisResult.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines result of speech synthesis.\n * @class SynthesisVoicesResult\n * Added in version 1.20.0\n */\nclass SynthesisVoicesResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SynthesisResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param requestId - result id for request.\n   * @param json - json payload from endpoint.\n   */\n  constructor(requestId, json, errorDetails) {\n    if (Array.isArray(json)) {\n      super(requestId, _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.VoicesListRetrieved, undefined, new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection());\n      this.privVoices = [];\n      for (const item of json) {\n        this.privVoices.push(new _Exports__WEBPACK_IMPORTED_MODULE_3__.VoiceInfo(item));\n      }\n    } else {\n      super(requestId, _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled, errorDetails ? errorDetails : \"Error information unavailable\", new _Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyCollection());\n    }\n  }\n  /**\n   * The list of voices\n   * @member SynthesisVoicesResult.prototype.voices\n   * @function\n   * @public\n   * @returns {VoiceInfo[]} List of synthesized voices.\n   */\n  get voices() {\n    return this.privVoices;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SynthesisVoicesResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Conversation\": () => (/* binding */ Conversation),\n/* harmony export */   \"ConversationImpl\": () => (/* binding */ ConversationImpl)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorInterfaces.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationManager.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationTranslatorRecognizer.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\nclass Conversation {\n  constructor() {\n    return;\n  }\n  /**\n   * Create a conversation\n   * @param speechConfig\n   * @param cb\n   * @param err\n   */\n  static createConversationAsync(speechConfig, arg2, arg3, arg4) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(speechConfig, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"config\"));\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(speechConfig.region, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Region\"));\n    if (!speechConfig.subscriptionKey && !speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token])) {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(speechConfig.subscriptionKey, _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors.invalidArgs.replace(\"{arg}\", \"SpeechServiceConnection_Key\"));\n    }\n    let conversationImpl;\n    let cb;\n    let err;\n    if (typeof arg2 === \"string\") {\n      conversationImpl = new ConversationImpl(speechConfig, arg2);\n      // eslint-disable-next-line @typescript-eslint/no-empty-function\n      (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {}))(), arg3, arg4);\n    } else {\n      conversationImpl = new ConversationImpl(speechConfig);\n      cb = arg2;\n      err = arg3;\n      conversationImpl.createConversationAsync(() => {\n        if (!!cb) {\n          cb();\n        }\n      }, error => {\n        if (!!err) {\n          err(error);\n        }\n      });\n    }\n    return conversationImpl;\n  }\n}\nclass ConversationImpl extends Conversation {\n  /**\n   * Create a conversation impl\n   * @param speechConfig\n   * @param {string} id - optional conversationId\n   */\n  constructor(speechConfig, id) {\n    super();\n    this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.restErrors;\n    /** websocket callbacks */\n    /* eslint-disable @typescript-eslint/typedef */\n    this.onConnected = e => {\n      var _a;\n      this.privIsConnected = true;\n      try {\n        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStarted)) {\n          this.privConversationTranslator.sessionStarted(this.privConversationTranslator, e);\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onDisconnected = e => {\n      var _a;\n      try {\n        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.sessionStopped)) {\n          this.privConversationTranslator.sessionStopped(this.privConversationTranslator, e);\n        }\n      } catch (e) {\n        //\n      } finally {\n        void this.close(false);\n      }\n    };\n    this.onCanceled = (r, e) => {\n      var _a;\n      try {\n        if (!!((_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.canceled)) {\n          this.privConversationTranslator.canceled(this.privConversationTranslator, e);\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onParticipantUpdateCommandReceived = (r, e) => {\n      try {\n        const updatedParticipant = this.privParticipants.getParticipant(e.id);\n        if (updatedParticipant !== undefined) {\n          switch (e.key) {\n            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.changeNickname:\n              updatedParticipant.displayName = e.value;\n              break;\n            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setUseTTS:\n              updatedParticipant.isUsingTts = e.value;\n              break;\n            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setProfanityFiltering:\n              updatedParticipant.profanity = e.value;\n              break;\n            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setMute:\n              updatedParticipant.isMuted = e.value;\n              break;\n            case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setTranslateToLanguages:\n              updatedParticipant.translateToLanguages = e.value;\n              break;\n          }\n          this.privParticipants.addOrUpdateParticipant(updatedParticipant);\n          if (!!this.privConversationTranslator) {\n            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.Updated, [this.toParticipant(updatedParticipant)], e.sessionId));\n          }\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onLockRoomCommandReceived = () => {\n      // TODO\n    };\n    this.onMuteAllCommandReceived = (r, e) => {\n      try {\n        this.privParticipants.participants.forEach(p => p.isMuted = p.isHost ? false : e.isMuted);\n        if (!!this.privConversationTranslator) {\n          this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.Updated, this.toParticipants(false), e.sessionId));\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onParticipantJoinCommandReceived = (r, e) => {\n      try {\n        const newParticipant = this.privParticipants.addOrUpdateParticipant(e.participant);\n        if (newParticipant !== undefined) {\n          if (!!this.privConversationTranslator) {\n            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.JoinedConversation, [this.toParticipant(newParticipant)], e.sessionId));\n          }\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onParticipantLeaveCommandReceived = (r, e) => {\n      try {\n        const ejectedParticipant = this.privParticipants.getParticipant(e.participant.id);\n        if (ejectedParticipant !== undefined) {\n          // remove the participant from the internal participants list\n          this.privParticipants.deleteParticipant(e.participant.id);\n          if (!!this.privConversationTranslator) {\n            // notify subscribers that the participant has left the conversation\n            this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.LeftConversation, [this.toParticipant(ejectedParticipant)], e.sessionId));\n          }\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onTranslationReceived = (r, e) => {\n      try {\n        switch (e.command) {\n          case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.final:\n            if (!!this.privConversationTranslator) {\n              this.privConversationTranslator.transcribed(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n            }\n            break;\n          case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.partial:\n            if (!!this.privConversationTranslator) {\n              this.privConversationTranslator.transcribing(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n            }\n            break;\n          case _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.instantMessage:\n            if (!!this.privConversationTranslator) {\n              this.privConversationTranslator.textMessageReceived(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_7__.ConversationTranslationEventArgs(e.payload, undefined, e.sessionId));\n            }\n            break;\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onParticipantsListReceived = (r, e) => {\n      var _a;\n      try {\n        // check if the session token needs to be updated\n        if (e.sessionToken !== undefined && e.sessionToken !== null) {\n          this.privRoom.token = e.sessionToken;\n        }\n        // save the participants\n        this.privParticipants.participants = [...e.participants];\n        // enable the conversation\n        if (this.privParticipants.me !== undefined) {\n          this.privIsReady = true;\n        }\n        if (!!this.privConversationTranslator) {\n          this.privConversationTranslator.participantsChanged(this.privConversationTranslator, new _Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationParticipantsChangedEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_6__.ParticipantChangedReason.JoinedConversation, this.toParticipants(true), e.sessionId));\n        }\n        // if this is the host, update the nickname if needed\n        if (this.me.isHost) {\n          const nickname = (_a = this.privConversationTranslator) === null || _a === void 0 ? void 0 : _a.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.ConversationTranslator_Name);\n          if (nickname !== undefined && nickname.length > 0 && nickname !== this.me.displayName) {\n            // issue a change nickname request\n            this.changeNicknameAsync(nickname);\n          }\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.onConversationExpiration = (r, e) => {\n      try {\n        if (!!this.privConversationTranslator) {\n          this.privConversationTranslator.conversationExpiration(this.privConversationTranslator, e);\n        }\n      } catch (e) {\n        //\n      }\n    };\n    this.privIsConnected = false;\n    this.privIsDisposed = false;\n    this.privConversationId = \"\";\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_8__.PropertyCollection();\n    this.privManager = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.ConversationManager();\n    // check the speech language\n    const language = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    if (!language) {\n      speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.defaultLanguageCode);\n    }\n    this.privLanguage = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n    if (!id) {\n      // check the target language(s)\n      if (speechConfig.targetLanguages.length === 0) {\n        speechConfig.addTargetLanguage(this.privLanguage);\n      }\n      // check the profanity setting: speech and conversationTranslator should be in sync\n      const profanity = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceResponse_ProfanityOption]);\n      if (!profanity) {\n        speechConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_10__.ProfanityOption.Masked);\n      }\n      // check the nickname: it should pass this regex: ^\\w+([\\s-][\\w\\(\\)]+)*$\"\n      // TODO: specify the regex required. Nicknames must be unique or get the duplicate nickname error\n      // TODO: check what the max length is and if a truncation is required or if the service handles it without an error\n      let hostNickname = speechConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.ConversationTranslator_Name]);\n      if (hostNickname === undefined || hostNickname === null || hostNickname.length <= 1 || hostNickname.length > 50) {\n        hostNickname = \"Host\";\n      }\n      speechConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.ConversationTranslator_Name], hostNickname);\n    } else {\n      this.privConversationId = id;\n    }\n    // save the speech config for future usage\n    this.privConfig = speechConfig;\n    // save the config properties\n    const configImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(configImpl, \"speechConfig\");\n    this.privProperties = configImpl.properties.clone();\n    this.privIsConnected = false;\n    this.privParticipants = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.InternalParticipants();\n    this.privIsReady = false;\n    this.privTextMessageMaxLength = 1000;\n  }\n  // get the internal data about a conversation\n  get room() {\n    return this.privRoom;\n  }\n  // get the wrapper for connecting to the websockets\n  get connection() {\n    return this.privConversationRecognizer; // this.privConnection;\n  }\n  // get the config\n  get config() {\n    return this.privConfig;\n  }\n  // get the conversation Id\n  get conversationId() {\n    return this.privRoom ? this.privRoom.roomId : this.privConversationId;\n  }\n  // get the properties\n  get properties() {\n    return this.privProperties;\n  }\n  // get the speech language\n  get speechRecognitionLanguage() {\n    return this.privLanguage;\n  }\n  get isMutedByHost() {\n    var _a, _b;\n    return ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost) ? false : (_b = this.privParticipants.me) === null || _b === void 0 ? void 0 : _b.isMuted;\n  }\n  get isConnected() {\n    return this.privIsConnected && this.privIsReady;\n  }\n  get participants() {\n    return this.toParticipants(true);\n  }\n  get me() {\n    return this.toParticipant(this.privParticipants.me);\n  }\n  get host() {\n    return this.toParticipant(this.privParticipants.host);\n  }\n  get transcriberRecognizer() {\n    return this.privTranscriberRecognizer;\n  }\n  get conversationInfo() {\n    const convId = this.conversationId;\n    const p = this.participants.map(part => ({\n      id: part.id,\n      preferredLanguage: part.preferredLanguage,\n      voice: part.voice\n    }));\n    const props = {};\n    for (const key of _common_speech_Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationConnectionConfig.transcriptionEventKeys) {\n      const val = this.properties.getProperty(key, \"\");\n      if (val !== \"\") {\n        props[key] = val;\n      }\n    }\n    const info = {\n      id: convId,\n      participants: p,\n      conversationProperties: props\n    };\n    return info;\n  }\n  get canSend() {\n    var _a;\n    return this.privIsConnected && !((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isMuted);\n  }\n  get canSendAsHost() {\n    var _a;\n    return this.privIsConnected && ((_a = this.privParticipants.me) === null || _a === void 0 ? void 0 : _a.isHost);\n  }\n  // get / set the speech auth token\n  // eslint-disable-next-line @typescript-eslint/member-ordering\n  get authorizationToken() {\n    return this.privToken;\n  }\n  set authorizationToken(value) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(value, \"authorizationToken\");\n    this.privToken = value;\n  }\n  set conversationTranslator(conversationTranslator) {\n    this.privConversationTranslator = conversationTranslator;\n  }\n  /**\n   * Create a new conversation as Host\n   * @param cb\n   * @param err\n   */\n  createConversationAsync(cb, err) {\n    try {\n      if (!!this.privConversationRecognizer) {\n        this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n      }\n      this.privManager.createOrJoin(this.privProperties, undefined, room => {\n        if (!room) {\n          this.handleError(new Error(this.privErrors.permissionDeniedConnect), err);\n        }\n        this.privRoom = room;\n        this.handleCallback(cb, err);\n      }, error => {\n        this.handleError(error, err);\n      });\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Starts a new conversation as host.\n   * @param cb\n   * @param err\n   */\n  startConversationAsync(cb, err) {\n    try {\n      // check if there is already a recognizer\n      if (!!this.privConversationRecognizer) {\n        this.handleError(new Error(this.privErrors.permissionDeniedStart), err);\n      }\n      // check if there is conversation data available\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedConnect);\n      // connect to the conversation websocket\n      this.privParticipants.meId = this.privRoom.participantId;\n      this.privConversationRecognizer = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_11__.ConversationRecognizerFactory.fromConfig(this, this.privConfig);\n      // Because ConversationTranslator manually sets up and manages the connection, Conversation\n      // has to forward serviceRecognizer connection events that usually get passed automatically\n      this.privConversationRecognizer.connected = this.onConnected;\n      this.privConversationRecognizer.disconnected = this.onDisconnected;\n      this.privConversationRecognizer.canceled = this.onCanceled;\n      this.privConversationRecognizer.participantUpdateCommandReceived = this.onParticipantUpdateCommandReceived;\n      this.privConversationRecognizer.lockRoomCommandReceived = this.onLockRoomCommandReceived;\n      this.privConversationRecognizer.muteAllCommandReceived = this.onMuteAllCommandReceived;\n      this.privConversationRecognizer.participantJoinCommandReceived = this.onParticipantJoinCommandReceived;\n      this.privConversationRecognizer.participantLeaveCommandReceived = this.onParticipantLeaveCommandReceived;\n      this.privConversationRecognizer.translationReceived = this.onTranslationReceived;\n      this.privConversationRecognizer.participantsListReceived = this.onParticipantsListReceived;\n      this.privConversationRecognizer.conversationExpiration = this.onConversationExpiration;\n      this.privConversationRecognizer.connect(this.privRoom.token, () => {\n        this.handleCallback(cb, err);\n      }, error => {\n        this.handleError(error, err);\n      });\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Join a conversation as a participant.\n   * @param { IParticipant } participant - participant to add\n   * @param cb\n   * @param err\n   */\n  addParticipantAsync(participant, cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(participant, \"Participant\");\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.addParticipantImplAsync(participant), cb, err);\n  }\n  /**\n   * Join a conversation as a participant.\n   * @param conversation\n   * @param nickname\n   * @param lang\n   * @param cb\n   * @param err\n   */\n  joinConversationAsync(conversationId, nickname, lang, cb, err) {\n    try {\n      // TODO\n      // if (!!this.privConversationRecognizer) {\n      //     throw new Error(this.privErrors.permissionDeniedStart);\n      // }\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(conversationId, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversationId\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(lang, this.privErrors.invalidArgs.replace(\"{arg}\", \"language\"));\n      // join the conversation\n      this.privManager.createOrJoin(this.privProperties, conversationId, room => {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(room, this.privErrors.permissionDeniedConnect);\n        this.privRoom = room;\n        this.privConfig.authorizationToken = room.cognitiveSpeechAuthToken;\n        // join callback\n        if (!!cb) {\n          cb(room.cognitiveSpeechAuthToken);\n        }\n      }, error => {\n        this.handleError(error, err);\n      });\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Deletes a conversation\n   * @param cb\n   * @param err\n   */\n  deleteConversationAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.deleteConversationImplAsync(), cb, err);\n  }\n  deleteConversationImplAsync() {\n    return __awaiter(this, void 0, void 0, function* () {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privProperties, this.privErrors.permissionDeniedConnect);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.token, this.privErrors.permissionDeniedConnect);\n      yield this.privManager.leave(this.privProperties, this.privRoom.token);\n      this.dispose();\n    });\n  }\n  /**\n   * Issues a request to close the client websockets\n   * @param cb\n   * @param err\n   */\n  endConversationAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.endConversationImplAsync(), cb, err);\n  }\n  endConversationImplAsync() {\n    return this.close(true);\n  }\n  /**\n   * Issues a request to lock the conversation\n   * @param cb\n   * @param err\n   */\n  lockConversationAsync(cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      if (!this.canSendAsHost) {\n        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"lock\")), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getLockCommand(true), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Issues a request to mute the conversation\n   * @param cb\n   * @param err\n   */\n  muteAllParticipantsAsync(cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privConversationRecognizer, this.privErrors.permissionDeniedSend);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      // check the user's permissions\n      if (!this.canSendAsHost) {\n        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"mute\")), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(true), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Issues a request to mute a participant in the conversation\n   * @param userId\n   * @param cb\n   * @param err\n   */\n  muteParticipantAsync(userId, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      // check the connection is open (host + participant can perform the mute command)\n      if (!this.canSend) {\n        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n      }\n      // if not host, check the participant is not muting another participant\n      if (!this.me.isHost && this.me.id !== userId) {\n        this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n      }\n      // check the user exists\n      const exists = this.privParticipants.getParticipantIndex(userId);\n      if (exists === -1) {\n        this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, true), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Issues a request to remove a participant from the conversation\n   * @param userId\n   * @param cb\n   * @param err\n   */\n  removeParticipantAsync(userId, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      if (!!this.privTranscriberRecognizer && userId.hasOwnProperty(\"id\")) {\n        // Assume this is a transcription participant\n        (0,_common_Exports__WEBPACK_IMPORTED_MODULE_3__.marshalPromiseToCallbacks)(this.removeParticipantImplAsync(userId), cb, err);\n      } else {\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n        if (!this.canSendAsHost) {\n          this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"remove\")), err);\n        }\n        let participantId = \"\";\n        if (typeof userId === \"string\") {\n          participantId = userId;\n        } else if (userId.hasOwnProperty(\"id\")) {\n          const participant = userId;\n          participantId = participant.id;\n        } else if (userId.hasOwnProperty(\"userId\")) {\n          const user = userId;\n          participantId = user.userId;\n        }\n        _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(participantId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n        // check the participant exists\n        const index = this.participants.findIndex(p => p.id === participantId);\n        if (index === -1) {\n          this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n        }\n        if (!!this.privConversationRecognizer) {\n          this.privConversationRecognizer.sendRequest(this.getEjectCommand(participantId), () => {\n            this.handleCallback(cb, err);\n          }, error => {\n            this.handleError(error, err);\n          });\n        }\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Issues a request to unlock the conversation\n   * @param cb\n   * @param err\n   */\n  unlockConversationAsync(cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      if (!this.canSendAsHost) {\n        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unlock\")), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getLockCommand(false), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Issues a request to unmute all participants in the conversation\n   * @param cb\n   * @param err\n   */\n  unmuteAllParticipantsAsync(cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      if (!this.canSendAsHost) {\n        this.handleError(new Error(this.privErrors.permissionDeniedConversation.replace(\"{command}\", \"unmute all\")), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getMuteAllCommand(false), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Issues a request to unmute a participant in the conversation\n   * @param userId\n   * @param cb\n   * @param err\n   */\n  unmuteParticipantAsync(userId, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(userId, this.privErrors.invalidArgs.replace(\"{arg}\", \"userId\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      // check the connection is open (host + participant can perform the mute command)\n      if (!this.canSend) {\n        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n      }\n      // if not host, check the participant is not muting another participant\n      if (!this.me.isHost && this.me.id !== userId) {\n        this.handleError(new Error(this.privErrors.permissionDeniedParticipant.replace(\"{command}\", \"mute\")), err);\n      }\n      // check the user exists\n      const exists = this.privParticipants.getParticipantIndex(userId);\n      if (exists === -1) {\n        this.handleError(new Error(this.privErrors.invalidParticipantRequest), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getMuteCommand(userId, false), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Send a text message\n   * @param message\n   * @param cb\n   * @param err\n   */\n  sendTextMessageAsync(message, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", \"message\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      if (!this.canSend) {\n        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n      }\n      // TODO: is a max length check required?\n      if (message.length > this.privTextMessageMaxLength) {\n        this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"message length\")), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getMessageCommand(message), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Set translated to languages\n   * @param {string[]} languages - languages to translate to\n   * @param cb\n   * @param err\n   */\n  setTranslatedLanguagesAsync(languages, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfArrayEmptyOrWhitespace(languages, this.privErrors.invalidArgs.replace(\"{arg}\", \"languages\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      if (!this.canSend) {\n        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getSetTranslateToLanguagesCommand(languages), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Change nickname\n   * @param {string} nickname - new nickname for the room\n   * @param cb\n   * @param err\n   */\n  changeNicknameAsync(nickname, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privIsDisposed);\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfDisposed(this.privConversationRecognizer.isDisposed());\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(this.privRoom, this.privErrors.permissionDeniedSend);\n      if (!this.canSend) {\n        this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n      }\n      if (!!this.privConversationRecognizer) {\n        this.privConversationRecognizer.sendRequest(this.getChangeNicknameCommand(nickname), () => {\n          this.handleCallback(cb, err);\n        }, error => {\n          this.handleError(error, err);\n        });\n      }\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  dispose() {\n    if (this.isDisposed) {\n      return;\n    }\n    this.privIsDisposed = true;\n    if (!!this.config) {\n      this.config.close();\n    }\n    this.privConfig = undefined;\n    this.privLanguage = undefined;\n    this.privProperties = undefined;\n    this.privRoom = undefined;\n    this.privToken = undefined;\n    this.privManager = undefined;\n    this.privIsConnected = false;\n    this.privIsReady = false;\n    this.privParticipants = undefined;\n  }\n  connectTranscriberRecognizer(recognizer) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (!!this.privTranscriberRecognizer) {\n        yield this.privTranscriberRecognizer.close();\n      }\n      yield recognizer.enforceAudioGating();\n      this.privTranscriberRecognizer = recognizer;\n      this.privTranscriberRecognizer.conversation = this;\n    });\n  }\n  getKeepAlive() {\n    const nickname = !!this.me ? this.me.displayName : \"default_nickname\";\n    return JSON.stringify({\n      id: \"0\",\n      nickname,\n      participantId: this.privRoom.participantId,\n      roomId: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.keepAlive\n    });\n  }\n  /* eslint-enable @typescript-eslint/typedef */\n  addParticipantImplAsync(participant) {\n    const newParticipant = this.privParticipants.addOrUpdateParticipant(participant);\n    if (newParticipant !== undefined) {\n      if (!!this.privTranscriberRecognizer) {\n        const conversationInfo = this.conversationInfo;\n        conversationInfo.participants = [participant];\n        return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, \"join\");\n      }\n    }\n  }\n  removeParticipantImplAsync(participant) {\n    this.privParticipants.deleteParticipant(participant.id);\n    const conversationInfo = this.conversationInfo;\n    conversationInfo.participants = [participant];\n    return this.privTranscriberRecognizer.pushConversationEvent(conversationInfo, \"leave\");\n  }\n  close(dispose) {\n    var _a;\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        this.privIsConnected = false;\n        yield (_a = this.privConversationRecognizer) === null || _a === void 0 ? void 0 : _a.close();\n        this.privConversationRecognizer = undefined;\n        if (!!this.privConversationTranslator) {\n          this.privConversationTranslator.dispose();\n        }\n      } catch (e) {\n        // ignore error\n        throw e;\n      }\n      if (dispose) {\n        this.dispose();\n      }\n    });\n  }\n  /** Helpers */\n  handleCallback(cb, err) {\n    if (!!cb) {\n      try {\n        cb();\n      } catch (e) {\n        if (!!err) {\n          err(e);\n        }\n      }\n      cb = undefined;\n    }\n  }\n  handleError(error, err) {\n    if (!!err) {\n      if (error instanceof Error) {\n        const typedError = error;\n        err(typedError.name + \": \" + typedError.message);\n      } else {\n        err(error);\n      }\n    }\n  }\n  /** Participant Helpers */\n  toParticipants(includeHost) {\n    const participants = this.privParticipants.participants.map(p => this.toParticipant(p));\n    if (!includeHost) {\n      return participants.filter(p => p.isHost === false);\n    } else {\n      return participants;\n    }\n  }\n  toParticipant(p) {\n    return new _Exports__WEBPACK_IMPORTED_MODULE_12__.Participant(p.id, p.avatar, p.displayName, p.isHost, p.isMuted, p.isUsingTts, p.preferredLanguage, p.voice);\n  }\n  getMuteAllCommand(isMuted) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n    return JSON.stringify({\n      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setMuteAll,\n      participantId: this.privRoom.participantId,\n      roomid: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,\n      value: isMuted\n    });\n  }\n  getMuteCommand(participantId, isMuted) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(participantId, \"participantId\");\n    return JSON.stringify({\n      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setMute,\n      // eslint-disable-next-line object-shorthand\n      participantId: participantId,\n      roomid: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,\n      value: isMuted\n    });\n  }\n  getLockCommand(isLocked) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n    return JSON.stringify({\n      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setLockState,\n      participantId: this.privRoom.participantId,\n      roomid: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,\n      value: isLocked\n    });\n  }\n  getEjectCommand(participantId) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(participantId, \"participantId\");\n    return JSON.stringify({\n      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.ejectParticipant,\n      // eslint-disable-next-line object-shorthand\n      participantId: participantId,\n      roomid: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand\n    });\n  }\n  getSetTranslateToLanguagesCommand(languages) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n    return JSON.stringify({\n      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.setTranslateToLanguages,\n      participantId: this.privRoom.participantId,\n      roomid: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,\n      value: languages\n    });\n  }\n  getChangeNicknameCommand(nickname) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(nickname, \"nickname\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n    return JSON.stringify({\n      command: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorCommandTypes.changeNickname,\n      nickname,\n      participantId: this.privRoom.participantId,\n      roomid: this.privRoom.roomId,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.participantCommand,\n      value: nickname\n    });\n  }\n  getMessageCommand(message) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.roomId, \"conversationId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(this.privRoom.participantId, \"participantId\");\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(message, \"message\");\n    return JSON.stringify({\n      participantId: this.privRoom.participantId,\n      roomId: this.privRoom.roomId,\n      text: message,\n      type: _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationTranslatorMessageTypes.instantMessage\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationCommon\": () => (/* binding */ ConversationCommon)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nclass ConversationCommon {\n  constructor(audioConfig) {\n    this.privAudioConfig = audioConfig;\n  }\n  handleCallback(cb, err) {\n    if (!!cb) {\n      try {\n        cb();\n      } catch (e) {\n        if (!!err) {\n          err(e);\n        }\n      }\n      cb = undefined;\n    }\n  }\n  handleError(error, err) {\n    if (!!err) {\n      if (error instanceof Error) {\n        const typedError = error;\n        err(typedError.name + \": \" + typedError.message);\n      } else {\n        err(error);\n      }\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationExpirationEventArgs\": () => (/* binding */ ConversationExpirationEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationExpirationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(expirationTime, sessionId) {\n    super(sessionId);\n    this.privExpirationTime = expirationTime;\n  }\n  /** How much longer until the conversation expires (in minutes). */\n  get expirationTime() {\n    return this.privExpirationTime;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationExpirationEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationParticipantsChangedEventArgs\": () => (/* binding */ ConversationParticipantsChangedEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationParticipantsChangedEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  constructor(reason, participants, sessionId) {\n    super(sessionId);\n    this.privReason = reason;\n    this.privParticipant = participants;\n  }\n  get reason() {\n    return this.privReason;\n  }\n  get participants() {\n    return this.privParticipant;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationParticipantsChangedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranscriber\": () => (/* binding */ ConversationTranscriber)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/TranscriberRecognizer.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\nclass ConversationTranscriber {\n  /**\n   * ConversationTranscriber constructor.\n   * @constructor\n   * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer\n   */\n  constructor(audioConfig) {\n    this.privAudioConfig = audioConfig;\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n    this.privRecognizer = undefined;\n    this.privDisposedRecognizer = false;\n  }\n  /**\n   * Gets the spoken language of recognition.\n   * @member ConversationTranscriber.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @returns {string} The spoken language of recognition.\n   */\n  get speechRecognitionLanguage() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceConnection_RecoLanguage);\n  }\n  /**\n   * The collection of properties and their values defined for this ConversationTranscriber.\n   * @member ConversationTranscriber.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this ConversationTranscriber.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * @Internal\n   * Internal data member to support fromRecognizer* pattern methods on other classes.\n   * Do not use externally, object returned will change without warning or notice.\n   */\n  get internalData() {\n    return this.privRecognizer.internalData;\n  }\n  /**\n   * @Deprecated\n   * @Obsolete\n   * Please use the Connection.fromRecognizer pattern to obtain a connection object\n   */\n  get connection() {\n    return _Exports__WEBPACK_IMPORTED_MODULE_3__.Connection.fromRecognizer(this.privRecognizer);\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member ConversationTranscriber.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member ConversationTranscriber.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n  set authorizationToken(token) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_2__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * @param {Conversation} conversation - conversation to be recognized\n   */\n  joinConversationAsync(conversation, cb, err) {\n    const conversationImpl = conversation;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(conversationImpl, \"Conversation\");\n    // ref the conversation object\n    // create recognizer and subscribe to recognizer events\n    this.privRecognizer = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_4__.TranscriberRecognizer(conversation.config, this.privAudioConfig);\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(this.privRecognizer, \"Recognizer\");\n    this.privRecognizer.connectCallbacks(this);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_5__.marshalPromiseToCallbacks)(conversationImpl.connectTranscriberRecognizer(this.privRecognizer), cb, err);\n  }\n  /**\n   * Starts conversation transcription, until stopTranscribingAsync() is called.\n   * User must subscribe to events to receive transcription results.\n   * @member ConversationTranscriber.prototype.startTranscribingAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the transcription has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  startTranscribingAsync(cb, err) {\n    this.privRecognizer.startContinuousRecognitionAsync(cb, err);\n  }\n  /**\n   * Starts conversation transcription, until stopTranscribingAsync() is called.\n   * User must subscribe to events to receive transcription results.\n   * @member ConversationTranscriber.prototype.stopTranscribingAsync\n   * @function\n   * @public\n   * @param cb - Callback invoked once the transcription has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  stopTranscribingAsync(cb, err) {\n    this.privRecognizer.stopContinuousRecognitionAsync(cb, err);\n  }\n  /**\n   * Leave the current conversation. After this is called, you will no longer receive any events.\n   */\n  leaveConversationAsync(cb, err) {\n    this.privRecognizer.disconnectCallbacks();\n    // eslint-disable-next-line\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_5__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {\n      return;\n    }))(), cb, err);\n  }\n  /**\n   * closes all external resources held by an instance of this class.\n   * @member ConversationTranscriber.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, errorCb) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedRecognizer);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_5__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n  }\n  /**\n   * Disposes any resources held by the object.\n   * @member ConversationTranscriber.prototype.dispose\n   * @function\n   * @public\n   * @param {boolean} disposing - true if disposing the object.\n   */\n  dispose(disposing) {\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposedRecognizer) {\n        return;\n      }\n      if (!!this.privRecognizer) {\n        yield this.privRecognizer.close();\n        this.privRecognizer = undefined;\n      }\n      if (disposing) {\n        this.privDisposedRecognizer = true;\n      }\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranscriber.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslationCanceledEventArgs\": () => (/* binding */ ConversationTranslationCanceledEventArgs)\n/* harmony export */ });\n/* harmony import */ var _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../CancellationEventArgsBase */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationEventArgsBase.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationCanceledEventArgs extends _CancellationEventArgsBase__WEBPACK_IMPORTED_MODULE_0__.CancellationEventArgsBase {}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslationEventArgs\": () => (/* binding */ ConversationTranslationEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {ConversationTranslationResult} result - The translation recognition result.\n   * @param {number} offset - The offset.\n   * @param {string} sessionId - The session id.\n   */\n  constructor(result, offset, sessionId) {\n    super(offset, sessionId);\n    this.privResult = result;\n  }\n  /**\n   * Specifies the recognition result.\n   * @returns {ConversationTranslationResult} the recognition result.\n   */\n  get result() {\n    return this.privResult;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslationResult\": () => (/* binding */ ConversationTranslationResult)\n/* harmony export */ });\n/* harmony import */ var _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../TranslationRecognitionResult */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n\nclass ConversationTranslationResult extends _TranslationRecognitionResult__WEBPACK_IMPORTED_MODULE_0__.TranslationRecognitionResult {\n  constructor(participantId, translations, originalLanguage, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n    super(translations, resultId, reason, text, duration, offset, errorDetails, json, properties);\n    this.privId = participantId;\n    this.privOrigLang = originalLanguage;\n  }\n  /**\n   * The unique identifier for the participant this result is for.\n   */\n  get participantId() {\n    return this.privId;\n  }\n  /**\n   * The original language this result was in.\n   */\n  get originalLang() {\n    return this.privOrigLang;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ConversationTranslator\": () => (/* binding */ ConversationTranslator),\n/* harmony export */   \"SpeechState\": () => (/* binding */ SpeechState)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Transcription/ConversationConnectionConfig.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechTranslationConfig.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ProfanityOption.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Audio/AudioConfig.js\");\n/* harmony import */ var _Conversation__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./Conversation */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/Conversation.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslationCanceledEventArgs.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationCommon.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n/* eslint-disable max-classes-per-file */\n\n\n\n\n\n\nvar SpeechState;\n(function (SpeechState) {\n  SpeechState[SpeechState[\"Inactive\"] = 0] = \"Inactive\";\n  SpeechState[SpeechState[\"Connecting\"] = 1] = \"Connecting\";\n  SpeechState[SpeechState[\"Connected\"] = 2] = \"Connected\";\n})(SpeechState || (SpeechState = {}));\n// child class of TranslationRecognizer meant only for use with ConversationTranslator\nclass ConversationTranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.TranslationRecognizer {\n  constructor(speechConfig, audioConfig, translator) {\n    super(speechConfig, audioConfig);\n    this.privSpeechState = SpeechState.Inactive;\n    if (!!translator) {\n      this.privTranslator = translator;\n      this.sessionStarted = () => {\n        this.privSpeechState = SpeechState.Connected;\n      };\n      this.sessionStopped = () => {\n        this.privSpeechState = SpeechState.Inactive;\n      };\n      // eslint-disable-next-line @typescript-eslint/no-misused-promises\n      this.recognized = (tr, e) => __awaiter(this, void 0, void 0, function* () {\n        // TODO: add support for getting recognitions from here if own speech\n        var _a;\n        // if there is an error connecting to the conversation service from the speech service the error will be returned in the ErrorDetails field.\n        if ((_a = e.result) === null || _a === void 0 ? void 0 : _a.errorDetails) {\n          yield this.cancelSpeech();\n          // TODO: format the error message contained in 'errorDetails'\n          this.fireCancelEvent(e.result.errorDetails);\n        }\n      });\n      // eslint-disable-next-line @typescript-eslint/no-misused-promises\n      this.canceled = () => __awaiter(this, void 0, void 0, function* () {\n        if (this.privSpeechState !== SpeechState.Inactive) {\n          try {\n            yield this.cancelSpeech();\n          } catch (error) {\n            this.privSpeechState = SpeechState.Inactive;\n          }\n        }\n      });\n    }\n  }\n  get state() {\n    return this.privSpeechState;\n  }\n  set state(newState) {\n    this.privSpeechState = newState;\n  }\n  onConnection() {\n    this.privSpeechState = SpeechState.Connected;\n  }\n  onDisconnection() {\n    return __awaiter(this, void 0, void 0, function* () {\n      this.privSpeechState = SpeechState.Inactive;\n      yield this.cancelSpeech();\n    });\n  }\n  /**\n   * Fire a cancel event\n   * @param error\n   */\n  fireCancelEvent(error) {\n    try {\n      if (!!this.privTranslator.canceled) {\n        const cancelEvent = new _Exports__WEBPACK_IMPORTED_MODULE_1__.ConversationTranslationCanceledEventArgs(_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationReason.Error, error, _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.RuntimeError);\n        this.privTranslator.canceled(this.privTranslator, cancelEvent);\n      }\n    } catch (e) {\n      //\n    }\n  }\n  cancelSpeech() {\n    var _a;\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        this.stopContinuousRecognitionAsync();\n        yield (_a = this.privReco) === null || _a === void 0 ? void 0 : _a.disconnect();\n        this.privSpeechState = SpeechState.Inactive;\n      } catch (e) {\n        // ignore the error\n      }\n    });\n  }\n}\n/**\n * Join, leave or connect to a conversation.\n */\nclass ConversationTranslator extends _Exports__WEBPACK_IMPORTED_MODULE_4__.ConversationCommon {\n  constructor(audioConfig) {\n    super(audioConfig);\n    this.privErrors = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationConnectionConfig.restErrors;\n    this.privIsDisposed = false;\n    this.privIsSpeaking = false;\n    this.privPlaceholderKey = \"abcdefghijklmnopqrstuvwxyz012345\";\n    this.privPlaceholderRegion = \"westus\";\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_6__.PropertyCollection();\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  get speechRecognitionLanguage() {\n    return this.privSpeechRecognitionLanguage;\n  }\n  get participants() {\n    var _a;\n    return (_a = this.privConversation) === null || _a === void 0 ? void 0 : _a.participants;\n  }\n  get canSpeak() {\n    // is there a Conversation websocket available and has the Recognizer been set up\n    if (!this.privConversation.isConnected || !this.privCTRecognizer) {\n      return false;\n    }\n    // is the user already speaking\n    if (this.privIsSpeaking || this.privCTRecognizer.state === SpeechState.Connected || this.privCTRecognizer.state === SpeechState.Connecting) {\n      return false;\n    }\n    // is the user muted\n    if (this.privConversation.isMutedByHost) {\n      return false;\n    }\n    return true;\n  }\n  joinConversationAsync(conversation, nickname, param1, param2, param3) {\n    try {\n      if (typeof conversation === \"string\") {\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversation id\"));\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n        if (!!this.privConversation) {\n          this.handleError(new Error(this.privErrors.permissionDeniedStart), param3);\n        }\n        let lang = param1;\n        if (lang === undefined || lang === null || lang === \"\") {\n          lang = _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationConnectionConfig.defaultLanguageCode;\n        }\n        // create a placeholder config\n        this.privSpeechTranslationConfig = _Exports__WEBPACK_IMPORTED_MODULE_8__.SpeechTranslationConfig.fromSubscription(this.privPlaceholderKey, this.privPlaceholderRegion);\n        this.privSpeechTranslationConfig.setProfanity(_Exports__WEBPACK_IMPORTED_MODULE_9__.ProfanityOption.Masked);\n        this.privSpeechTranslationConfig.addTargetLanguage(lang);\n        this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_RecoLanguage], lang);\n        this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.ConversationTranslator_Name], nickname);\n        const endpoint = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.ConversationTranslator_Host);\n        if (endpoint) {\n          this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.ConversationTranslator_Host], endpoint);\n        }\n        const speechEndpointHost = this.privProperties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_Host);\n        if (speechEndpointHost) {\n          this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_Host], speechEndpointHost);\n        }\n        // join the conversation\n        this.privConversation = new _Conversation__WEBPACK_IMPORTED_MODULE_11__.ConversationImpl(this.privSpeechTranslationConfig);\n        this.privConversation.conversationTranslator = this;\n        this.privConversation.joinConversationAsync(conversation, nickname, lang, result => {\n          if (!result) {\n            this.handleError(new Error(this.privErrors.permissionDeniedConnect), param3);\n          }\n          this.privSpeechTranslationConfig.authorizationToken = result;\n          // connect to the ws\n          this.privConversation.startConversationAsync(() => {\n            this.handleCallback(param2, param3);\n          }, error => {\n            this.handleError(error, param3);\n          });\n        }, error => {\n          this.handleError(error, param3);\n        });\n      } else if (typeof conversation === \"object\") {\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(conversation, this.privErrors.invalidArgs.replace(\"{arg}\", \"conversation id\"));\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrWhitespace(nickname, this.privErrors.invalidArgs.replace(\"{arg}\", \"nickname\"));\n        // save the nickname\n        this.privProperties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.ConversationTranslator_Name, nickname);\n        // ref the conversation object\n        this.privConversation = conversation;\n        // ref the conversation translator object\n        this.privConversation.conversationTranslator = this;\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedConnect);\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);\n        this.privSpeechTranslationConfig = conversation.config;\n        this.handleCallback(param1, param2);\n      } else {\n        this.handleError(new Error(this.privErrors.invalidArgs.replace(\"{arg}\", \"invalid conversation type\")), param2);\n      }\n    } catch (error) {\n      this.handleError(error, typeof param1 === \"string\" ? param3 : param2);\n    }\n  }\n  /**\n   * Leave the conversation\n   * @param cb\n   * @param err\n   */\n  leaveConversationAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_12__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {\n      // stop the speech websocket\n      yield this.cancelSpeech();\n      // stop the websocket\n      yield this.privConversation.endConversationImplAsync();\n      // https delete request\n      yield this.privConversation.deleteConversationImplAsync();\n      this.dispose();\n    }))(), cb, err);\n  }\n  /**\n   * Send a text message\n   * @param message\n   * @param cb\n   * @param err\n   */\n  sendTextMessageAsync(message, cb, err) {\n    try {\n      _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);\n      _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrWhitespace(message, this.privErrors.invalidArgs.replace(\"{arg}\", message));\n      this.privConversation.sendTextMessageAsync(message, cb, err);\n    } catch (error) {\n      this.handleError(error, err);\n    }\n  }\n  /**\n   * Start speaking\n   * @param cb\n   * @param err\n   */\n  startTranscribingAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_12__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {\n      try {\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(this.privConversation, this.privErrors.permissionDeniedSend);\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(this.privConversation.room.token, this.privErrors.permissionDeniedConnect);\n        if (this.privCTRecognizer === undefined) {\n          yield this.connectTranslatorRecognizer();\n        }\n        _Contracts__WEBPACK_IMPORTED_MODULE_7__.Contracts.throwIfNullOrUndefined(this.privCTRecognizer, this.privErrors.permissionDeniedSend);\n        if (!this.canSpeak) {\n          this.handleError(new Error(this.privErrors.permissionDeniedSend), err);\n        }\n        yield this.startContinuousRecognition();\n        this.privIsSpeaking = true;\n      } catch (error) {\n        this.privIsSpeaking = false;\n        yield this.cancelSpeech();\n        throw error;\n      }\n    }))(), cb, err);\n  }\n  /**\n   * Stop speaking\n   * @param cb\n   * @param err\n   */\n  stopTranscribingAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_12__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {\n      try {\n        if (!this.privIsSpeaking) {\n          // stop speech\n          yield this.cancelSpeech();\n          return;\n        }\n        // stop the recognition but leave the websocket open\n        this.privIsSpeaking = false;\n        yield new Promise((resolve, reject) => {\n          this.privCTRecognizer.stopContinuousRecognitionAsync(resolve, reject);\n        });\n      } catch (error) {\n        yield this.cancelSpeech();\n      }\n    }))(), cb, err);\n  }\n  isDisposed() {\n    return this.privIsDisposed;\n  }\n  dispose(reason, success, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_12__.marshalPromiseToCallbacks)((() => __awaiter(this, void 0, void 0, function* () {\n      if (this.isDisposed && !this.privIsSpeaking) {\n        return;\n      }\n      yield this.cancelSpeech();\n      this.privIsDisposed = true;\n      this.privSpeechTranslationConfig.close();\n      this.privSpeechRecognitionLanguage = undefined;\n      this.privProperties = undefined;\n      this.privAudioConfig = undefined;\n      this.privSpeechTranslationConfig = undefined;\n      this.privConversation.dispose();\n      this.privConversation = undefined;\n    }))(), success, err);\n  }\n  /**\n   * Cancel the speech websocket\n   */\n  cancelSpeech() {\n    var _a;\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        this.privIsSpeaking = false;\n        yield (_a = this.privCTRecognizer) === null || _a === void 0 ? void 0 : _a.onDisconnection();\n        this.privCTRecognizer = undefined;\n      } catch (e) {\n        // ignore the error\n      }\n    });\n  }\n  /**\n   * Connect to the speech translation recognizer.\n   * Currently there is no language validation performed before sending the SpeechLanguage code to the service.\n   * If it's an invalid language the raw error will be: 'Error during WebSocket handshake: Unexpected response code: 400'\n   * e.g. pass in 'fr' instead of 'fr-FR', or a text-only language 'cy'\n   */\n  connectTranslatorRecognizer() {\n    return __awaiter(this, void 0, void 0, function* () {\n      try {\n        if (this.privAudioConfig === undefined) {\n          this.privAudioConfig = _Exports__WEBPACK_IMPORTED_MODULE_13__.AudioConfig.fromDefaultMicrophoneInput();\n        }\n        // clear the temp subscription key if it's a participant joining\n        if (this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_Key]) === this.privPlaceholderKey) {\n          this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_Key], \"\");\n        }\n        // TODO\n        const token = encodeURIComponent(this.privConversation.room.token);\n        let endpointHost = this.privSpeechTranslationConfig.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_Host], _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationConnectionConfig.speechHost);\n        endpointHost = endpointHost.replace(\"{region}\", this.privConversation.room.cognitiveSpeechRegion);\n        const url = `wss://${endpointHost}${_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationConnectionConfig.speechPath}?${_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.ConversationConnectionConfig.configParams.token}=${token}`;\n        this.privSpeechTranslationConfig.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_10__.PropertyId.SpeechServiceConnection_Endpoint], url);\n        this.privCTRecognizer = new ConversationTranslationRecognizer(this.privSpeechTranslationConfig, this.privAudioConfig, this);\n      } catch (error) {\n        yield this.cancelSpeech();\n        throw error;\n      }\n    });\n  }\n  /**\n   * Handle the start speaking request\n   */\n  startContinuousRecognition() {\n    return new Promise((resolve, reject) => {\n      this.privCTRecognizer.startContinuousRecognitionAsync(resolve, reject);\n    });\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ConversationTranslator.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Participant\": () => (/* binding */ Participant),\n/* harmony export */   \"User\": () => (/* binding */ User)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\n/* eslint-disable max-classes-per-file */\n\nclass User {\n  constructor(userId) {\n    this.privUserId = userId;\n  }\n  get userId() {\n    return this.privUserId;\n  }\n}\nclass Participant {\n  constructor(id, avatar, displayName, isHost, isMuted, isUsingTts, preferredLanguage, voice) {\n    this.privId = id;\n    this.privAvatar = avatar;\n    this.privDisplayName = displayName;\n    this.privIsHost = isHost;\n    this.privIsMuted = isMuted;\n    this.privIsUsingTts = isUsingTts;\n    this.privPreferredLanguage = preferredLanguage;\n    this.privVoice = voice;\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n  }\n  get avatar() {\n    return this.privAvatar;\n  }\n  get displayName() {\n    return this.privDisplayName;\n  }\n  get id() {\n    return this.privId;\n  }\n  get preferredLanguage() {\n    return this.privPreferredLanguage;\n  }\n  get isHost() {\n    return this.privIsHost;\n  }\n  get isMuted() {\n    return this.privIsMuted;\n  }\n  get isUsingTts() {\n    return this.privIsUsingTts;\n  }\n  get voice() {\n    return this.privVoice;\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  static From(id, language, voice) {\n    return new Participant(id, \"\", id, false, false, false, language, voice);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/IParticipant.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ParticipantChangedReason\": () => (/* binding */ ParticipantChangedReason)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n// Multi-device Conversation is a Preview feature.\nvar ParticipantChangedReason;\n(function (ParticipantChangedReason) {\n  /** Participant has joined the conversation. */\n  ParticipantChangedReason[ParticipantChangedReason[\"JoinedConversation\"] = 0] = \"JoinedConversation\";\n  /** Participant has left the conversation. This could be voluntary, or involuntary\n   * (e.g. they are experiencing networking issues).\n   */\n  ParticipantChangedReason[ParticipantChangedReason[\"LeftConversation\"] = 1] = \"LeftConversation\";\n  /** The participants' state has changed (e.g. they became muted, changed their nickname). */\n  ParticipantChangedReason[ParticipantChangedReason[\"Updated\"] = 2] = \"Updated\";\n})(ParticipantChangedReason || (ParticipantChangedReason = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Transcription/ParticipantChangedReason.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognitionCanceledEventArgs\": () => (/* binding */ TranslationRecognitionCanceledEventArgs)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Define payload of speech recognition canceled result events.\n * @class TranslationRecognitionCanceledEventArgs\n */\nclass TranslationRecognitionCanceledEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} sessionid - The session id.\n   * @param {CancellationReason} cancellationReason - The cancellation reason.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {TranslationRecognitionResult} result - The result.\n   */\n  constructor(sessionid, cancellationReason, errorDetails, errorCode, result) {\n    this.privCancelReason = cancellationReason;\n    this.privErrorDetails = errorDetails;\n    this.privResult = result;\n    this.privSessionId = sessionid;\n    this.privErrorCode = errorCode;\n  }\n  /**\n   * Specifies the recognition result.\n   * @member TranslationRecognitionCanceledEventArgs.prototype.result\n   * @function\n   * @public\n   * @returns {TranslationRecognitionResult} the recognition result.\n   */\n  get result() {\n    return this.privResult;\n  }\n  /**\n   * Specifies the session identifier.\n   * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId\n   * @function\n   * @public\n   * @returns {string} the session identifier.\n   */\n  get sessionId() {\n    return this.privSessionId;\n  }\n  /**\n   * The reason the recognition was canceled.\n   * @member TranslationRecognitionCanceledEventArgs.prototype.reason\n   * @function\n   * @public\n   * @returns {CancellationReason} Specifies the reason canceled.\n   */\n  get reason() {\n    return this.privCancelReason;\n  }\n  /**\n   * The error code in case of an unsuccessful recognition.\n   * Added in version 1.1.0.\n   * @return An error code that represents the error reason.\n   */\n  get errorCode() {\n    return this.privErrorCode;\n  }\n  /**\n   * In case of an unsuccessful recognition, provides details of the occurred error.\n   * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails\n   * @function\n   * @public\n   * @returns {string} A String that represents the error details.\n   */\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionCanceledEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognitionEventArgs\": () => (/* binding */ TranslationRecognitionEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/RecognitionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation text result event arguments.\n * @class TranslationRecognitionEventArgs\n */\nclass TranslationRecognitionEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.RecognitionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {TranslationRecognitionResult} result - The translation recognition result.\n   * @param {number} offset - The offset.\n   * @param {string} sessionId - The session id.\n   */\n  constructor(result, offset, sessionId) {\n    super(offset, sessionId);\n    this.privResult = result;\n  }\n  /**\n   * Specifies the recognition result.\n   * @member TranslationRecognitionEventArgs.prototype.result\n   * @function\n   * @public\n   * @returns {TranslationRecognitionResult} the recognition result.\n   */\n  get result() {\n    return this.privResult;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognitionResult\": () => (/* binding */ TranslationRecognitionResult)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SpeechRecognitionResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation text result.\n * @class TranslationRecognitionResult\n */\nclass TranslationRecognitionResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SpeechRecognitionResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {Translations} translations - The translations.\n   * @param {string} resultId - The result id.\n   * @param {ResultReason} reason - The reason.\n   * @param {string} text - The recognized text.\n   * @param {number} duration - The duration.\n   * @param {number} offset - The offset into the stream.\n   * @param {string} errorDetails - Error details, if provided.\n   * @param {string} json - Additional Json, if provided.\n   * @param {PropertyCollection} properties - Additional properties, if provided.\n   */\n  constructor(translations, resultId, reason, text, duration, offset, errorDetails, json, properties) {\n    super(resultId, reason, text, duration, offset, undefined, undefined, undefined, errorDetails, json, properties);\n    this.privTranslations = translations;\n  }\n  /**\n   * Presents the translation results. Each item in the dictionary represents\n   * a translation result in one of target languages, where the key is the name\n   * of the target language, in BCP-47 format, and the value is the translation\n   * text in the specified language.\n   * @member TranslationRecognitionResult.prototype.translations\n   * @function\n   * @public\n   * @returns {Translations} the current translation map that holds all translations requested.\n   */\n  get translations() {\n    return this.privTranslations;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognitionResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationRecognizer\": () => (/* binding */ TranslationRecognizer)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationConnectionFactory.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/TranslationServiceRecognizer.js\");\n/* harmony import */ var _common_Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common/Promise.js\");\n/* harmony import */ var _Connection__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Connection */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Connection.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Recognizer.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n\n\n/**\n * Translation recognizer\n * @class TranslationRecognizer\n */\nclass TranslationRecognizer extends _Exports__WEBPACK_IMPORTED_MODULE_0__.Recognizer {\n  /**\n   * Initializes an instance of the TranslationRecognizer.\n   * @constructor\n   * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.\n   * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer\n   */\n  constructor(speechConfig, audioConfig) {\n    const configImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNull(configImpl, \"speechConfig\");\n    super(audioConfig, configImpl.properties, new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.TranslationConnectionFactory());\n    this.privDisposedTranslationRecognizer = false;\n    if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined) !== undefined) {\n      _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice]);\n    }\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages]);\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrWhitespace(this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage), _Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId[_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage]);\n  }\n  /**\n   * Gets the language name that was set when the recognizer was created.\n   * @member TranslationRecognizer.prototype.speechRecognitionLanguage\n   * @function\n   * @public\n   * @returns {string} Gets the language name that was set when the recognizer was created.\n   */\n  get speechRecognitionLanguage() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_RecoLanguage);\n  }\n  /**\n   * Gets target languages for translation that were set when the recognizer was created.\n   * The language is specified in BCP-47 format. The translation will provide translated text for each of language.\n   * @member TranslationRecognizer.prototype.targetLanguages\n   * @function\n   * @public\n   * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.\n   */\n  get targetLanguages() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n  }\n  /**\n   * Gets the name of output voice.\n   * @member TranslationRecognizer.prototype.voiceName\n   * @function\n   * @public\n   * @returns {string} the name of output voice.\n   */\n  get voiceName() {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationVoice, undefined);\n  }\n  /**\n   * The collection of properties and their values defined for this TranslationRecognizer.\n   * @member TranslationRecognizer.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member TranslationRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member TranslationRecognizer.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} value - Authorization token.\n   */\n  set authorizationToken(value) {\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceAuthorization_Token, value);\n  }\n  /**\n   * Starts recognition and translation, and stops after the first utterance is recognized.\n   * The task returns the translation text as result.\n   * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitable only\n   * for single shot recognition like command or query. For long-running recognition,\n   * use startContinuousRecognitionAsync() instead.\n   * @member TranslationRecognizer.prototype.recognizeOnceAsync\n   * @function\n   * @public\n   * @param cb - Callback that received the result when the translation has completed.\n   * @param err - Callback invoked in case of an error.\n   */\n  recognizeOnceAsync(cb, err) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.recognizeOnceAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);\n  }\n  /**\n   * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.\n   * User must subscribe to events to receive translation results.\n   * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback that received the translation has started.\n   * @param err - Callback invoked in case of an error.\n   */\n  startContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.startContinuousRecognitionAsyncImpl(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognitionMode.Conversation), cb, err);\n  }\n  /**\n   * Stops continuous recognition and translation.\n   * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync\n   * @function\n   * @public\n   * @param cb - Callback that received the translation has stopped.\n   * @param err - Callback invoked in case of an error.\n   */\n  stopContinuousRecognitionAsync(cb, err) {\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.stopContinuousRecognitionAsyncImpl(), cb, err);\n  }\n  /**\n   * dynamically remove a language from list of target language\n   * (can be used while recognition is ongoing)\n   * @member TranslationRecognizer.prototype.removeTargetLanguage\n   * @function\n   * @param lang - language to be removed\n   * @public\n   */\n  removeTargetLanguage(lang) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(lang, \"language to be removed\");\n    if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n      const languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n      const index = languages.indexOf(lang);\n      if (index > -1) {\n        languages.splice(index, 1);\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n        this.updateLanguages(languages);\n      }\n    }\n  }\n  /**\n   * dynamically add a language to list of target language\n   * (can be used while recognition is ongoing)\n   * @member TranslationRecognizer.prototype.addTargetLanguage\n   * @function\n   * @param lang - language to be added\n   * @public\n   */\n  addTargetLanguage(lang) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(lang, \"language to be added\");\n    let languages = [];\n    if (this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, undefined) !== undefined) {\n      languages = this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages).split(\",\");\n      if (!languages.includes(lang)) {\n        languages.push(lang);\n        this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, languages.join(\",\"));\n      }\n    } else {\n      this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_3__.PropertyId.SpeechServiceConnection_TranslationToLanguages, lang);\n      languages = [lang];\n    }\n    this.updateLanguages(languages);\n  }\n  /**\n   * closes all external resources held by an instance of this class.\n   * @member TranslationRecognizer.prototype.close\n   * @function\n   * @public\n   */\n  close(cb, errorCb) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfDisposed(this.privDisposedTranslationRecognizer);\n    (0,_common_Exports__WEBPACK_IMPORTED_MODULE_4__.marshalPromiseToCallbacks)(this.dispose(true), cb, errorCb);\n  }\n  /**\n   * handles ConnectionEstablishedEvent for conversation translation scenarios.\n   * @member TranslationRecognizer.prototype.onConnection\n   * @function\n   * @public\n   */\n  // eslint-disable-next-line @typescript-eslint/no-empty-function\n  onConnection() {}\n  /**\n   * handles disconnection events for conversation translation scenarios.\n   * @member TranslationRecognizer.prototype.onDisconnection\n   * @function\n   * @public\n   */\n  // eslint-disable-next-line @typescript-eslint/no-empty-function\n  onDisconnection() {\n    return __awaiter(this, void 0, void 0, function* () {});\n  }\n  dispose(disposing) {\n    const _super = Object.create(null, {\n      dispose: {\n        get: () => super.dispose\n      }\n    });\n    return __awaiter(this, void 0, void 0, function* () {\n      if (this.privDisposedTranslationRecognizer) {\n        return;\n      }\n      this.privDisposedTranslationRecognizer = true;\n      if (disposing) {\n        yield this.implRecognizerStop();\n        yield _super.dispose.call(this, disposing);\n      }\n    });\n  }\n  createRecognizerConfig(speechConfig) {\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_5__.RecognizerConfig(speechConfig, this.properties);\n  }\n  createServiceRecognizer(authentication, connectionFactory, audioConfig, recognizerConfig) {\n    const configImpl = audioConfig;\n    return new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_6__.TranslationServiceRecognizer(authentication, connectionFactory, configImpl, recognizerConfig, this);\n  }\n  updateLanguages(languages) {\n    const conn = _Connection__WEBPACK_IMPORTED_MODULE_7__.Connection.fromRecognizer(this);\n    if (!!conn) {\n      conn.setMessageProperty(\"speech.context\", \"translationcontext\", {\n        to: languages\n      });\n      conn.sendMessageAsync(\"event\", JSON.stringify({\n        id: \"translation\",\n        name: \"updateLanguage\",\n        to: languages\n      }));\n    }\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationRecognizer.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationSynthesisEventArgs\": () => (/* binding */ TranslationSynthesisEventArgs)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/SessionEventArgs.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Translation Synthesis event arguments\n * @class TranslationSynthesisEventArgs\n */\nclass TranslationSynthesisEventArgs extends _Exports__WEBPACK_IMPORTED_MODULE_0__.SessionEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {TranslationSynthesisResult} result - The translation synthesis result.\n   * @param {string} sessionId - The session id.\n   */\n  constructor(result, sessionId) {\n    super(sessionId);\n    this.privResult = result;\n  }\n  /**\n   * Specifies the translation synthesis result.\n   * @member TranslationSynthesisEventArgs.prototype.result\n   * @function\n   * @public\n   * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.\n   */\n  get result() {\n    return this.privResult;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TranslationSynthesisResult\": () => (/* binding */ TranslationSynthesisResult)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines translation synthesis result, i.e. the voice output of the translated\n * text in the target language.\n * @class TranslationSynthesisResult\n */\nclass TranslationSynthesisResult {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {ResultReason} reason - The synthesis reason.\n   * @param {ArrayBuffer} audio - The audio data.\n   */\n  constructor(reason, audio) {\n    this.privReason = reason;\n    this.privAudio = audio;\n  }\n  /**\n   * Translated text in the target language.\n   * @member TranslationSynthesisResult.prototype.audio\n   * @function\n   * @public\n   * @returns {ArrayBuffer} Translated audio in the target language.\n   */\n  get audio() {\n    return this.privAudio;\n  }\n  /**\n   * The synthesis status.\n   * @member TranslationSynthesisResult.prototype.reason\n   * @function\n   * @public\n   * @returns {ResultReason} The synthesis status.\n   */\n  get reason() {\n    return this.privReason;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TranslationSynthesisResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Translations\": () => (/* binding */ Translations)\n/* harmony export */ });\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Represents collection of parameters and their values.\n * @class Translations\n */\nclass Translations {\n  constructor() {\n    // Use an PropertyCollection internally, just wrapping it to hide the | enum syntax it has.\n    this.privMap = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n  }\n  /**\n   * Get the languages in the object in a String array.\n   * @member Translations.prototype.languages\n   * @function\n   * @public\n   * @returns {string[]} languages in translations object.\n   */\n  get languages() {\n    return this.privMap.keys;\n  }\n  /**\n   * Returns the parameter value in type String. The parameter must have the same type as String.\n   * Currently only String, int and bool are allowed.\n   * If the name is not available, the specified defaultValue is returned.\n   * @member Translations.prototype.get\n   * @function\n   * @public\n   * @param {string} key - The parameter name.\n   * @param {string} def - The default value which is returned if the parameter is not available in the collection.\n   * @returns {string} value of the parameter.\n   */\n  get(key, def) {\n    return this.privMap.getProperty(key, def);\n  }\n  /**\n   * Sets the String value of the parameter specified by name.\n   * @member Translations.prototype.set\n   * @function\n   * @public\n   * @param {string} key - The parameter name.\n   * @param {string} value - The value of the parameter.\n   */\n  set(key, value) {\n    this.privMap.setProperty(key, value);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Translations.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TurnStatusReceivedEventArgs\": () => (/* binding */ TurnStatusReceivedEventArgs)\n/* harmony export */ });\n/* harmony import */ var _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common.speech/ServiceMessages/TurnStatusPayload */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/ServiceMessages/TurnStatusPayload.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n/**\n * Defines contents of received message/events.\n * @class TurnStatusReceivedEventArgs\n */\nclass TurnStatusReceivedEventArgs {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} turnStatus - The JSON-encoded turn status message.\n   */\n  constructor(turnStatus) {\n    this.privTurnStatus = _common_speech_ServiceMessages_TurnStatusPayload__WEBPACK_IMPORTED_MODULE_0__.TurnStatusResponsePayload.fromJSON(turnStatus);\n  }\n  /**\n   * Gets the interaction identifier associated with this turn status event.\n   * @member TurnStatusReceivedEventArgs.prototype.interactionId\n   * @function\n   * @public\n   * @returns {any} the received interaction id.\n   */\n  get interactionId() {\n    return this.privTurnStatus.interactionId;\n  }\n  /**\n   * Gets the conversation identifier associated with this turn status event.\n   * @member TurnStatusReceivedEventArgs.prototype.conversationId\n   * @function\n   * @public\n   * @returns {any} the received conversation id.\n   */\n  get conversationId() {\n    return this.privTurnStatus.conversationId;\n  }\n  /**\n   * Gets the received turn status code.\n   * @member TurnStatusReceivedEventArgs.prototype.statusCode\n   * @function\n   * @public\n   * @returns {number} the received turn status.\n   */\n  get statusCode() {\n    return this.privTurnStatus.statusCode; // eslint-disable-line @typescript-eslint/no-unsafe-return\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/TurnStatusReceivedEventArgs.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SynthesisVoiceGender\": () => (/* binding */ SynthesisVoiceGender),\n/* harmony export */   \"SynthesisVoiceType\": () => (/* binding */ SynthesisVoiceType),\n/* harmony export */   \"VoiceInfo\": () => (/* binding */ VoiceInfo)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines the gender of synthesis voices.\n * Added in version 1.20.0.\n */\nvar SynthesisVoiceGender;\n(function (SynthesisVoiceGender) {\n  /** Gender unknown */\n  SynthesisVoiceGender[SynthesisVoiceGender[\"Unknown\"] = 0] = \"Unknown\";\n  /** Female voice */\n  SynthesisVoiceGender[SynthesisVoiceGender[\"Female\"] = 1] = \"Female\";\n  /** Male voice */\n  SynthesisVoiceGender[SynthesisVoiceGender[\"Male\"] = 2] = \"Male\";\n})(SynthesisVoiceGender || (SynthesisVoiceGender = {}));\nvar SynthesisVoiceType;\n(function (SynthesisVoiceType) {\n  SynthesisVoiceType[SynthesisVoiceType[\"OnlineNeural\"] = 1] = \"OnlineNeural\";\n  SynthesisVoiceType[SynthesisVoiceType[\"OnlineStandard\"] = 2] = \"OnlineStandard\";\n  SynthesisVoiceType[SynthesisVoiceType[\"OfflineNeural\"] = 3] = \"OfflineNeural\";\n  SynthesisVoiceType[SynthesisVoiceType[\"OfflineStandard\"] = 4] = \"OfflineStandard\";\n})(SynthesisVoiceType || (SynthesisVoiceType = {}));\n/**\n * Information about Speech Synthesis voice\n * Added in version 1.20.0.\n * @class VoiceInfo\n */\nclass VoiceInfo {\n  constructor(json) {\n    this.privStyleList = [];\n    this.privVoicePath = \"\";\n    if (!!json) {\n      this.privName = json.Name;\n      this.privLocale = json.Locale;\n      this.privShortName = json.ShortName;\n      this.privLocalName = json.LocalName;\n      this.privVoiceType = json.VoiceType.endsWith(\"Standard\") ? SynthesisVoiceType.OnlineStandard : SynthesisVoiceType.OnlineNeural;\n      this.privGender = json.Gender === \"Male\" ? SynthesisVoiceGender.Male : json.Gender === \"Female\" ? SynthesisVoiceGender.Female : SynthesisVoiceGender.Unknown;\n      if (!!json.StyleList && Array.isArray(json.StyleList)) {\n        for (const style of json.StyleList) {\n          this.privStyleList.push(style);\n        }\n      }\n    }\n  }\n  get name() {\n    return this.privName;\n  }\n  get locale() {\n    return this.privLocale;\n  }\n  get shortName() {\n    return this.privShortName;\n  }\n  get localName() {\n    return this.privLocalName;\n  }\n  get gender() {\n    return this.privGender;\n  }\n  get voiceType() {\n    return this.privVoiceType;\n  }\n  get styleList() {\n    return this.privStyleList;\n  }\n  get voicePath() {\n    return this.privVoicePath;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceInfo.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfile\": () => (/* binding */ VoiceProfile)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Defines Voice Profile class for Speaker Recognition\n * @class VoiceProfile\n */\nclass VoiceProfile {\n  /**\n   * Creates and initializes an instance of this class.\n   * @constructor\n   * @param {string} profileId - profileId of this Voice Profile.\n   * @param {VoiceProfileType} profileType - profileType of this Voice Profile.\n   */\n  constructor(profileId, profileType) {\n    this.privId = profileId;\n    this.privProfileType = profileType;\n  }\n  /**\n   * profileId of this Voice Profile instance\n   * @member VoiceProfile.prototype.profileId\n   * @function\n   * @public\n   * @returns {string} profileId of this Voice Profile instance.\n   */\n  get profileId() {\n    return this.privId;\n  }\n  /**\n   * profileType of this Voice Profile instance\n   * @member VoiceProfile.prototype.profileType\n   * @function\n   * @public\n   * @returns {VoiceProfileType} profile type of this Voice Profile instance.\n   */\n  get profileType() {\n    return this.privProfileType;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfileClient\": () => (/* binding */ VoiceProfileClient)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerRecognitionConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/RecognizerConfig.js\");\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/SpeakerIdMessageAdapter.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyId.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfile.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\nvar __awaiter = undefined && undefined.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\n\n\n/**\n * Defines VoiceProfileClient class for Speaker Recognition\n * Handles operations from user for Voice Profile operations (e.g. createProfile, deleteProfile)\n * @class VoiceProfileClient\n */\nclass VoiceProfileClient {\n  /**\n   * VoiceProfileClient constructor.\n   * @constructor\n   * @param {SpeechConfig} speechConfig - An set of initial properties for this synthesizer (authentication key, region, &c)\n   */\n  constructor(speechConfig) {\n    const speechConfigImpl = speechConfig;\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNull(speechConfigImpl, \"speechConfig\");\n    this.privProperties = speechConfigImpl.properties.clone();\n    this.implClientSetup();\n  }\n  /**\n   * The collection of properties and their values defined for this VoiceProfileClient.\n   * @member VoiceProfileClient.prototype.properties\n   * @function\n   * @public\n   * @returns {PropertyCollection} The collection of properties and their values defined for this VoiceProfileClient.\n   */\n  get properties() {\n    return this.privProperties;\n  }\n  /**\n   * Gets the authorization token used to communicate with the service.\n   * @member VoiceProfileClient.prototype.authorizationToken\n   * @function\n   * @public\n   * @returns {string} Authorization token.\n   */\n  get authorizationToken() {\n    return this.properties.getProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token);\n  }\n  /**\n   * Gets/Sets the authorization token used to communicate with the service.\n   * @member VoiceProfileClient.prototype.authorizationToken\n   * @function\n   * @public\n   * @param {string} token - Authorization token.\n   */\n  set authorizationToken(token) {\n    _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrWhitespace(token, \"token\");\n    this.properties.setProperty(_Exports__WEBPACK_IMPORTED_MODULE_1__.PropertyId.SpeechServiceAuthorization_Token, token);\n  }\n  /**\n   * Create a speaker recognition voice profile\n   * @member VoiceProfileClient.prototype.createProfileAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfileType} profileType Type of Voice Profile to be created\n   * @param {string} lang Language string (locale) for Voice Profile\n   * @return {Promise<VoiceProfile>} - Promise of a VoiceProfile.\n   */\n  createProfileAsync(profileType, lang) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const result = yield this.privAdapter.createProfile(profileType, lang);\n      if (!result.ok) {\n        throw new Error(`createProfileAsync failed with code: ${result.status}, message: ${result.statusText}`);\n      }\n      const response = result.json;\n      const profile = new _Exports__WEBPACK_IMPORTED_MODULE_2__.VoiceProfile(response.profileId, profileType);\n      return profile;\n    });\n  }\n  /**\n   * Get current information of a voice profile\n   * @member VoiceProfileClient.prototype.retrieveEnrollmentResultAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfile} profile Voice Profile to retrieve info for\n   * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.\n   */\n  retrieveEnrollmentResultAsync(profile) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const result = yield this.privAdapter.getProfileStatus(profile);\n      return new _Exports__WEBPACK_IMPORTED_MODULE_3__.VoiceProfileEnrollmentResult(result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.Canceled, result.data, result.statusText);\n    });\n  }\n  /**\n   * Get all voice profiles on account with given voice profile type\n   * @member VoiceProfileClient.prototype.getAllProfilesAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfileType} profileType profile type (identification/verification) for which to list profiles\n   * @return {Promise<VoiceProfileEnrollmentResult[]>} - Promise of an array of VoiceProfileEnrollmentResults.\n   */\n  getAllProfilesAsync(profileType) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const result = yield this.privAdapter.getProfiles(profileType);\n      if (profileType === _Exports__WEBPACK_IMPORTED_MODULE_5__.VoiceProfileType.TextIndependentIdentification) {\n        return _Exports__WEBPACK_IMPORTED_MODULE_3__.VoiceProfileEnrollmentResult.FromIdentificationProfileList(result.json);\n      }\n      return _Exports__WEBPACK_IMPORTED_MODULE_3__.VoiceProfileEnrollmentResult.FromVerificationProfileList(result.json);\n    });\n  }\n  /**\n   * Get valid authorization phrases for voice profile enrollment\n   * @member VoiceProfileClient.prototype.getAuthorizationPhrasesAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfileType} profileType Profile Type to get activation phrases for\n   * @param {string} lang Language string (locale) for Voice Profile\n   */\n  getActivationPhrasesAsync(profileType, lang) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const result = yield this.privAdapter.getPhrases(profileType, lang);\n      return new _Exports__WEBPACK_IMPORTED_MODULE_6__.VoiceProfilePhraseResult(result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.EnrollingVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.Canceled, result.statusText, result.json);\n    });\n  }\n  /**\n   * Create a speaker recognition voice profile\n   * @member VoiceProfileClient.prototype.enrollProfileAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfile} profile Voice Profile to create enrollment for\n   * @param {AudioConfig} audioConfig source info from which to create enrollment\n   * @return {Promise<VoiceProfileEnrollmentResult>} - Promise of a VoiceProfileEnrollmentResult.\n   */\n  enrollProfileAsync(profile, audioConfig) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const configImpl = audioConfig;\n      _Contracts__WEBPACK_IMPORTED_MODULE_0__.Contracts.throwIfNullOrUndefined(configImpl, \"audioConfig\");\n      const result = yield this.privAdapter.createEnrollment(profile, configImpl);\n      return new _Exports__WEBPACK_IMPORTED_MODULE_3__.VoiceProfileEnrollmentResult(result.ok ? _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.Canceled, result.data, result.statusText);\n    });\n  }\n  /**\n   * Delete a speaker recognition voice profile\n   * @member VoiceProfileClient.prototype.deleteProfileAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfile} profile Voice Profile to be deleted\n   * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.\n   */\n  deleteProfileAsync(profile) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const result = yield this.privAdapter.deleteProfile(profile);\n      return this.getResult(result, _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.DeletedVoiceProfile);\n    });\n  }\n  /**\n   * Remove all enrollments for a speaker recognition voice profile\n   * @member VoiceProfileClient.prototype.resetProfileAsync\n   * @function\n   * @public\n   * @async\n   * @param {VoiceProfile} profile Voice Profile to be reset\n   * @return {Promise<VoiceProfileResult>} - Promise of a VoiceProfileResult.\n   */\n  resetProfileAsync(profile) {\n    return __awaiter(this, void 0, void 0, function* () {\n      const result = yield this.privAdapter.resetProfile(profile);\n      return this.getResult(result, _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.ResetVoiceProfile);\n    });\n  }\n  /**\n   * Included for compatibility\n   * @member VoiceProfileClient.prototype.close\n   * @function\n   * @public\n   */\n  close() {\n    return;\n  }\n  // Does class setup, swiped from Recognizer.\n  implClientSetup() {\n    let osPlatform = typeof window !== \"undefined\" ? \"Browser\" : \"Node\";\n    let osName = \"unknown\";\n    let osVersion = \"unknown\";\n    if (typeof navigator !== \"undefined\") {\n      osPlatform = osPlatform + \"/\" + navigator.platform;\n      osName = navigator.userAgent;\n      osVersion = navigator.appVersion;\n    }\n    const recognizerConfig = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_7__.SpeakerRecognitionConfig(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.Context(new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_8__.OS(osPlatform, osName, osVersion)), this.privProperties);\n    this.privAdapter = new _common_speech_Exports__WEBPACK_IMPORTED_MODULE_9__.SpeakerIdMessageAdapter(recognizerConfig);\n  }\n  getResult(result, successReason) {\n    const response = new _Exports__WEBPACK_IMPORTED_MODULE_10__.VoiceProfileResult(result.ok ? successReason : _Exports__WEBPACK_IMPORTED_MODULE_4__.ResultReason.Canceled, result.statusText);\n    return response;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileClient.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfileEnrollmentCancellationDetails\": () => (/* binding */ VoiceProfileEnrollmentCancellationDetails),\n/* harmony export */   \"VoiceProfileEnrollmentResult\": () => (/* binding */ VoiceProfileEnrollmentResult)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\nconst parse = json => JSON.parse(json);\n/**\n * Output format\n * @class VoiceProfileEnrollmentResult\n */\nclass VoiceProfileEnrollmentResult {\n  constructor(reason, json, statusText) {\n    this.privReason = reason;\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n    if (this.privReason !== _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled) {\n      if (!!json) {\n        this.privDetails = parse(json);\n        if (this.privDetails.enrollmentStatus.toLowerCase() === \"enrolling\") {\n          this.privReason = _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrollingVoiceProfile;\n        }\n      }\n    } else {\n      this.privErrorDetails = statusText;\n      this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.ServiceError]);\n    }\n  }\n  get reason() {\n    return this.privReason;\n  }\n  get enrollmentsCount() {\n    return this.privDetails.enrollmentsCount;\n  }\n  get enrollmentsLengthInSec() {\n    return this.privDetails.enrollmentsLengthInSec;\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  get enrollmentResultDetails() {\n    return this.privDetails;\n  }\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n  static FromIdentificationProfileList(json) {\n    const results = [];\n    for (const item of json.value) {\n      const reason = item.enrollmentStatus.toLowerCase() === \"enrolling\" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === \"enrolled\" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled;\n      const result = new VoiceProfileEnrollmentResult(reason, null, null);\n      result.privDetails = this.getIdentificationDetails(item);\n      results.push(result);\n    }\n    return results;\n  }\n  static FromVerificationProfileList(json) {\n    const results = [];\n    for (const item of json.value) {\n      const reason = item.enrollmentStatus.toLowerCase() === \"enrolling\" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrollingVoiceProfile : item.enrollmentStatus.toLowerCase() === \"enrolled\" ? _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.EnrolledVoiceProfile : _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled;\n      const result = new VoiceProfileEnrollmentResult(reason, null, null);\n      result.privDetails = this.getVerificationDetails(item);\n      results.push(result);\n    }\n    return results;\n  }\n  static getIdentificationDetails(json) {\n    return {\n      audioLengthInSec: json.audioLengthInSec ? parseFloat(json.audioLengthInSec) : 0,\n      audioSpeechLengthInSec: json.audioSpeechLengthInSec ? parseFloat(json.audioSpeechLengthInSec) : 0,\n      enrollmentStatus: json.enrollmentStatus,\n      enrollmentsCount: json.enrollmentsCount || 0,\n      enrollmentsLengthInSec: json.enrollmentsLengthInSec ? parseFloat(json.enrollmentsLengthInSec) : 0,\n      enrollmentsSpeechLengthInSec: json.enrollmentsSpeechLengthInSec ? parseFloat(json.enrollmentsSpeechLengthInSec) : 0,\n      profileId: json.profileId || json.identificationProfileId,\n      remainingEnrollmentsSpeechLengthInSec: json.remainingEnrollmentsSpeechLengthInSec ? parseFloat(json.remainingEnrollmentsSpeechLengthInSec) : 0\n    };\n  }\n  static getVerificationDetails(json) {\n    return {\n      audioLengthInSec: json.audioLengthInSec ? parseFloat(json.audioLengthInSec) : 0,\n      audioSpeechLengthInSec: json.audioSpeechLengthInSec ? parseFloat(json.audioSpeechLengthInSec) : 0,\n      enrollmentStatus: json.enrollmentStatus,\n      enrollmentsCount: json.enrollmentsCount,\n      enrollmentsLengthInSec: json.enrollmentsLengthInSec ? parseFloat(json.enrollmentsLengthInSec) : 0,\n      enrollmentsSpeechLengthInSec: json.enrollmentsSpeechLengthInSec ? parseFloat(json.enrollmentsSpeechLengthInSec) : 0,\n      profileId: json.profileId || json.verificationProfileId,\n      remainingEnrollmentsCount: json.remainingEnrollments || json.remainingEnrollmentsCount,\n      remainingEnrollmentsSpeechLengthInSec: json.remainingEnrollmentsSpeechLengthInSec ? parseFloat(json.remainingEnrollmentsSpeechLengthInSec) : 0\n    };\n  }\n}\n/**\n * @class VoiceProfileEnrollmentCancellationDetails\n */\nclass VoiceProfileEnrollmentCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationDetailsBase {\n  constructor(reason, errorDetails, errorCode) {\n    super(reason, errorDetails, errorCode);\n  }\n  /**\n   * Creates an instance of VoiceProfileEnrollmentCancellationDetails object for the canceled VoiceProfileEnrollmentResult.\n   * @member VoiceProfileEnrollmentCancellationDetails.fromResult\n   * @function\n   * @public\n   * @param {VoiceProfileEnrollmentResult} result - The result that was canceled.\n   * @returns {VoiceProfileEnrollmentCancellationDetails} The cancellation details object being created.\n   */\n  static fromResult(result) {\n    const reason = _Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationReason.Error;\n    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError;\n    if (!!result.properties) {\n      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_2__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCode.NoError])]; //eslint-disable-line\n    }\n\n    return new VoiceProfileEnrollmentCancellationDetails(reason, result.errorDetails, errorCode);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileEnrollmentResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfilePhraseResult\": () => (/* binding */ VoiceProfilePhraseResult)\n/* harmony export */ });\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n\n\n/**\n * Output format\n * @class VoiceProfilePhraseResult\n */\nclass VoiceProfilePhraseResult extends _Exports__WEBPACK_IMPORTED_MODULE_0__.VoiceProfileResult {\n  constructor(reason, statusText, json) {\n    super(reason, statusText);\n    this.privPhrases = [];\n    _Contracts__WEBPACK_IMPORTED_MODULE_1__.Contracts.throwIfNullOrUndefined(json, \"phrase result JSON\");\n    if (!!json.value && !!json.value[0]) {\n      for (const item of json.value) {\n        this.privPhrases.push(item.passPhrase || item.activationPhrase);\n      }\n    }\n  }\n  get phrases() {\n    return this.privPhrases;\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfilePhraseResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfileCancellationDetails\": () => (/* binding */ VoiceProfileCancellationDetails),\n/* harmony export */   \"VoiceProfileResult\": () => (/* binding */ VoiceProfileResult)\n/* harmony export */ });\n/* harmony import */ var _common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../common.speech/Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/common.speech/Exports.js\");\n/* harmony import */ var _Contracts__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Contracts */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/Contracts.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/PropertyCollection.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/ResultReason.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationErrorCodes.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationDetailsBase.js\");\n/* harmony import */ var _Exports__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Exports */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/CancellationReason.js\");\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/* eslint-disable max-classes-per-file */\n\n\n\n/**\n * Output format\n * @class VoiceProfileResult\n */\nclass VoiceProfileResult {\n  constructor(reason, statusText) {\n    this.privReason = reason;\n    this.privProperties = new _Exports__WEBPACK_IMPORTED_MODULE_0__.PropertyCollection();\n    if (reason === _Exports__WEBPACK_IMPORTED_MODULE_1__.ResultReason.Canceled) {\n      _Contracts__WEBPACK_IMPORTED_MODULE_2__.Contracts.throwIfNullOrUndefined(statusText, \"statusText\");\n      this.privErrorDetails = statusText;\n      this.privProperties.setProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.ServiceError]);\n    }\n  }\n  get reason() {\n    return this.privReason;\n  }\n  get properties() {\n    return this.privProperties;\n  }\n  get errorDetails() {\n    return this.privErrorDetails;\n  }\n}\n/**\n * @class VoiceProfileCancellationDetails\n */\nclass VoiceProfileCancellationDetails extends _Exports__WEBPACK_IMPORTED_MODULE_5__.CancellationDetailsBase {\n  constructor(reason, errorDetails, errorCode) {\n    super(reason, errorDetails, errorCode);\n  }\n  /**\n   * Creates an instance of VoiceProfileCancellationDetails object for the canceled VoiceProfileResult.\n   * @member VoiceProfileCancellationDetails.fromResult\n   * @function\n   * @public\n   * @param {VoiceProfileResult} result - The result that was canceled.\n   * @returns {VoiceProfileCancellationDetails} The cancellation details object being created.\n   */\n  static fromResult(result) {\n    const reason = _Exports__WEBPACK_IMPORTED_MODULE_6__.CancellationReason.Error;\n    let errorCode = _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.NoError;\n    if (!!result.properties) {\n      errorCode = _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[result.properties.getProperty(_common_speech_Exports__WEBPACK_IMPORTED_MODULE_3__.CancellationErrorCodePropertyName, _Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode[_Exports__WEBPACK_IMPORTED_MODULE_4__.CancellationErrorCode.NoError])]; //eslint-disable-line\n    }\n\n    return new VoiceProfileCancellationDetails(reason, result.errorDetails, errorCode);\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileResult.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VoiceProfileType\": () => (/* binding */ VoiceProfileType)\n/* harmony export */ });\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT license.\n/**\n * Output format\n * @class VoiceProfileType\n */\nvar VoiceProfileType;\n(function (VoiceProfileType) {\n  /**\n   * Text independent speaker identification\n   * @member VoiceProfileType.TextIndependentIdentification\n   */\n  VoiceProfileType[VoiceProfileType[\"TextIndependentIdentification\"] = 0] = \"TextIndependentIdentification\";\n  /**\n   * Text dependent speaker verification\n   * @member VoiceProfileType.TextDependentVerification\n   */\n  VoiceProfileType[VoiceProfileType[\"TextDependentVerification\"] = 1] = \"TextDependentVerification\";\n  /**\n   * Text independent speaker verification\n   * @member VoiceProfileType.TextIndependentVerification\n   */\n  VoiceProfileType[VoiceProfileType[\"TextIndependentVerification\"] = 2] = \"TextIndependentVerification\";\n})(VoiceProfileType || (VoiceProfileType = {}));\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/src/sdk/VoiceProfileType.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/regex.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/regex.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/regex.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/rng.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/rng.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ rng)\n/* harmony export */ });\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nvar getRandomValues;\nvar rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation. Also,\n    // find the complete implementation of crypto (msCrypto) on IE11.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto) || typeof msCrypto !== 'undefined' && typeof msCrypto.getRandomValues === 'function' && msCrypto.getRandomValues.bind(msCrypto);\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/rng.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/stringify.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/stringify.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/validate.js\");\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nvar byteToHex = [];\nfor (var i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).substr(1));\n}\nfunction stringify(arr) {\n  var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  var uuid = (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase(); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n  return uuid;\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (stringify);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/stringify.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/v4.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/v4.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/stringify.js\");\n\n\nfunction v4(options, buf, offset) {\n  options = options || {};\n  var rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n    for (var i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n    return buf;\n  }\n  return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(rnds);\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v4);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/v4.js?");

/***/ }),

/***/ "./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/validate.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/validate.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/regex.js\");\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].test(uuid);\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (validate);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/microsoft-cognitiveservices-speech-sdk/node_modules/uuid/dist/esm-browser/validate.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nObject.defineProperty(exports, \"NIL\", ({\n  enumerable: true,\n  get: function get() {\n    return _nil.default;\n  }\n}));\nObject.defineProperty(exports, \"parse\", ({\n  enumerable: true,\n  get: function get() {\n    return _parse.default;\n  }\n}));\nObject.defineProperty(exports, \"stringify\", ({\n  enumerable: true,\n  get: function get() {\n    return _stringify.default;\n  }\n}));\nObject.defineProperty(exports, \"v1\", ({\n  enumerable: true,\n  get: function get() {\n    return _v.default;\n  }\n}));\nObject.defineProperty(exports, \"v3\", ({\n  enumerable: true,\n  get: function get() {\n    return _v2.default;\n  }\n}));\nObject.defineProperty(exports, \"v4\", ({\n  enumerable: true,\n  get: function get() {\n    return _v3.default;\n  }\n}));\nObject.defineProperty(exports, \"v5\", ({\n  enumerable: true,\n  get: function get() {\n    return _v4.default;\n  }\n}));\nObject.defineProperty(exports, \"validate\", ({\n  enumerable: true,\n  get: function get() {\n    return _validate.default;\n  }\n}));\nObject.defineProperty(exports, \"version\", ({\n  enumerable: true,\n  get: function get() {\n    return _version.default;\n  }\n}));\nvar _v = _interopRequireDefault(__webpack_require__(/*! ./v1.js */ \"./node_modules/uuid/dist/commonjs-browser/v1.js\"));\nvar _v2 = _interopRequireDefault(__webpack_require__(/*! ./v3.js */ \"./node_modules/uuid/dist/commonjs-browser/v3.js\"));\nvar _v3 = _interopRequireDefault(__webpack_require__(/*! ./v4.js */ \"./node_modules/uuid/dist/commonjs-browser/v4.js\"));\nvar _v4 = _interopRequireDefault(__webpack_require__(/*! ./v5.js */ \"./node_modules/uuid/dist/commonjs-browser/v5.js\"));\nvar _nil = _interopRequireDefault(__webpack_require__(/*! ./nil.js */ \"./node_modules/uuid/dist/commonjs-browser/nil.js\"));\nvar _version = _interopRequireDefault(__webpack_require__(/*! ./version.js */ \"./node_modules/uuid/dist/commonjs-browser/version.js\"));\nvar _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/commonjs-browser/validate.js\"));\nvar _stringify = _interopRequireDefault(__webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/commonjs-browser/stringify.js\"));\nvar _parse = _interopRequireDefault(__webpack_require__(/*! ./parse.js */ \"./node_modules/uuid/dist/commonjs-browser/parse.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/index.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/md5.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/md5.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\n/*\n * Browser-compatible JavaScript MD5\n *\n * Modification of JavaScript MD5\n * https://github.com/blueimp/JavaScript-MD5\n *\n * Copyright 2011, Sebastian Tschan\n * https://blueimp.net\n *\n * Licensed under the MIT license:\n * https://opensource.org/licenses/MIT\n *\n * Based on\n * A JavaScript implementation of the RSA Data Security, Inc. MD5 Message\n * Digest Algorithm, as defined in RFC 1321.\n * Version 2.2 Copyright (C) Paul Johnston 1999 - 2009\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n * Distributed under the BSD License\n * See http://pajhome.org.uk/crypt/md5 for more info.\n */\nfunction md5(bytes) {\n  if (typeof bytes === 'string') {\n    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = new Uint8Array(msg.length);\n    for (let i = 0; i < msg.length; ++i) {\n      bytes[i] = msg.charCodeAt(i);\n    }\n  }\n  return md5ToHexEncodedArray(wordsToMd5(bytesToWords(bytes), bytes.length * 8));\n}\n/*\n * Convert an array of little-endian words to an array of bytes\n */\n\nfunction md5ToHexEncodedArray(input) {\n  const output = [];\n  const length32 = input.length * 32;\n  const hexTab = '0123456789abcdef';\n  for (let i = 0; i < length32; i += 8) {\n    const x = input[i >> 5] >>> i % 32 & 0xff;\n    const hex = parseInt(hexTab.charAt(x >>> 4 & 0x0f) + hexTab.charAt(x & 0x0f), 16);\n    output.push(hex);\n  }\n  return output;\n}\n/**\n * Calculate output length with padding and bit length\n */\n\nfunction getOutputLength(inputLength8) {\n  return (inputLength8 + 64 >>> 9 << 4) + 14 + 1;\n}\n/*\n * Calculate the MD5 of an array of little-endian words, and a bit length.\n */\n\nfunction wordsToMd5(x, len) {\n  /* append padding */\n  x[len >> 5] |= 0x80 << len % 32;\n  x[getOutputLength(len) - 1] = len;\n  let a = 1732584193;\n  let b = -271733879;\n  let c = -1732584194;\n  let d = 271733878;\n  for (let i = 0; i < x.length; i += 16) {\n    const olda = a;\n    const oldb = b;\n    const oldc = c;\n    const oldd = d;\n    a = md5ff(a, b, c, d, x[i], 7, -680876936);\n    d = md5ff(d, a, b, c, x[i + 1], 12, -389564586);\n    c = md5ff(c, d, a, b, x[i + 2], 17, 606105819);\n    b = md5ff(b, c, d, a, x[i + 3], 22, -1044525330);\n    a = md5ff(a, b, c, d, x[i + 4], 7, -176418897);\n    d = md5ff(d, a, b, c, x[i + 5], 12, 1200080426);\n    c = md5ff(c, d, a, b, x[i + 6], 17, -1473231341);\n    b = md5ff(b, c, d, a, x[i + 7], 22, -45705983);\n    a = md5ff(a, b, c, d, x[i + 8], 7, 1770035416);\n    d = md5ff(d, a, b, c, x[i + 9], 12, -1958414417);\n    c = md5ff(c, d, a, b, x[i + 10], 17, -42063);\n    b = md5ff(b, c, d, a, x[i + 11], 22, -1990404162);\n    a = md5ff(a, b, c, d, x[i + 12], 7, 1804603682);\n    d = md5ff(d, a, b, c, x[i + 13], 12, -40341101);\n    c = md5ff(c, d, a, b, x[i + 14], 17, -1502002290);\n    b = md5ff(b, c, d, a, x[i + 15], 22, 1236535329);\n    a = md5gg(a, b, c, d, x[i + 1], 5, -165796510);\n    d = md5gg(d, a, b, c, x[i + 6], 9, -1069501632);\n    c = md5gg(c, d, a, b, x[i + 11], 14, 643717713);\n    b = md5gg(b, c, d, a, x[i], 20, -373897302);\n    a = md5gg(a, b, c, d, x[i + 5], 5, -701558691);\n    d = md5gg(d, a, b, c, x[i + 10], 9, 38016083);\n    c = md5gg(c, d, a, b, x[i + 15], 14, -660478335);\n    b = md5gg(b, c, d, a, x[i + 4], 20, -405537848);\n    a = md5gg(a, b, c, d, x[i + 9], 5, 568446438);\n    d = md5gg(d, a, b, c, x[i + 14], 9, -1019803690);\n    c = md5gg(c, d, a, b, x[i + 3], 14, -187363961);\n    b = md5gg(b, c, d, a, x[i + 8], 20, 1163531501);\n    a = md5gg(a, b, c, d, x[i + 13], 5, -1444681467);\n    d = md5gg(d, a, b, c, x[i + 2], 9, -51403784);\n    c = md5gg(c, d, a, b, x[i + 7], 14, 1735328473);\n    b = md5gg(b, c, d, a, x[i + 12], 20, -1926607734);\n    a = md5hh(a, b, c, d, x[i + 5], 4, -378558);\n    d = md5hh(d, a, b, c, x[i + 8], 11, -2022574463);\n    c = md5hh(c, d, a, b, x[i + 11], 16, 1839030562);\n    b = md5hh(b, c, d, a, x[i + 14], 23, -35309556);\n    a = md5hh(a, b, c, d, x[i + 1], 4, -1530992060);\n    d = md5hh(d, a, b, c, x[i + 4], 11, 1272893353);\n    c = md5hh(c, d, a, b, x[i + 7], 16, -155497632);\n    b = md5hh(b, c, d, a, x[i + 10], 23, -1094730640);\n    a = md5hh(a, b, c, d, x[i + 13], 4, 681279174);\n    d = md5hh(d, a, b, c, x[i], 11, -358537222);\n    c = md5hh(c, d, a, b, x[i + 3], 16, -722521979);\n    b = md5hh(b, c, d, a, x[i + 6], 23, 76029189);\n    a = md5hh(a, b, c, d, x[i + 9], 4, -640364487);\n    d = md5hh(d, a, b, c, x[i + 12], 11, -421815835);\n    c = md5hh(c, d, a, b, x[i + 15], 16, 530742520);\n    b = md5hh(b, c, d, a, x[i + 2], 23, -995338651);\n    a = md5ii(a, b, c, d, x[i], 6, -198630844);\n    d = md5ii(d, a, b, c, x[i + 7], 10, 1126891415);\n    c = md5ii(c, d, a, b, x[i + 14], 15, -1416354905);\n    b = md5ii(b, c, d, a, x[i + 5], 21, -57434055);\n    a = md5ii(a, b, c, d, x[i + 12], 6, 1700485571);\n    d = md5ii(d, a, b, c, x[i + 3], 10, -1894986606);\n    c = md5ii(c, d, a, b, x[i + 10], 15, -1051523);\n    b = md5ii(b, c, d, a, x[i + 1], 21, -2054922799);\n    a = md5ii(a, b, c, d, x[i + 8], 6, 1873313359);\n    d = md5ii(d, a, b, c, x[i + 15], 10, -30611744);\n    c = md5ii(c, d, a, b, x[i + 6], 15, -1560198380);\n    b = md5ii(b, c, d, a, x[i + 13], 21, 1309151649);\n    a = md5ii(a, b, c, d, x[i + 4], 6, -145523070);\n    d = md5ii(d, a, b, c, x[i + 11], 10, -1120210379);\n    c = md5ii(c, d, a, b, x[i + 2], 15, 718787259);\n    b = md5ii(b, c, d, a, x[i + 9], 21, -343485551);\n    a = safeAdd(a, olda);\n    b = safeAdd(b, oldb);\n    c = safeAdd(c, oldc);\n    d = safeAdd(d, oldd);\n  }\n  return [a, b, c, d];\n}\n/*\n * Convert an array bytes to an array of little-endian words\n * Characters >255 have their high-byte silently ignored.\n */\n\nfunction bytesToWords(input) {\n  if (input.length === 0) {\n    return [];\n  }\n  const length8 = input.length * 8;\n  const output = new Uint32Array(getOutputLength(length8));\n  for (let i = 0; i < length8; i += 8) {\n    output[i >> 5] |= (input[i / 8] & 0xff) << i % 32;\n  }\n  return output;\n}\n/*\n * Add integers, wrapping at 2^32. This uses 16-bit operations internally\n * to work around bugs in some JS interpreters.\n */\n\nfunction safeAdd(x, y) {\n  const lsw = (x & 0xffff) + (y & 0xffff);\n  const msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n  return msw << 16 | lsw & 0xffff;\n}\n/*\n * Bitwise rotate a 32-bit number to the left.\n */\n\nfunction bitRotateLeft(num, cnt) {\n  return num << cnt | num >>> 32 - cnt;\n}\n/*\n * These functions implement the four basic operations the algorithm uses.\n */\n\nfunction md5cmn(q, a, b, x, s, t) {\n  return safeAdd(bitRotateLeft(safeAdd(safeAdd(a, q), safeAdd(x, t)), s), b);\n}\nfunction md5ff(a, b, c, d, x, s, t) {\n  return md5cmn(b & c | ~b & d, a, b, x, s, t);\n}\nfunction md5gg(a, b, c, d, x, s, t) {\n  return md5cmn(b & d | c & ~d, a, b, x, s, t);\n}\nfunction md5hh(a, b, c, d, x, s, t) {\n  return md5cmn(b ^ c ^ d, a, b, x, s, t);\n}\nfunction md5ii(a, b, c, d, x, s, t) {\n  return md5cmn(c ^ (b | ~d), a, b, x, s, t);\n}\nvar _default = md5;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/md5.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/native.js":
/*!***********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/native.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nconst randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\nvar _default = {\n  randomUUID\n};\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/native.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/nil.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/nil.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _default = '00000000-0000-0000-0000-000000000000';\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/nil.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/parse.js":
/*!**********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/parse.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/commonjs-browser/validate.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  let v;\n  const arr = new Uint8Array(16); // Parse ########-....-....-....-............\n\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff; // Parse ........-####-....-....-............\n\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff; // Parse ........-....-####-....-............\n\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff; // Parse ........-....-....-####-............\n\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff; // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\nvar _default = parse;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/parse.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/regex.js":
/*!**********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/regex.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/regex.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/rng.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/rng.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = rng;\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nlet getRandomValues;\nconst rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/rng.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/sha1.js":
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/sha1.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\n// Adapted from Chris Veness' SHA1 code at\n// http://www.movable-type.co.uk/scripts/sha1.html\nfunction f(s, x, y, z) {\n  switch (s) {\n    case 0:\n      return x & y ^ ~x & z;\n    case 1:\n      return x ^ y ^ z;\n    case 2:\n      return x & y ^ x & z ^ y & z;\n    case 3:\n      return x ^ y ^ z;\n  }\n}\nfunction ROTL(x, n) {\n  return x << n | x >>> 32 - n;\n}\nfunction sha1(bytes) {\n  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6];\n  const H = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0];\n  if (typeof bytes === 'string') {\n    const msg = unescape(encodeURIComponent(bytes)); // UTF8 escape\n\n    bytes = [];\n    for (let i = 0; i < msg.length; ++i) {\n      bytes.push(msg.charCodeAt(i));\n    }\n  } else if (!Array.isArray(bytes)) {\n    // Convert Array-like to Array\n    bytes = Array.prototype.slice.call(bytes);\n  }\n  bytes.push(0x80);\n  const l = bytes.length / 4 + 2;\n  const N = Math.ceil(l / 16);\n  const M = new Array(N);\n  for (let i = 0; i < N; ++i) {\n    const arr = new Uint32Array(16);\n    for (let j = 0; j < 16; ++j) {\n      arr[j] = bytes[i * 64 + j * 4] << 24 | bytes[i * 64 + j * 4 + 1] << 16 | bytes[i * 64 + j * 4 + 2] << 8 | bytes[i * 64 + j * 4 + 3];\n    }\n    M[i] = arr;\n  }\n  M[N - 1][14] = (bytes.length - 1) * 8 / Math.pow(2, 32);\n  M[N - 1][14] = Math.floor(M[N - 1][14]);\n  M[N - 1][15] = (bytes.length - 1) * 8 & 0xffffffff;\n  for (let i = 0; i < N; ++i) {\n    const W = new Uint32Array(80);\n    for (let t = 0; t < 16; ++t) {\n      W[t] = M[i][t];\n    }\n    for (let t = 16; t < 80; ++t) {\n      W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1);\n    }\n    let a = H[0];\n    let b = H[1];\n    let c = H[2];\n    let d = H[3];\n    let e = H[4];\n    for (let t = 0; t < 80; ++t) {\n      const s = Math.floor(t / 20);\n      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] >>> 0;\n      e = d;\n      d = c;\n      c = ROTL(b, 30) >>> 0;\n      b = a;\n      a = T;\n    }\n    H[0] = H[0] + a >>> 0;\n    H[1] = H[1] + b >>> 0;\n    H[2] = H[2] + c >>> 0;\n    H[3] = H[3] + d >>> 0;\n    H[4] = H[4] + e >>> 0;\n  }\n  return [H[0] >> 24 & 0xff, H[0] >> 16 & 0xff, H[0] >> 8 & 0xff, H[0] & 0xff, H[1] >> 24 & 0xff, H[1] >> 16 & 0xff, H[1] >> 8 & 0xff, H[1] & 0xff, H[2] >> 24 & 0xff, H[2] >> 16 & 0xff, H[2] >> 8 & 0xff, H[2] & 0xff, H[3] >> 24 & 0xff, H[3] >> 16 & 0xff, H[3] >> 8 & 0xff, H[3] & 0xff, H[4] >> 24 & 0xff, H[4] >> 16 & 0xff, H[4] >> 8 & 0xff, H[4] & 0xff];\n}\nvar _default = sha1;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/sha1.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/stringify.js":
/*!**************************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/stringify.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nexports.unsafeStringify = unsafeStringify;\nvar _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/commonjs-browser/validate.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nfunction unsafeStringify(arr) {\n  let offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr) {\n  let offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n  return uuid;\n}\nvar _default = stringify;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/stringify.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/v1.js":
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v1.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _rng = _interopRequireDefault(__webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/commonjs-browser/rng.js\"));\nvar _stringify = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/commonjs-browser/stringify.js\");\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\nlet _nodeId;\nlet _clockseq; // Previous uuid creation time\n\nlet _lastMSecs = 0;\nlet _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details\n\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node || _nodeId;\n  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n    }\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)\n\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression\n\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  } // Per 4.2.1.2 Throw error if too many uuids are requested\n\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n\n  msecs += 12219292800000; // `time_low`\n\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff; // `time_mid`\n\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff; // `time_high_and_version`\n\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n\n  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n\n  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`\n\n  b[i++] = clockseq & 0xff; // `node`\n\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n  return buf || (0, _stringify.unsafeStringify)(b);\n}\nvar _default = v1;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/v1.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/v3.js":
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v3.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _v = _interopRequireDefault(__webpack_require__(/*! ./v35.js */ \"./node_modules/uuid/dist/commonjs-browser/v35.js\"));\nvar _md = _interopRequireDefault(__webpack_require__(/*! ./md5.js */ \"./node_modules/uuid/dist/commonjs-browser/md5.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = v3;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/v3.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/v35.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v35.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports.URL = exports.DNS = void 0;\nexports[\"default\"] = v35;\nvar _stringify = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/commonjs-browser/stringify.js\");\nvar _parse = _interopRequireDefault(__webpack_require__(/*! ./parse.js */ \"./node_modules/uuid/dist/commonjs-browser/parse.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n  return bytes;\n}\nconst DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nexports.DNS = DNS;\nconst URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nexports.URL = URL;\nfunction v35(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    var _namespace;\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n    if (((_namespace = namespace) === null || _namespace === void 0 ? void 0 : _namespace.length) !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    } // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n    if (buf) {\n      offset = offset || 0;\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n      return buf;\n    }\n    return (0, _stringify.unsafeStringify)(bytes);\n  } // Function#name is not settable on some platforms (#270)\n\n  try {\n    generateUUID.name = name; // eslint-disable-next-line no-empty\n  } catch (err) {} // For CommonJS default export support\n\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/v35.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/v4.js":
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v4.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _native = _interopRequireDefault(__webpack_require__(/*! ./native.js */ \"./node_modules/uuid/dist/commonjs-browser/native.js\"));\nvar _rng = _interopRequireDefault(__webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/commonjs-browser/rng.js\"));\nvar _stringify = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/commonjs-browser/stringify.js\");\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nfunction v4(options, buf, offset) {\n  if (_native.default.randomUUID && !buf && !options) {\n    return _native.default.randomUUID();\n  }\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng.default)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n    return buf;\n  }\n  return (0, _stringify.unsafeStringify)(rnds);\n}\nvar _default = v4;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/v4.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/v5.js":
/*!*******************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/v5.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _v = _interopRequireDefault(__webpack_require__(/*! ./v35.js */ \"./node_modules/uuid/dist/commonjs-browser/v35.js\"));\nvar _sha = _interopRequireDefault(__webpack_require__(/*! ./sha1.js */ \"./node_modules/uuid/dist/commonjs-browser/sha1.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = v5;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/v5.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/validate.js":
/*!*************************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/validate.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _regex = _interopRequireDefault(__webpack_require__(/*! ./regex.js */ \"./node_modules/uuid/dist/commonjs-browser/regex.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\nvar _default = validate;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/validate.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/commonjs-browser/version.js":
/*!************************************************************!*\
  !*** ./node_modules/uuid/dist/commonjs-browser/version.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\nvar _validate = _interopRequireDefault(__webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/commonjs-browser/validate.js\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n  return parseInt(uuid.slice(14, 15), 16);\n}\nvar _default = version;\nexports[\"default\"] = _default;\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/uuid/dist/commonjs-browser/version.js?");

/***/ }),

/***/ "./src/public/js/app.js":
/*!******************************!*\
  !*** ./src/public/js/app.js ***!
  \******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _css_style_css__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../css/style.css */ \"./src/public/css/style.css\");\n/* harmony import */ var cross_fetch__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! cross-fetch */ \"./node_modules/cross-fetch/dist/browser-ponyfill.js\");\n/* harmony import */ var cross_fetch__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(cross_fetch__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var axios__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! axios */ \"./node_modules/axios/index.js\");\n\n\n\nconst socket = io();\n\n//enter direct    \n\n//var enterreserved = document.querySelector(\"#enterdirect\");\n\nfunction handledirectClick() {\n  document.querySelector(\"#roomName\").value = iroomName;\n  document.querySelector(\"#nickname\").value = inickName;\n  console.log(\"test\", iroomName, inickName);\n  document.querySelector(\"#enterbtn\").click();\n}\n\n//enterreserved.addEventListener(\"click\",handledirectClick);\n\n//stt api \nconst {\n  v4: uuidv4\n} = __webpack_require__(/*! uuid */ \"./node_modules/uuid/dist/commonjs-browser/index.js\");\n\n// api \nconst speechsdk = __webpack_require__(/*! microsoft-cognitiveservices-speech-sdk */ \"./node_modules/microsoft-cognitiveservices-speech-sdk/distrib/es2015/microsoft.cognitiveservices.speech.sdk.js\");\n\n// \nconst startbtn = document.querySelector(\"#startSpeech\"); //pug   id \n\nconst myFace = document.querySelector(\"#myFace\");\nconst muteBtn = document.querySelector(\"#mute\");\nconst muteIcon = muteBtn.querySelector(\".muteIcon\");\nconst unMuteIcon = muteBtn.querySelector(\".unMuteIcon\");\nconst cameraBtn = document.querySelector(\"#camera\");\nconst cameraIcon = cameraBtn.querySelector(\".cameraIcon\");\nconst unCameraIcon = cameraBtn.querySelector(\".unCameraIcon\");\nconst camerasSelect = document.querySelector(\"#cameras\");\nconst call = document.querySelector(\"#call\");\nconst welcome = document.querySelector(\"#welcome\");\nconst HIDDEN_CN = \"hidden\";\nlet myStream;\nlet muted = true;\nunMuteIcon.classList.add(HIDDEN_CN);\nlet cameraOff = false;\nunCameraIcon.classList.add(HIDDEN_CN);\nlet roomName = \"\";\nlet nickname = \"\";\nlet peopleInRoom = 1;\nlet pcObj = {\n  // remoteSocketId: pc\n};\nasync function getCameras() {\n  try {\n    const devices = await navigator.mediaDevices.enumerateDevices();\n    const cameras = devices.filter(device => device.kind === \"videoinput\");\n    const currentCamera = myStream.getVideoTracks();\n    cameras.forEach(camera => {\n      const option = document.createElement(\"option\");\n      option.value = camera.deviceId;\n      option.innerText = camera.label;\n      if (currentCamera.label == camera.label) {\n        option.selected = true;\n      }\n      camerasSelect.appendChild(option);\n    });\n  } catch (error) {\n    console.log(error);\n  }\n}\nasync function getMedia(deviceId) {\n  const initialConstraints = {\n    audio: true,\n    video: {\n      facingMode: \"user\"\n    }\n  };\n  const cameraConstraints = {\n    audio: true,\n    video: {\n      deviceId: {\n        exact: deviceId\n      }\n    }\n  };\n  try {\n    myStream = await navigator.mediaDevices.getUserMedia(deviceId ? cameraConstraints : initialConstraints);\n\n    // stream mute   HTML video element mute.\n    myFace.srcObject = myStream;\n    myFace.muted = true;\n    if (!deviceId) {\n      // mute default\n      myStream //\n      .getAudioTracks().forEach(track => track.enabled = false);\n      await getCameras();\n    }\n  } catch (error) {\n    console.log(error);\n  }\n}\nfunction handleMuteClick() {\n  myStream //\n  .getAudioTracks().forEach(track => track.enabled = !track.enabled);\n  if (muted) {\n    unMuteIcon.classList.remove(HIDDEN_CN);\n    muteIcon.classList.add(HIDDEN_CN);\n    muted = false;\n  } else {\n    muteIcon.classList.remove(HIDDEN_CN);\n    unMuteIcon.classList.add(HIDDEN_CN);\n    muted = true;\n  }\n}\nfunction handleCameraClick() {\n  myStream //\n  .getVideoTracks().forEach(track => track.enabled = !track.enabled);\n  if (cameraOff) {\n    cameraIcon.classList.remove(HIDDEN_CN);\n    unCameraIcon.classList.add(HIDDEN_CN);\n    cameraOff = false;\n  } else {\n    unCameraIcon.classList.remove(HIDDEN_CN);\n    cameraIcon.classList.add(HIDDEN_CN);\n    cameraOff = true;\n  }\n}\nasync function handleCameraChange() {\n  try {\n    await getMedia(camerasSelect.value);\n    if (peerConnectionObjArr.length > 0) {\n      const newVideoTrack = myStream.getVideoTracks()[0];\n      peerConnectionObjArr.forEach(peerConnectionObj => {\n        const peerConnection = peerConnectionObj.connection;\n        const peerVideoSender = peerConnection.getSenders().find(sender => sender.track.kind == \"video\");\n        peerVideoSender.replaceTrack(newVideoTrack);\n      });\n    }\n  } catch (error) {\n    console.log(error);\n  }\n}\nmuteBtn.addEventListener(\"click\", handleMuteClick);\ncameraBtn.addEventListener(\"click\", handleCameraClick);\ncamerasSelect.addEventListener(\"input\", handleCameraChange);\n\n/////////////////////////////////// prototype\n// Screen Sharing\n\n// Welcome Form (choose room)\n\ncall.classList.add(HIDDEN_CN);\n// welcome.hidden = true;\n\nconst welcomeForm = welcome.querySelector(\"form\");\nasync function initCall() {\n  welcome.hidden = true;\n  call.classList.remove(HIDDEN_CN);\n  await getMedia();\n}\nasync function handleWelcomeSubmit(event) {\n  event.preventDefault();\n  if (socket.disconnected) {\n    socket.connect();\n  }\n  const welcomeRoomName = welcomeForm.querySelector(\"#roomName\");\n  const welcomeNickname = welcomeForm.querySelector(\"#nickname\");\n  const nicknameContainer = document.querySelector(\"#userNickname\");\n  roomName = welcomeRoomName.value;\n  welcomeRoomName.value = \"\";\n  nickname = welcomeNickname.value;\n  welcomeNickname.value = \"\";\n  nicknameContainer.innerText = nickname;\n  socket.emit(\"join_room\", roomName, nickname);\n}\nwelcomeForm.addEventListener(\"submit\", handleWelcomeSubmit);\n\n// Chat Form\n\nconst chatForm = document.querySelector(\"#chatForm\");\nconst chatBox = document.querySelector(\"#chatBox\");\nconst MYCHAT_CN = \"myChat\";\nconst NOTICE_CN = \"noticeChat\";\nchatForm.addEventListener(\"submit\", handleChatSubmit);\nfunction handleChatSubmit(event) {\n  event.preventDefault();\n  const chatInput = chatForm.querySelector(\"input\");\n  const message = chatInput.value;\n  chatInput.value = \"\";\n  socket.emit(\"chat\", `${nickname}: ${message}`, roomName);\n  writeChat(`You: ${message}`, MYCHAT_CN);\n}\nfunction writeChat(message) {\n  let className = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n  const li = document.createElement(\"li\");\n  const span = document.createElement(\"span\");\n  span.innerText = message;\n  li.appendChild(span);\n  li.classList.add(className);\n  chatBox.prepend(li);\n}\n\n// Leave Room\n\nconst leaveBtn = document.querySelector(\"#leave\");\nfunction leaveRoom() {\n  socket.disconnect();\n  call.classList.add(HIDDEN_CN);\n  welcome.hidden = false;\n  peerConnectionObjArr = [];\n  peopleInRoom = 1;\n  nickname = \"\";\n  myStream.getTracks().forEach(track => track.stop());\n  const nicknameContainer = document.querySelector(\"#userNickname\");\n  nicknameContainer.innerText = \"\";\n  myFace.srcObject = null;\n  clearAllVideos();\n  clearAllChat();\n}\nfunction removeVideo(leavedSocketId) {\n  const streams = document.querySelector(\"#streams\");\n  const streamArr = streams.querySelectorAll(\"div\");\n  streamArr.forEach(streamElement => {\n    if (streamElement.id === leavedSocketId) {\n      streams.removeChild(streamElement);\n    }\n  });\n}\nfunction clearAllVideos() {\n  const streams = document.querySelector(\"#streams\");\n  const streamArr = streams.querySelectorAll(\"div\");\n  streamArr.forEach(streamElement => {\n    if (streamElement.id != \"myStream\") {\n      streams.removeChild(streamElement);\n    }\n  });\n}\nfunction clearAllChat() {\n  const chatArr = chatBox.querySelectorAll(\"li\");\n  chatArr.forEach(chat => chatBox.removeChild(chat));\n}\nleaveBtn.addEventListener(\"click\", leaveRoom);\n\n// Modal code\n\nconst modal = document.querySelector(\".modal\");\nconst modalText = modal.querySelector(\".modal__text\");\nconst modalBtn = modal.querySelector(\".modal__btn\");\nfunction paintModal(text) {\n  modalText.innerText = text;\n  modal.classList.remove(HIDDEN_CN);\n  modal.addEventListener(\"click\", removeModal);\n  modalBtn.addEventListener(\"click\", removeModal);\n  document.addEventListener(\"keydown\", handleKeydown);\n}\nfunction removeModal() {\n  modal.classList.add(HIDDEN_CN);\n  modalText.innerText = \"\";\n}\nfunction handleKeydown(event) {\n  if (event.code === \"Escape\" || event.code === \"Enter\") {\n    removeModal();\n  }\n}\n\n// Socket code\n\nsocket.on(\"reject_join\", () => {\n  // Paint modal\n  paintModal(\"Sorry, The room is already full.\");\n\n  // Erase names\n  const nicknameContainer = document.querySelector(\"#userNickname\");\n  nicknameContainer.innerText = \"\";\n  roomName = \"\";\n  nickname = \"\";\n});\nsocket.on(\"accept_join\", async userObjArr => {\n  await initCall();\n  const length = userObjArr.length;\n  if (length === 1) {\n    return;\n  }\n  writeChat(\"Notice!\", NOTICE_CN);\n  for (let i = 0; i < length - 1; ++i) {\n    try {\n      const newPC = createConnection(userObjArr[i].socketId, userObjArr[i].nickname);\n      const offer = await newPC.createOffer();\n      await newPC.setLocalDescription(offer);\n      socket.emit(\"offer\", offer, userObjArr[i].socketId, nickname);\n      writeChat(`__${userObjArr[i].nickname}__`, NOTICE_CN);\n    } catch (err) {\n      console.error(err);\n    }\n  }\n  writeChat(\"is in the room.\", NOTICE_CN);\n});\nsocket.on(\"offer\", async (offer, remoteSocketId, remoteNickname) => {\n  try {\n    const newPC = createConnection(remoteSocketId, remoteNickname);\n    await newPC.setRemoteDescription(offer);\n    const answer = await newPC.createAnswer();\n    await newPC.setLocalDescription(answer);\n    socket.emit(\"answer\", answer, remoteSocketId);\n    writeChat(`notice! __${remoteNickname}__ joined the room`, NOTICE_CN);\n  } catch (err) {\n    console.error(err);\n  }\n});\nsocket.on(\"answer\", async (answer, remoteSocketId) => {\n  await pcObj[remoteSocketId].setRemoteDescription(answer);\n});\nsocket.on(\"ice\", async (ice, remoteSocketId) => {\n  await pcObj[remoteSocketId].addIceCandidate(ice);\n});\nsocket.on(\"chat\", message => {\n  writeChat(message);\n});\nsocket.on(\"leave_room\", (leavedSocketId, nickname) => {\n  removeVideo(leavedSocketId);\n  writeChat(`notice! ${nickname} leaved the room.`, NOTICE_CN);\n  --peopleInRoom;\n  sortStreams();\n});\n\n// RTC code\n\nfunction createConnection(remoteSocketId, remoteNickname) {\n  const myPeerConnection = new RTCPeerConnection({\n    iceServers: [{\n      urls: [\"stun:stun.l.google.com:19302\", \"stun:stun1.l.google.com:19302\", \"stun:stun2.l.google.com:19302\", \"stun:stun3.l.google.com:19302\", \"stun:stun4.l.google.com:19302\"]\n    }]\n  });\n  myPeerConnection.addEventListener(\"icecandidate\", event => {\n    handleIce(event, remoteSocketId);\n  });\n  myPeerConnection.addEventListener(\"addstream\", event => {\n    handleAddStream(event, remoteSocketId, remoteNickname);\n  });\n  // myPeerConnection.addEventListener(\n  //   \"iceconnectionstatechange\",\n  //   handleConnectionStateChange\n  // );\n  myStream //\n  .getTracks().forEach(track => myPeerConnection.addTrack(track, myStream));\n  pcObj[remoteSocketId] = myPeerConnection;\n  ++peopleInRoom;\n  sortStreams();\n  return myPeerConnection;\n}\nfunction handleIce(event, remoteSocketId) {\n  if (event.candidate) {\n    socket.emit(\"ice\", event.candidate, remoteSocketId);\n  }\n}\nfunction handleAddStream(event, remoteSocketId, remoteNickname) {\n  const peerStream = event.stream;\n  paintPeerFace(peerStream, remoteSocketId, remoteNickname);\n}\nfunction paintPeerFace(peerStream, id, remoteNickname) {\n  const streams = document.querySelector(\"#streams\");\n  const div = document.createElement(\"div\");\n  div.id = id;\n  const video = document.createElement(\"video\");\n  video.autoplay = true;\n  video.playsInline = true;\n  video.width = \"400\";\n  video.height = \"400\";\n  video.srcObject = peerStream;\n  const nicknameContainer = document.createElement(\"h3\");\n  nicknameContainer.id = \"userNickname\";\n  nicknameContainer.innerText = remoteNickname;\n  div.appendChild(video);\n  div.appendChild(nicknameContainer);\n  streams.appendChild(div);\n  sortStreams();\n}\nfunction sortStreams() {\n  const streams = document.querySelector(\"#streams\");\n  const streamArr = streams.querySelectorAll(\"div\");\n  streamArr.forEach(stream => stream.className = `people${peopleInRoom}`);\n}\n\n//  \nasync function handleSpeechClick() {\n  // \n  const speechConfig = speechsdk.SpeechConfig.fromSubscription(\"6b56e306d60644f1b2563bc8dbf26cd1\", \"koreacentral\");\n  speechConfig.speechRecognitionLanguage = 'ko-KR';\n  const audioConfig = speechsdk.AudioConfig.fromDefaultMicrophoneInput();\n  const recognizer = new speechsdk.SpeechRecognizer(speechConfig, audioConfig);\n  recognizer.recognizeOnceAsync(result => {\n    let displayText;\n    if (result.reason === speechsdk.ResultReason.RecognizedSpeech) {\n      displayText = `${result.text}`;\n      console.log(displayText);\n      writeChat(displayText);\n      // \n      (0,axios__WEBPACK_IMPORTED_MODULE_2__[\"default\"])({\n        baseURL: \"https://api.cognitive.microsofttranslator.com\",\n        url: '/translate',\n        method: 'POST',\n        headers: {\n          'Ocp-Apim-Subscription-Key': \"2a2f2653bf284b8fa7c33c656156823b\",\n          'Ocp-Apim-Subscription-Region': \"koreacentral\",\n          'Content-type': 'application/json',\n          'X-ClientTraceId': uuidv4().toString()\n        },\n        params: {\n          'api-version': '3.0',\n          'from': 'ko',\n          'to': ['en']\n        },\n        data: [{\n          'text': displayText\n        }],\n        responseType: 'json'\n      }).then(function (response) {\n        console.log(response.data);\n        writeChat(JSON.stringify(response.data, null, 4));\n        console.log(JSON.stringify(response.data, null, 4));\n        // json \n      });\n    } else {\n      displayText = 'ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.';\n      console.log(displayText);\n      writeChat(displayText);\n      //   \n    }\n  });\n}\n\n//  \nstartbtn.addEventListener(\"click\", handleSpeechClick);\nif (invite === \"true\" && islogin === \"true\") {\n  document.querySelector(\"#roomName\").value = iroomName;\n  document.querySelector(\"#nickname\").value = inickName;\n  console.log(\"test\", iroomName, inickName);\n  document.querySelector(\"#enterbtn\").click();\n}\n\n//    \nif (islogin === \"true\") {\n  alert(\"islogin === true\");\n  var loginbtn = document.querySelector(\"#loginbtn\");\n  var logoutbtn = document.querySelector(\"#logoutbtn\");\n  var roomnameinput = document.querySelector(\"#roomName\");\n  var nicknameinput = document.querySelector(\"#nickname\");\n  var enterbtn = document.querySelector(\"#enterbtn\");\n  var invitetxt = document.querySelector(\"#invtxt\");\n  var enterreserved = document.querySelector(\"#enterdirect\");\n  //enterreserved = document.querySelector(\"#enterdirect\");\n  loginbtn.style.visibility = 'hidden';\n  logoutbtn.style.visibility = 'visible';\n  roomnameinput.style.visibility = 'visible';\n  nicknameinput.style.visibility = 'visible';\n  enterbtn.style.visibility = 'visible';\n  invitetxt.style.visibiity = 'hidden';\n  invitetxt.innerHTML = \"\";\n  enterreserved.style.visibiity = 'hidden';\n  if (invite === \"true\") {\n    alert(\"islogin === true&&invite == true\");\n    enterreserved.style.visibiity = 'visible';\n  }\n} else {\n  alert(\"islogin === false\");\n  var loginbtn = document.querySelector(\"#loginbtn\");\n  var logoutbtn = document.querySelector(\"#logoutbtn\");\n  var roomnameinput = document.querySelector(\"#roomName\");\n  var nicknameinput = document.querySelector(\"#nickname\");\n  var enterbtn = document.querySelector(\"#enterbtn\");\n  var invitetxt = document.querySelector(\"#invtxt\");\n  var enterreserved = document.querySelector(\"#enterdirect\");\n  loginbtn.style.visibility = 'visible';\n  logoutbtn.style.visibility = 'hidden';\n  roomnameinput.style.visibility = 'hidden';\n  nicknameinput.style.visibility = 'hidden';\n  enterbtn.style.visibility = 'hidden';\n  invitetxt.style.visibiity = 'hidden';\n  enterreserved.style.visibiity = 'hidden';\n  if (invite === \"true\") {\n    alert(\"islogin === false&&invite == true\");\n    invitetxt.style.visibiity = 'visible';\n  } else {\n    alert(\"islogin === false&&invite == false\");\n    invitetxt.innerHTML = \"\";\n    enterreserved.style.visibiity = 'hidden';\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./src/public/js/app.js?");

/***/ }),

/***/ "./src/public/css/style.css":
/*!**********************************!*\
  !*** ./src/public/css/style.css ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// extracted by mini-css-extract-plugin\n\n\n//# sourceURL=webpack://webrtctranslate/./src/public/css/style.css?");

/***/ }),

/***/ "?2454":
/*!******************************************!*\
  !*** ../../external/ocsp/ocsp (ignored) ***!
  \******************************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/../../external/ocsp/ocsp_(ignored)?");

/***/ }),

/***/ "?6483":
/*!****************************!*\
  !*** agent-base (ignored) ***!
  \****************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/agent-base_(ignored)?");

/***/ }),

/***/ "?bed2":
/*!**********************************!*\
  !*** async-disk-cache (ignored) ***!
  \**********************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/async-disk-cache_(ignored)?");

/***/ }),

/***/ "?0825":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/fs_(ignored)?");

/***/ }),

/***/ "?72ad":
/*!***********************************!*\
  !*** https-proxy-agent (ignored) ***!
  \***********************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/https-proxy-agent_(ignored)?");

/***/ }),

/***/ "?a1bf":
/*!*********************!*\
  !*** net (ignored) ***!
  \*********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/net_(ignored)?");

/***/ }),

/***/ "?14d6":
/*!*********************!*\
  !*** tls (ignored) ***!
  \*********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/tls_(ignored)?");

/***/ }),

/***/ "?e42a":
/*!********************!*\
  !*** ws (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/ws_(ignored)?");

/***/ }),

/***/ "?9463":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://webrtctranslate/fs_(ignored)?");

/***/ }),

/***/ "./node_modules/axios/index.js":
/*!*************************************!*\
  !*** ./node_modules/axios/index.js ***!
  \*************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Axios\": () => (/* binding */ Axios),\n/* harmony export */   \"AxiosError\": () => (/* binding */ AxiosError),\n/* harmony export */   \"Cancel\": () => (/* binding */ Cancel),\n/* harmony export */   \"CancelToken\": () => (/* binding */ CancelToken),\n/* harmony export */   \"CanceledError\": () => (/* binding */ CanceledError),\n/* harmony export */   \"VERSION\": () => (/* binding */ VERSION),\n/* harmony export */   \"all\": () => (/* binding */ all),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   \"isAxiosError\": () => (/* binding */ isAxiosError),\n/* harmony export */   \"isCancel\": () => (/* binding */ isCancel),\n/* harmony export */   \"spread\": () => (/* binding */ spread),\n/* harmony export */   \"toFormData\": () => (/* binding */ toFormData)\n/* harmony export */ });\n/* harmony import */ var _lib_axios_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/axios.js */ \"./node_modules/axios/lib/axios.js\");\n\n\n// Keep top-level export same with static properties\n// so that it can keep same with es module or cjs\nconst {\n  Axios,\n  AxiosError,\n  CanceledError,\n  isCancel,\n  CancelToken,\n  VERSION,\n  all,\n  Cancel,\n  isAxiosError,\n  spread,\n  toFormData\n} = _lib_axios_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_lib_axios_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]);\n\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/index.js?");

/***/ }),

/***/ "./node_modules/axios/lib/adapters/index.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/adapters/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _http_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./xhr.js */ \"./node_modules/axios/lib/adapters/xhr.js\");\n\n\n\nconst adapters = {\n  http: _http_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  xhr: _http_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  getAdapter: nameOrAdapter => {\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(nameOrAdapter)) {\n      const adapter = adapters[nameOrAdapter];\n      if (!nameOrAdapter) {\n        throw Error(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasOwnProp(nameOrAdapter) ? `Adapter '${nameOrAdapter}' is not available in the build` : `Can not resolve adapter '${nameOrAdapter}'`);\n      }\n      return adapter;\n    }\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(nameOrAdapter)) {\n      throw new TypeError('adapter is not a function');\n    }\n    return nameOrAdapter;\n  },\n  adapters\n});\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/adapters/index.js?");

/***/ }),

/***/ "./node_modules/axios/lib/adapters/xhr.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/adapters/xhr.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ xhrAdapter)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_settle_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./../core/settle.js */ \"./node_modules/axios/lib/core/settle.js\");\n/* harmony import */ var _helpers_cookies_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./../helpers/cookies.js */ \"./node_modules/axios/lib/helpers/cookies.js\");\n/* harmony import */ var _helpers_buildURL_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./../helpers/buildURL.js */ \"./node_modules/axios/lib/helpers/buildURL.js\");\n/* harmony import */ var _core_buildFullPath_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/buildFullPath.js */ \"./node_modules/axios/lib/core/buildFullPath.js\");\n/* harmony import */ var _helpers_isURLSameOrigin_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./../helpers/isURLSameOrigin.js */ \"./node_modules/axios/lib/helpers/isURLSameOrigin.js\");\n/* harmony import */ var _defaults_transitional_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../defaults/transitional.js */ \"./node_modules/axios/lib/defaults/transitional.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _helpers_parseProtocol_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../helpers/parseProtocol.js */ \"./node_modules/axios/lib/helpers/parseProtocol.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n/* harmony import */ var _helpers_speedometer_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../helpers/speedometer.js */ \"./node_modules/axios/lib/helpers/speedometer.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction progressEventReducer(listener, isDownloadStream) {\n  let bytesNotified = 0;\n  const _speedometer = (0,_helpers_speedometer_js__WEBPACK_IMPORTED_MODULE_12__[\"default\"])(50, 250);\n  return e => {\n    const loaded = e.loaded;\n    const total = e.lengthComputable ? e.total : undefined;\n    const progressBytes = loaded - bytesNotified;\n    const rate = _speedometer(progressBytes);\n    const inRange = loaded <= total;\n    bytesNotified = loaded;\n    const data = {\n      loaded,\n      total,\n      progress: total ? loaded / total : undefined,\n      bytes: progressBytes,\n      rate: rate ? rate : undefined,\n      estimated: rate && total && inRange ? (total - loaded) / rate : undefined\n    };\n    data[isDownloadStream ? 'download' : 'upload'] = true;\n    listener(data);\n  };\n}\nfunction xhrAdapter(config) {\n  return new Promise(function dispatchXhrRequest(resolve, reject) {\n    let requestData = config.data;\n    const requestHeaders = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"].from(config.headers).normalize();\n    const responseType = config.responseType;\n    let onCanceled;\n    function done() {\n      if (config.cancelToken) {\n        config.cancelToken.unsubscribe(onCanceled);\n      }\n      if (config.signal) {\n        config.signal.removeEventListener('abort', onCanceled);\n      }\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFormData(requestData) && _platform_index_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"].isStandardBrowserEnv) {\n      requestHeaders.setContentType(false); // Let the browser set it\n    }\n\n    let request = new XMLHttpRequest();\n\n    // HTTP basic authentication\n    if (config.auth) {\n      const username = config.auth.username || '';\n      const password = config.auth.password ? unescape(encodeURIComponent(config.auth.password)) : '';\n      requestHeaders.set('Authorization', 'Basic ' + btoa(username + ':' + password));\n    }\n    const fullPath = (0,_core_buildFullPath_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(config.baseURL, config.url);\n    request.open(config.method.toUpperCase(), (0,_helpers_buildURL_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(fullPath, config.params, config.paramsSerializer), true);\n\n    // Set the request timeout in MS\n    request.timeout = config.timeout;\n    function onloadend() {\n      if (!request) {\n        return;\n      }\n      // Prepare the response\n      const responseHeaders = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"].from('getAllResponseHeaders' in request && request.getAllResponseHeaders());\n      const responseData = !responseType || responseType === 'text' || responseType === 'json' ? request.responseText : request.response;\n      const response = {\n        data: responseData,\n        status: request.status,\n        statusText: request.statusText,\n        headers: responseHeaders,\n        config,\n        request\n      };\n      (0,_core_settle_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(function _resolve(value) {\n        resolve(value);\n        done();\n      }, function _reject(err) {\n        reject(err);\n        done();\n      }, response);\n\n      // Clean up request\n      request = null;\n    }\n    if ('onloadend' in request) {\n      // Use onloadend if available\n      request.onloadend = onloadend;\n    } else {\n      // Listen for ready state to emulate onloadend\n      request.onreadystatechange = function handleLoad() {\n        if (!request || request.readyState !== 4) {\n          return;\n        }\n\n        // The request errored out and we didn't get a response, this will be\n        // handled by onerror instead\n        // With one exception: request that using file: protocol, most browsers\n        // will return status as 0 even though it's a successful request\n        if (request.status === 0 && !(request.responseURL && request.responseURL.indexOf('file:') === 0)) {\n          return;\n        }\n        // readystate handler is calling before onerror or ontimeout handlers,\n        // so we should call onloadend on the next 'tick'\n        setTimeout(onloadend);\n      };\n    }\n\n    // Handle browser request cancellation (as opposed to a manual cancellation)\n    request.onabort = function handleAbort() {\n      if (!request) {\n        return;\n      }\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]('Request aborted', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].ECONNABORTED, config, request));\n\n      // Clean up request\n      request = null;\n    };\n\n    // Handle low level network errors\n    request.onerror = function handleError() {\n      // Real errors are hidden from us by the browser\n      // onerror should only fire if it's a network error\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]('Network Error', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].ERR_NETWORK, config, request));\n\n      // Clean up request\n      request = null;\n    };\n\n    // Handle timeout\n    request.ontimeout = function handleTimeout() {\n      let timeoutErrorMessage = config.timeout ? 'timeout of ' + config.timeout + 'ms exceeded' : 'timeout exceeded';\n      const transitional = config.transitional || _defaults_transitional_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"];\n      if (config.timeoutErrorMessage) {\n        timeoutErrorMessage = config.timeoutErrorMessage;\n      }\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"](timeoutErrorMessage, transitional.clarifyTimeoutError ? _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].ETIMEDOUT : _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].ECONNABORTED, config, request));\n\n      // Clean up request\n      request = null;\n    };\n\n    // Add xsrf header\n    // This is only done if running in a standard browser environment.\n    // Specifically not if we're in a web worker, or react-native.\n    if (_platform_index_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"].isStandardBrowserEnv) {\n      // Add xsrf header\n      const xsrfValue = (config.withCredentials || (0,_helpers_isURLSameOrigin_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(fullPath)) && config.xsrfCookieName && _helpers_cookies_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].read(config.xsrfCookieName);\n      if (xsrfValue) {\n        requestHeaders.set(config.xsrfHeaderName, xsrfValue);\n      }\n    }\n\n    // Remove Content-Type if data is undefined\n    requestData === undefined && requestHeaders.setContentType(null);\n\n    // Add headers to the request\n    if ('setRequestHeader' in request) {\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(requestHeaders.toJSON(), function setRequestHeader(val, key) {\n        request.setRequestHeader(key, val);\n      });\n    }\n\n    // Add withCredentials to request if needed\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(config.withCredentials)) {\n      request.withCredentials = !!config.withCredentials;\n    }\n\n    // Add responseType to request if needed\n    if (responseType && responseType !== 'json') {\n      request.responseType = config.responseType;\n    }\n\n    // Handle progress if needed\n    if (typeof config.onDownloadProgress === 'function') {\n      request.addEventListener('progress', progressEventReducer(config.onDownloadProgress, true));\n    }\n\n    // Not all browsers support upload events\n    if (typeof config.onUploadProgress === 'function' && request.upload) {\n      request.upload.addEventListener('progress', progressEventReducer(config.onUploadProgress));\n    }\n    if (config.cancelToken || config.signal) {\n      // Handle cancellation\n      // eslint-disable-next-line func-names\n      onCanceled = cancel => {\n        if (!request) {\n          return;\n        }\n        reject(!cancel || cancel.type ? new _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"](null, config, request) : cancel);\n        request.abort();\n        request = null;\n      };\n      config.cancelToken && config.cancelToken.subscribe(onCanceled);\n      if (config.signal) {\n        config.signal.aborted ? onCanceled() : config.signal.addEventListener('abort', onCanceled);\n      }\n    }\n    const protocol = (0,_helpers_parseProtocol_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"])(fullPath);\n    if (protocol && _platform_index_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"].protocols.indexOf(protocol) === -1) {\n      reject(new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]('Unsupported protocol ' + protocol + ':', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].ERR_BAD_REQUEST, config));\n      return;\n    }\n\n    // Send the request\n    request.send(requestData || null);\n  });\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/adapters/xhr.js?");

/***/ }),

/***/ "./node_modules/axios/lib/axios.js":
/*!*****************************************!*\
  !*** ./node_modules/axios/lib/axios.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_bind_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./helpers/bind.js */ \"./node_modules/axios/lib/helpers/bind.js\");\n/* harmony import */ var _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./core/Axios.js */ \"./node_modules/axios/lib/core/Axios.js\");\n/* harmony import */ var _core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./core/mergeConfig.js */ \"./node_modules/axios/lib/core/mergeConfig.js\");\n/* harmony import */ var _defaults_index_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./defaults/index.js */ \"./node_modules/axios/lib/defaults/index.js\");\n/* harmony import */ var _helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./helpers/formDataToJSON.js */ \"./node_modules/axios/lib/helpers/formDataToJSON.js\");\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _cancel_CancelToken_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./cancel/CancelToken.js */ \"./node_modules/axios/lib/cancel/CancelToken.js\");\n/* harmony import */ var _cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./cancel/isCancel.js */ \"./node_modules/axios/lib/cancel/isCancel.js\");\n/* harmony import */ var _env_data_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./env/data.js */ \"./node_modules/axios/lib/env/data.js\");\n/* harmony import */ var _helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./helpers/toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _helpers_spread_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./helpers/spread.js */ \"./node_modules/axios/lib/helpers/spread.js\");\n/* harmony import */ var _helpers_isAxiosError_js__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./helpers/isAxiosError.js */ \"./node_modules/axios/lib/helpers/isAxiosError.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Create an instance of Axios\n *\n * @param {Object} defaultConfig The default config for the instance\n *\n * @returns {Axios} A new instance of Axios\n */\nfunction createInstance(defaultConfig) {\n  const context = new _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](defaultConfig);\n  const instance = (0,_helpers_bind_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(_core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].prototype.request, context);\n\n  // Copy axios.prototype to instance\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].extend(instance, _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].prototype, context, {\n    allOwnKeys: true\n  });\n\n  // Copy context to instance\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].extend(instance, context, null, {\n    allOwnKeys: true\n  });\n\n  // Factory for creating new instances\n  instance.create = function create(instanceConfig) {\n    return createInstance((0,_core_mergeConfig_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(defaultConfig, instanceConfig));\n  };\n  return instance;\n}\n\n// Create the default instance to be exported\nconst axios = createInstance(_defaults_index_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]);\n\n// Expose Axios class to allow class inheritance\naxios.Axios = _core_Axios_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"];\n\n// Expose Cancel & CancelToken\naxios.CanceledError = _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"];\naxios.CancelToken = _cancel_CancelToken_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"];\naxios.isCancel = _cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"];\naxios.VERSION = _env_data_js__WEBPACK_IMPORTED_MODULE_9__.VERSION;\naxios.toFormData = _helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"];\n\n// Expose AxiosError class\naxios.AxiosError = _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"];\n\n// alias for CanceledError for backward compatibility\naxios.Cancel = axios.CanceledError;\n\n// Expose all/spread\naxios.all = function all(promises) {\n  return Promise.all(promises);\n};\naxios.spread = _helpers_spread_js__WEBPACK_IMPORTED_MODULE_12__[\"default\"];\n\n// Expose isAxiosError\naxios.isAxiosError = _helpers_isAxiosError_js__WEBPACK_IMPORTED_MODULE_13__[\"default\"];\naxios.formToJSON = thing => {\n  return (0,_helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isHTMLForm(thing) ? new FormData(thing) : thing);\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (axios);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/axios.js?");

/***/ }),

/***/ "./node_modules/axios/lib/cancel/CancelToken.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/cancel/CancelToken.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _CanceledError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n\n\n\n\n/**\n * A `CancelToken` is an object that can be used to request cancellation of an operation.\n *\n * @param {Function} executor The executor function.\n *\n * @returns {CancelToken}\n */\nclass CancelToken {\n  constructor(executor) {\n    if (typeof executor !== 'function') {\n      throw new TypeError('executor must be a function.');\n    }\n    let resolvePromise;\n    this.promise = new Promise(function promiseExecutor(resolve) {\n      resolvePromise = resolve;\n    });\n    const token = this;\n\n    // eslint-disable-next-line func-names\n    this.promise.then(cancel => {\n      if (!token._listeners) return;\n      let i = token._listeners.length;\n      while (i-- > 0) {\n        token._listeners[i](cancel);\n      }\n      token._listeners = null;\n    });\n\n    // eslint-disable-next-line func-names\n    this.promise.then = onfulfilled => {\n      let _resolve;\n      // eslint-disable-next-line func-names\n      const promise = new Promise(resolve => {\n        token.subscribe(resolve);\n        _resolve = resolve;\n      }).then(onfulfilled);\n      promise.cancel = function reject() {\n        token.unsubscribe(_resolve);\n      };\n      return promise;\n    };\n    executor(function cancel(message, config, request) {\n      if (token.reason) {\n        // Cancellation has already been requested\n        return;\n      }\n      token.reason = new _CanceledError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](message, config, request);\n      resolvePromise(token.reason);\n    });\n  }\n\n  /**\n   * Throws a `CanceledError` if cancellation has been requested.\n   */\n  throwIfRequested() {\n    if (this.reason) {\n      throw this.reason;\n    }\n  }\n\n  /**\n   * Subscribe to the cancel signal\n   */\n\n  subscribe(listener) {\n    if (this.reason) {\n      listener(this.reason);\n      return;\n    }\n    if (this._listeners) {\n      this._listeners.push(listener);\n    } else {\n      this._listeners = [listener];\n    }\n  }\n\n  /**\n   * Unsubscribe from the cancel signal\n   */\n\n  unsubscribe(listener) {\n    if (!this._listeners) {\n      return;\n    }\n    const index = this._listeners.indexOf(listener);\n    if (index !== -1) {\n      this._listeners.splice(index, 1);\n    }\n  }\n\n  /**\n   * Returns an object that contains a new `CancelToken` and a function that, when called,\n   * cancels the `CancelToken`.\n   */\n  static source() {\n    let cancel;\n    const token = new CancelToken(function executor(c) {\n      cancel = c;\n    });\n    return {\n      token,\n      cancel\n    };\n  }\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CancelToken);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/cancel/CancelToken.js?");

/***/ }),

/***/ "./node_modules/axios/lib/cancel/CanceledError.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/cancel/CanceledError.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n\n/**\n * A `CanceledError` is an object that is thrown when an operation is canceled.\n *\n * @param {string=} message The message.\n * @param {Object=} config The config.\n * @param {Object=} request The request.\n *\n * @returns {CanceledError} The created error.\n */\nfunction CanceledError(message, config, request) {\n  // eslint-disable-next-line no-eq-null,eqeqeq\n  _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(this, message == null ? 'canceled' : message, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ERR_CANCELED, config, request);\n  this.name = 'CanceledError';\n}\n_utils_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].inherits(CanceledError, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"], {\n  __CANCEL__: true\n});\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (CanceledError);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/cancel/CanceledError.js?");

/***/ }),

/***/ "./node_modules/axios/lib/cancel/isCancel.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/cancel/isCancel.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isCancel)\n/* harmony export */ });\n\n\nfunction isCancel(value) {\n  return !!(value && value.__CANCEL__);\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/cancel/isCancel.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/Axios.js":
/*!**********************************************!*\
  !*** ./node_modules/axios/lib/core/Axios.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_buildURL_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/buildURL.js */ \"./node_modules/axios/lib/helpers/buildURL.js\");\n/* harmony import */ var _InterceptorManager_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./InterceptorManager.js */ \"./node_modules/axios/lib/core/InterceptorManager.js\");\n/* harmony import */ var _dispatchRequest_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./dispatchRequest.js */ \"./node_modules/axios/lib/core/dispatchRequest.js\");\n/* harmony import */ var _mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./mergeConfig.js */ \"./node_modules/axios/lib/core/mergeConfig.js\");\n/* harmony import */ var _buildFullPath_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./buildFullPath.js */ \"./node_modules/axios/lib/core/buildFullPath.js\");\n/* harmony import */ var _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/validator.js */ \"./node_modules/axios/lib/helpers/validator.js\");\n/* harmony import */ var _AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n\n\n\n\n\n\n\n\n\n\nconst validators = _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].validators;\n\n/**\n * Create a new instance of Axios\n *\n * @param {Object} instanceConfig The default config for the instance\n *\n * @return {Axios} A new instance of Axios\n */\nclass Axios {\n  constructor(instanceConfig) {\n    this.defaults = instanceConfig;\n    this.interceptors = {\n      request: new _InterceptorManager_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](),\n      response: new _InterceptorManager_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()\n    };\n  }\n\n  /**\n   * Dispatch a request\n   *\n   * @param {String|Object} configOrUrl The config specific for this request (merged with this.defaults)\n   * @param {?Object} config\n   *\n   * @returns {Promise} The Promise to be fulfilled\n   */\n  request(configOrUrl, config) {\n    /*eslint no-param-reassign:0*/\n    // Allow for axios('example/url'[, config]) a la fetch API\n    if (typeof configOrUrl === 'string') {\n      config = config || {};\n      config.url = configOrUrl;\n    } else {\n      config = configOrUrl || {};\n    }\n    config = (0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(this.defaults, config);\n    const {\n      transitional,\n      paramsSerializer\n    } = config;\n    if (transitional !== undefined) {\n      _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].assertOptions(transitional, {\n        silentJSONParsing: validators.transitional(validators.boolean),\n        forcedJSONParsing: validators.transitional(validators.boolean),\n        clarifyTimeoutError: validators.transitional(validators.boolean)\n      }, false);\n    }\n    if (paramsSerializer !== undefined) {\n      _helpers_validator_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"].assertOptions(paramsSerializer, {\n        encode: validators.function,\n        serialize: validators.function\n      }, true);\n    }\n\n    // Set config.method\n    config.method = (config.method || this.defaults.method || 'get').toLowerCase();\n\n    // Flatten headers\n    const defaultHeaders = config.headers && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge(config.headers.common, config.headers[config.method]);\n    defaultHeaders && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['delete', 'get', 'head', 'post', 'put', 'patch', 'common'], function cleanHeaderConfig(method) {\n      delete config.headers[method];\n    });\n    config.headers = new _AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"](config.headers, defaultHeaders);\n\n    // filter out skipped interceptors\n    const requestInterceptorChain = [];\n    let synchronousRequestInterceptors = true;\n    this.interceptors.request.forEach(function unshiftRequestInterceptors(interceptor) {\n      if (typeof interceptor.runWhen === 'function' && interceptor.runWhen(config) === false) {\n        return;\n      }\n      synchronousRequestInterceptors = synchronousRequestInterceptors && interceptor.synchronous;\n      requestInterceptorChain.unshift(interceptor.fulfilled, interceptor.rejected);\n    });\n    const responseInterceptorChain = [];\n    this.interceptors.response.forEach(function pushResponseInterceptors(interceptor) {\n      responseInterceptorChain.push(interceptor.fulfilled, interceptor.rejected);\n    });\n    let promise;\n    let i = 0;\n    let len;\n    if (!synchronousRequestInterceptors) {\n      const chain = [_dispatchRequest_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].bind(this), undefined];\n      chain.unshift.apply(chain, requestInterceptorChain);\n      chain.push.apply(chain, responseInterceptorChain);\n      len = chain.length;\n      promise = Promise.resolve(config);\n      while (i < len) {\n        promise = promise.then(chain[i++], chain[i++]);\n      }\n      return promise;\n    }\n    len = requestInterceptorChain.length;\n    let newConfig = config;\n    i = 0;\n    while (i < len) {\n      const onFulfilled = requestInterceptorChain[i++];\n      const onRejected = requestInterceptorChain[i++];\n      try {\n        newConfig = onFulfilled(newConfig);\n      } catch (error) {\n        onRejected.call(this, error);\n        break;\n      }\n    }\n    try {\n      promise = _dispatchRequest_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"].call(this, newConfig);\n    } catch (error) {\n      return Promise.reject(error);\n    }\n    i = 0;\n    len = responseInterceptorChain.length;\n    while (i < len) {\n      promise = promise.then(responseInterceptorChain[i++], responseInterceptorChain[i++]);\n    }\n    return promise;\n  }\n  getUri(config) {\n    config = (0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(this.defaults, config);\n    const fullPath = (0,_buildFullPath_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(config.baseURL, config.url);\n    return (0,_helpers_buildURL_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(fullPath, config.params, config.paramsSerializer);\n  }\n}\n\n// Provide aliases for supported request methods\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['delete', 'get', 'head', 'options'], function forEachMethodNoData(method) {\n  /*eslint func-names:0*/\n  Axios.prototype[method] = function (url, config) {\n    return this.request((0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(config || {}, {\n      method,\n      url,\n      data: (config || {}).data\n    }));\n  };\n});\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['post', 'put', 'patch'], function forEachMethodWithData(method) {\n  /*eslint func-names:0*/\n\n  function generateHTTPMethod(isForm) {\n    return function httpMethod(url, data, config) {\n      return this.request((0,_mergeConfig_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(config || {}, {\n        method,\n        headers: isForm ? {\n          'Content-Type': 'multipart/form-data'\n        } : {},\n        url,\n        data\n      }));\n    };\n  }\n  Axios.prototype[method] = generateHTTPMethod();\n  Axios.prototype[method + 'Form'] = generateHTTPMethod(true);\n});\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Axios);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/Axios.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/AxiosError.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/core/AxiosError.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * Create an Error with the specified message, config, error code, request and response.\n *\n * @param {string} message The error message.\n * @param {string} [code] The error code (for example, 'ECONNABORTED').\n * @param {Object} [config] The config.\n * @param {Object} [request] The request.\n * @param {Object} [response] The response.\n *\n * @returns {Error} The created error.\n */\nfunction AxiosError(message, code, config, request, response) {\n  Error.call(this);\n  if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, this.constructor);\n  } else {\n    this.stack = new Error().stack;\n  }\n  this.message = message;\n  this.name = 'AxiosError';\n  code && (this.code = code);\n  config && (this.config = config);\n  request && (this.request = request);\n  response && (this.response = response);\n}\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].inherits(AxiosError, Error, {\n  toJSON: function toJSON() {\n    return {\n      // Standard\n      message: this.message,\n      name: this.name,\n      // Microsoft\n      description: this.description,\n      number: this.number,\n      // Mozilla\n      fileName: this.fileName,\n      lineNumber: this.lineNumber,\n      columnNumber: this.columnNumber,\n      stack: this.stack,\n      // Axios\n      config: this.config,\n      code: this.code,\n      status: this.response && this.response.status ? this.response.status : null\n    };\n  }\n});\nconst prototype = AxiosError.prototype;\nconst descriptors = {};\n['ERR_BAD_OPTION_VALUE', 'ERR_BAD_OPTION', 'ECONNABORTED', 'ETIMEDOUT', 'ERR_NETWORK', 'ERR_FR_TOO_MANY_REDIRECTS', 'ERR_DEPRECATED', 'ERR_BAD_RESPONSE', 'ERR_BAD_REQUEST', 'ERR_CANCELED', 'ERR_NOT_SUPPORT', 'ERR_INVALID_URL'\n// eslint-disable-next-line func-names\n].forEach(code => {\n  descriptors[code] = {\n    value: code\n  };\n});\nObject.defineProperties(AxiosError, descriptors);\nObject.defineProperty(prototype, 'isAxiosError', {\n  value: true\n});\n\n// eslint-disable-next-line func-names\nAxiosError.from = (error, code, config, request, response, customProps) => {\n  const axiosError = Object.create(prototype);\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toFlatObject(error, axiosError, function filter(obj) {\n    return obj !== Error.prototype;\n  }, prop => {\n    return prop !== 'isAxiosError';\n  });\n  AxiosError.call(axiosError, error.message, code, config, request, response);\n  axiosError.cause = error;\n  axiosError.name = error.name;\n  customProps && Object.assign(axiosError, customProps);\n  return axiosError;\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AxiosError);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/AxiosError.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/AxiosHeaders.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/core/AxiosHeaders.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_parseHeaders_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/parseHeaders.js */ \"./node_modules/axios/lib/helpers/parseHeaders.js\");\n\n\n\n\nconst $internals = Symbol('internals');\nconst $defaults = Symbol('defaults');\nfunction normalizeHeader(header) {\n  return header && String(header).trim().toLowerCase();\n}\nfunction normalizeValue(value) {\n  if (value === false || value == null) {\n    return value;\n  }\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(value) ? value.map(normalizeValue) : String(value);\n}\nfunction parseTokens(str) {\n  const tokens = Object.create(null);\n  const tokensRE = /([^\\s,;=]+)\\s*(?:=\\s*([^,;]+))?/g;\n  let match;\n  while (match = tokensRE.exec(str)) {\n    tokens[match[1]] = match[2];\n  }\n  return tokens;\n}\nfunction matchHeaderValue(context, value, header, filter) {\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(filter)) {\n    return filter.call(this, value, header);\n  }\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(value)) return;\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(filter)) {\n    return value.indexOf(filter) !== -1;\n  }\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isRegExp(filter)) {\n    return filter.test(value);\n  }\n}\nfunction formatHeader(header) {\n  return header.trim().toLowerCase().replace(/([a-z\\d])(\\w*)/g, (w, char, str) => {\n    return char.toUpperCase() + str;\n  });\n}\nfunction buildAccessors(obj, header) {\n  const accessorName = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toCamelCase(' ' + header);\n  ['get', 'set', 'has'].forEach(methodName => {\n    Object.defineProperty(obj, methodName + accessorName, {\n      value: function (arg1, arg2, arg3) {\n        return this[methodName].call(this, header, arg1, arg2, arg3);\n      },\n      configurable: true\n    });\n  });\n}\nfunction findKey(obj, key) {\n  key = key.toLowerCase();\n  const keys = Object.keys(obj);\n  let i = keys.length;\n  let _key;\n  while (i-- > 0) {\n    _key = keys[i];\n    if (key === _key.toLowerCase()) {\n      return _key;\n    }\n  }\n  return null;\n}\nfunction AxiosHeaders(headers, defaults) {\n  headers && this.set(headers);\n  this[$defaults] = defaults || null;\n}\nObject.assign(AxiosHeaders.prototype, {\n  set: function (header, valueOrRewrite, rewrite) {\n    const self = this;\n    function setHeader(_value, _header, _rewrite) {\n      const lHeader = normalizeHeader(_header);\n      if (!lHeader) {\n        throw new Error('header name must be a non-empty string');\n      }\n      const key = findKey(self, lHeader);\n      if (key && _rewrite !== true && (self[key] === false || _rewrite === false)) {\n        return;\n      }\n      self[key || _header] = normalizeValue(_value);\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(header)) {\n      _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(header, (_value, _header) => {\n        setHeader(_value, _header, valueOrRewrite);\n      });\n    } else {\n      setHeader(valueOrRewrite, header, rewrite);\n    }\n    return this;\n  },\n  get: function (header, parser) {\n    header = normalizeHeader(header);\n    if (!header) return undefined;\n    const key = findKey(this, header);\n    if (key) {\n      const value = this[key];\n      if (!parser) {\n        return value;\n      }\n      if (parser === true) {\n        return parseTokens(value);\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(parser)) {\n        return parser.call(this, value, key);\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isRegExp(parser)) {\n        return parser.exec(value);\n      }\n      throw new TypeError('parser must be boolean|regexp|function');\n    }\n  },\n  has: function (header, matcher) {\n    header = normalizeHeader(header);\n    if (header) {\n      const key = findKey(this, header);\n      return !!(key && (!matcher || matchHeaderValue(this, this[key], key, matcher)));\n    }\n    return false;\n  },\n  delete: function (header, matcher) {\n    const self = this;\n    let deleted = false;\n    function deleteHeader(_header) {\n      _header = normalizeHeader(_header);\n      if (_header) {\n        const key = findKey(self, _header);\n        if (key && (!matcher || matchHeaderValue(self, self[key], key, matcher))) {\n          delete self[key];\n          deleted = true;\n        }\n      }\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(header)) {\n      header.forEach(deleteHeader);\n    } else {\n      deleteHeader(header);\n    }\n    return deleted;\n  },\n  clear: function () {\n    return Object.keys(this).forEach(this.delete.bind(this));\n  },\n  normalize: function (format) {\n    const self = this;\n    const headers = {};\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(this, (value, header) => {\n      const key = findKey(headers, header);\n      if (key) {\n        self[key] = normalizeValue(value);\n        delete self[header];\n        return;\n      }\n      const normalized = format ? formatHeader(header) : String(header).trim();\n      if (normalized !== header) {\n        delete self[header];\n      }\n      self[normalized] = normalizeValue(value);\n      headers[normalized] = true;\n    });\n    return this;\n  },\n  toJSON: function (asStrings) {\n    const obj = Object.create(null);\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(Object.assign({}, this[$defaults] || null, this), (value, header) => {\n      if (value == null || value === false) return;\n      obj[header] = asStrings && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(value) ? value.join(', ') : value;\n    });\n    return obj;\n  }\n});\nObject.assign(AxiosHeaders, {\n  from: function (thing) {\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(thing)) {\n      return new this((0,_helpers_parseHeaders_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(thing));\n    }\n    return thing instanceof this ? thing : new this(thing);\n  },\n  accessor: function (header) {\n    const internals = this[$internals] = this[$internals] = {\n      accessors: {}\n    };\n    const accessors = internals.accessors;\n    const prototype = this.prototype;\n    function defineAccessor(_header) {\n      const lHeader = normalizeHeader(_header);\n      if (!accessors[lHeader]) {\n        buildAccessors(prototype, _header);\n        accessors[lHeader] = true;\n      }\n    }\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(header) ? header.forEach(defineAccessor) : defineAccessor(header);\n    return this;\n  }\n});\nAxiosHeaders.accessor(['Content-Type', 'Content-Length', 'Accept', 'Accept-Encoding', 'User-Agent']);\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].freezeMethods(AxiosHeaders.prototype);\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].freezeMethods(AxiosHeaders);\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AxiosHeaders);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/AxiosHeaders.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/InterceptorManager.js":
/*!***********************************************************!*\
  !*** ./node_modules/axios/lib/core/InterceptorManager.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\nclass InterceptorManager {\n  constructor() {\n    this.handlers = [];\n  }\n\n  /**\n   * Add a new interceptor to the stack\n   *\n   * @param {Function} fulfilled The function to handle `then` for a `Promise`\n   * @param {Function} rejected The function to handle `reject` for a `Promise`\n   *\n   * @return {Number} An ID used to remove interceptor later\n   */\n  use(fulfilled, rejected, options) {\n    this.handlers.push({\n      fulfilled,\n      rejected,\n      synchronous: options ? options.synchronous : false,\n      runWhen: options ? options.runWhen : null\n    });\n    return this.handlers.length - 1;\n  }\n\n  /**\n   * Remove an interceptor from the stack\n   *\n   * @param {Number} id The ID that was returned by `use`\n   *\n   * @returns {Boolean} `true` if the interceptor was removed, `false` otherwise\n   */\n  eject(id) {\n    if (this.handlers[id]) {\n      this.handlers[id] = null;\n    }\n  }\n\n  /**\n   * Clear all interceptors from the stack\n   *\n   * @returns {void}\n   */\n  clear() {\n    if (this.handlers) {\n      this.handlers = [];\n    }\n  }\n\n  /**\n   * Iterate over all the registered interceptors\n   *\n   * This method is particularly useful for skipping over any\n   * interceptors that may have become `null` calling `eject`.\n   *\n   * @param {Function} fn The function to call for each interceptor\n   *\n   * @returns {void}\n   */\n  forEach(fn) {\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(this.handlers, function forEachHandler(h) {\n      if (h !== null) {\n        fn(h);\n      }\n    });\n  }\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (InterceptorManager);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/InterceptorManager.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/buildFullPath.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/core/buildFullPath.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ buildFullPath)\n/* harmony export */ });\n/* harmony import */ var _helpers_isAbsoluteURL_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/isAbsoluteURL.js */ \"./node_modules/axios/lib/helpers/isAbsoluteURL.js\");\n/* harmony import */ var _helpers_combineURLs_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/combineURLs.js */ \"./node_modules/axios/lib/helpers/combineURLs.js\");\n\n\n\n\n\n/**\n * Creates a new URL by combining the baseURL with the requestedURL,\n * only when the requestedURL is not already an absolute URL.\n * If the requestURL is absolute, this function returns the requestedURL untouched.\n *\n * @param {string} baseURL The base URL\n * @param {string} requestedURL Absolute or relative URL to combine\n *\n * @returns {string} The combined full path\n */\nfunction buildFullPath(baseURL, requestedURL) {\n  if (baseURL && !(0,_helpers_isAbsoluteURL_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(requestedURL)) {\n    return (0,_helpers_combineURLs_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(baseURL, requestedURL);\n  }\n  return requestedURL;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/buildFullPath.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/dispatchRequest.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/core/dispatchRequest.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ dispatchRequest)\n/* harmony export */ });\n/* harmony import */ var _transformData_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./transformData.js */ \"./node_modules/axios/lib/core/transformData.js\");\n/* harmony import */ var _cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../cancel/isCancel.js */ \"./node_modules/axios/lib/cancel/isCancel.js\");\n/* harmony import */ var _defaults_index_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../defaults/index.js */ \"./node_modules/axios/lib/defaults/index.js\");\n/* harmony import */ var _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../cancel/CanceledError.js */ \"./node_modules/axios/lib/cancel/CanceledError.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n\n\n\n\n\n\n\n\n/**\n * Throws a `CanceledError` if cancellation has been requested.\n *\n * @param {Object} config The config that is to be used for the request\n *\n * @returns {void}\n */\nfunction throwIfCancellationRequested(config) {\n  if (config.cancelToken) {\n    config.cancelToken.throwIfRequested();\n  }\n  if (config.signal && config.signal.aborted) {\n    throw new _cancel_CanceledError_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]();\n  }\n}\n\n/**\n * Dispatch a request to the server using the configured adapter.\n *\n * @param {object} config The config that is to be used for the request\n *\n * @returns {Promise} The Promise to be fulfilled\n */\nfunction dispatchRequest(config) {\n  throwIfCancellationRequested(config);\n  config.headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"].from(config.headers);\n\n  // Transform request data\n  config.data = _transformData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(config, config.transformRequest);\n  const adapter = config.adapter || _defaults_index_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].adapter;\n  return adapter(config).then(function onAdapterResolution(response) {\n    throwIfCancellationRequested(config);\n\n    // Transform response data\n    response.data = _transformData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(config, config.transformResponse, response);\n    response.headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"].from(response.headers);\n    return response;\n  }, function onAdapterRejection(reason) {\n    if (!(0,_cancel_isCancel_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(reason)) {\n      throwIfCancellationRequested(config);\n\n      // Transform response data\n      if (reason && reason.response) {\n        reason.response.data = _transformData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].call(config, config.transformResponse, reason.response);\n        reason.response.headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"].from(reason.response.headers);\n      }\n    }\n    return Promise.reject(reason);\n  });\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/dispatchRequest.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/mergeConfig.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/core/mergeConfig.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ mergeConfig)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * Config-specific merge-function which creates a new config-object\n * by merging two configuration objects together.\n *\n * @param {Object} config1\n * @param {Object} config2\n *\n * @returns {Object} New object resulting from merging config2 to config1\n */\nfunction mergeConfig(config1, config2) {\n  // eslint-disable-next-line no-param-reassign\n  config2 = config2 || {};\n  const config = {};\n  function getMergedValue(target, source) {\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(target) && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(source)) {\n      return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge(target, source);\n    } else if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(source)) {\n      return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge({}, source);\n    } else if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(source)) {\n      return source.slice();\n    }\n    return source;\n  }\n\n  // eslint-disable-next-line consistent-return\n  function mergeDeepProperties(prop) {\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(config2[prop])) {\n      return getMergedValue(config1[prop], config2[prop]);\n    } else if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(config1[prop])) {\n      return getMergedValue(undefined, config1[prop]);\n    }\n  }\n\n  // eslint-disable-next-line consistent-return\n  function valueFromConfig2(prop) {\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(config2[prop])) {\n      return getMergedValue(undefined, config2[prop]);\n    }\n  }\n\n  // eslint-disable-next-line consistent-return\n  function defaultToConfig2(prop) {\n    if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(config2[prop])) {\n      return getMergedValue(undefined, config2[prop]);\n    } else if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(config1[prop])) {\n      return getMergedValue(undefined, config1[prop]);\n    }\n  }\n\n  // eslint-disable-next-line consistent-return\n  function mergeDirectKeys(prop) {\n    if (prop in config2) {\n      return getMergedValue(config1[prop], config2[prop]);\n    } else if (prop in config1) {\n      return getMergedValue(undefined, config1[prop]);\n    }\n  }\n  const mergeMap = {\n    'url': valueFromConfig2,\n    'method': valueFromConfig2,\n    'data': valueFromConfig2,\n    'baseURL': defaultToConfig2,\n    'transformRequest': defaultToConfig2,\n    'transformResponse': defaultToConfig2,\n    'paramsSerializer': defaultToConfig2,\n    'timeout': defaultToConfig2,\n    'timeoutMessage': defaultToConfig2,\n    'withCredentials': defaultToConfig2,\n    'adapter': defaultToConfig2,\n    'responseType': defaultToConfig2,\n    'xsrfCookieName': defaultToConfig2,\n    'xsrfHeaderName': defaultToConfig2,\n    'onUploadProgress': defaultToConfig2,\n    'onDownloadProgress': defaultToConfig2,\n    'decompress': defaultToConfig2,\n    'maxContentLength': defaultToConfig2,\n    'maxBodyLength': defaultToConfig2,\n    'beforeRedirect': defaultToConfig2,\n    'transport': defaultToConfig2,\n    'httpAgent': defaultToConfig2,\n    'httpsAgent': defaultToConfig2,\n    'cancelToken': defaultToConfig2,\n    'socketPath': defaultToConfig2,\n    'responseEncoding': defaultToConfig2,\n    'validateStatus': mergeDirectKeys\n  };\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(Object.keys(config1).concat(Object.keys(config2)), function computeConfigValue(prop) {\n    const merge = mergeMap[prop] || mergeDeepProperties;\n    const configValue = merge(prop);\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(configValue) && merge !== mergeDirectKeys || (config[prop] = configValue);\n  });\n  return config;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/mergeConfig.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/settle.js":
/*!***********************************************!*\
  !*** ./node_modules/axios/lib/core/settle.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ settle)\n/* harmony export */ });\n/* harmony import */ var _AxiosError_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n\n\n\n\n/**\n * Resolve or reject a Promise based on response status.\n *\n * @param {Function} resolve A function that resolves the promise.\n * @param {Function} reject A function that rejects the promise.\n * @param {object} response The response.\n *\n * @returns {object} The response.\n */\nfunction settle(resolve, reject, response) {\n  const validateStatus = response.config.validateStatus;\n  if (!response.status || !validateStatus || validateStatus(response.status)) {\n    resolve(response);\n  } else {\n    reject(new _AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]('Request failed with status code ' + response.status, [_AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ERR_BAD_REQUEST, _AxiosError_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].ERR_BAD_RESPONSE][Math.floor(response.status / 100) - 4], response.config, response.request, response));\n  }\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/settle.js?");

/***/ }),

/***/ "./node_modules/axios/lib/core/transformData.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/core/transformData.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ transformData)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _defaults_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../defaults/index.js */ \"./node_modules/axios/lib/defaults/index.js\");\n/* harmony import */ var _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/AxiosHeaders.js */ \"./node_modules/axios/lib/core/AxiosHeaders.js\");\n\n\n\n\n\n\n/**\n * Transform the data for a request or a response\n *\n * @param {Array|Function} fns A single function or Array of functions\n * @param {?Object} response The response object\n *\n * @returns {*} The resulting transformed data\n */\nfunction transformData(fns, response) {\n  const config = this || _defaults_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"];\n  const context = response || config;\n  const headers = _core_AxiosHeaders_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].from(context.headers);\n  let data = context.data;\n  _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(fns, function transform(fn) {\n    data = fn.call(config, data, headers.normalize(), response ? response.status : undefined);\n  });\n  headers.normalize();\n  return data;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/core/transformData.js?");

/***/ }),

/***/ "./node_modules/axios/lib/defaults/index.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/defaults/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _transitional_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./transitional.js */ \"./node_modules/axios/lib/defaults/transitional.js\");\n/* harmony import */ var _helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n/* harmony import */ var _helpers_toURLEncodedForm_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/toURLEncodedForm.js */ \"./node_modules/axios/lib/helpers/toURLEncodedForm.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n/* harmony import */ var _helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/formDataToJSON.js */ \"./node_modules/axios/lib/helpers/formDataToJSON.js\");\n/* harmony import */ var _adapters_index_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../adapters/index.js */ \"./node_modules/axios/lib/adapters/index.js\");\n\n\n\n\n\n\n\n\n\n\nconst DEFAULT_CONTENT_TYPE = {\n  'Content-Type': 'application/x-www-form-urlencoded'\n};\n\n/**\n * If the browser has an XMLHttpRequest object, use the XHR adapter, otherwise use the HTTP\n * adapter\n *\n * @returns {Function}\n */\nfunction getDefaultAdapter() {\n  let adapter;\n  if (typeof XMLHttpRequest !== 'undefined') {\n    // For browsers use XHR adapter\n    adapter = _adapters_index_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].getAdapter('xhr');\n  } else if (typeof process !== 'undefined' && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].kindOf(process) === 'process') {\n    // For node use HTTP adapter\n    adapter = _adapters_index_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"].getAdapter('http');\n  }\n  return adapter;\n}\n\n/**\n * It takes a string, tries to parse it, and if it fails, it returns the stringified version\n * of the input\n *\n * @param {any} rawValue - The value to be stringified.\n * @param {Function} parser - A function that parses a string into a JavaScript object.\n * @param {Function} encoder - A function that takes a value and returns a string.\n *\n * @returns {string} A stringified version of the rawValue.\n */\nfunction stringifySafely(rawValue, parser, encoder) {\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(rawValue)) {\n    try {\n      (parser || JSON.parse)(rawValue);\n      return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].trim(rawValue);\n    } catch (e) {\n      if (e.name !== 'SyntaxError') {\n        throw e;\n      }\n    }\n  }\n  return (encoder || JSON.stringify)(rawValue);\n}\nconst defaults = {\n  transitional: _transitional_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n  adapter: getDefaultAdapter(),\n  transformRequest: [function transformRequest(data, headers) {\n    const contentType = headers.getContentType() || '';\n    const hasJSONContentType = contentType.indexOf('application/json') > -1;\n    const isObjectPayload = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(data);\n    if (isObjectPayload && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isHTMLForm(data)) {\n      data = new FormData(data);\n    }\n    const isFormData = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFormData(data);\n    if (isFormData) {\n      if (!hasJSONContentType) {\n        return data;\n      }\n      return hasJSONContentType ? JSON.stringify((0,_helpers_formDataToJSON_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(data)) : data;\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArrayBuffer(data) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBuffer(data) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isStream(data) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFile(data) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBlob(data)) {\n      return data;\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArrayBufferView(data)) {\n      return data.buffer;\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isURLSearchParams(data)) {\n      headers.setContentType('application/x-www-form-urlencoded;charset=utf-8', false);\n      return data.toString();\n    }\n    let isFileList;\n    if (isObjectPayload) {\n      if (contentType.indexOf('application/x-www-form-urlencoded') > -1) {\n        return (0,_helpers_toURLEncodedForm_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(data, this.formSerializer).toString();\n      }\n      if ((isFileList = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFileList(data)) || contentType.indexOf('multipart/form-data') > -1) {\n        const _FormData = this.env && this.env.FormData;\n        return (0,_helpers_toFormData_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(isFileList ? {\n          'files[]': data\n        } : data, _FormData && new _FormData(), this.formSerializer);\n      }\n    }\n    if (isObjectPayload || hasJSONContentType) {\n      headers.setContentType('application/json', false);\n      return stringifySafely(data);\n    }\n    return data;\n  }],\n  transformResponse: [function transformResponse(data) {\n    const transitional = this.transitional || defaults.transitional;\n    const forcedJSONParsing = transitional && transitional.forcedJSONParsing;\n    const JSONRequested = this.responseType === 'json';\n    if (data && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(data) && (forcedJSONParsing && !this.responseType || JSONRequested)) {\n      const silentJSONParsing = transitional && transitional.silentJSONParsing;\n      const strictJSONParsing = !silentJSONParsing && JSONRequested;\n      try {\n        return JSON.parse(data);\n      } catch (e) {\n        if (strictJSONParsing) {\n          if (e.name === 'SyntaxError') {\n            throw _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].from(e, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_RESPONSE, this, null, this.response);\n          }\n          throw e;\n        }\n      }\n    }\n    return data;\n  }],\n  /**\n   * A timeout in milliseconds to abort a request. If set to 0 (default) a\n   * timeout is not created.\n   */\n  timeout: 0,\n  xsrfCookieName: 'XSRF-TOKEN',\n  xsrfHeaderName: 'X-XSRF-TOKEN',\n  maxContentLength: -1,\n  maxBodyLength: -1,\n  env: {\n    FormData: _platform_index_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"].classes.FormData,\n    Blob: _platform_index_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"].classes.Blob\n  },\n  validateStatus: function validateStatus(status) {\n    return status >= 200 && status < 300;\n  },\n  headers: {\n    common: {\n      'Accept': 'application/json, text/plain, */*'\n    }\n  }\n};\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['delete', 'get', 'head'], function forEachMethodNoData(method) {\n  defaults.headers[method] = {};\n});\n_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(['post', 'put', 'patch'], function forEachMethodWithData(method) {\n  defaults.headers[method] = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].merge(DEFAULT_CONTENT_TYPE);\n});\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (defaults);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/defaults/index.js?");

/***/ }),

/***/ "./node_modules/axios/lib/defaults/transitional.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/defaults/transitional.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  silentJSONParsing: true,\n  forcedJSONParsing: true,\n  clarifyTimeoutError: false\n});\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/defaults/transitional.js?");

/***/ }),

/***/ "./node_modules/axios/lib/env/classes/FormData.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/env/classes/FormData.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var form_data__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! form-data */ \"./node_modules/form-data/lib/browser.js\");\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (form_data__WEBPACK_IMPORTED_MODULE_0__);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/env/classes/FormData.js?");

/***/ }),

/***/ "./node_modules/axios/lib/env/data.js":
/*!********************************************!*\
  !*** ./node_modules/axios/lib/env/data.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"VERSION\": () => (/* binding */ VERSION)\n/* harmony export */ });\nconst VERSION = \"1.1.3\";\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/env/data.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/AxiosURLSearchParams.js":
/*!****************************************************************!*\
  !*** ./node_modules/axios/lib/helpers/AxiosURLSearchParams.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _toFormData_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n\n\n\n\n/**\n * It encodes a string by replacing all characters that are not in the unreserved set with\n * their percent-encoded equivalents\n *\n * @param {string} str - The string to encode.\n *\n * @returns {string} The encoded string.\n */\nfunction encode(str) {\n  const charMap = {\n    '!': '%21',\n    \"'\": '%27',\n    '(': '%28',\n    ')': '%29',\n    '~': '%7E',\n    '%20': '+',\n    '%00': '\\x00'\n  };\n  return encodeURIComponent(str).replace(/[!'()~]|%20|%00/g, function replacer(match) {\n    return charMap[match];\n  });\n}\n\n/**\n * It takes a params object and converts it to a FormData object\n *\n * @param {Object<string, any>} params - The parameters to be converted to a FormData object.\n * @param {Object<string, any>} options - The options object passed to the Axios constructor.\n *\n * @returns {void}\n */\nfunction AxiosURLSearchParams(params, options) {\n  this._pairs = [];\n  params && (0,_toFormData_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(params, this, options);\n}\nconst prototype = AxiosURLSearchParams.prototype;\nprototype.append = function append(name, value) {\n  this._pairs.push([name, value]);\n};\nprototype.toString = function toString(encoder) {\n  const _encode = encoder ? function (value) {\n    return encoder.call(this, value, encode);\n  } : encode;\n  return this._pairs.map(function each(pair) {\n    return _encode(pair[0]) + '=' + _encode(pair[1]);\n  }, '').join('&');\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AxiosURLSearchParams);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/AxiosURLSearchParams.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/bind.js":
/*!************************************************!*\
  !*** ./node_modules/axios/lib/helpers/bind.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ bind)\n/* harmony export */ });\n\n\nfunction bind(fn, thisArg) {\n  return function wrap() {\n    return fn.apply(thisArg, arguments);\n  };\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/bind.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/buildURL.js":
/*!****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/buildURL.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ buildURL)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/AxiosURLSearchParams.js */ \"./node_modules/axios/lib/helpers/AxiosURLSearchParams.js\");\n\n\n\n\n\n/**\n * It replaces all instances of the characters `:`, `$`, `,`, `+`, `[`, and `]` with their\n * URI encoded counterparts\n *\n * @param {string} val The value to be encoded.\n *\n * @returns {string} The encoded value.\n */\nfunction encode(val) {\n  return encodeURIComponent(val).replace(/%3A/gi, ':').replace(/%24/g, '$').replace(/%2C/gi, ',').replace(/%20/g, '+').replace(/%5B/gi, '[').replace(/%5D/gi, ']');\n}\n\n/**\n * Build a URL by appending params to the end\n *\n * @param {string} url The base of the url (e.g., http://www.google.com)\n * @param {object} [params] The params to be appended\n * @param {?object} options\n *\n * @returns {string} The formatted url\n */\nfunction buildURL(url, params, options) {\n  /*eslint no-param-reassign:0*/\n  if (!params) {\n    return url;\n  }\n  const _encode = options && options.encode || encode;\n  const serializeFn = options && options.serialize;\n  let serializedParams;\n  if (serializeFn) {\n    serializedParams = serializeFn(params, options);\n  } else {\n    serializedParams = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isURLSearchParams(params) ? params.toString() : new _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](params, options).toString(_encode);\n  }\n  if (serializedParams) {\n    const hashmarkIndex = url.indexOf(\"#\");\n    if (hashmarkIndex !== -1) {\n      url = url.slice(0, hashmarkIndex);\n    }\n    url += (url.indexOf('?') === -1 ? '?' : '&') + serializedParams;\n  }\n  return url;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/buildURL.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/combineURLs.js":
/*!*******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/combineURLs.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ combineURLs)\n/* harmony export */ });\n\n\n/**\n * Creates a new URL by combining the specified URLs\n *\n * @param {string} baseURL The base URL\n * @param {string} relativeURL The relative URL\n *\n * @returns {string} The combined URL\n */\nfunction combineURLs(baseURL, relativeURL) {\n  return relativeURL ? baseURL.replace(/\\/+$/, '') + '/' + relativeURL.replace(/^\\/+/, '') : baseURL;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/combineURLs.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/cookies.js":
/*!***************************************************!*\
  !*** ./node_modules/axios/lib/helpers/cookies.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_platform_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isStandardBrowserEnv ?\n// Standard browser envs support document.cookie\nfunction standardBrowserEnv() {\n  return {\n    write: function write(name, value, expires, path, domain, secure) {\n      const cookie = [];\n      cookie.push(name + '=' + encodeURIComponent(value));\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isNumber(expires)) {\n        cookie.push('expires=' + new Date(expires).toGMTString());\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(path)) {\n        cookie.push('path=' + path);\n      }\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(domain)) {\n        cookie.push('domain=' + domain);\n      }\n      if (secure === true) {\n        cookie.push('secure');\n      }\n      document.cookie = cookie.join('; ');\n    },\n    read: function read(name) {\n      const match = document.cookie.match(new RegExp('(^|;\\\\s*)(' + name + ')=([^;]*)'));\n      return match ? decodeURIComponent(match[3]) : null;\n    },\n    remove: function remove(name) {\n      this.write(name, '', Date.now() - 86400000);\n    }\n  };\n}() :\n// Non standard browser env (web workers, react-native) lack needed support.\nfunction nonStandardBrowserEnv() {\n  return {\n    write: function write() {},\n    read: function read() {\n      return null;\n    },\n    remove: function remove() {}\n  };\n}());\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/cookies.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/formDataToJSON.js":
/*!**********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/formDataToJSON.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * It takes a string like `foo[x][y][z]` and returns an array like `['foo', 'x', 'y', 'z']\n *\n * @param {string} name - The name of the property to get.\n *\n * @returns An array of strings.\n */\nfunction parsePropPath(name) {\n  // foo[x][y][z]\n  // foo.x.y.z\n  // foo-x-y-z\n  // foo x y z\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].matchAll(/\\w+|\\[(\\w*)]/g, name).map(match => {\n    return match[0] === '[]' ? '' : match[1] || match[0];\n  });\n}\n\n/**\n * Convert an array to an object.\n *\n * @param {Array<any>} arr - The array to convert to an object.\n *\n * @returns An object with the same keys and values as the array.\n */\nfunction arrayToObject(arr) {\n  const obj = {};\n  const keys = Object.keys(arr);\n  let i;\n  const len = keys.length;\n  let key;\n  for (i = 0; i < len; i++) {\n    key = keys[i];\n    obj[key] = arr[key];\n  }\n  return obj;\n}\n\n/**\n * It takes a FormData object and returns a JavaScript object\n *\n * @param {string} formData The FormData object to convert to JSON.\n *\n * @returns {Object<string, any> | null} The converted object.\n */\nfunction formDataToJSON(formData) {\n  function buildPath(path, value, target, index) {\n    let name = path[index++];\n    const isNumericKey = Number.isFinite(+name);\n    const isLast = index >= path.length;\n    name = !name && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(target) ? target.length : name;\n    if (isLast) {\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].hasOwnProp(target, name)) {\n        target[name] = [target[name], value];\n      } else {\n        target[name] = value;\n      }\n      return !isNumericKey;\n    }\n    if (!target[name] || !_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(target[name])) {\n      target[name] = [];\n    }\n    const result = buildPath(path, value, target[name], index);\n    if (result && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(target[name])) {\n      target[name] = arrayToObject(target[name]);\n    }\n    return !isNumericKey;\n  }\n  if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFormData(formData) && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(formData.entries)) {\n    const obj = {};\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEachEntry(formData, (name, value) => {\n      buildPath(parsePropPath(name), value, obj, 0);\n    });\n    return obj;\n  }\n  return null;\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (formDataToJSON);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/formDataToJSON.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isAbsoluteURL.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isAbsoluteURL.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isAbsoluteURL)\n/* harmony export */ });\n\n\n/**\n * Determines whether the specified URL is absolute\n *\n * @param {string} url The URL to test\n *\n * @returns {boolean} True if the specified URL is absolute, otherwise false\n */\nfunction isAbsoluteURL(url) {\n  // A URL is considered absolute if it begins with \"<scheme>://\" or \"//\" (protocol-relative URL).\n  // RFC 3986 defines scheme name as a sequence of characters beginning with a letter and followed\n  // by any combination of letters, digits, plus, period, or hyphen.\n  return /^([a-z][a-z\\d+\\-.]*:)?\\/\\//i.test(url);\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/isAbsoluteURL.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isAxiosError.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isAxiosError.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ isAxiosError)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n/**\n * Determines whether the payload is an error thrown by Axios\n *\n * @param {*} payload The value to test\n *\n * @returns {boolean} True if the payload is an error thrown by Axios, otherwise false\n */\nfunction isAxiosError(payload) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(payload) && payload.isAxiosError === true;\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/isAxiosError.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/isURLSameOrigin.js":
/*!***********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/isURLSameOrigin.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_platform_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].isStandardBrowserEnv ?\n// Standard browser envs have full support of the APIs needed to test\n// whether the request URL is of the same origin as current location.\nfunction standardBrowserEnv() {\n  const msie = /(msie|trident)/i.test(navigator.userAgent);\n  const urlParsingNode = document.createElement('a');\n  let originURL;\n\n  /**\n  * Parse a URL to discover it's components\n  *\n  * @param {String} url The URL to be parsed\n  * @returns {Object}\n  */\n  function resolveURL(url) {\n    let href = url;\n    if (msie) {\n      // IE needs attribute set twice to normalize properties\n      urlParsingNode.setAttribute('href', href);\n      href = urlParsingNode.href;\n    }\n    urlParsingNode.setAttribute('href', href);\n\n    // urlParsingNode provides the UrlUtils interface - http://url.spec.whatwg.org/#urlutils\n    return {\n      href: urlParsingNode.href,\n      protocol: urlParsingNode.protocol ? urlParsingNode.protocol.replace(/:$/, '') : '',\n      host: urlParsingNode.host,\n      search: urlParsingNode.search ? urlParsingNode.search.replace(/^\\?/, '') : '',\n      hash: urlParsingNode.hash ? urlParsingNode.hash.replace(/^#/, '') : '',\n      hostname: urlParsingNode.hostname,\n      port: urlParsingNode.port,\n      pathname: urlParsingNode.pathname.charAt(0) === '/' ? urlParsingNode.pathname : '/' + urlParsingNode.pathname\n    };\n  }\n  originURL = resolveURL(window.location.href);\n\n  /**\n  * Determine if a URL shares the same origin as the current location\n  *\n  * @param {String} requestURL The URL to test\n  * @returns {boolean} True if URL shares the same origin, otherwise false\n  */\n  return function isURLSameOrigin(requestURL) {\n    const parsed = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(requestURL) ? resolveURL(requestURL) : requestURL;\n    return parsed.protocol === originURL.protocol && parsed.host === originURL.host;\n  };\n}() :\n// Non standard browser envs (web workers, react-native) lack needed support.\nfunction nonStandardBrowserEnv() {\n  return function isURLSameOrigin() {\n    return true;\n  };\n}());\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/isURLSameOrigin.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/parseHeaders.js":
/*!********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/parseHeaders.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./../utils.js */ \"./node_modules/axios/lib/utils.js\");\n\n\n\n\n// RawAxiosHeaders whose duplicates are ignored by node\n// c.f. https://nodejs.org/api/http.html#http_message_headers\nconst ignoreDuplicateOf = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toObjectSet(['age', 'authorization', 'content-length', 'content-type', 'etag', 'expires', 'from', 'host', 'if-modified-since', 'if-unmodified-since', 'last-modified', 'location', 'max-forwards', 'proxy-authorization', 'referer', 'retry-after', 'user-agent']);\n\n/**\n * Parse headers into an object\n *\n * ```\n * Date: Wed, 27 Aug 2014 08:58:49 GMT\n * Content-Type: application/json\n * Connection: keep-alive\n * Transfer-Encoding: chunked\n * ```\n *\n * @param {String} rawHeaders Headers needing to be parsed\n *\n * @returns {Object} Headers parsed into an object\n */\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (rawHeaders => {\n  const parsed = {};\n  let key;\n  let val;\n  let i;\n  rawHeaders && rawHeaders.split('\\n').forEach(function parser(line) {\n    i = line.indexOf(':');\n    key = line.substring(0, i).trim().toLowerCase();\n    val = line.substring(i + 1).trim();\n    if (!key || parsed[key] && ignoreDuplicateOf[key]) {\n      return;\n    }\n    if (key === 'set-cookie') {\n      if (parsed[key]) {\n        parsed[key].push(val);\n      } else {\n        parsed[key] = [val];\n      }\n    } else {\n      parsed[key] = parsed[key] ? parsed[key] + ', ' + val : val;\n    }\n  });\n  return parsed;\n});\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/parseHeaders.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/parseProtocol.js":
/*!*********************************************************!*\
  !*** ./node_modules/axios/lib/helpers/parseProtocol.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ parseProtocol)\n/* harmony export */ });\n\n\nfunction parseProtocol(url) {\n  const match = /^([-+\\w]{1,25})(:?\\/\\/|:)/.exec(url);\n  return match && match[1] || '';\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/parseProtocol.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/speedometer.js":
/*!*******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/speedometer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/**\n * Calculate data maxRate\n * @param {Number} [samplesCount= 10]\n * @param {Number} [min= 1000]\n * @returns {Function}\n */\nfunction speedometer(samplesCount, min) {\n  samplesCount = samplesCount || 10;\n  const bytes = new Array(samplesCount);\n  const timestamps = new Array(samplesCount);\n  let head = 0;\n  let tail = 0;\n  let firstSampleTS;\n  min = min !== undefined ? min : 1000;\n  return function push(chunkLength) {\n    const now = Date.now();\n    const startedAt = timestamps[tail];\n    if (!firstSampleTS) {\n      firstSampleTS = now;\n    }\n    bytes[head] = chunkLength;\n    timestamps[head] = now;\n    let i = tail;\n    let bytesCount = 0;\n    while (i !== head) {\n      bytesCount += bytes[i++];\n      i = i % samplesCount;\n    }\n    head = (head + 1) % samplesCount;\n    if (head === tail) {\n      tail = (tail + 1) % samplesCount;\n    }\n    if (now - firstSampleTS < min) {\n      return;\n    }\n    const passed = startedAt && now - startedAt;\n    return passed ? Math.round(bytesCount * 1000 / passed) : undefined;\n  };\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (speedometer);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/speedometer.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/spread.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/helpers/spread.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ spread)\n/* harmony export */ });\n\n\n/**\n * Syntactic sugar for invoking a function and expanding an array for arguments.\n *\n * Common use case would be to use `Function.prototype.apply`.\n *\n *  ```js\n *  function f(x, y, z) {}\n *  var args = [1, 2, 3];\n *  f.apply(null, args);\n *  ```\n *\n * With `spread` this example can be re-written.\n *\n *  ```js\n *  spread(function(x, y, z) {})([1, 2, 3]);\n *  ```\n *\n * @param {Function} callback\n *\n * @returns {Function}\n */\nfunction spread(callback) {\n  return function wrap(arr) {\n    return callback.apply(null, arr);\n  };\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/spread.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/toFormData.js":
/*!******************************************************!*\
  !*** ./node_modules/axios/lib/helpers/toFormData.js ***!
  \******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n/* harmony import */ var _env_classes_FormData_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../env/classes/FormData.js */ \"./node_modules/axios/lib/env/classes/FormData.js\");\n\n\n\n\n\n\n/**\n * Determines if the given thing is a array or js object.\n *\n * @param {string} thing - The object or array to be visited.\n *\n * @returns {boolean}\n */\nfunction isVisitable(thing) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isPlainObject(thing) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(thing);\n}\n\n/**\n * It removes the brackets from the end of a string\n *\n * @param {string} key - The key of the parameter.\n *\n * @returns {string} the key without the brackets.\n */\nfunction removeBrackets(key) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].endsWith(key, '[]') ? key.slice(0, -2) : key;\n}\n\n/**\n * It takes a path, a key, and a boolean, and returns a string\n *\n * @param {string} path - The path to the current key.\n * @param {string} key - The key of the current object being iterated over.\n * @param {string} dots - If true, the key will be rendered with dots instead of brackets.\n *\n * @returns {string} The path to the current key.\n */\nfunction renderKey(path, key, dots) {\n  if (!path) return key;\n  return path.concat(key).map(function each(token, i) {\n    // eslint-disable-next-line no-param-reassign\n    token = removeBrackets(token);\n    return !dots && i ? '[' + token + ']' : token;\n  }).join(dots ? '.' : '');\n}\n\n/**\n * If the array is an array and none of its elements are visitable, then it's a flat array.\n *\n * @param {Array<any>} arr - The array to check\n *\n * @returns {boolean}\n */\nfunction isFlatArray(arr) {\n  return _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(arr) && !arr.some(isVisitable);\n}\nconst predicates = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toFlatObject(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"], {}, null, function filter(prop) {\n  return /^is[A-Z]/.test(prop);\n});\n\n/**\n * If the thing is a FormData object, return true, otherwise return false.\n *\n * @param {unknown} thing - The thing to check.\n *\n * @returns {boolean}\n */\nfunction isSpecCompliant(thing) {\n  return thing && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(thing.append) && thing[Symbol.toStringTag] === 'FormData' && thing[Symbol.iterator];\n}\n\n/**\n * Convert a data object to FormData\n *\n * @param {Object} obj\n * @param {?Object} [formData]\n * @param {?Object} [options]\n * @param {Function} [options.visitor]\n * @param {Boolean} [options.metaTokens = true]\n * @param {Boolean} [options.dots = false]\n * @param {?Boolean} [options.indexes = false]\n *\n * @returns {Object}\n **/\n\n/**\n * It converts an object into a FormData object\n *\n * @param {Object<any, any>} obj - The object to convert to form data.\n * @param {string} formData - The FormData object to append to.\n * @param {Object<string, any>} options\n *\n * @returns\n */\nfunction toFormData(obj, formData, options) {\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(obj)) {\n    throw new TypeError('target must be an object');\n  }\n\n  // eslint-disable-next-line no-param-reassign\n  formData = formData || new (_env_classes_FormData_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"] || FormData)();\n\n  // eslint-disable-next-line no-param-reassign\n  options = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toFlatObject(options, {\n    metaTokens: true,\n    dots: false,\n    indexes: false\n  }, false, function defined(option, source) {\n    // eslint-disable-next-line no-eq-null,eqeqeq\n    return !_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(source[option]);\n  });\n  const metaTokens = options.metaTokens;\n  // eslint-disable-next-line no-use-before-define\n  const visitor = options.visitor || defaultVisitor;\n  const dots = options.dots;\n  const indexes = options.indexes;\n  const _Blob = options.Blob || typeof Blob !== 'undefined' && Blob;\n  const useBlob = _Blob && isSpecCompliant(formData);\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFunction(visitor)) {\n    throw new TypeError('visitor must be a function');\n  }\n  function convertValue(value) {\n    if (value === null) return '';\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isDate(value)) {\n      return value.toISOString();\n    }\n    if (!useBlob && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBlob(value)) {\n      throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('Blob is not supported. Use a Buffer instead.');\n    }\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArrayBuffer(value) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isTypedArray(value)) {\n      return useBlob && typeof Blob === 'function' ? new Blob([value]) : Buffer.from(value);\n    }\n    return value;\n  }\n\n  /**\n   * Default visitor.\n   *\n   * @param {*} value\n   * @param {String|Number} key\n   * @param {Array<String|Number>} path\n   * @this {FormData}\n   *\n   * @returns {boolean} return true to visit the each prop of the value recursively\n   */\n  function defaultVisitor(value, key, path) {\n    let arr = value;\n    if (value && !path && typeof value === 'object') {\n      if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].endsWith(key, '{}')) {\n        // eslint-disable-next-line no-param-reassign\n        key = metaTokens ? key : key.slice(0, -2);\n        // eslint-disable-next-line no-param-reassign\n        value = JSON.stringify(value);\n      } else if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isArray(value) && isFlatArray(value) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isFileList(value) || _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].endsWith(key, '[]') && (arr = _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].toArray(value))) {\n        // eslint-disable-next-line no-param-reassign\n        key = removeBrackets(key);\n        arr.forEach(function each(el, index) {\n          !(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(el) || el === null) && formData.append(\n          // eslint-disable-next-line no-nested-ternary\n          indexes === true ? renderKey([key], index, dots) : indexes === null ? key : key + '[]', convertValue(el));\n        });\n        return false;\n      }\n    }\n    if (isVisitable(value)) {\n      return true;\n    }\n    formData.append(renderKey(path, key, dots), convertValue(value));\n    return false;\n  }\n  const stack = [];\n  const exposedHelpers = Object.assign(predicates, {\n    defaultVisitor,\n    convertValue,\n    isVisitable\n  });\n  function build(value, path) {\n    if (_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(value)) return;\n    if (stack.indexOf(value) !== -1) {\n      throw Error('Circular reference detected in ' + path.join('.'));\n    }\n    stack.push(value);\n    _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].forEach(value, function each(el, key) {\n      const result = !(_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isUndefined(el) || el === null) && visitor.call(formData, el, _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isString(key) ? key.trim() : key, path, exposedHelpers);\n      if (result === true) {\n        build(el, path ? path.concat(key) : [key]);\n      }\n    });\n    stack.pop();\n  }\n  if (!_utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isObject(obj)) {\n    throw new TypeError('data must be an object');\n  }\n  build(obj);\n  return formData;\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toFormData);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/toFormData.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/toURLEncodedForm.js":
/*!************************************************************!*\
  !*** ./node_modules/axios/lib/helpers/toURLEncodedForm.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ toURLEncodedForm)\n/* harmony export */ });\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils.js */ \"./node_modules/axios/lib/utils.js\");\n/* harmony import */ var _toFormData_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./toFormData.js */ \"./node_modules/axios/lib/helpers/toFormData.js\");\n/* harmony import */ var _platform_index_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../platform/index.js */ \"./node_modules/axios/lib/platform/index.js\");\n\n\n\n\n\nfunction toURLEncodedForm(data, options) {\n  return (0,_toFormData_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(data, new _platform_index_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].classes.URLSearchParams(), Object.assign({\n    visitor: function (value, key, path, helpers) {\n      if (_platform_index_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].isNode && _utils_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isBuffer(value)) {\n        this.append(key, value.toString('base64'));\n        return false;\n      }\n      return helpers.defaultVisitor.apply(this, arguments);\n    }\n  }, options));\n}\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/toURLEncodedForm.js?");

/***/ }),

/***/ "./node_modules/axios/lib/helpers/validator.js":
/*!*****************************************************!*\
  !*** ./node_modules/axios/lib/helpers/validator.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _env_data_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../env/data.js */ \"./node_modules/axios/lib/env/data.js\");\n/* harmony import */ var _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/AxiosError.js */ \"./node_modules/axios/lib/core/AxiosError.js\");\n\n\n\n\nconst validators = {};\n\n// eslint-disable-next-line func-names\n['object', 'boolean', 'number', 'function', 'string', 'symbol'].forEach((type, i) => {\n  validators[type] = function validator(thing) {\n    return typeof thing === type || 'a' + (i < 1 ? 'n ' : ' ') + type;\n  };\n});\nconst deprecatedWarnings = {};\n\n/**\n * Transitional option validator\n *\n * @param {function|boolean?} validator - set to false if the transitional option has been removed\n * @param {string?} version - deprecated version / removed since version\n * @param {string?} message - some message with additional info\n *\n * @returns {function}\n */\nvalidators.transitional = function transitional(validator, version, message) {\n  function formatMessage(opt, desc) {\n    return '[Axios v' + _env_data_js__WEBPACK_IMPORTED_MODULE_0__.VERSION + '] Transitional option \\'' + opt + '\\'' + desc + (message ? '. ' + message : '');\n  }\n\n  // eslint-disable-next-line func-names\n  return (value, opt, opts) => {\n    if (validator === false) {\n      throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](formatMessage(opt, ' has been removed' + (version ? ' in ' + version : '')), _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_DEPRECATED);\n    }\n    if (version && !deprecatedWarnings[opt]) {\n      deprecatedWarnings[opt] = true;\n      // eslint-disable-next-line no-console\n      console.warn(formatMessage(opt, ' has been deprecated since v' + version + ' and will be removed in the near future'));\n    }\n    return validator ? validator(value, opt, opts) : true;\n  };\n};\n\n/**\n * Assert object's properties type\n *\n * @param {object} options\n * @param {object} schema\n * @param {boolean?} allowUnknown\n *\n * @returns {object}\n */\n\nfunction assertOptions(options, schema, allowUnknown) {\n  if (typeof options !== 'object') {\n    throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('options must be an object', _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_OPTION_VALUE);\n  }\n  const keys = Object.keys(options);\n  let i = keys.length;\n  while (i-- > 0) {\n    const opt = keys[i];\n    const validator = schema[opt];\n    if (validator) {\n      const value = options[opt];\n      const result = value === undefined || validator(value, opt, options);\n      if (result !== true) {\n        throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('option ' + opt + ' must be ' + result, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_OPTION_VALUE);\n      }\n      continue;\n    }\n    if (allowUnknown !== true) {\n      throw new _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]('Unknown option ' + opt, _core_AxiosError_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].ERR_BAD_OPTION);\n    }\n  }\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  assertOptions,\n  validators\n});\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/helpers/validator.js?");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/classes/FormData.js":
/*!*********************************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/classes/FormData.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FormData);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/platform/browser/classes/FormData.js?");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js":
/*!****************************************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../helpers/AxiosURLSearchParams.js */ \"./node_modules/axios/lib/helpers/AxiosURLSearchParams.js\");\n\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (typeof URLSearchParams !== 'undefined' ? URLSearchParams : _helpers_AxiosURLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]);\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js?");

/***/ }),

/***/ "./node_modules/axios/lib/platform/browser/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/axios/lib/platform/browser/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _classes_URLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./classes/URLSearchParams.js */ \"./node_modules/axios/lib/platform/browser/classes/URLSearchParams.js\");\n/* harmony import */ var _classes_FormData_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./classes/FormData.js */ \"./node_modules/axios/lib/platform/browser/classes/FormData.js\");\n\n\n\n/**\n * Determine if we're running in a standard browser environment\n *\n * This allows axios to run in a web worker, and react-native.\n * Both environments support XMLHttpRequest, but not fully standard globals.\n *\n * web workers:\n *  typeof window -> undefined\n *  typeof document -> undefined\n *\n * react-native:\n *  navigator.product -> 'ReactNative'\n * nativescript\n *  navigator.product -> 'NativeScript' or 'NS'\n *\n * @returns {boolean}\n */\nconst isStandardBrowserEnv = (() => {\n  let product;\n  if (typeof navigator !== 'undefined' && ((product = navigator.product) === 'ReactNative' || product === 'NativeScript' || product === 'NS')) {\n    return false;\n  }\n  return typeof window !== 'undefined' && typeof document !== 'undefined';\n})();\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  isBrowser: true,\n  classes: {\n    URLSearchParams: _classes_URLSearchParams_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n    FormData: _classes_FormData_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n    Blob\n  },\n  isStandardBrowserEnv,\n  protocols: ['http', 'https', 'file', 'blob', 'url', 'data']\n});\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/platform/browser/index.js?");

/***/ }),

/***/ "./node_modules/axios/lib/platform/index.js":
/*!**************************************************!*\
  !*** ./node_modules/axios/lib/platform/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* reexport safe */ _node_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _node_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./node/index.js */ \"./node_modules/axios/lib/platform/browser/index.js\");\n\n\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/platform/index.js?");

/***/ }),

/***/ "./node_modules/axios/lib/utils.js":
/*!*****************************************!*\
  !*** ./node_modules/axios/lib/utils.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _helpers_bind_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./helpers/bind.js */ \"./node_modules/axios/lib/helpers/bind.js\");\n\n\n\n\n// utils is a library of generic helper functions non-specific to axios\n\nconst {\n  toString\n} = Object.prototype;\nconst {\n  getPrototypeOf\n} = Object;\nconst kindOf = (cache => thing => {\n  const str = toString.call(thing);\n  return cache[str] || (cache[str] = str.slice(8, -1).toLowerCase());\n})(Object.create(null));\nconst kindOfTest = type => {\n  type = type.toLowerCase();\n  return thing => kindOf(thing) === type;\n};\nconst typeOfTest = type => thing => typeof thing === type;\n\n/**\n * Determine if a value is an Array\n *\n * @param {Object} val The value to test\n *\n * @returns {boolean} True if value is an Array, otherwise false\n */\nconst {\n  isArray\n} = Array;\n\n/**\n * Determine if a value is undefined\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if the value is undefined, otherwise false\n */\nconst isUndefined = typeOfTest('undefined');\n\n/**\n * Determine if a value is a Buffer\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Buffer, otherwise false\n */\nfunction isBuffer(val) {\n  return val !== null && !isUndefined(val) && val.constructor !== null && !isUndefined(val.constructor) && isFunction(val.constructor.isBuffer) && val.constructor.isBuffer(val);\n}\n\n/**\n * Determine if a value is an ArrayBuffer\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is an ArrayBuffer, otherwise false\n */\nconst isArrayBuffer = kindOfTest('ArrayBuffer');\n\n/**\n * Determine if a value is a view on an ArrayBuffer\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a view on an ArrayBuffer, otherwise false\n */\nfunction isArrayBufferView(val) {\n  let result;\n  if (typeof ArrayBuffer !== 'undefined' && ArrayBuffer.isView) {\n    result = ArrayBuffer.isView(val);\n  } else {\n    result = val && val.buffer && isArrayBuffer(val.buffer);\n  }\n  return result;\n}\n\n/**\n * Determine if a value is a String\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a String, otherwise false\n */\nconst isString = typeOfTest('string');\n\n/**\n * Determine if a value is a Function\n *\n * @param {*} val The value to test\n * @returns {boolean} True if value is a Function, otherwise false\n */\nconst isFunction = typeOfTest('function');\n\n/**\n * Determine if a value is a Number\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Number, otherwise false\n */\nconst isNumber = typeOfTest('number');\n\n/**\n * Determine if a value is an Object\n *\n * @param {*} thing The value to test\n *\n * @returns {boolean} True if value is an Object, otherwise false\n */\nconst isObject = thing => thing !== null && typeof thing === 'object';\n\n/**\n * Determine if a value is a Boolean\n *\n * @param {*} thing The value to test\n * @returns {boolean} True if value is a Boolean, otherwise false\n */\nconst isBoolean = thing => thing === true || thing === false;\n\n/**\n * Determine if a value is a plain Object\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a plain Object, otherwise false\n */\nconst isPlainObject = val => {\n  if (kindOf(val) !== 'object') {\n    return false;\n  }\n  const prototype = getPrototypeOf(val);\n  return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in val) && !(Symbol.iterator in val);\n};\n\n/**\n * Determine if a value is a Date\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Date, otherwise false\n */\nconst isDate = kindOfTest('Date');\n\n/**\n * Determine if a value is a File\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a File, otherwise false\n */\nconst isFile = kindOfTest('File');\n\n/**\n * Determine if a value is a Blob\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Blob, otherwise false\n */\nconst isBlob = kindOfTest('Blob');\n\n/**\n * Determine if a value is a FileList\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a File, otherwise false\n */\nconst isFileList = kindOfTest('FileList');\n\n/**\n * Determine if a value is a Stream\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a Stream, otherwise false\n */\nconst isStream = val => isObject(val) && isFunction(val.pipe);\n\n/**\n * Determine if a value is a FormData\n *\n * @param {*} thing The value to test\n *\n * @returns {boolean} True if value is an FormData, otherwise false\n */\nconst isFormData = thing => {\n  const pattern = '[object FormData]';\n  return thing && (typeof FormData === 'function' && thing instanceof FormData || toString.call(thing) === pattern || isFunction(thing.toString) && thing.toString() === pattern);\n};\n\n/**\n * Determine if a value is a URLSearchParams object\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a URLSearchParams object, otherwise false\n */\nconst isURLSearchParams = kindOfTest('URLSearchParams');\n\n/**\n * Trim excess whitespace off the beginning and end of a string\n *\n * @param {String} str The String to trim\n *\n * @returns {String} The String freed of excess whitespace\n */\nconst trim = str => str.trim ? str.trim() : str.replace(/^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g, '');\n\n/**\n * Iterate over an Array or an Object invoking a function for each item.\n *\n * If `obj` is an Array callback will be called passing\n * the value, index, and complete array for each item.\n *\n * If 'obj' is an Object callback will be called passing\n * the value, key, and complete object for each property.\n *\n * @param {Object|Array} obj The object to iterate\n * @param {Function} fn The callback to invoke for each item\n *\n * @param {Boolean} [allOwnKeys = false]\n * @returns {void}\n */\nfunction forEach(obj, fn) {\n  let {\n    allOwnKeys = false\n  } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n  // Don't bother if no value provided\n  if (obj === null || typeof obj === 'undefined') {\n    return;\n  }\n  let i;\n  let l;\n\n  // Force an array if not already something iterable\n  if (typeof obj !== 'object') {\n    /*eslint no-param-reassign:0*/\n    obj = [obj];\n  }\n  if (isArray(obj)) {\n    // Iterate over array values\n    for (i = 0, l = obj.length; i < l; i++) {\n      fn.call(null, obj[i], i, obj);\n    }\n  } else {\n    // Iterate over object keys\n    const keys = allOwnKeys ? Object.getOwnPropertyNames(obj) : Object.keys(obj);\n    const len = keys.length;\n    let key;\n    for (i = 0; i < len; i++) {\n      key = keys[i];\n      fn.call(null, obj[key], key, obj);\n    }\n  }\n}\n\n/**\n * Accepts varargs expecting each argument to be an object, then\n * immutably merges the properties of each object and returns result.\n *\n * When multiple objects contain the same key the later object in\n * the arguments list will take precedence.\n *\n * Example:\n *\n * ```js\n * var result = merge({foo: 123}, {foo: 456});\n * console.log(result.foo); // outputs 456\n * ```\n *\n * @param {Object} obj1 Object to merge\n *\n * @returns {Object} Result of all merge properties\n */\nfunction merge( /* obj1, obj2, obj3, ... */\n) {\n  const result = {};\n  const assignValue = (val, key) => {\n    if (isPlainObject(result[key]) && isPlainObject(val)) {\n      result[key] = merge(result[key], val);\n    } else if (isPlainObject(val)) {\n      result[key] = merge({}, val);\n    } else if (isArray(val)) {\n      result[key] = val.slice();\n    } else {\n      result[key] = val;\n    }\n  };\n  for (let i = 0, l = arguments.length; i < l; i++) {\n    arguments[i] && forEach(arguments[i], assignValue);\n  }\n  return result;\n}\n\n/**\n * Extends object a by mutably adding to it the properties of object b.\n *\n * @param {Object} a The object to be extended\n * @param {Object} b The object to copy properties from\n * @param {Object} thisArg The object to bind function to\n *\n * @param {Boolean} [allOwnKeys]\n * @returns {Object} The resulting value of object a\n */\nconst extend = function (a, b, thisArg) {\n  let {\n    allOwnKeys\n  } = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};\n  forEach(b, (val, key) => {\n    if (thisArg && isFunction(val)) {\n      a[key] = (0,_helpers_bind_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(val, thisArg);\n    } else {\n      a[key] = val;\n    }\n  }, {\n    allOwnKeys\n  });\n  return a;\n};\n\n/**\n * Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)\n *\n * @param {string} content with BOM\n *\n * @returns {string} content value without BOM\n */\nconst stripBOM = content => {\n  if (content.charCodeAt(0) === 0xFEFF) {\n    content = content.slice(1);\n  }\n  return content;\n};\n\n/**\n * Inherit the prototype methods from one constructor into another\n * @param {function} constructor\n * @param {function} superConstructor\n * @param {object} [props]\n * @param {object} [descriptors]\n *\n * @returns {void}\n */\nconst inherits = (constructor, superConstructor, props, descriptors) => {\n  constructor.prototype = Object.create(superConstructor.prototype, descriptors);\n  constructor.prototype.constructor = constructor;\n  Object.defineProperty(constructor, 'super', {\n    value: superConstructor.prototype\n  });\n  props && Object.assign(constructor.prototype, props);\n};\n\n/**\n * Resolve object with deep prototype chain to a flat object\n * @param {Object} sourceObj source object\n * @param {Object} [destObj]\n * @param {Function|Boolean} [filter]\n * @param {Function} [propFilter]\n *\n * @returns {Object}\n */\nconst toFlatObject = (sourceObj, destObj, filter, propFilter) => {\n  let props;\n  let i;\n  let prop;\n  const merged = {};\n  destObj = destObj || {};\n  // eslint-disable-next-line no-eq-null,eqeqeq\n  if (sourceObj == null) return destObj;\n  do {\n    props = Object.getOwnPropertyNames(sourceObj);\n    i = props.length;\n    while (i-- > 0) {\n      prop = props[i];\n      if ((!propFilter || propFilter(prop, sourceObj, destObj)) && !merged[prop]) {\n        destObj[prop] = sourceObj[prop];\n        merged[prop] = true;\n      }\n    }\n    sourceObj = filter !== false && getPrototypeOf(sourceObj);\n  } while (sourceObj && (!filter || filter(sourceObj, destObj)) && sourceObj !== Object.prototype);\n  return destObj;\n};\n\n/**\n * Determines whether a string ends with the characters of a specified string\n *\n * @param {String} str\n * @param {String} searchString\n * @param {Number} [position= 0]\n *\n * @returns {boolean}\n */\nconst endsWith = (str, searchString, position) => {\n  str = String(str);\n  if (position === undefined || position > str.length) {\n    position = str.length;\n  }\n  position -= searchString.length;\n  const lastIndex = str.indexOf(searchString, position);\n  return lastIndex !== -1 && lastIndex === position;\n};\n\n/**\n * Returns new array from array like object or null if failed\n *\n * @param {*} [thing]\n *\n * @returns {?Array}\n */\nconst toArray = thing => {\n  if (!thing) return null;\n  if (isArray(thing)) return thing;\n  let i = thing.length;\n  if (!isNumber(i)) return null;\n  const arr = new Array(i);\n  while (i-- > 0) {\n    arr[i] = thing[i];\n  }\n  return arr;\n};\n\n/**\n * Checking if the Uint8Array exists and if it does, it returns a function that checks if the\n * thing passed in is an instance of Uint8Array\n *\n * @param {TypedArray}\n *\n * @returns {Array}\n */\n// eslint-disable-next-line func-names\nconst isTypedArray = (TypedArray => {\n  // eslint-disable-next-line func-names\n  return thing => {\n    return TypedArray && thing instanceof TypedArray;\n  };\n})(typeof Uint8Array !== 'undefined' && getPrototypeOf(Uint8Array));\n\n/**\n * For each entry in the object, call the function with the key and value.\n *\n * @param {Object<any, any>} obj - The object to iterate over.\n * @param {Function} fn - The function to call for each entry.\n *\n * @returns {void}\n */\nconst forEachEntry = (obj, fn) => {\n  const generator = obj && obj[Symbol.iterator];\n  const iterator = generator.call(obj);\n  let result;\n  while ((result = iterator.next()) && !result.done) {\n    const pair = result.value;\n    fn.call(obj, pair[0], pair[1]);\n  }\n};\n\n/**\n * It takes a regular expression and a string, and returns an array of all the matches\n *\n * @param {string} regExp - The regular expression to match against.\n * @param {string} str - The string to search.\n *\n * @returns {Array<boolean>}\n */\nconst matchAll = (regExp, str) => {\n  let matches;\n  const arr = [];\n  while ((matches = regExp.exec(str)) !== null) {\n    arr.push(matches);\n  }\n  return arr;\n};\n\n/* Checking if the kindOfTest function returns true when passed an HTMLFormElement. */\nconst isHTMLForm = kindOfTest('HTMLFormElement');\nconst toCamelCase = str => {\n  return str.toLowerCase().replace(/[_-\\s]([a-z\\d])(\\w*)/g, function replacer(m, p1, p2) {\n    return p1.toUpperCase() + p2;\n  });\n};\n\n/* Creating a function that will check if an object has a property. */\nconst hasOwnProperty = (_ref => {\n  let {\n    hasOwnProperty\n  } = _ref;\n  return (obj, prop) => hasOwnProperty.call(obj, prop);\n})(Object.prototype);\n\n/**\n * Determine if a value is a RegExp object\n *\n * @param {*} val The value to test\n *\n * @returns {boolean} True if value is a RegExp object, otherwise false\n */\nconst isRegExp = kindOfTest('RegExp');\nconst reduceDescriptors = (obj, reducer) => {\n  const descriptors = Object.getOwnPropertyDescriptors(obj);\n  const reducedDescriptors = {};\n  forEach(descriptors, (descriptor, name) => {\n    if (reducer(descriptor, name, obj) !== false) {\n      reducedDescriptors[name] = descriptor;\n    }\n  });\n  Object.defineProperties(obj, reducedDescriptors);\n};\n\n/**\n * Makes all methods read-only\n * @param {Object} obj\n */\n\nconst freezeMethods = obj => {\n  reduceDescriptors(obj, (descriptor, name) => {\n    const value = obj[name];\n    if (!isFunction(value)) return;\n    descriptor.enumerable = false;\n    if ('writable' in descriptor) {\n      descriptor.writable = false;\n      return;\n    }\n    if (!descriptor.set) {\n      descriptor.set = () => {\n        throw Error('Can not read-only method \\'' + name + '\\'');\n      };\n    }\n  });\n};\nconst toObjectSet = (arrayOrString, delimiter) => {\n  const obj = {};\n  const define = arr => {\n    arr.forEach(value => {\n      obj[value] = true;\n    });\n  };\n  isArray(arrayOrString) ? define(arrayOrString) : define(String(arrayOrString).split(delimiter));\n  return obj;\n};\nconst noop = () => {};\nconst toFiniteNumber = (value, defaultValue) => {\n  value = +value;\n  return Number.isFinite(value) ? value : defaultValue;\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  isArray,\n  isArrayBuffer,\n  isBuffer,\n  isFormData,\n  isArrayBufferView,\n  isString,\n  isNumber,\n  isBoolean,\n  isObject,\n  isPlainObject,\n  isUndefined,\n  isDate,\n  isFile,\n  isBlob,\n  isRegExp,\n  isFunction,\n  isStream,\n  isURLSearchParams,\n  isTypedArray,\n  isFileList,\n  forEach,\n  merge,\n  extend,\n  trim,\n  stripBOM,\n  inherits,\n  toFlatObject,\n  kindOf,\n  kindOfTest,\n  endsWith,\n  toArray,\n  forEachEntry,\n  matchAll,\n  isHTMLForm,\n  hasOwnProperty,\n  hasOwnProp: hasOwnProperty,\n  // an alias to avoid ESLint no-prototype-builtins detection\n  reduceDescriptors,\n  freezeMethods,\n  toObjectSet,\n  toCamelCase,\n  noop,\n  toFiniteNumber\n});\n\n//# sourceURL=webpack://webrtctranslate/./node_modules/axios/lib/utils.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/public/js/app.js");
/******/ 	
/******/ })()
;